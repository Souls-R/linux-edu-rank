<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_19.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><span>[20]</span><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_21.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit dc12baacb95f205948f64dc936a47d89ee110117
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Apr 11 14:58:27 2018 -0400

    random: use a different mixing algorithm for add_device_randomness()
    
    add_device_randomness() use of crng_fast_load() was highly
    problematic.  Some callers of add_device_randomness() can pass in a
    large amount of static information.  This would immediately promote
    the crng_init state from 0 to 1, without really doing much to
    initialize the primary_crng's internal state with something even
    vaguely unpredictable.
    
    Since we don't have the speed constraints of add_interrupt_randomness(),
    we can do a better job mixing in the what unpredictability a device
    driver or architecture maintainer might see fit to give us, and do it
    in a way which does not bump the crng_init_cnt variable.
    
    Also, since add_device_randomness() doesn't bump any entropy
    accounting in crng_init state 0, mix the device randomness into the
    input_pool entropy pool as well.  This is related to CVE-2018-1108.
    
    Reported-by: Jann Horn &lt;jannh@google.com&gt;
    Fixes: ee7998c50c26 ("random: do not ignore early device randomness")
    Cc: stable@kernel.org # 4.13+
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index c8ec1e70abde..6baa828c0493 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -787,6 +787,10 @@ static void crng_initialize(struct crng_state *crng)
 	crng-&gt;init_time = jiffies - CRNG_RESEED_INTERVAL - 1;
 }
 
+/*
+ * crng_fast_load() can be called by code in the interrupt service
+ * path.  So we can't afford to dilly-dally.
+ */
 static int crng_fast_load(const char *cp, size_t len)
 {
 	unsigned long flags;
@@ -813,6 +817,51 @@ static int crng_fast_load(const char *cp, size_t len)
 	return 1;
 }
 
+/*
+ * crng_slow_load() is called by add_device_randomness, which has two
+ * attributes.  (1) We can't trust the buffer passed to it is
+ * guaranteed to be unpredictable (so it might not have any entropy at
+ * all), and (2) it doesn't have the performance constraints of
+ * crng_fast_load().
+ *
+ * So we do something more comprehensive which is guaranteed to touch
+ * all of the primary_crng's state, and which uses a LFSR with a
+ * period of 255 as part of the mixing algorithm.  Finally, we do
+ * *not* advance crng_init_cnt since buffer we may get may be something
+ * like a fixed DMI table (for example), which might very well be
+ * unique to the machine, but is otherwise unvarying.
+ */
+static int crng_slow_load(const char *cp, size_t len)
+{
+	unsigned long		flags;
+	static unsigned char	lfsr = 1;
+	unsigned char		tmp;
+	unsigned		i, max = CHACHA20_KEY_SIZE;
+	const char *		src_buf = cp;
+	char *			dest_buf = (char *) &amp;primary_crng.state[4];
+
+	if (!spin_trylock_irqsave(&amp;primary_crng.lock, flags))
+		return 0;
+	if (crng_init != 0) {
+		spin_unlock_irqrestore(&amp;primary_crng.lock, flags);
+		return 0;
+	}
+	if (len &gt; max)
+		max = len;
+
+	for (i = 0; i &lt; max ; i++) {
+		tmp = lfsr;
+		lfsr &gt;&gt;= 1;
+		if (tmp &amp; 1)
+			lfsr ^= 0xE1;
+		tmp = dest_buf[i % CHACHA20_KEY_SIZE];
+		dest_buf[i % CHACHA20_KEY_SIZE] ^= src_buf[i % len] ^ lfsr;
+		lfsr += (tmp &lt;&lt; 3) | (tmp &gt;&gt; 5);
+	}
+	spin_unlock_irqrestore(&amp;primary_crng.lock, flags);
+	return 1;
+}
+
 static void crng_reseed(struct crng_state *crng, struct entropy_store *r)
 {
 	unsigned long	flags;
@@ -981,10 +1030,8 @@ void add_device_randomness(const void *buf, unsigned int size)
 	unsigned long time = random_get_entropy() ^ jiffies;
 	unsigned long flags;
 
-	if (!crng_ready()) {
-		crng_fast_load(buf, size);
-		return;
-	}
+	if (!crng_ready() &amp;&amp; size)
+		crng_slow_load(buf, size);
 
 	trace_add_device_randomness(size, _RET_IP_);
 	spin_lock_irqsave(&amp;input_pool.lock, flags);</pre><hr><pre>commit 43838a23a05fbd13e47d750d3dfd77001536dd33
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Apr 11 13:27:52 2018 -0400

    random: fix crng_ready() test
    
    The crng_init variable has three states:
    
    0: The CRNG is not initialized at all
    1: The CRNG has a small amount of entropy, hopefully good enough for
       early-boot, non-cryptographical use cases
    2: The CRNG is fully initialized and we are sure it is safe for
       cryptographic use cases.
    
    The crng_ready() function should only return true once we are in the
    last state.  This addresses CVE-2018-1108.
    
    Reported-by: Jann Horn &lt;jannh@google.com&gt;
    Fixes: e192be9d9a30 ("random: replace non-blocking pool...")
    Cc: stable@kernel.org # 4.8+
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Reviewed-by: Jann Horn &lt;jannh@google.com&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index e027e7fa1472..c8ec1e70abde 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -427,7 +427,7 @@ struct crng_state primary_crng = {
  * its value (from 0-&gt;1-&gt;2).
  */
 static int crng_init = 0;
-#define crng_ready() (likely(crng_init &gt; 0))
+#define crng_ready() (likely(crng_init &gt; 1))
 static int crng_init_cnt = 0;
 #define CRNG_INIT_CNT_THRESH (2*CHACHA20_KEY_SIZE)
 static void _extract_crng(struct crng_state *crng,
@@ -794,7 +794,7 @@ static int crng_fast_load(const char *cp, size_t len)
 
 	if (!spin_trylock_irqsave(&amp;primary_crng.lock, flags))
 		return 0;
-	if (crng_ready()) {
+	if (crng_init != 0) {
 		spin_unlock_irqrestore(&amp;primary_crng.lock, flags);
 		return 0;
 	}
@@ -856,7 +856,7 @@ static void _extract_crng(struct crng_state *crng,
 {
 	unsigned long v, flags;
 
-	if (crng_init &gt; 1 &amp;&amp;
+	if (crng_ready() &amp;&amp;
 	    time_after(jiffies, crng-&gt;init_time + CRNG_RESEED_INTERVAL))
 		crng_reseed(crng, crng == &amp;primary_crng ? &amp;input_pool : NULL);
 	spin_lock_irqsave(&amp;crng-&gt;lock, flags);
@@ -1139,7 +1139,7 @@ void add_interrupt_randomness(int irq, int irq_flags)
 	fast_mix(fast_pool);
 	add_interrupt_bench(cycles);
 
-	if (!crng_ready()) {
+	if (unlikely(crng_init == 0)) {
 		if ((fast_pool-&gt;count &gt;= 64) &amp;&amp;
 		    crng_fast_load((char *) fast_pool-&gt;pool,
 				   sizeof(fast_pool-&gt;pool))) {
@@ -2212,7 +2212,7 @@ void add_hwgenerator_randomness(const char *buffer, size_t count,
 {
 	struct entropy_store *poolp = &amp;input_pool;
 
-	if (!crng_ready()) {
+	if (unlikely(crng_init == 0)) {
 		crng_fast_load(buffer, count);
 		return;
 	}</pre><hr><pre>commit e40ff213898502d299351cc2fe1e350cd186f0d3
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Apr 1 23:21:03 2018 -0400

    ext4: force revalidation of directory pointer after seekdir(2)
    
    A malicious user could force the directory pointer to be in an invalid
    spot by using seekdir(2).  Use the mechanism we already have to notice
    if the directory has changed since the last time we called
    ext4_readdir() to force a revalidation of the pointer.
    
    Reported-by: syzbot+1236ce66f79263e8a862@syzkaller.appspotmail.com
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/dir.c b/fs/ext4/dir.c
index da87cf757f7d..e2902d394f1b 100644
--- a/fs/ext4/dir.c
+++ b/fs/ext4/dir.c
@@ -365,13 +365,15 @@ static loff_t ext4_dir_llseek(struct file *file, loff_t offset, int whence)
 {
 	struct inode *inode = file-&gt;f_mapping-&gt;host;
 	int dx_dir = is_dx_dir(inode);
-	loff_t htree_max = ext4_get_htree_eof(file);
+	loff_t ret, htree_max = ext4_get_htree_eof(file);
 
 	if (likely(dx_dir))
-		return generic_file_llseek_size(file, offset, whence,
+		ret = generic_file_llseek_size(file, offset, whence,
 						    htree_max, htree_max);
 	else
-		return ext4_llseek(file, offset, whence);
+		ret = ext4_llseek(file, offset, whence);
+	file-&gt;f_version = inode_peek_iversion(inode) - 1;
+	return ret;
 }
 
 /*</pre><hr><pre>commit 54dd0e0a1b255f115f8647fc6fb93273251b01b9
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Mar 30 20:04:11 2018 -0400

    ext4: add extra checks to ext4_xattr_block_get()
    
    Add explicit checks in ext4_xattr_block_get() just in case the
    e_value_offs and e_value_size fields in the the xattr block are
    corrupted in memory after the buffer_verified bit is set on the xattr
    block.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@kernel.org

diff --git a/fs/ext4/xattr.c b/fs/ext4/xattr.c
index 6304e81bfe6a..499cb4b1fbd2 100644
--- a/fs/ext4/xattr.c
+++ b/fs/ext4/xattr.c
@@ -197,7 +197,7 @@ ext4_xattr_check_entries(struct ext4_xattr_entry *entry, void *end,
 	while (!IS_LAST_ENTRY(entry)) {
 		u32 size = le32_to_cpu(entry-&gt;e_value_size);
 
-		if (size &gt; INT_MAX)
+		if (size &gt; EXT4_XATTR_SIZE_MAX)
 			return -EFSCORRUPTED;
 
 		if (size != 0 &amp;&amp; entry-&gt;e_value_inum == 0) {
@@ -540,8 +540,10 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	if (error)
 		goto cleanup;
 	size = le32_to_cpu(entry-&gt;e_value_size);
+	error = -ERANGE;
+	if (unlikely(size &gt; EXT4_XATTR_SIZE_MAX))
+		goto cleanup;
 	if (buffer) {
-		error = -ERANGE;
 		if (size &gt; buffer_size)
 			goto cleanup;
 		if (entry-&gt;e_value_inum) {
@@ -550,8 +552,12 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 			if (error)
 				goto cleanup;
 		} else {
-			memcpy(buffer, bh-&gt;b_data +
-			       le16_to_cpu(entry-&gt;e_value_offs), size);
+			u16 offset = le16_to_cpu(entry-&gt;e_value_offs);
+			void *p = bh-&gt;b_data + offset;
+
+			if (unlikely(p + size &gt; end))
+				goto cleanup;
+			memcpy(buffer, p, size);
 		}
 	}
 	error = size;
@@ -589,8 +595,10 @@ ext4_xattr_ibody_get(struct inode *inode, int name_index, const char *name,
 	if (error)
 		goto cleanup;
 	size = le32_to_cpu(entry-&gt;e_value_size);
+	error = -ERANGE;
+	if (unlikely(size &gt; EXT4_XATTR_SIZE_MAX))
+		goto cleanup;
 	if (buffer) {
-		error = -ERANGE;
 		if (size &gt; buffer_size)
 			goto cleanup;
 		if (entry-&gt;e_value_inum) {
@@ -599,8 +607,12 @@ ext4_xattr_ibody_get(struct inode *inode, int name_index, const char *name,
 			if (error)
 				goto cleanup;
 		} else {
-			memcpy(buffer, (void *)IFIRST(header) +
-			       le16_to_cpu(entry-&gt;e_value_offs), size);
+			u16 offset = le16_to_cpu(entry-&gt;e_value_offs);
+			void *p = (void *)IFIRST(header) + offset;
+
+			if (unlikely(p + size &gt; end))
+				goto cleanup;
+			memcpy(buffer, p, size);
 		}
 	}
 	error = size;
diff --git a/fs/ext4/xattr.h b/fs/ext4/xattr.h
index dd54c4f995c8..f39cad2abe2a 100644
--- a/fs/ext4/xattr.h
+++ b/fs/ext4/xattr.h
@@ -70,6 +70,17 @@ struct ext4_xattr_entry {
 		EXT4_I(inode)-&gt;i_extra_isize))
 #define IFIRST(hdr) ((struct ext4_xattr_entry *)((hdr)+1))
 
+/*
+ * XATTR_SIZE_MAX is currently 64k, but for the purposes of checking
+ * for file system consistency errors, we use a somewhat bigger value.
+ * This allows XATTR_SIZE_MAX to grow in the future, but by using this
+ * instead of INT_MAX for certain consistency checks, we don't need to
+ * worry about arithmetic overflows.  (Actually XATTR_SIZE_MAX is
+ * defined in include/uapi/linux/limits.h, so changing it is going
+ * not going to be trivial....)
+ */
+#define EXT4_XATTR_SIZE_MAX (1 &lt;&lt; 24)
+
 /*
  * The minimum size of EA value when you start storing it in an external inode
  * size of block - size of header - size of 1 entry - 4 null bytes</pre><hr><pre>commit 9496005d6ca4cf8f5ee8f828165a8956872dc59d
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Mar 30 20:00:56 2018 -0400

    ext4: add bounds checking to ext4_xattr_find_entry()
    
    Add some paranoia checks to make sure we don't stray beyond the end of
    the valid memory region containing ext4 xattr entries while we are
    scanning for a match.
    
    Also rename the function to xattr_find_entry() since it is static and
    thus only used in fs/ext4/xattr.c
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@kernel.org

diff --git a/fs/ext4/xattr.c b/fs/ext4/xattr.c
index c030e41818ab..6304e81bfe6a 100644
--- a/fs/ext4/xattr.c
+++ b/fs/ext4/xattr.c
@@ -276,18 +276,22 @@ __xattr_check_inode(struct inode *inode, struct ext4_xattr_ibody_header *header,
 	__xattr_check_inode((inode), (header), (end), __func__, __LINE__)
 
 static int
-ext4_xattr_find_entry(struct ext4_xattr_entry **pentry, int name_index,
-		      const char *name, int sorted)
+xattr_find_entry(struct inode *inode, struct ext4_xattr_entry **pentry,
+		 void *end, int name_index, const char *name, int sorted)
 {
-	struct ext4_xattr_entry *entry;
+	struct ext4_xattr_entry *entry, *next;
 	size_t name_len;
 	int cmp = 1;
 
 	if (name == NULL)
 		return -EINVAL;
 	name_len = strlen(name);
-	entry = *pentry;
-	for (; !IS_LAST_ENTRY(entry); entry = EXT4_XATTR_NEXT(entry)) {
+	for (entry = *pentry; !IS_LAST_ENTRY(entry); entry = next) {
+		next = EXT4_XATTR_NEXT(entry);
+		if ((void *) next &gt;= end) {
+			EXT4_ERROR_INODE(inode, "corrupted xattr entries");
+			return -EFSCORRUPTED;
+		}
 		cmp = name_index - entry-&gt;e_name_index;
 		if (!cmp)
 			cmp = name_len - entry-&gt;e_name_len;
@@ -509,6 +513,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct buffer_head *bh = NULL;
 	struct ext4_xattr_entry *entry;
 	size_t size;
+	void *end;
 	int error;
 	struct mb_cache *ea_block_cache = EA_BLOCK_CACHE(inode);
 
@@ -530,7 +535,8 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 		goto cleanup;
 	ext4_xattr_block_cache_insert(ea_block_cache, bh);
 	entry = BFIRST(bh);
-	error = ext4_xattr_find_entry(&amp;entry, name_index, name, 1);
+	end = bh-&gt;b_data + bh-&gt;b_size;
+	error = xattr_find_entry(inode, &amp;entry, end, name_index, name, 1);
 	if (error)
 		goto cleanup;
 	size = le32_to_cpu(entry-&gt;e_value_size);
@@ -579,7 +585,7 @@ ext4_xattr_ibody_get(struct inode *inode, int name_index, const char *name,
 	if (error)
 		goto cleanup;
 	entry = IFIRST(header);
-	error = ext4_xattr_find_entry(&amp;entry, name_index, name, 0);
+	error = xattr_find_entry(inode, &amp;entry, end, name_index, name, 0);
 	if (error)
 		goto cleanup;
 	size = le32_to_cpu(entry-&gt;e_value_size);
@@ -1808,8 +1814,8 @@ ext4_xattr_block_find(struct inode *inode, struct ext4_xattr_info *i,
 		bs-&gt;s.first = BFIRST(bs-&gt;bh);
 		bs-&gt;s.end = bs-&gt;bh-&gt;b_data + bs-&gt;bh-&gt;b_size;
 		bs-&gt;s.here = bs-&gt;s.first;
-		error = ext4_xattr_find_entry(&amp;bs-&gt;s.here, i-&gt;name_index,
-					      i-&gt;name, 1);
+		error = xattr_find_entry(inode, &amp;bs-&gt;s.here, bs-&gt;s.end,
+					 i-&gt;name_index, i-&gt;name, 1);
 		if (error &amp;&amp; error != -ENODATA)
 			goto cleanup;
 		bs-&gt;s.not_found = error;
@@ -2168,8 +2174,8 @@ int ext4_xattr_ibody_find(struct inode *inode, struct ext4_xattr_info *i,
 		if (error)
 			return error;
 		/* Find the named attribute. */
-		error = ext4_xattr_find_entry(&amp;is-&gt;s.here, i-&gt;name_index,
-					      i-&gt;name, 0);
+		error = xattr_find_entry(inode, &amp;is-&gt;s.here, is-&gt;s.end,
+					 i-&gt;name_index, i-&gt;name, 0);
 		if (error &amp;&amp; error != -ENODATA)
 			return error;
 		is-&gt;s.not_found = error;</pre><hr><pre>commit de05ca8526796c7e9f7c7282b7f89a818af19818
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Mar 30 15:42:25 2018 -0400

    ext4: move call to ext4_error() into ext4_xattr_check_block()
    
    Refactor the call to EXT4_ERROR_INODE() into ext4_xattr_check_block().
    This simplifies the code, and fixes a problem where not all callers of
    ext4_xattr_check_block() were not resulting in ext4_error() getting
    called when the xattr block is corrupted.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/xattr.c b/fs/ext4/xattr.c
index 2077d87b09f2..c030e41818ab 100644
--- a/fs/ext4/xattr.c
+++ b/fs/ext4/xattr.c
@@ -225,25 +225,36 @@ ext4_xattr_check_entries(struct ext4_xattr_entry *entry, void *end,
 }
 
 static inline int
-ext4_xattr_check_block(struct inode *inode, struct buffer_head *bh)
+__ext4_xattr_check_block(struct inode *inode, struct buffer_head *bh,
+			 const char *function, unsigned int line)
 {
-	int error;
+	int error = -EFSCORRUPTED;
 
 	if (buffer_verified(bh))
 		return 0;
 
 	if (BHDR(bh)-&gt;h_magic != cpu_to_le32(EXT4_XATTR_MAGIC) ||
 	    BHDR(bh)-&gt;h_blocks != cpu_to_le32(1))
-		return -EFSCORRUPTED;
+		goto errout;
+	error = -EFSBADCRC;
 	if (!ext4_xattr_block_csum_verify(inode, bh))
-		return -EFSBADCRC;
+		goto errout;
 	error = ext4_xattr_check_entries(BFIRST(bh), bh-&gt;b_data + bh-&gt;b_size,
 					 bh-&gt;b_data);
-	if (!error)
+errout:
+	if (error)
+		__ext4_error_inode(inode, function, line, 0,
+				   "corrupted xattr block %llu",
+				   (unsigned long long) bh-&gt;b_blocknr);
+	else
 		set_buffer_verified(bh);
 	return error;
 }
 
+#define ext4_xattr_check_block(inode, bh) \
+	__ext4_xattr_check_block((inode), (bh),  __func__, __LINE__)
+
+
 static int
 __xattr_check_inode(struct inode *inode, struct ext4_xattr_ibody_header *header,
 			 void *end, const char *function, unsigned int line)
@@ -514,12 +525,9 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 		goto cleanup;
 	ea_bdebug(bh, "b_count=%d, refcount=%d",
 		atomic_read(&amp;(bh-&gt;b_count)), le32_to_cpu(BHDR(bh)-&gt;h_refcount));
-	if (ext4_xattr_check_block(inode, bh)) {
-		EXT4_ERROR_INODE(inode, "bad block %llu",
-				 EXT4_I(inode)-&gt;i_file_acl);
-		error = -EFSCORRUPTED;
+	error = ext4_xattr_check_block(inode, bh);
+	if (error)
 		goto cleanup;
-	}
 	ext4_xattr_block_cache_insert(ea_block_cache, bh);
 	entry = BFIRST(bh);
 	error = ext4_xattr_find_entry(&amp;entry, name_index, name, 1);
@@ -679,12 +687,9 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 		goto cleanup;
 	ea_bdebug(bh, "b_count=%d, refcount=%d",
 		atomic_read(&amp;(bh-&gt;b_count)), le32_to_cpu(BHDR(bh)-&gt;h_refcount));
-	if (ext4_xattr_check_block(inode, bh)) {
-		EXT4_ERROR_INODE(inode, "bad block %llu",
-				 EXT4_I(inode)-&gt;i_file_acl);
-		error = -EFSCORRUPTED;
+	error = ext4_xattr_check_block(inode, bh);
+	if (error)
 		goto cleanup;
-	}
 	ext4_xattr_block_cache_insert(EA_BLOCK_CACHE(inode), bh);
 	error = ext4_xattr_list_entries(dentry, BFIRST(bh), buffer, buffer_size);
 
@@ -811,10 +816,9 @@ int ext4_get_inode_usage(struct inode *inode, qsize_t *usage)
 			goto out;
 		}
 
-		if (ext4_xattr_check_block(inode, bh)) {
-			ret = -EFSCORRUPTED;
+		ret = ext4_xattr_check_block(inode, bh);
+		if (ret)
 			goto out;
-		}
 
 		for (entry = BFIRST(bh); !IS_LAST_ENTRY(entry);
 		     entry = EXT4_XATTR_NEXT(entry))
@@ -1796,12 +1800,9 @@ ext4_xattr_block_find(struct inode *inode, struct ext4_xattr_info *i,
 		ea_bdebug(bs-&gt;bh, "b_count=%d, refcount=%d",
 			atomic_read(&amp;(bs-&gt;bh-&gt;b_count)),
 			le32_to_cpu(BHDR(bs-&gt;bh)-&gt;h_refcount));
-		if (ext4_xattr_check_block(inode, bs-&gt;bh)) {
-			EXT4_ERROR_INODE(inode, "bad block %llu",
-					 EXT4_I(inode)-&gt;i_file_acl);
-			error = -EFSCORRUPTED;
+		error = ext4_xattr_check_block(inode, bs-&gt;bh);
+		if (error)
 			goto cleanup;
-		}
 		/* Find the named attribute. */
 		bs-&gt;s.base = BHDR(bs-&gt;bh);
 		bs-&gt;s.first = BFIRST(bs-&gt;bh);
@@ -2724,13 +2725,9 @@ int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,
 		error = -EIO;
 		if (!bh)
 			goto cleanup;
-		if (ext4_xattr_check_block(inode, bh)) {
-			EXT4_ERROR_INODE(inode, "bad block %llu",
-					 EXT4_I(inode)-&gt;i_file_acl);
-			error = -EFSCORRUPTED;
-			brelse(bh);
+		error = ext4_xattr_check_block(inode, bh);
+		if (error)
 			goto cleanup;
-		}
 		base = BHDR(bh);
 		end = bh-&gt;b_data + bh-&gt;b_size;
 		min_offs = end - base;
@@ -2887,11 +2884,8 @@ int ext4_xattr_delete_inode(handle_t *handle, struct inode *inode,
 			goto cleanup;
 		}
 		error = ext4_xattr_check_block(inode, bh);
-		if (error) {
-			EXT4_ERROR_INODE(inode, "bad block %llu (error %d)",
-					 EXT4_I(inode)-&gt;i_file_acl, error);
+		if (error)
 			goto cleanup;
-		}
 
 		if (ext4_has_feature_ea_inode(inode-&gt;i_sb)) {
 			for (entry = BFIRST(bh); !IS_LAST_ENTRY(entry);</pre><hr><pre>commit 18db4b4e6fc31eda838dd1c1296d67dbcb3dc957
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Thu Mar 29 22:10:35 2018 -0400

    ext4: don't allow r/w mounts if metadata blocks overlap the superblock
    
    If some metadata block, such as an allocation bitmap, overlaps the
    superblock, it's very likely that if the file system is mounted
    read/write, the results will not be pretty.  So disallow r/w mounts
    for file systems corrupted in this particular way.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 7cd022c344d1..edcfe6956eba 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -2335,6 +2335,8 @@ static int ext4_check_descriptors(struct super_block *sb,
 			ext4_msg(sb, KERN_ERR, "ext4_check_descriptors: "
 				 "Block bitmap for group %u overlaps "
 				 "superblock", i);
+			if (!sb_rdonly(sb))
+				return 0;
 		}
 		if (block_bitmap &lt; first_block || block_bitmap &gt; last_block) {
 			ext4_msg(sb, KERN_ERR, "ext4_check_descriptors: "
@@ -2347,6 +2349,8 @@ static int ext4_check_descriptors(struct super_block *sb,
 			ext4_msg(sb, KERN_ERR, "ext4_check_descriptors: "
 				 "Inode bitmap for group %u overlaps "
 				 "superblock", i);
+			if (!sb_rdonly(sb))
+				return 0;
 		}
 		if (inode_bitmap &lt; first_block || inode_bitmap &gt; last_block) {
 			ext4_msg(sb, KERN_ERR, "ext4_check_descriptors: "
@@ -2359,6 +2363,8 @@ static int ext4_check_descriptors(struct super_block *sb,
 			ext4_msg(sb, KERN_ERR, "ext4_check_descriptors: "
 				 "Inode table for group %u overlaps "
 				 "superblock", i);
+			if (!sb_rdonly(sb))
+				return 0;
 		}
 		if (inode_table &lt; first_block ||
 		    inode_table + sbi-&gt;s_itb_per_group - 1 &gt; last_block) {</pre><hr><pre>commit a45403b51582a87872927a3e0fc0a389c26867f1
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Thu Mar 29 22:10:31 2018 -0400

    ext4: always initialize the crc32c checksum driver
    
    The extended attribute code now uses the crc32c checksum for hashing
    purposes, so we should just always always initialize it.  We also want
    to prevent NULL pointer dereferences if one of the metadata checksum
    features is enabled after the file sytsem is originally mounted.
    
    This issue has been assigned CVE-2018-1094.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199183
    https://bugzilla.redhat.com/show_bug.cgi?id=1560788
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 9d1da40c1f62..7cd022c344d1 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -3492,15 +3492,12 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	}
 
 	/* Load the checksum driver */
-	if (ext4_has_feature_metadata_csum(sb) ||
-	    ext4_has_feature_ea_inode(sb)) {
-		sbi-&gt;s_chksum_driver = crypto_alloc_shash("crc32c", 0, 0);
-		if (IS_ERR(sbi-&gt;s_chksum_driver)) {
-			ext4_msg(sb, KERN_ERR, "Cannot load crc32c driver.");
-			ret = PTR_ERR(sbi-&gt;s_chksum_driver);
-			sbi-&gt;s_chksum_driver = NULL;
-			goto failed_mount;
-		}
+	sbi-&gt;s_chksum_driver = crypto_alloc_shash("crc32c", 0, 0);
+	if (IS_ERR(sbi-&gt;s_chksum_driver)) {
+		ext4_msg(sb, KERN_ERR, "Cannot load crc32c driver.");
+		ret = PTR_ERR(sbi-&gt;s_chksum_driver);
+		sbi-&gt;s_chksum_driver = NULL;
+		goto failed_mount;
 	}
 
 	/* Check superblock checksum */</pre><hr><pre>commit 8e4b5eae5decd9dfe5a4ee369c22028f90ab4c44
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Thu Mar 29 21:56:09 2018 -0400

    ext4: fail ext4_iget for root directory if unallocated
    
    If the root directory has an i_links_count of zero, then when the file
    system is mounted, then when ext4_fill_super() notices the problem and
    tries to call iput() the root directory in the error return path,
    ext4_evict_inode() will try to free the inode on disk, before all of
    the file system structures are set up, and this will result in an OOPS
    caused by a NULL pointer dereference.
    
    This issue has been assigned CVE-2018-1092.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199179
    https://bugzilla.redhat.com/show_bug.cgi?id=1560777
    
    Reported-by: Wen Xu &lt;wen.xu@gatech.edu&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 435965598cb8..18aa2ef963ad 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -4732,6 +4732,12 @@ struct inode *ext4_iget(struct super_block *sb, unsigned long ino)
 		goto bad_inode;
 	raw_inode = ext4_raw_inode(&amp;iloc);
 
+	if ((ino == EXT4_ROOT_INO) &amp;&amp; (raw_inode-&gt;i_links_count == 0)) {
+		EXT4_ERROR_INODE(inode, "root inode unallocated");
+		ret = -EFSCORRUPTED;
+		goto bad_inode;
+	}
+
 	if (EXT4_INODE_SIZE(inode-&gt;i_sb) &gt; EXT4_GOOD_OLD_INODE_SIZE) {
 		ei-&gt;i_extra_isize = le16_to_cpu(raw_inode-&gt;i_extra_isize);
 		if (EXT4_GOOD_OLD_INODE_SIZE + ei-&gt;i_extra_isize &gt;</pre><hr><pre>commit 7dac4a1726a9c64a517d595c40e95e2d0d135f6f
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Mar 26 23:54:10 2018 -0400

    ext4: add validity checks for bitmap block numbers
    
    An privileged attacker can cause a crash by mounting a crafted ext4
    image which triggers a out-of-bounds read in the function
    ext4_valid_block_bitmap() in fs/ext4/balloc.c.
    
    This issue has been assigned CVE-2018-1093.
    
    BugLink: https://bugzilla.kernel.org/show_bug.cgi?id=199181
    BugLink: https://bugzilla.redhat.com/show_bug.cgi?id=1560782
    Reported-by: Wen Xu &lt;wen.xu@gatech.edu&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/balloc.c b/fs/ext4/balloc.c
index f82c4966f4ce..a33d8fb1bf2a 100644
--- a/fs/ext4/balloc.c
+++ b/fs/ext4/balloc.c
@@ -338,20 +338,25 @@ static ext4_fsblk_t ext4_valid_block_bitmap(struct super_block *sb,
 	/* check whether block bitmap block number is set */
 	blk = ext4_block_bitmap(sb, desc);
 	offset = blk - group_first_block;
-	if (!ext4_test_bit(EXT4_B2C(sbi, offset), bh-&gt;b_data))
+	if (offset &lt; 0 || EXT4_B2C(sbi, offset) &gt;= sb-&gt;s_blocksize ||
+	    !ext4_test_bit(EXT4_B2C(sbi, offset), bh-&gt;b_data))
 		/* bad block bitmap */
 		return blk;
 
 	/* check whether the inode bitmap block number is set */
 	blk = ext4_inode_bitmap(sb, desc);
 	offset = blk - group_first_block;
-	if (!ext4_test_bit(EXT4_B2C(sbi, offset), bh-&gt;b_data))
+	if (offset &lt; 0 || EXT4_B2C(sbi, offset) &gt;= sb-&gt;s_blocksize ||
+	    !ext4_test_bit(EXT4_B2C(sbi, offset), bh-&gt;b_data))
 		/* bad block bitmap */
 		return blk;
 
 	/* check whether the inode table block number is set */
 	blk = ext4_inode_table(sb, desc);
 	offset = blk - group_first_block;
+	if (offset &lt; 0 || EXT4_B2C(sbi, offset) &gt;= sb-&gt;s_blocksize ||
+	    EXT4_B2C(sbi, offset + sbi-&gt;s_itb_per_group) &gt;= sb-&gt;s_blocksize)
+		return blk;
 	next_zero_bit = ext4_find_next_zero_bit(bh-&gt;b_data,
 			EXT4_B2C(sbi, offset + sbi-&gt;s_itb_per_group),
 			EXT4_B2C(sbi, offset));
@@ -417,6 +422,7 @@ struct buffer_head *
 ext4_read_block_bitmap_nowait(struct super_block *sb, ext4_group_t block_group)
 {
 	struct ext4_group_desc *desc;
+	struct ext4_sb_info *sbi = EXT4_SB(sb);
 	struct buffer_head *bh;
 	ext4_fsblk_t bitmap_blk;
 	int err;
@@ -425,6 +431,12 @@ ext4_read_block_bitmap_nowait(struct super_block *sb, ext4_group_t block_group)
 	if (!desc)
 		return ERR_PTR(-EFSCORRUPTED);
 	bitmap_blk = ext4_block_bitmap(sb, desc);
+	if ((bitmap_blk &lt;= le32_to_cpu(sbi-&gt;s_es-&gt;s_first_data_block)) ||
+	    (bitmap_blk &gt;= ext4_blocks_count(sbi-&gt;s_es))) {
+		ext4_error(sb, "Invalid block bitmap block %llu in "
+			   "block_group %u", bitmap_blk, block_group);
+		return ERR_PTR(-EFSCORRUPTED);
+	}
 	bh = sb_getblk(sb, bitmap_blk);
 	if (unlikely(!bh)) {
 		ext4_error(sb, "Cannot get buffer for block bitmap - "
diff --git a/fs/ext4/ialloc.c b/fs/ext4/ialloc.c
index 3fa93665b4a3..df92e3ec9913 100644
--- a/fs/ext4/ialloc.c
+++ b/fs/ext4/ialloc.c
@@ -122,6 +122,7 @@ static struct buffer_head *
 ext4_read_inode_bitmap(struct super_block *sb, ext4_group_t block_group)
 {
 	struct ext4_group_desc *desc;
+	struct ext4_sb_info *sbi = EXT4_SB(sb);
 	struct buffer_head *bh = NULL;
 	ext4_fsblk_t bitmap_blk;
 	int err;
@@ -131,6 +132,12 @@ ext4_read_inode_bitmap(struct super_block *sb, ext4_group_t block_group)
 		return ERR_PTR(-EFSCORRUPTED);
 
 	bitmap_blk = ext4_inode_bitmap(sb, desc);
+	if ((bitmap_blk &lt;= le32_to_cpu(sbi-&gt;s_es-&gt;s_first_data_block)) ||
+	    (bitmap_blk &gt;= ext4_blocks_count(sbi-&gt;s_es))) {
+		ext4_error(sb, "Invalid inode bitmap blk %llu in "
+			   "block_group %u", bitmap_blk, block_group);
+		return ERR_PTR(-EFSCORRUPTED);
+	}
 	bh = sb_getblk(sb, bitmap_blk);
 	if (unlikely(!bh)) {
 		ext4_error(sb, "Cannot read inode bitmap - "</pre>
    <div class="pagination">
        <a href='1_19.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><span>[20]</span><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_21.html'>Next&gt;&gt;</a>
    <div>
</body>
