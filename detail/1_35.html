<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_34.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><span>[35]</span><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_36.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit a2f4870697a5bcf4a87073ec6b32dd2928c1211d
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Mar 17 12:23:19 2015 -0400

    fs: make sure the timestamps for lazytime inodes eventually get written
    
    Jan Kara pointed out that if there is an inode which is constantly
    getting dirtied with I_DIRTY_PAGES, an inode with an updated timestamp
    will never be written since inode-&gt;dirtied_when is constantly getting
    updated.  We fix this by adding an extra field to the inode,
    dirtied_time_when, so inodes with a stale dirtytime can get detected
    and handled.
    
    In addition, if we have a dirtytime inode caused by an atime update,
    and there is no write activity on the file system, we need to have a
    secondary system to make sure these inodes get written out.  We do
    this by setting up a second delayed work structure which wakes up the
    CPU much more rarely compared to writeback_expire_centisecs.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Reviewed-by: Jan Kara &lt;jack@suse.cz&gt;

diff --git a/fs/fs-writeback.c b/fs/fs-writeback.c
index e907052eeadb..2cfcd74faf87 100644
--- a/fs/fs-writeback.c
+++ b/fs/fs-writeback.c
@@ -53,6 +53,18 @@ struct wb_writeback_work {
 	struct completion *done;	/* set if the caller waits */
 };
 
+/*
+ * If an inode is constantly having its pages dirtied, but then the
+ * updates stop dirtytime_expire_interval seconds in the past, it's
+ * possible for the worst case time between when an inode has its
+ * timestamps updated and when they finally get written out to be two
+ * dirtytime_expire_intervals.  We set the default to 12 hours (in
+ * seconds), which means most of the time inodes will have their
+ * timestamps written to disk after 12 hours, but in the worst case a
+ * few inodes might not their timestamps updated for 24 hours.
+ */
+unsigned int dirtytime_expire_interval = 12 * 60 * 60;
+
 /**
  * writeback_in_progress - determine whether there is writeback in progress
  * @bdi: the device's backing_dev_info structure.
@@ -275,8 +287,8 @@ static int move_expired_inodes(struct list_head *delaying_queue,
 
 	if ((flags &amp; EXPIRE_DIRTY_ATIME) == 0)
 		older_than_this = work-&gt;older_than_this;
-	else if ((work-&gt;reason == WB_REASON_SYNC) == 0) {
-		expire_time = jiffies - (HZ * 86400);
+	else if (!work-&gt;for_sync) {
+		expire_time = jiffies - (dirtytime_expire_interval * HZ);
 		older_than_this = &amp;expire_time;
 	}
 	while (!list_empty(delaying_queue)) {
@@ -458,6 +470,7 @@ static void requeue_inode(struct inode *inode, struct bdi_writeback *wb,
 		 */
 		redirty_tail(inode, wb);
 	} else if (inode-&gt;i_state &amp; I_DIRTY_TIME) {
+		inode-&gt;dirtied_when = jiffies;
 		list_move(&amp;inode-&gt;i_wb_list, &amp;wb-&gt;b_dirty_time);
 	} else {
 		/* The inode is clean. Remove from writeback lists. */
@@ -505,12 +518,17 @@ __writeback_single_inode(struct inode *inode, struct writeback_control *wbc)
 	spin_lock(&amp;inode-&gt;i_lock);
 
 	dirty = inode-&gt;i_state &amp; I_DIRTY;
-	if (((dirty &amp; (I_DIRTY_SYNC | I_DIRTY_DATASYNC)) &amp;&amp;
-	     (inode-&gt;i_state &amp; I_DIRTY_TIME)) ||
-	    (inode-&gt;i_state &amp; I_DIRTY_TIME_EXPIRED)) {
-		dirty |= I_DIRTY_TIME | I_DIRTY_TIME_EXPIRED;
-		trace_writeback_lazytime(inode);
-	}
+	if (inode-&gt;i_state &amp; I_DIRTY_TIME) {
+		if ((dirty &amp; (I_DIRTY_SYNC | I_DIRTY_DATASYNC)) ||
+		    unlikely(inode-&gt;i_state &amp; I_DIRTY_TIME_EXPIRED) ||
+		    unlikely(time_after(jiffies,
+					(inode-&gt;dirtied_time_when +
+					 dirtytime_expire_interval * HZ)))) {
+			dirty |= I_DIRTY_TIME | I_DIRTY_TIME_EXPIRED;
+			trace_writeback_lazytime(inode);
+		}
+	} else
+		inode-&gt;i_state &amp;= ~I_DIRTY_TIME_EXPIRED;
 	inode-&gt;i_state &amp;= ~dirty;
 
 	/*
@@ -1131,6 +1149,45 @@ void wakeup_flusher_threads(long nr_pages, enum wb_reason reason)
 	rcu_read_unlock();
 }
 
+/*
+ * Wake up bdi's periodically to make sure dirtytime inodes gets
+ * written back periodically.  We deliberately do *not* check the
+ * b_dirtytime list in wb_has_dirty_io(), since this would cause the
+ * kernel to be constantly waking up once there are any dirtytime
+ * inodes on the system.  So instead we define a separate delayed work
+ * function which gets called much more rarely.  (By default, only
+ * once every 12 hours.)
+ *
+ * If there is any other write activity going on in the file system,
+ * this function won't be necessary.  But if the only thing that has
+ * happened on the file system is a dirtytime inode caused by an atime
+ * update, we need this infrastructure below to make sure that inode
+ * eventually gets pushed out to disk.
+ */
+static void wakeup_dirtytime_writeback(struct work_struct *w);
+static DECLARE_DELAYED_WORK(dirtytime_work, wakeup_dirtytime_writeback);
+
+static void wakeup_dirtytime_writeback(struct work_struct *w)
+{
+	struct backing_dev_info *bdi;
+
+	rcu_read_lock();
+	list_for_each_entry_rcu(bdi, &amp;bdi_list, bdi_list) {
+		if (list_empty(&amp;bdi-&gt;wb.b_dirty_time))
+			continue;
+		bdi_wakeup_thread(bdi);
+	}
+	rcu_read_unlock();
+	schedule_delayed_work(&amp;dirtytime_work, dirtytime_expire_interval * HZ);
+}
+
+static int __init start_dirtytime_writeback(void)
+{
+	schedule_delayed_work(&amp;dirtytime_work, dirtytime_expire_interval * HZ);
+	return 0;
+}
+__initcall(start_dirtytime_writeback);
+
 static noinline void block_dump___mark_inode_dirty(struct inode *inode)
 {
 	if (inode-&gt;i_ino || strcmp(inode-&gt;i_sb-&gt;s_id, "bdev")) {
@@ -1269,8 +1326,13 @@ void __mark_inode_dirty(struct inode *inode, int flags)
 			}
 
 			inode-&gt;dirtied_when = jiffies;
-			list_move(&amp;inode-&gt;i_wb_list, dirtytime ?
-				  &amp;bdi-&gt;wb.b_dirty_time : &amp;bdi-&gt;wb.b_dirty);
+			if (dirtytime)
+				inode-&gt;dirtied_time_when = jiffies;
+			if (inode-&gt;i_state &amp; (I_DIRTY_INODE | I_DIRTY_PAGES))
+				list_move(&amp;inode-&gt;i_wb_list, &amp;bdi-&gt;wb.b_dirty);
+			else
+				list_move(&amp;inode-&gt;i_wb_list,
+					  &amp;bdi-&gt;wb.b_dirty_time);
 			spin_unlock(&amp;bdi-&gt;wb.list_lock);
 			trace_writeback_dirty_inode_enqueue(inode);
 
diff --git a/include/linux/fs.h b/include/linux/fs.h
index b4d71b5e1ff2..f4131e8ead74 100644
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@ -604,6 +604,7 @@ struct inode {
 	struct mutex		i_mutex;
 
 	unsigned long		dirtied_when;	/* jiffies of first dirtying */
+	unsigned long		dirtied_time_when;
 
 	struct hlist_node	i_hash;
 	struct list_head	i_wb_list;	/* backing dev IO list */</pre><hr><pre>commit a26f49926da938f47561f386be56a83dd37a496d
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Feb 2 00:37:02 2015 -0500

    ext4: add optimization for the lazytime mount option
    
    Add an optimization for the MS_LAZYTIME mount option so that we will
    opportunistically write out any inodes with the I_DIRTY_TIME flag set
    in a particular inode table block when we need to update some inode in
    that inode table block anyway.
    
    Also add some temporary code so that we can set the lazytime mount
    option without needing a modified /sbin/mount program which can set
    MS_LAZYTIME.  We can eventually make this go away once util-linux has
    added support.
    
    Google-Bug-Id: 18297052
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Signed-off-by: Al Viro &lt;viro@zeniv.linux.org.uk&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 628df5ba44a6..9193ea130dcb 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -4139,6 +4139,65 @@ static int ext4_inode_blocks_set(handle_t *handle,
 	return 0;
 }
 
+struct other_inode {
+	unsigned long		orig_ino;
+	struct ext4_inode	*raw_inode;
+};
+
+static int other_inode_match(struct inode * inode, unsigned long ino,
+			     void *data)
+{
+	struct other_inode *oi = (struct other_inode *) data;
+
+	if ((inode-&gt;i_ino != ino) ||
+	    (inode-&gt;i_state &amp; (I_FREEING | I_WILL_FREE | I_NEW |
+			       I_DIRTY_SYNC | I_DIRTY_DATASYNC)) ||
+	    ((inode-&gt;i_state &amp; I_DIRTY_TIME) == 0))
+		return 0;
+	spin_lock(&amp;inode-&gt;i_lock);
+	if (((inode-&gt;i_state &amp; (I_FREEING | I_WILL_FREE | I_NEW |
+				I_DIRTY_SYNC | I_DIRTY_DATASYNC)) == 0) &amp;&amp;
+	    (inode-&gt;i_state &amp; I_DIRTY_TIME)) {
+		struct ext4_inode_info	*ei = EXT4_I(inode);
+
+		inode-&gt;i_state &amp;= ~(I_DIRTY_TIME | I_DIRTY_TIME_EXPIRED);
+		spin_unlock(&amp;inode-&gt;i_lock);
+
+		spin_lock(&amp;ei-&gt;i_raw_lock);
+		EXT4_INODE_SET_XTIME(i_ctime, inode, oi-&gt;raw_inode);
+		EXT4_INODE_SET_XTIME(i_mtime, inode, oi-&gt;raw_inode);
+		EXT4_INODE_SET_XTIME(i_atime, inode, oi-&gt;raw_inode);
+		ext4_inode_csum_set(inode, oi-&gt;raw_inode, ei);
+		spin_unlock(&amp;ei-&gt;i_raw_lock);
+		trace_ext4_other_inode_update_time(inode, oi-&gt;orig_ino);
+		return -1;
+	}
+	spin_unlock(&amp;inode-&gt;i_lock);
+	return -1;
+}
+
+/*
+ * Opportunistically update the other time fields for other inodes in
+ * the same inode table block.
+ */
+static void ext4_update_other_inodes_time(struct super_block *sb,
+					  unsigned long orig_ino, char *buf)
+{
+	struct other_inode oi;
+	unsigned long ino;
+	int i, inodes_per_block = EXT4_SB(sb)-&gt;s_inodes_per_block;
+	int inode_size = EXT4_INODE_SIZE(sb);
+
+	oi.orig_ino = orig_ino;
+	ino = orig_ino &amp; ~(inodes_per_block - 1);
+	for (i = 0; i &lt; inodes_per_block; i++, ino++, buf += inode_size) {
+		if (ino == orig_ino)
+			continue;
+		oi.raw_inode = (struct ext4_inode *) buf;
+		(void) find_inode_nowait(sb, ino, other_inode_match, &amp;oi);
+	}
+}
+
 /*
  * Post the struct inode info into an on-disk inode location in the
  * buffer-cache.  This gobbles the caller's reference to the
@@ -4248,10 +4307,11 @@ static int ext4_do_update_inode(handle_t *handle,
 				cpu_to_le16(ei-&gt;i_extra_isize);
 		}
 	}
-
 	ext4_inode_csum_set(inode, raw_inode, ei);
-
 	spin_unlock(&amp;ei-&gt;i_raw_lock);
+	if (inode-&gt;i_sb-&gt;s_flags &amp; MS_LAZYTIME)
+		ext4_update_other_inodes_time(inode-&gt;i_sb, inode-&gt;i_ino,
+					      bh-&gt;b_data);
 
 	BUFFER_TRACE(bh, "call ext4_handle_dirty_metadata");
 	rc = ext4_handle_dirty_metadata(handle, NULL, bh);
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 74c5f53595fb..362b23c8497a 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -1139,6 +1139,7 @@ enum {
 	Opt_noquota, Opt_barrier, Opt_nobarrier, Opt_err,
 	Opt_usrquota, Opt_grpquota, Opt_i_version,
 	Opt_stripe, Opt_delalloc, Opt_nodelalloc, Opt_mblk_io_submit,
+	Opt_lazytime, Opt_nolazytime,
 	Opt_nomblk_io_submit, Opt_block_validity, Opt_noblock_validity,
 	Opt_inode_readahead_blks, Opt_journal_ioprio,
 	Opt_dioread_nolock, Opt_dioread_lock,
@@ -1202,6 +1203,8 @@ static const match_table_t tokens = {
 	{Opt_i_version, "i_version"},
 	{Opt_stripe, "stripe=%u"},
 	{Opt_delalloc, "delalloc"},
+	{Opt_lazytime, "lazytime"},
+	{Opt_nolazytime, "nolazytime"},
 	{Opt_nodelalloc, "nodelalloc"},
 	{Opt_removed, "mblk_io_submit"},
 	{Opt_removed, "nomblk_io_submit"},
@@ -1459,6 +1462,12 @@ static int handle_mount_opt(struct super_block *sb, char *opt, int token,
 	case Opt_i_version:
 		sb-&gt;s_flags |= MS_I_VERSION;
 		return 1;
+	case Opt_lazytime:
+		sb-&gt;s_flags |= MS_LAZYTIME;
+		return 1;
+	case Opt_nolazytime:
+		sb-&gt;s_flags &amp;= ~MS_LAZYTIME;
+		return 1;
 	}
 
 	for (m = ext4_mount_opts; m-&gt;token != Opt_err; m++)
@@ -5020,6 +5029,7 @@ static int ext4_remount(struct super_block *sb, int *flags, char *data)
 	}
 #endif
 
+	*flags = (*flags &amp; ~MS_LAZYTIME) | (sb-&gt;s_flags &amp; MS_LAZYTIME);
 	ext4_msg(sb, KERN_INFO, "re-mounted. Opts: %s", orig_data);
 	kfree(orig_data);
 	return 0;
diff --git a/include/trace/events/ext4.h b/include/trace/events/ext4.h
index 6cfb841fea7c..6e5abd6d38a2 100644
--- a/include/trace/events/ext4.h
+++ b/include/trace/events/ext4.h
@@ -73,6 +73,36 @@ struct extent_status;
 	{ FALLOC_FL_ZERO_RANGE,		"ZERO_RANGE"})
 
 
+TRACE_EVENT(ext4_other_inode_update_time,
+	TP_PROTO(struct inode *inode, ino_t orig_ino),
+
+	TP_ARGS(inode, orig_ino),
+
+	TP_STRUCT__entry(
+		__field(	dev_t,	dev			)
+		__field(	ino_t,	ino			)
+		__field(	ino_t,	orig_ino		)
+		__field(	uid_t,	uid			)
+		__field(	gid_t,	gid			)
+		__field(	__u16, mode			)
+	),
+
+	TP_fast_assign(
+		__entry-&gt;orig_ino = orig_ino;
+		__entry-&gt;dev	= inode-&gt;i_sb-&gt;s_dev;
+		__entry-&gt;ino	= inode-&gt;i_ino;
+		__entry-&gt;uid	= i_uid_read(inode);
+		__entry-&gt;gid	= i_gid_read(inode);
+		__entry-&gt;mode	= inode-&gt;i_mode;
+	),
+
+	TP_printk("dev %d,%d orig_ino %lu ino %lu mode 0%o uid %u gid %u",
+		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
+		  (unsigned long) __entry-&gt;orig_ino,
+		  (unsigned long) __entry-&gt;ino, __entry-&gt;mode,
+		  __entry-&gt;uid, __entry-&gt;gid)
+);
+
 TRACE_EVENT(ext4_free_inode,
 	TP_PROTO(struct inode *inode),
 </pre><hr><pre>commit fe032c422c5ba562ba9c2d316f55e258e03259c6
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Feb 2 00:37:01 2015 -0500

    vfs: add find_inode_nowait() function
    
    Add a new function find_inode_nowait() which is an even more general
    version of ilookup5_nowait().  It is designed for callers which need
    very fine grained control over when the function is allowed to block
    or increment the inode's reference count.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Signed-off-by: Al Viro &lt;viro@zeniv.linux.org.uk&gt;

diff --git a/fs/inode.c b/fs/inode.c
index 4feb85cc125f..740cba79c2b9 100644
--- a/fs/inode.c
+++ b/fs/inode.c
@@ -1284,6 +1284,56 @@ struct inode *ilookup(struct super_block *sb, unsigned long ino)
 }
 EXPORT_SYMBOL(ilookup);
 
+/**
+ * find_inode_nowait - find an inode in the inode cache
+ * @sb:		super block of file system to search
+ * @hashval:	hash value (usually inode number) to search for
+ * @match:	callback used for comparisons between inodes
+ * @data:	opaque data pointer to pass to @match
+ *
+ * Search for the inode specified by @hashval and @data in the inode
+ * cache, where the helper function @match will return 0 if the inode
+ * does not match, 1 if the inode does match, and -1 if the search
+ * should be stopped.  The @match function must be responsible for
+ * taking the i_lock spin_lock and checking i_state for an inode being
+ * freed or being initialized, and incrementing the reference count
+ * before returning 1.  It also must not sleep, since it is called with
+ * the inode_hash_lock spinlock held.
+ *
+ * This is a even more generalized version of ilookup5() when the
+ * function must never block --- find_inode() can block in
+ * __wait_on_freeing_inode() --- or when the caller can not increment
+ * the reference count because the resulting iput() might cause an
+ * inode eviction.  The tradeoff is that the @match funtion must be
+ * very carefully implemented.
+ */
+struct inode *find_inode_nowait(struct super_block *sb,
+				unsigned long hashval,
+				int (*match)(struct inode *, unsigned long,
+					     void *),
+				void *data)
+{
+	struct hlist_head *head = inode_hashtable + hash(sb, hashval);
+	struct inode *inode, *ret_inode = NULL;
+	int mval;
+
+	spin_lock(&amp;inode_hash_lock);
+	hlist_for_each_entry(inode, head, i_hash) {
+		if (inode-&gt;i_sb != sb)
+			continue;
+		mval = match(inode, hashval, data);
+		if (mval == 0)
+			continue;
+		if (mval == 1)
+			ret_inode = inode;
+		goto out;
+	}
+out:
+	spin_unlock(&amp;inode_hash_lock);
+	return ret_inode;
+}
+EXPORT_SYMBOL(find_inode_nowait);
+
 int insert_inode_locked(struct inode *inode)
 {
 	struct super_block *sb = inode-&gt;i_sb;
diff --git a/include/linux/fs.h b/include/linux/fs.h
index cd027ce2c705..5ea8b6e46a3d 100644
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@ -2441,6 +2441,11 @@ extern struct inode *ilookup(struct super_block *sb, unsigned long ino);
 
 extern struct inode * iget5_locked(struct super_block *, unsigned long, int (*test)(struct inode *, void *), int (*set)(struct inode *, void *), void *);
 extern struct inode * iget_locked(struct super_block *, unsigned long);
+extern struct inode *find_inode_nowait(struct super_block *,
+				       unsigned long,
+				       int (*match)(struct inode *,
+						    unsigned long, void *),
+				       void *data);
 extern int insert_inode_locked4(struct inode *, unsigned long, int (*test)(struct inode *, void *), void *);
 extern int insert_inode_locked(struct inode *);
 #ifdef CONFIG_DEBUG_LOCK_ALLOC</pre><hr><pre>commit 0ae45f63d4ef8d8eeec49c7d8b44a1775fff13e8
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Feb 2 00:37:00 2015 -0500

    vfs: add support for a lazytime mount option
    
    Add a new mount option which enables a new "lazytime" mode.  This mode
    causes atime, mtime, and ctime updates to only be made to the
    in-memory version of the inode.  The on-disk times will only get
    updated when (a) if the inode needs to be updated for some non-time
    related change, (b) if userspace calls fsync(), syncfs() or sync(), or
    (c) just before an undeleted inode is evicted from memory.
    
    This is OK according to POSIX because there are no guarantees after a
    crash unless userspace explicitly requests via a fsync(2) call.
    
    For workloads which feature a large number of random write to a
    preallocated file, the lazytime mount option significantly reduces
    writes to the inode table.  The repeated 4k writes to a single block
    will result in undesirable stress on flash devices and SMR disk
    drives.  Even on conventional HDD's, the repeated writes to the inode
    table block will trigger Adjacent Track Interference (ATI) remediation
    latencies, which very negatively impact long tail latencies --- which
    is a very big deal for web serving tiers (for example).
    
    Google-Bug-Id: 18297052
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Signed-off-by: Al Viro &lt;viro@zeniv.linux.org.uk&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 5653fa42930b..628df5ba44a6 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -4840,11 +4840,17 @@ int ext4_mark_inode_dirty(handle_t *handle, struct inode *inode)
  * If the inode is marked synchronous, we don't honour that here - doing
  * so would cause a commit on atime updates, which we don't bother doing.
  * We handle synchronous inodes at the highest possible level.
+ *
+ * If only the I_DIRTY_TIME flag is set, we can skip everything.  If
+ * I_DIRTY_TIME and I_DIRTY_SYNC is set, the only inode fields we need
+ * to copy into the on-disk inode structure are the timestamp files.
  */
 void ext4_dirty_inode(struct inode *inode, int flags)
 {
 	handle_t *handle;
 
+	if (flags == I_DIRTY_TIME)
+		return;
 	handle = ext4_journal_start(inode, EXT4_HT_INODE, 2);
 	if (IS_ERR(handle))
 		goto out;
diff --git a/fs/fs-writeback.c b/fs/fs-writeback.c
index 2d609a5fbfea..004686191354 100644
--- a/fs/fs-writeback.c
+++ b/fs/fs-writeback.c
@@ -247,14 +247,19 @@ static bool inode_dirtied_after(struct inode *inode, unsigned long t)
 	return ret;
 }
 
+#define EXPIRE_DIRTY_ATIME 0x0001
+
 /*
  * Move expired (dirtied before work-&gt;older_than_this) dirty inodes from
  * @delaying_queue to @dispatch_queue.
  */
 static int move_expired_inodes(struct list_head *delaying_queue,
 			       struct list_head *dispatch_queue,
+			       int flags,
 			       struct wb_writeback_work *work)
 {
+	unsigned long *older_than_this = NULL;
+	unsigned long expire_time;
 	LIST_HEAD(tmp);
 	struct list_head *pos, *node;
 	struct super_block *sb = NULL;
@@ -262,13 +267,21 @@ static int move_expired_inodes(struct list_head *delaying_queue,
 	int do_sb_sort = 0;
 	int moved = 0;
 
+	if ((flags &amp; EXPIRE_DIRTY_ATIME) == 0)
+		older_than_this = work-&gt;older_than_this;
+	else if ((work-&gt;reason == WB_REASON_SYNC) == 0) {
+		expire_time = jiffies - (HZ * 86400);
+		older_than_this = &amp;expire_time;
+	}
 	while (!list_empty(delaying_queue)) {
 		inode = wb_inode(delaying_queue-&gt;prev);
-		if (work-&gt;older_than_this &amp;&amp;
-		    inode_dirtied_after(inode, *work-&gt;older_than_this))
+		if (older_than_this &amp;&amp;
+		    inode_dirtied_after(inode, *older_than_this))
 			break;
 		list_move(&amp;inode-&gt;i_wb_list, &amp;tmp);
 		moved++;
+		if (flags &amp; EXPIRE_DIRTY_ATIME)
+			set_bit(__I_DIRTY_TIME_EXPIRED, &amp;inode-&gt;i_state);
 		if (sb_is_blkdev_sb(inode-&gt;i_sb))
 			continue;
 		if (sb &amp;&amp; sb != inode-&gt;i_sb)
@@ -309,9 +322,12 @@ static int move_expired_inodes(struct list_head *delaying_queue,
 static void queue_io(struct bdi_writeback *wb, struct wb_writeback_work *work)
 {
 	int moved;
+
 	assert_spin_locked(&amp;wb-&gt;list_lock);
 	list_splice_init(&amp;wb-&gt;b_more_io, &amp;wb-&gt;b_io);
-	moved = move_expired_inodes(&amp;wb-&gt;b_dirty, &amp;wb-&gt;b_io, work);
+	moved = move_expired_inodes(&amp;wb-&gt;b_dirty, &amp;wb-&gt;b_io, 0, work);
+	moved += move_expired_inodes(&amp;wb-&gt;b_dirty_time, &amp;wb-&gt;b_io,
+				     EXPIRE_DIRTY_ATIME, work);
 	trace_writeback_queue_io(wb, work, moved);
 }
 
@@ -435,6 +451,8 @@ static void requeue_inode(struct inode *inode, struct bdi_writeback *wb,
 		 * updates after data IO completion.
 		 */
 		redirty_tail(inode, wb);
+	} else if (inode-&gt;i_state &amp; I_DIRTY_TIME) {
+		list_move(&amp;inode-&gt;i_wb_list, &amp;wb-&gt;b_dirty_time);
 	} else {
 		/* The inode is clean. Remove from writeback lists. */
 		list_del_init(&amp;inode-&gt;i_wb_list);
@@ -481,7 +499,13 @@ __writeback_single_inode(struct inode *inode, struct writeback_control *wbc)
 	spin_lock(&amp;inode-&gt;i_lock);
 
 	dirty = inode-&gt;i_state &amp; I_DIRTY;
-	inode-&gt;i_state &amp;= ~I_DIRTY;
+	if (((dirty &amp; (I_DIRTY_SYNC | I_DIRTY_DATASYNC)) &amp;&amp;
+	     (inode-&gt;i_state &amp; I_DIRTY_TIME)) ||
+	    (inode-&gt;i_state &amp; I_DIRTY_TIME_EXPIRED)) {
+		dirty |= I_DIRTY_TIME | I_DIRTY_TIME_EXPIRED;
+		trace_writeback_lazytime(inode);
+	}
+	inode-&gt;i_state &amp;= ~dirty;
 
 	/*
 	 * Paired with smp_mb() in __mark_inode_dirty().  This allows
@@ -501,8 +525,10 @@ __writeback_single_inode(struct inode *inode, struct writeback_control *wbc)
 
 	spin_unlock(&amp;inode-&gt;i_lock);
 
+	if (dirty &amp; I_DIRTY_TIME)
+		mark_inode_dirty_sync(inode);
 	/* Don't write the inode if only I_DIRTY_PAGES was set */
-	if (dirty &amp; (I_DIRTY_SYNC | I_DIRTY_DATASYNC)) {
+	if (dirty &amp; ~I_DIRTY_PAGES) {
 		int err = write_inode(inode, wbc);
 		if (ret == 0)
 			ret = err;
@@ -550,7 +576,7 @@ writeback_single_inode(struct inode *inode, struct bdi_writeback *wb,
 	 * make sure inode is on some writeback list and leave it there unless
 	 * we have completely cleaned the inode.
 	 */
-	if (!(inode-&gt;i_state &amp; I_DIRTY) &amp;&amp;
+	if (!(inode-&gt;i_state &amp; I_DIRTY_ALL) &amp;&amp;
 	    (wbc-&gt;sync_mode != WB_SYNC_ALL ||
 	     !mapping_tagged(inode-&gt;i_mapping, PAGECACHE_TAG_WRITEBACK)))
 		goto out;
@@ -565,7 +591,7 @@ writeback_single_inode(struct inode *inode, struct bdi_writeback *wb,
 	 * If inode is clean, remove it from writeback lists. Otherwise don't
 	 * touch it. See comment above for explanation.
 	 */
-	if (!(inode-&gt;i_state &amp; I_DIRTY))
+	if (!(inode-&gt;i_state &amp; I_DIRTY_ALL))
 		list_del_init(&amp;inode-&gt;i_wb_list);
 	spin_unlock(&amp;wb-&gt;list_lock);
 	inode_sync_complete(inode);
@@ -707,7 +733,7 @@ static long writeback_sb_inodes(struct super_block *sb,
 		wrote += write_chunk - wbc.nr_to_write;
 		spin_lock(&amp;wb-&gt;list_lock);
 		spin_lock(&amp;inode-&gt;i_lock);
-		if (!(inode-&gt;i_state &amp; I_DIRTY))
+		if (!(inode-&gt;i_state &amp; I_DIRTY_ALL))
 			wrote++;
 		requeue_inode(inode, wb, &amp;wbc);
 		inode_sync_complete(inode);
@@ -1145,16 +1171,20 @@ static noinline void block_dump___mark_inode_dirty(struct inode *inode)
  * page-&gt;mapping-&gt;host, so the page-dirtying time is recorded in the internal
  * blockdev inode.
  */
+#define I_DIRTY_INODE (I_DIRTY_SYNC | I_DIRTY_DATASYNC)
 void __mark_inode_dirty(struct inode *inode, int flags)
 {
 	struct super_block *sb = inode-&gt;i_sb;
 	struct backing_dev_info *bdi = NULL;
+	int dirtytime;
+
+	trace_writeback_mark_inode_dirty(inode, flags);
 
 	/*
 	 * Don't do this for I_DIRTY_PAGES - that doesn't actually
 	 * dirty the inode itself
 	 */
-	if (flags &amp; (I_DIRTY_SYNC | I_DIRTY_DATASYNC)) {
+	if (flags &amp; (I_DIRTY_SYNC | I_DIRTY_DATASYNC | I_DIRTY_TIME)) {
 		trace_writeback_dirty_inode_start(inode, flags);
 
 		if (sb-&gt;s_op-&gt;dirty_inode)
@@ -1162,6 +1192,9 @@ void __mark_inode_dirty(struct inode *inode, int flags)
 
 		trace_writeback_dirty_inode(inode, flags);
 	}
+	if (flags &amp; I_DIRTY_INODE)
+		flags &amp;= ~I_DIRTY_TIME;
+	dirtytime = flags &amp; I_DIRTY_TIME;
 
 	/*
 	 * Paired with smp_mb() in __writeback_single_inode() for the
@@ -1169,16 +1202,21 @@ void __mark_inode_dirty(struct inode *inode, int flags)
 	 */
 	smp_mb();
 
-	if ((inode-&gt;i_state &amp; flags) == flags)
+	if (((inode-&gt;i_state &amp; flags) == flags) ||
+	    (dirtytime &amp;&amp; (inode-&gt;i_state &amp; I_DIRTY_INODE)))
 		return;
 
 	if (unlikely(block_dump))
 		block_dump___mark_inode_dirty(inode);
 
 	spin_lock(&amp;inode-&gt;i_lock);
+	if (dirtytime &amp;&amp; (inode-&gt;i_state &amp; I_DIRTY_INODE))
+		goto out_unlock_inode;
 	if ((inode-&gt;i_state &amp; flags) != flags) {
 		const int was_dirty = inode-&gt;i_state &amp; I_DIRTY;
 
+		if (flags &amp; I_DIRTY_INODE)
+			inode-&gt;i_state &amp;= ~I_DIRTY_TIME;
 		inode-&gt;i_state |= flags;
 
 		/*
@@ -1225,8 +1263,10 @@ void __mark_inode_dirty(struct inode *inode, int flags)
 			}
 
 			inode-&gt;dirtied_when = jiffies;
-			list_move(&amp;inode-&gt;i_wb_list, &amp;bdi-&gt;wb.b_dirty);
+			list_move(&amp;inode-&gt;i_wb_list, dirtytime ?
+				  &amp;bdi-&gt;wb.b_dirty_time : &amp;bdi-&gt;wb.b_dirty);
 			spin_unlock(&amp;bdi-&gt;wb.list_lock);
+			trace_writeback_dirty_inode_enqueue(inode);
 
 			if (wakeup_bdi)
 				bdi_wakeup_thread_delayed(bdi);
diff --git a/fs/gfs2/file.c b/fs/gfs2/file.c
index 6e600abf694a..15c44cf457cc 100644
--- a/fs/gfs2/file.c
+++ b/fs/gfs2/file.c
@@ -655,7 +655,7 @@ static int gfs2_fsync(struct file *file, loff_t start, loff_t end,
 {
 	struct address_space *mapping = file-&gt;f_mapping;
 	struct inode *inode = mapping-&gt;host;
-	int sync_state = inode-&gt;i_state &amp; I_DIRTY;
+	int sync_state = inode-&gt;i_state &amp; I_DIRTY_ALL;
 	struct gfs2_inode *ip = GFS2_I(inode);
 	int ret = 0, ret1 = 0;
 
@@ -668,7 +668,7 @@ static int gfs2_fsync(struct file *file, loff_t start, loff_t end,
 	if (!gfs2_is_jdata(ip))
 		sync_state &amp;= ~I_DIRTY_PAGES;
 	if (datasync)
-		sync_state &amp;= ~I_DIRTY_SYNC;
+		sync_state &amp;= ~(I_DIRTY_SYNC | I_DIRTY_TIME);
 
 	if (sync_state) {
 		ret = sync_inode_metadata(inode, 1);
diff --git a/fs/inode.c b/fs/inode.c
index aa149e7262ac..4feb85cc125f 100644
--- a/fs/inode.c
+++ b/fs/inode.c
@@ -18,6 +18,7 @@
 #include &lt;linux/buffer_head.h&gt; /* for inode_has_buffers */
 #include &lt;linux/ratelimit.h&gt;
 #include &lt;linux/list_lru.h&gt;
+#include &lt;trace/events/writeback.h&gt;
 #include "internal.h"
 
 /*
@@ -30,7 +31,7 @@
  * inode_sb_list_lock protects:
  *   sb-&gt;s_inodes, inode-&gt;i_sb_list
  * bdi-&gt;wb.list_lock protects:
- *   bdi-&gt;wb.b_{dirty,io,more_io}, inode-&gt;i_wb_list
+ *   bdi-&gt;wb.b_{dirty,io,more_io,dirty_time}, inode-&gt;i_wb_list
  * inode_hash_lock protects:
  *   inode_hashtable, inode-&gt;i_hash
  *
@@ -416,7 +417,8 @@ static void inode_lru_list_add(struct inode *inode)
  */
 void inode_add_lru(struct inode *inode)
 {
-	if (!(inode-&gt;i_state &amp; (I_DIRTY | I_SYNC | I_FREEING | I_WILL_FREE)) &amp;&amp;
+	if (!(inode-&gt;i_state &amp; (I_DIRTY_ALL | I_SYNC |
+				I_FREEING | I_WILL_FREE)) &amp;&amp;
 	    !atomic_read(&amp;inode-&gt;i_count) &amp;&amp; inode-&gt;i_sb-&gt;s_flags &amp; MS_ACTIVE)
 		inode_lru_list_add(inode);
 }
@@ -647,7 +649,7 @@ int invalidate_inodes(struct super_block *sb, bool kill_dirty)
 			spin_unlock(&amp;inode-&gt;i_lock);
 			continue;
 		}
-		if (inode-&gt;i_state &amp; I_DIRTY &amp;&amp; !kill_dirty) {
+		if (inode-&gt;i_state &amp; I_DIRTY_ALL &amp;&amp; !kill_dirty) {
 			spin_unlock(&amp;inode-&gt;i_lock);
 			busy = 1;
 			continue;
@@ -1432,11 +1434,20 @@ static void iput_final(struct inode *inode)
  */
 void iput(struct inode *inode)
 {
-	if (inode) {
-		BUG_ON(inode-&gt;i_state &amp; I_CLEAR);
-
-		if (atomic_dec_and_lock(&amp;inode-&gt;i_count, &amp;inode-&gt;i_lock))
-			iput_final(inode);
+	if (!inode)
+		return;
+	BUG_ON(inode-&gt;i_state &amp; I_CLEAR);
+retry:
+	if (atomic_dec_and_lock(&amp;inode-&gt;i_count, &amp;inode-&gt;i_lock)) {
+		if (inode-&gt;i_nlink &amp;&amp; (inode-&gt;i_state &amp; I_DIRTY_TIME)) {
+			atomic_inc(&amp;inode-&gt;i_count);
+			inode-&gt;i_state &amp;= ~I_DIRTY_TIME;
+			spin_unlock(&amp;inode-&gt;i_lock);
+			trace_writeback_lazytime_iput(inode);
+			mark_inode_dirty_sync(inode);
+			goto retry;
+		}
+		iput_final(inode);
 	}
 }
 EXPORT_SYMBOL(iput);
@@ -1495,14 +1506,9 @@ static int relatime_need_update(struct vfsmount *mnt, struct inode *inode,
 	return 0;
 }
 
-/*
- * This does the actual work of updating an inodes time or version.  Must have
- * had called mnt_want_write() before calling this.
- */
-static int update_time(struct inode *inode, struct timespec *time, int flags)
+int generic_update_time(struct inode *inode, struct timespec *time, int flags)
 {
-	if (inode-&gt;i_op-&gt;update_time)
-		return inode-&gt;i_op-&gt;update_time(inode, time, flags);
+	int iflags = I_DIRTY_TIME;
 
 	if (flags &amp; S_ATIME)
 		inode-&gt;i_atime = *time;
@@ -1512,9 +1518,27 @@ static int update_time(struct inode *inode, struct timespec *time, int flags)
 		inode-&gt;i_ctime = *time;
 	if (flags &amp; S_MTIME)
 		inode-&gt;i_mtime = *time;
-	mark_inode_dirty_sync(inode);
+
+	if (!(inode-&gt;i_sb-&gt;s_flags &amp; MS_LAZYTIME) || (flags &amp; S_VERSION))
+		iflags |= I_DIRTY_SYNC;
+	__mark_inode_dirty(inode, iflags);
 	return 0;
 }
+EXPORT_SYMBOL(generic_update_time);
+
+/*
+ * This does the actual work of updating an inodes time or version.  Must have
+ * had called mnt_want_write() before calling this.
+ */
+static int update_time(struct inode *inode, struct timespec *time, int flags)
+{
+	int (*update_time)(struct inode *, struct timespec *, int);
+
+	update_time = inode-&gt;i_op-&gt;update_time ? inode-&gt;i_op-&gt;update_time :
+		generic_update_time;
+
+	return update_time(inode, time, flags);
+}
 
 /**
  *	touch_atime	-	update the access time
diff --git a/fs/jfs/file.c b/fs/jfs/file.c
index 33aa0cc1f8b8..10815f8dfd8b 100644
--- a/fs/jfs/file.c
+++ b/fs/jfs/file.c
@@ -39,7 +39,7 @@ int jfs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 		return rc;
 
 	mutex_lock(&amp;inode-&gt;i_mutex);
-	if (!(inode-&gt;i_state &amp; I_DIRTY) ||
+	if (!(inode-&gt;i_state &amp; I_DIRTY_ALL) ||
 	    (datasync &amp;&amp; !(inode-&gt;i_state &amp; I_DIRTY_DATASYNC))) {
 		/* Make sure committed changes hit the disk */
 		jfs_flush_journal(JFS_SBI(inode-&gt;i_sb)-&gt;log, 1);
diff --git a/fs/libfs.c b/fs/libfs.c
index 005843ce5dbd..b2ffdb045be4 100644
--- a/fs/libfs.c
+++ b/fs/libfs.c
@@ -948,7 +948,7 @@ int __generic_file_fsync(struct file *file, loff_t start, loff_t end,
 
 	mutex_lock(&amp;inode-&gt;i_mutex);
 	ret = sync_mapping_buffers(inode-&gt;i_mapping);
-	if (!(inode-&gt;i_state &amp; I_DIRTY))
+	if (!(inode-&gt;i_state &amp; I_DIRTY_ALL))
 		goto out;
 	if (datasync &amp;&amp; !(inode-&gt;i_state &amp; I_DIRTY_DATASYNC))
 		goto out;
diff --git a/fs/proc_namespace.c b/fs/proc_namespace.c
index 0f96f71ab32b..8db932da4009 100644
--- a/fs/proc_namespace.c
+++ b/fs/proc_namespace.c
@@ -44,6 +44,7 @@ static int show_sb_opts(struct seq_file *m, struct super_block *sb)
 		{ MS_SYNCHRONOUS, ",sync" },
 		{ MS_DIRSYNC, ",dirsync" },
 		{ MS_MANDLOCK, ",mand" },
+		{ MS_LAZYTIME, ",lazytime" },
 		{ 0, NULL }
 	};
 	const struct proc_fs_info *fs_infop;
diff --git a/fs/sync.c b/fs/sync.c
index 01d9f18a70b5..fbc98ee62044 100644
--- a/fs/sync.c
+++ b/fs/sync.c
@@ -177,8 +177,16 @@ SYSCALL_DEFINE1(syncfs, int, fd)
  */
 int vfs_fsync_range(struct file *file, loff_t start, loff_t end, int datasync)
 {
+	struct inode *inode = file-&gt;f_mapping-&gt;host;
+
 	if (!file-&gt;f_op-&gt;fsync)
 		return -EINVAL;
+	if (!datasync &amp;&amp; (inode-&gt;i_state &amp; I_DIRTY_TIME)) {
+		spin_lock(&amp;inode-&gt;i_lock);
+		inode-&gt;i_state &amp;= ~I_DIRTY_TIME;
+		spin_unlock(&amp;inode-&gt;i_lock);
+		mark_inode_dirty_sync(inode);
+	}
 	return file-&gt;f_op-&gt;fsync(file, start, end, datasync);
 }
 EXPORT_SYMBOL(vfs_fsync_range);
diff --git a/include/linux/backing-dev.h b/include/linux/backing-dev.h
index 5da6012b7a14..4cdf7336f64a 100644
--- a/include/linux/backing-dev.h
+++ b/include/linux/backing-dev.h
@@ -55,6 +55,7 @@ struct bdi_writeback {
 	struct list_head b_dirty;	/* dirty inodes */
 	struct list_head b_io;		/* parked for writeback */
 	struct list_head b_more_io;	/* parked for more writeback */
+	struct list_head b_dirty_time;	/* time stamps are dirty */
 	spinlock_t list_lock;		/* protects the b_* lists */
 };
 
diff --git a/include/linux/fs.h b/include/linux/fs.h
index 42efe13077b6..cd027ce2c705 100644
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@ -1746,8 +1746,12 @@ struct super_operations {
 #define __I_DIO_WAKEUP		9
 #define I_DIO_WAKEUP		(1 &lt;&lt; I_DIO_WAKEUP)
 #define I_LINKABLE		(1 &lt;&lt; 10)
+#define I_DIRTY_TIME		(1 &lt;&lt; 11)
+#define __I_DIRTY_TIME_EXPIRED	12
+#define I_DIRTY_TIME_EXPIRED	(1 &lt;&lt; __I_DIRTY_TIME_EXPIRED)
 
 #define I_DIRTY (I_DIRTY_SYNC | I_DIRTY_DATASYNC | I_DIRTY_PAGES)
+#define I_DIRTY_ALL (I_DIRTY | I_DIRTY_TIME)
 
 extern void __mark_inode_dirty(struct inode *, int);
 static inline void mark_inode_dirty(struct inode *inode)
@@ -1910,6 +1914,7 @@ extern int current_umask(void);
 
 extern void ihold(struct inode * inode);
 extern void iput(struct inode *);
+extern int generic_update_time(struct inode *, struct timespec *, int);
 
 static inline struct inode *file_inode(const struct file *f)
 {
diff --git a/include/trace/events/writeback.h b/include/trace/events/writeback.h
index cee02d65ab3f..5ecb4c234625 100644
--- a/include/trace/events/writeback.h
+++ b/include/trace/events/writeback.h
@@ -18,6 +18,8 @@
 		{I_FREEING,		"I_FREEING"},		\
 		{I_CLEAR,		"I_CLEAR"},		\
 		{I_SYNC,		"I_SYNC"},		\
+		{I_DIRTY_TIME,		"I_DIRTY_TIME"},	\
+		{I_DIRTY_TIME_EXPIRED,	"I_DIRTY_TIME_EXPIRED"}, \
 		{I_REFERENCED,		"I_REFERENCED"}		\
 	)
 
@@ -68,6 +70,7 @@ DECLARE_EVENT_CLASS(writeback_dirty_inode_template,
 	TP_STRUCT__entry (
 		__array(char, name, 32)
 		__field(unsigned long, ino)
+		__field(unsigned long, state)
 		__field(unsigned long, flags)
 	),
 
@@ -78,16 +81,25 @@ DECLARE_EVENT_CLASS(writeback_dirty_inode_template,
 		strncpy(__entry-&gt;name,
 			bdi-&gt;dev ? dev_name(bdi-&gt;dev) : "(unknown)", 32);
 		__entry-&gt;ino		= inode-&gt;i_ino;
+		__entry-&gt;state		= inode-&gt;i_state;
 		__entry-&gt;flags		= flags;
 	),
 
-	TP_printk("bdi %s: ino=%lu flags=%s",
+	TP_printk("bdi %s: ino=%lu state=%s flags=%s",
 		__entry-&gt;name,
 		__entry-&gt;ino,
+		show_inode_state(__entry-&gt;state),
 		show_inode_state(__entry-&gt;flags)
 	)
 );
 
+DEFINE_EVENT(writeback_dirty_inode_template, writeback_mark_inode_dirty,
+
+	TP_PROTO(struct inode *inode, int flags),
+
+	TP_ARGS(inode, flags)
+);
+
 DEFINE_EVENT(writeback_dirty_inode_template, writeback_dirty_inode_start,
 
 	TP_PROTO(struct inode *inode, int flags),
@@ -598,6 +610,52 @@ DEFINE_EVENT(writeback_single_inode_template, writeback_single_inode,
 	TP_ARGS(inode, wbc, nr_to_write)
 );
 
+DECLARE_EVENT_CLASS(writeback_lazytime_template,
+	TP_PROTO(struct inode *inode),
+
+	TP_ARGS(inode),
+
+	TP_STRUCT__entry(
+		__field(	dev_t,	dev			)
+		__field(unsigned long,	ino			)
+		__field(unsigned long,	state			)
+		__field(	__u16, mode			)
+		__field(unsigned long, dirtied_when		)
+	),
+
+	TP_fast_assign(
+		__entry-&gt;dev	= inode-&gt;i_sb-&gt;s_dev;
+		__entry-&gt;ino	= inode-&gt;i_ino;
+		__entry-&gt;state	= inode-&gt;i_state;
+		__entry-&gt;mode	= inode-&gt;i_mode;
+		__entry-&gt;dirtied_when = inode-&gt;dirtied_when;
+	),
+
+	TP_printk("dev %d,%d ino %lu dirtied %lu state %s mode 0%o",
+		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
+		  __entry-&gt;ino, __entry-&gt;dirtied_when,
+		  show_inode_state(__entry-&gt;state), __entry-&gt;mode)
+);
+
+DEFINE_EVENT(writeback_lazytime_template, writeback_lazytime,
+	TP_PROTO(struct inode *inode),
+
+	TP_ARGS(inode)
+);
+
+DEFINE_EVENT(writeback_lazytime_template, writeback_lazytime_iput,
+	TP_PROTO(struct inode *inode),
+
+	TP_ARGS(inode)
+);
+
+DEFINE_EVENT(writeback_lazytime_template, writeback_dirty_inode_enqueue,
+
+	TP_PROTO(struct inode *inode),
+
+	TP_ARGS(inode)
+);
+
 #endif /* _TRACE_WRITEBACK_H */
 
 /* This part must be outside protection */
diff --git a/include/uapi/linux/fs.h b/include/uapi/linux/fs.h
index 3735fa0a6784..9b964a5920af 100644
--- a/include/uapi/linux/fs.h
+++ b/include/uapi/linux/fs.h
@@ -90,6 +90,7 @@ struct inodes_stat_t {
 #define MS_KERNMOUNT	(1&lt;&lt;22) /* this is a kern_mount call */
 #define MS_I_VERSION	(1&lt;&lt;23) /* Update inode I_version field */
 #define MS_STRICTATIME	(1&lt;&lt;24) /* Always perform atime updates */
+#define MS_LAZYTIME	(1&lt;&lt;25) /* Update the on-disk [acm]times lazily */
 
 /* These sb flags are internal to the kernel */
 #define MS_NOSEC	(1&lt;&lt;28)
@@ -100,7 +101,8 @@ struct inodes_stat_t {
 /*
  * Superblock flags that can be altered by MS_REMOUNT
  */
-#define MS_RMT_MASK	(MS_RDONLY|MS_SYNCHRONOUS|MS_MANDLOCK|MS_I_VERSION)
+#define MS_RMT_MASK	(MS_RDONLY|MS_SYNCHRONOUS|MS_MANDLOCK|MS_I_VERSION|\
+			 MS_LAZYTIME)
 
 /*
  * Old magic mount flag and mask
diff --git a/mm/backing-dev.c b/mm/backing-dev.c
index 0ae0df55000b..915feea94c66 100644
--- a/mm/backing-dev.c
+++ b/mm/backing-dev.c
@@ -69,10 +69,10 @@ static int bdi_debug_stats_show(struct seq_file *m, void *v)
 	unsigned long background_thresh;
 	unsigned long dirty_thresh;
 	unsigned long bdi_thresh;
-	unsigned long nr_dirty, nr_io, nr_more_io;
+	unsigned long nr_dirty, nr_io, nr_more_io, nr_dirty_time;
 	struct inode *inode;
 
-	nr_dirty = nr_io = nr_more_io = 0;
+	nr_dirty = nr_io = nr_more_io = nr_dirty_time = 0;
 	spin_lock(&amp;wb-&gt;list_lock);
 	list_for_each_entry(inode, &amp;wb-&gt;b_dirty, i_wb_list)
 		nr_dirty++;
@@ -80,6 +80,9 @@ static int bdi_debug_stats_show(struct seq_file *m, void *v)
 		nr_io++;
 	list_for_each_entry(inode, &amp;wb-&gt;b_more_io, i_wb_list)
 		nr_more_io++;
+	list_for_each_entry(inode, &amp;wb-&gt;b_dirty_time, i_wb_list)
+		if (inode-&gt;i_state &amp; I_DIRTY_TIME)
+			nr_dirty_time++;
 	spin_unlock(&amp;wb-&gt;list_lock);
 
 	global_dirty_limits(&amp;background_thresh, &amp;dirty_thresh);
@@ -98,6 +101,7 @@ static int bdi_debug_stats_show(struct seq_file *m, void *v)
 		   "b_dirty:            %10lu\n"
 		   "b_io:               %10lu\n"
 		   "b_more_io:          %10lu\n"
+		   "b_dirty_time:       %10lu\n"
 		   "bdi_list:           %10u\n"
 		   "state:              %10lx\n",
 		   (unsigned long) K(bdi_stat(bdi, BDI_WRITEBACK)),
@@ -111,6 +115,7 @@ static int bdi_debug_stats_show(struct seq_file *m, void *v)
 		   nr_dirty,
 		   nr_io,
 		   nr_more_io,
+		   nr_dirty_time,
 		   !list_empty(&amp;bdi-&gt;bdi_list), bdi-&gt;state);
 #undef K
 
@@ -418,6 +423,7 @@ static void bdi_wb_init(struct bdi_writeback *wb, struct backing_dev_info *bdi)
 	INIT_LIST_HEAD(&amp;wb-&gt;b_dirty);
 	INIT_LIST_HEAD(&amp;wb-&gt;b_io);
 	INIT_LIST_HEAD(&amp;wb-&gt;b_more_io);
+	INIT_LIST_HEAD(&amp;wb-&gt;b_dirty_time);
 	spin_lock_init(&amp;wb-&gt;list_lock);
 	INIT_DELAYED_WORK(&amp;wb-&gt;dwork, bdi_writeback_workfn);
 }</pre><hr><pre>commit 3edc18d84540b94c0eba9226d01a8cbe4c162b55
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Jan 19 16:00:58 2015 -0500

    ext4: reserve codepoints used by the ext4 encryption feature
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index a75fba67bb1f..b7f393df2e4c 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -364,7 +364,8 @@ struct flex_groups {
 #define EXT4_DIRTY_FL			0x00000100
 #define EXT4_COMPRBLK_FL		0x00000200 /* One or more compressed clusters */
 #define EXT4_NOCOMPR_FL			0x00000400 /* Don't compress */
-#define EXT4_ECOMPR_FL			0x00000800 /* Compression error */
+	/* nb: was previously EXT2_ECOMPR_FL */
+#define EXT4_ENCRYPT_FL			0x00000800 /* encrypted file */
 /* End compression flags --- maybe not all used */
 #define EXT4_INDEX_FL			0x00001000 /* hash-indexed directory */
 #define EXT4_IMAGIC_FL			0x00002000 /* AFS directory */
@@ -421,7 +422,7 @@ enum {
 	EXT4_INODE_DIRTY	= 8,
 	EXT4_INODE_COMPRBLK	= 9,	/* One or more compressed clusters */
 	EXT4_INODE_NOCOMPR	= 10,	/* Don't compress */
-	EXT4_INODE_ECOMPR	= 11,	/* Compression error */
+	EXT4_INODE_ENCRYPT	= 11,	/* Compression error */
 /* End compression flags --- maybe not all used */
 	EXT4_INODE_INDEX	= 12,	/* hash-indexed directory */
 	EXT4_INODE_IMAGIC	= 13,	/* AFS directory */
@@ -466,7 +467,7 @@ static inline void ext4_check_flag_values(void)
 	CHECK_FLAG_VALUE(DIRTY);
 	CHECK_FLAG_VALUE(COMPRBLK);
 	CHECK_FLAG_VALUE(NOCOMPR);
-	CHECK_FLAG_VALUE(ECOMPR);
+	CHECK_FLAG_VALUE(ENCRYPT);
 	CHECK_FLAG_VALUE(INDEX);
 	CHECK_FLAG_VALUE(IMAGIC);
 	CHECK_FLAG_VALUE(JOURNAL_DATA);
@@ -1043,6 +1044,12 @@ extern void ext4_set_bits(void *bm, int cur, int len);
 /* Metadata checksum algorithm codes */
 #define EXT4_CRC32C_CHKSUM		1
 
+/* Encryption algorithms */
+#define EXT4_ENCRYPTION_MODE_INVALID		0
+#define EXT4_ENCRYPTION_MODE_AES_256_XTS	1
+#define EXT4_ENCRYPTION_MODE_AES_256_GCM	2
+#define EXT4_ENCRYPTION_MODE_AES_256_CBC	3
+
 /*
  * Structure of the super block
  */
@@ -1156,7 +1163,8 @@ struct ext4_super_block {
 	__le32	s_grp_quota_inum;	/* inode for tracking group quota */
 	__le32	s_overhead_clusters;	/* overhead blocks/clusters in fs */
 	__le32	s_backup_bgs[2];	/* groups with sparse_super2 SBs */
-	__le32	s_reserved[106];	/* Padding to the end of the block */
+	__u8	s_encrypt_algos[4];	/* Encryption algorithms in use  */
+	__le32	s_reserved[105];	/* Padding to the end of the block */
 	__le32	s_checksum;		/* crc32c(superblock) */
 };
 
@@ -1537,6 +1545,7 @@ static inline void ext4_clear_state_flags(struct ext4_inode_info *ei)
 #define EXT4_FEATURE_INCOMPAT_BG_USE_META_CSUM	0x2000 /* use crc32c for bg */
 #define EXT4_FEATURE_INCOMPAT_LARGEDIR		0x4000 /* &gt;2GB or 3-lvl htree */
 #define EXT4_FEATURE_INCOMPAT_INLINE_DATA	0x8000 /* data in inode */
+#define EXT4_FEATURE_INCOMPAT_ENCRYPT		0x10000
 
 #define EXT2_FEATURE_COMPAT_SUPP	EXT4_FEATURE_COMPAT_EXT_ATTR
 #define EXT2_FEATURE_INCOMPAT_SUPP	(EXT4_FEATURE_INCOMPAT_FILETYPE| \</pre><hr><pre>commit ad7fefb109b0418bb4f16fc1176fd082f986698b
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Jan 2 15:16:00 2015 -0500

    Revert "ext4: fix suboptimal seek_{data,hole} extents traversial"
    
    This reverts commit 14516bb7bb6ffbd49f35389f9ece3b2045ba5815.
    
    This was causing regression test failures with generic/285 with an ext3
    filesystem using CONFIG_EXT4_USE_FOR_EXT23.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c
index e5d3eadf47b1..bed43081720f 100644
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@ -5166,8 +5166,8 @@ int ext4_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 
 	/* fallback to generic here if not in extents fmt */
 	if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))
-		return __generic_block_fiemap(inode, fieinfo, start, len,
-					      ext4_get_block);
+		return generic_block_fiemap(inode, fieinfo, start, len,
+			ext4_get_block);
 
 	if (fiemap_check_flags(fieinfo, EXT4_FIEMAP_FLAGS))
 		return -EBADR;
diff --git a/fs/ext4/file.c b/fs/ext4/file.c
index 513c12cf444c..8131be8c0af3 100644
--- a/fs/ext4/file.c
+++ b/fs/ext4/file.c
@@ -273,19 +273,24 @@ static int ext4_file_open(struct inode * inode, struct file * filp)
  * we determine this extent as a data or a hole according to whether the
  * page cache has data or not.
  */
-static int ext4_find_unwritten_pgoff(struct inode *inode, int whence,
-				     loff_t endoff, loff_t *offset)
+static int ext4_find_unwritten_pgoff(struct inode *inode,
+				     int whence,
+				     struct ext4_map_blocks *map,
+				     loff_t *offset)
 {
 	struct pagevec pvec;
+	unsigned int blkbits;
 	pgoff_t index;
 	pgoff_t end;
+	loff_t endoff;
 	loff_t startoff;
 	loff_t lastoff;
 	int found = 0;
 
+	blkbits = inode-&gt;i_sb-&gt;s_blocksize_bits;
 	startoff = *offset;
 	lastoff = startoff;
-
+	endoff = (loff_t)(map-&gt;m_lblk + map-&gt;m_len) &lt;&lt; blkbits;
 
 	index = startoff &gt;&gt; PAGE_CACHE_SHIFT;
 	end = endoff &gt;&gt; PAGE_CACHE_SHIFT;
@@ -403,144 +408,147 @@ static int ext4_find_unwritten_pgoff(struct inode *inode, int whence,
 static loff_t ext4_seek_data(struct file *file, loff_t offset, loff_t maxsize)
 {
 	struct inode *inode = file-&gt;f_mapping-&gt;host;
-	struct fiemap_extent_info fie;
-	struct fiemap_extent ext[2];
-	loff_t next;
-	int i, ret = 0;
+	struct ext4_map_blocks map;
+	struct extent_status es;
+	ext4_lblk_t start, last, end;
+	loff_t dataoff, isize;
+	int blkbits;
+	int ret = 0;
 
 	mutex_lock(&amp;inode-&gt;i_mutex);
-	if (offset &gt;= inode-&gt;i_size) {
+
+	isize = i_size_read(inode);
+	if (offset &gt;= isize) {
 		mutex_unlock(&amp;inode-&gt;i_mutex);
 		return -ENXIO;
 	}
-	fie.fi_flags = 0;
-	fie.fi_extents_max = 2;
-	fie.fi_extents_start = (struct fiemap_extent __user *) &amp;ext;
-	while (1) {
-		mm_segment_t old_fs = get_fs();
-
-		fie.fi_extents_mapped = 0;
-		memset(ext, 0, sizeof(*ext) * fie.fi_extents_max);
-
-		set_fs(get_ds());
-		ret = ext4_fiemap(inode, &amp;fie, offset, maxsize - offset);
-		set_fs(old_fs);
-		if (ret)
+
+	blkbits = inode-&gt;i_sb-&gt;s_blocksize_bits;
+	start = offset &gt;&gt; blkbits;
+	last = start;
+	end = isize &gt;&gt; blkbits;
+	dataoff = offset;
+
+	do {
+		map.m_lblk = last;
+		map.m_len = end - last + 1;
+		ret = ext4_map_blocks(NULL, inode, &amp;map, 0);
+		if (ret &gt; 0 &amp;&amp; !(map.m_flags &amp; EXT4_MAP_UNWRITTEN)) {
+			if (last != start)
+				dataoff = (loff_t)last &lt;&lt; blkbits;
 			break;
+		}
 
-		/* No extents found, EOF */
-		if (!fie.fi_extents_mapped) {
-			ret = -ENXIO;
+		/*
+		 * If there is a delay extent at this offset,
+		 * it will be as a data.
+		 */
+		ext4_es_find_delayed_extent_range(inode, last, last, &amp;es);
+		if (es.es_len != 0 &amp;&amp; in_range(last, es.es_lblk, es.es_len)) {
+			if (last != start)
+				dataoff = (loff_t)last &lt;&lt; blkbits;
 			break;
 		}
-		for (i = 0; i &lt; fie.fi_extents_mapped; i++) {
-			next = (loff_t)(ext[i].fe_length + ext[i].fe_logical);
 
-			if (offset &lt; (loff_t)ext[i].fe_logical)
-				offset = (loff_t)ext[i].fe_logical;
-			/*
-			 * If extent is not unwritten, then it contains valid
-			 * data, mapped or delayed.
-			 */
-			if (!(ext[i].fe_flags &amp; FIEMAP_EXTENT_UNWRITTEN))
-				goto out;
+		/*
+		 * If there is a unwritten extent at this offset,
+		 * it will be as a data or a hole according to page
+		 * cache that has data or not.
+		 */
+		if (map.m_flags &amp; EXT4_MAP_UNWRITTEN) {
+			int unwritten;
+			unwritten = ext4_find_unwritten_pgoff(inode, SEEK_DATA,
+							      &amp;map, &amp;dataoff);
+			if (unwritten)
+				break;
+		}
 
-			/*
-			 * If there is a unwritten extent at this offset,
-			 * it will be as a data or a hole according to page
-			 * cache that has data or not.
-			 */
-			if (ext4_find_unwritten_pgoff(inode, SEEK_DATA,
-						      next, &amp;offset))
-				goto out;
+		last++;
+		dataoff = (loff_t)last &lt;&lt; blkbits;
+	} while (last &lt;= end);
 
-			if (ext[i].fe_flags &amp; FIEMAP_EXTENT_LAST) {
-				ret = -ENXIO;
-				goto out;
-			}
-			offset = next;
-		}
-	}
-	if (offset &gt; inode-&gt;i_size)
-		offset = inode-&gt;i_size;
-out:
 	mutex_unlock(&amp;inode-&gt;i_mutex);
-	if (ret)
-		return ret;
 
-	return vfs_setpos(file, offset, maxsize);
+	if (dataoff &gt; isize)
+		return -ENXIO;
+
+	return vfs_setpos(file, dataoff, maxsize);
 }
 
 /*
- * ext4_seek_hole() retrieves the offset for SEEK_HOLE
+ * ext4_seek_hole() retrieves the offset for SEEK_HOLE.
  */
 static loff_t ext4_seek_hole(struct file *file, loff_t offset, loff_t maxsize)
 {
 	struct inode *inode = file-&gt;f_mapping-&gt;host;
-	struct fiemap_extent_info fie;
-	struct fiemap_extent ext[2];
-	loff_t next;
-	int i, ret = 0;
+	struct ext4_map_blocks map;
+	struct extent_status es;
+	ext4_lblk_t start, last, end;
+	loff_t holeoff, isize;
+	int blkbits;
+	int ret = 0;
 
 	mutex_lock(&amp;inode-&gt;i_mutex);
-	if (offset &gt;= inode-&gt;i_size) {
+
+	isize = i_size_read(inode);
+	if (offset &gt;= isize) {
 		mutex_unlock(&amp;inode-&gt;i_mutex);
 		return -ENXIO;
 	}
 
-	fie.fi_flags = 0;
-	fie.fi_extents_max = 2;
-	fie.fi_extents_start = (struct fiemap_extent __user *)&amp;ext;
-	while (1) {
-		mm_segment_t old_fs = get_fs();
-
-		fie.fi_extents_mapped = 0;
-		memset(ext, 0, sizeof(*ext));
+	blkbits = inode-&gt;i_sb-&gt;s_blocksize_bits;
+	start = offset &gt;&gt; blkbits;
+	last = start;
+	end = isize &gt;&gt; blkbits;
+	holeoff = offset;
 
-		set_fs(get_ds());
-		ret = ext4_fiemap(inode, &amp;fie, offset, maxsize - offset);
-		set_fs(old_fs);
-		if (ret)
-			break;
+	do {
+		map.m_lblk = last;
+		map.m_len = end - last + 1;
+		ret = ext4_map_blocks(NULL, inode, &amp;map, 0);
+		if (ret &gt; 0 &amp;&amp; !(map.m_flags &amp; EXT4_MAP_UNWRITTEN)) {
+			last += ret;
+			holeoff = (loff_t)last &lt;&lt; blkbits;
+			continue;
+		}
 
-		/* No extents found */
-		if (!fie.fi_extents_mapped)
-			break;
+		/*
+		 * If there is a delay extent at this offset,
+		 * we will skip this extent.
+		 */
+		ext4_es_find_delayed_extent_range(inode, last, last, &amp;es);
+		if (es.es_len != 0 &amp;&amp; in_range(last, es.es_lblk, es.es_len)) {
+			last = es.es_lblk + es.es_len;
+			holeoff = (loff_t)last &lt;&lt; blkbits;
+			continue;
+		}
 
-		for (i = 0; i &lt; fie.fi_extents_mapped; i++) {
-			next = (loff_t)(ext[i].fe_logical + ext[i].fe_length);
-			/*
-			 * If extent is not unwritten, then it contains valid
-			 * data, mapped or delayed.
-			 */
-			if (!(ext[i].fe_flags &amp; FIEMAP_EXTENT_UNWRITTEN)) {
-				if (offset &lt; (loff_t)ext[i].fe_logical)
-					goto out;
-				offset = next;
+		/*
+		 * If there is a unwritten extent at this offset,
+		 * it will be as a data or a hole according to page
+		 * cache that has data or not.
+		 */
+		if (map.m_flags &amp; EXT4_MAP_UNWRITTEN) {
+			int unwritten;
+			unwritten = ext4_find_unwritten_pgoff(inode, SEEK_HOLE,
+							      &amp;map, &amp;holeoff);
+			if (!unwritten) {
+				last += ret;
+				holeoff = (loff_t)last &lt;&lt; blkbits;
 				continue;
 			}
-			/*
-			 * If there is a unwritten extent at this offset,
-			 * it will be as a data or a hole according to page
-			 * cache that has data or not.
-			 */
-			if (ext4_find_unwritten_pgoff(inode, SEEK_HOLE,
-						      next, &amp;offset))
-				goto out;
-
-			offset = next;
-			if (ext[i].fe_flags &amp; FIEMAP_EXTENT_LAST)
-				goto out;
 		}
-	}
-	if (offset &gt; inode-&gt;i_size)
-		offset = inode-&gt;i_size;
-out:
+
+		/* find a hole */
+		break;
+	} while (last &lt;= end);
+
 	mutex_unlock(&amp;inode-&gt;i_mutex);
-	if (ret)
-		return ret;
 
-	return vfs_setpos(file, offset, maxsize);
+	if (holeoff &gt; isize)
+		holeoff = isize;
+
+	return vfs_setpos(file, holeoff, maxsize);
 }
 
 /*</pre><hr><pre>commit 011fa99404bea3f5d897c4983f6bd51170e3b18f
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Dec 26 23:58:21 2014 -0500

    ext4: prevent online resize with backup superblock
    
    Prevent BUG or corrupted file systems after the following:
    
    mkfs.ext4 /dev/vdc 100M
    mount -t ext4 -o sb=40961 /dev/vdc /vdc
    resize2fs /dev/vdc
    
    We previously prevented online resizing using the old resize ioctl.
    Move the code to ext4_resize_begin(), so the check applies for all of
    the resize ioctl's.
    
    Reported-by: Maxim Malkov &lt;malkov@ispras.ru&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/resize.c b/fs/ext4/resize.c
index bf76f405a5f9..8a8ec6293b19 100644
--- a/fs/ext4/resize.c
+++ b/fs/ext4/resize.c
@@ -23,6 +23,18 @@ int ext4_resize_begin(struct super_block *sb)
 	if (!capable(CAP_SYS_RESOURCE))
 		return -EPERM;
 
+	/*
+	 * If we are not using the primary superblock/GDT copy don't resize,
+         * because the user tools have no way of handling this.  Probably a
+         * bad time to do it anyways.
+         */
+	if (EXT4_SB(sb)-&gt;s_sbh-&gt;b_blocknr !=
+	    le32_to_cpu(EXT4_SB(sb)-&gt;s_es-&gt;s_first_data_block)) {
+		ext4_warning(sb, "won't resize using backup superblock at %llu",
+			(unsigned long long)EXT4_SB(sb)-&gt;s_sbh-&gt;b_blocknr);
+		return -EPERM;
+	}
+
 	/*
 	 * We are not allowed to do online-resizing on a filesystem mounted
 	 * with error, because it can destroy the filesystem easily.
@@ -758,18 +770,6 @@ static int add_new_gdb(handle_t *handle, struct inode *inode,
 		       "EXT4-fs: ext4_add_new_gdb: adding group block %lu\n",
 		       gdb_num);
 
-	/*
-	 * If we are not using the primary superblock/GDT copy don't resize,
-         * because the user tools have no way of handling this.  Probably a
-         * bad time to do it anyways.
-         */
-	if (EXT4_SB(sb)-&gt;s_sbh-&gt;b_blocknr !=
-	    le32_to_cpu(EXT4_SB(sb)-&gt;s_es-&gt;s_first_data_block)) {
-		ext4_warning(sb, "won't resize using backup superblock at %llu",
-			(unsigned long long)EXT4_SB(sb)-&gt;s_sbh-&gt;b_blocknr);
-		return -EPERM;
-	}
-
 	gdb_bh = sb_bread(sb, gdblock);
 	if (!gdb_bh)
 		return -EIO;</pre><hr><pre>commit d9f39d1e44c43fba26becc4145fabf9d767ff1cd
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Nov 25 20:02:37 2014 -0500

    jbd2: remove unnecessary NULL check before iput()
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/fs/jbd2/journal.c b/fs/jbd2/journal.c
index e4dc74713a43..56dde1e85c24 100644
--- a/fs/jbd2/journal.c
+++ b/fs/jbd2/journal.c
@@ -1714,8 +1714,7 @@ int jbd2_journal_destroy(journal_t *journal)
 
 	if (journal-&gt;j_proc_entry)
 		jbd2_stats_proc_exit(journal);
-	if (journal-&gt;j_inode)
-		iput(journal-&gt;j_inode);
+	iput(journal-&gt;j_inode);
 	if (journal-&gt;j_revoke)
 		jbd2_journal_destroy_revoke(journal);
 	if (journal-&gt;j_chksum_driver)</pre><hr><pre>commit d48458d4a768cece43f80a081a26cf912877da9c
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Thu Oct 30 10:53:17 2014 -0400

    jbd2: use a better hash function for the revoke table
    
    The old hash function didn't work well for 64-bit block numbers, and
    used undefined (negative) shift right behavior.  Use the generic
    64-bit hash function instead.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Reported-by: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;

diff --git a/fs/jbd2/revoke.c b/fs/jbd2/revoke.c
index d5e95a175c92..c6cbaef2bda1 100644
--- a/fs/jbd2/revoke.c
+++ b/fs/jbd2/revoke.c
@@ -92,6 +92,7 @@
 #include &lt;linux/init.h&gt;
 #include &lt;linux/bio.h&gt;
 #include &lt;linux/log2.h&gt;
+#include &lt;linux/hash.h&gt;
 #endif
 
 static struct kmem_cache *jbd2_revoke_record_cache;
@@ -130,16 +131,9 @@ static void flush_descriptor(journal_t *, struct buffer_head *, int, int);
 
 /* Utility functions to maintain the revoke table */
 
-/* Borrowed from buffer.c: this is a tried and tested block hash function */
 static inline int hash(journal_t *journal, unsigned long long block)
 {
-	struct jbd2_revoke_table_s *table = journal-&gt;j_revoke;
-	int hash_shift = table-&gt;hash_shift;
-	int hash = (int)block ^ (int)((block &gt;&gt; 31) &gt;&gt; 1);
-
-	return ((hash &lt;&lt; (hash_shift - 6)) ^
-		(hash &gt;&gt; 13) ^
-		(hash &lt;&lt; (hash_shift - 12))) &amp; (table-&gt;hash_size - 1);
+	return hash_64(block, journal-&gt;j_revoke-&gt;hash_shift);
 }
 
 static int insert_revoke_hash(journal_t *journal, unsigned long long blocknr,</pre><hr><pre>commit f4bb2981024fc91b23b4d09a8817c415396dbabb
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Oct 5 22:56:00 2014 -0400

    ext4: add ext4_iget_normal() which is to be used for dir tree lookups
    
    If there is a corrupted file system which has directory entries that
    point at reserved, metadata inodes, prohibit them from being used by
    treating them the same way we treat Boot Loader inodes --- that is,
    mark them to be bad inodes.  This prohibits them from being opened,
    deleted, or modified via chmod, chown, utimes, etc.
    
    In particular, this prevents a corrupted file system which has a
    directory entry which points at the journal inode from being deleted
    and its blocks released, after which point Much Hilarity Ensues.
    
    Reported-by: Sami Liedes &lt;sami.liedes@iki.fi&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index 1eb5b7b912a8..012e89bd9644 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -2109,6 +2109,7 @@ int do_journal_get_write_access(handle_t *handle,
 #define CONVERT_INLINE_DATA	 2
 
 extern struct inode *ext4_iget(struct super_block *, unsigned long);
+extern struct inode *ext4_iget_normal(struct super_block *, unsigned long);
 extern int  ext4_write_inode(struct inode *, struct writeback_control *);
 extern int  ext4_setattr(struct dentry *, struct iattr *);
 extern int  ext4_getattr(struct vfsmount *mnt, struct dentry *dentry,
diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 59983b28a93c..e204d8aabe7d 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -4104,6 +4104,13 @@ struct inode *ext4_iget(struct super_block *sb, unsigned long ino)
 	return ERR_PTR(ret);
 }
 
+struct inode *ext4_iget_normal(struct super_block *sb, unsigned long ino)
+{
+	if (ino &lt; EXT4_FIRST_INO(sb) &amp;&amp; ino != EXT4_ROOT_INO)
+		return ERR_PTR(-EIO);
+	return ext4_iget(sb, ino);
+}
+
 static int ext4_inode_blocks_set(handle_t *handle,
 				struct ext4_inode *raw_inode,
 				struct ext4_inode_info *ei)
diff --git a/fs/ext4/namei.c b/fs/ext4/namei.c
index a2a9d40522d2..7037ecf0fc23 100644
--- a/fs/ext4/namei.c
+++ b/fs/ext4/namei.c
@@ -1417,7 +1417,7 @@ static struct dentry *ext4_lookup(struct inode *dir, struct dentry *dentry, unsi
 					 dentry);
 			return ERR_PTR(-EIO);
 		}
-		inode = ext4_iget(dir-&gt;i_sb, ino);
+		inode = ext4_iget_normal(dir-&gt;i_sb, ino);
 		if (inode == ERR_PTR(-ESTALE)) {
 			EXT4_ERROR_INODE(dir,
 					 "deleted inode referenced: %u",
@@ -1450,7 +1450,7 @@ struct dentry *ext4_get_parent(struct dentry *child)
 		return ERR_PTR(-EIO);
 	}
 
-	return d_obtain_alias(ext4_iget(child-&gt;d_inode-&gt;i_sb, ino));
+	return d_obtain_alias(ext4_iget_normal(child-&gt;d_inode-&gt;i_sb, ino));
 }
 
 /*
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 1070d6e521c6..a0811cc00c91 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -1001,7 +1001,7 @@ static struct inode *ext4_nfs_get_inode(struct super_block *sb,
 	 * Currently we don't know the generation for parent directory, so
 	 * a generation of 0 means "accept any"
 	 */
-	inode = ext4_iget(sb, ino);
+	inode = ext4_iget_normal(sb, ino);
 	if (IS_ERR(inode))
 		return ERR_CAST(inode);
 	if (generation &amp;&amp; inode-&gt;i_generation != generation) {</pre>
    <div class="pagination">
        <a href='1_34.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><span>[35]</span><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_36.html'>Next&gt;&gt;</a>
    <div>
</body>
