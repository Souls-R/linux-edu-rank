<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by University of Michigan - Ann Arbor</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by University of Michigan - Ann Arbor</h1>
    <div class="pagination">
        <a href='4_5.html'>&lt;&lt;Prev</a><a href='4.html'>1</a><a href='4_2.html'>2</a><a href='4_3.html'>3</a><a href='4_4.html'>4</a><a href='4_5.html'>5</a><span>[6]</span><a href='4_7.html'>7</a><a href='4_8.html'>8</a><a href='4_9.html'>9</a><a href='4_10.html'>10</a><a href='4_11.html'>11</a><a href='4_12.html'>12</a><a href='4_13.html'>13</a><a href='4_14.html'>14</a><a href='4_15.html'>15</a><a href='4_16.html'>16</a><a href='4_17.html'>17</a><a href='4_18.html'>18</a><a href='4_19.html'>19</a><a href='4_20.html'>20</a><a href='4_21.html'>21</a><a href='4_22.html'>22</a><a href='4_23.html'>23</a><a href='4_24.html'>24</a><a href='4_25.html'>25</a><a href='4_26.html'>26</a><a href='4_27.html'>27</a><a href='4_28.html'>28</a><a href='4_29.html'>29</a><a href='4_30.html'>30</a><a href='4_31.html'>31</a><a href='4_32.html'>32</a><a href='4_33.html'>33</a><a href='4_34.html'>34</a><a href='4_35.html'>35</a><a href='4_36.html'>36</a><a href='4_37.html'>37</a><a href='4_38.html'>38</a><a href='4_39.html'>39</a><a href='4_40.html'>40</a><a href='4_41.html'>41</a><a href='4_42.html'>42</a><a href='4_43.html'>43</a><a href='4_44.html'>44</a><a href='4_45.html'>45</a><a href='4_46.html'>46</a><a href='4_47.html'>47</a><a href='4_48.html'>48</a><a href='4_49.html'>49</a><a href='4_50.html'>50</a><a href='4_51.html'>51</a><a href='4_52.html'>52</a><a href='4_53.html'>53</a><a href='4_54.html'>54</a><a href='4_55.html'>55</a><a href='4_56.html'>56</a><a href='4_57.html'>57</a><a href='4_7.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit 3b6445a6f68b839d1b437756b9c72312e33339b2
Author: Jim Rees &lt;rees@umich.edu&gt;
Date:   Tue Feb 22 19:31:57 2011 -0500

    NFSv4.1: fix typo in filelayout_check_layout
    
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;

diff --git a/fs/nfs/nfs4filelayout.c b/fs/nfs/nfs4filelayout.c
index be79dc9f386d..dd6ccf007673 100644
--- a/fs/nfs/nfs4filelayout.c
+++ b/fs/nfs/nfs4filelayout.c
@@ -428,7 +428,7 @@ filelayout_check_layout(struct pnfs_layout_hdr *lo,
 	dprintk("--&gt; %s\n", __func__);
 
 	if (fl-&gt;pattern_offset &gt; lgr-&gt;range.offset) {
-		dprintk("%s pattern_offset %lld to large\n",
+		dprintk("%s pattern_offset %lld too large\n",
 				__func__, fl-&gt;pattern_offset);
 		goto out;
 	}</pre><hr><pre>commit 7ab672ce312133ee4a5d85b71447b2b334403681
Author: Dean Hildebrand &lt;dhildebz@umich.edu&gt;
Date:   Wed Oct 20 00:18:00 2010 -0400

    NFSv4.1: pnfs: filelayout: introduce minimal file layout driver
    
    This driver just registers itself and supplies trivial mount/umount functions.
    
    Signed-off-by: Dean Hildebrand &lt;dhildebz@umich.edu&gt;
    Signed-off-by: Marc Eshel &lt;eshel@almaden.ibm.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Fred Isaman &lt;iisaman@netapp.com&gt;
    Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/fs/nfs/Makefile b/fs/nfs/Makefile
index bb9e773d4312..08a8889c5149 100644
--- a/fs/nfs/Makefile
+++ b/fs/nfs/Makefile
@@ -18,3 +18,6 @@ nfs-$(CONFIG_NFS_V4)	+= nfs4proc.o nfs4xdr.o nfs4state.o nfs4renewd.o \
 nfs-$(CONFIG_NFS_V4_1)	+= pnfs.o
 nfs-$(CONFIG_SYSCTL) += sysctl.o
 nfs-$(CONFIG_NFS_FSCACHE) += fscache.o fscache-index.o
+
+obj-$(CONFIG_PNFS_FILE_LAYOUT) += nfs_layout_nfsv41_files.o
+nfs_layout_nfsv41_files-y := nfs4filelayout.o
diff --git a/fs/nfs/nfs4filelayout.c b/fs/nfs/nfs4filelayout.c
new file mode 100644
index 000000000000..696e283c2632
--- /dev/null
+++ b/fs/nfs/nfs4filelayout.c
@@ -0,0 +1,78 @@
+/*
+ *  Module for the pnfs nfs4 file layout driver.
+ *  Defines all I/O and Policy interface operations, plus code
+ *  to register itself with the pNFS client.
+ *
+ *  Copyright (c) 2002
+ *  The Regents of the University of Michigan
+ *  All Rights Reserved
+ *
+ *  Dean Hildebrand &lt;dhildebz@umich.edu&gt;
+ *
+ *  Permission is granted to use, copy, create derivative works, and
+ *  redistribute this software and such derivative works for any purpose,
+ *  so long as the name of the University of Michigan is not used in
+ *  any advertising or publicity pertaining to the use or distribution
+ *  of this software without specific, written prior authorization. If
+ *  the above copyright notice or any other identification of the
+ *  University of Michigan is included in any copy of any portion of
+ *  this software, then the disclaimer below must also be included.
+ *
+ *  This software is provided as is, without representation or warranty
+ *  of any kind either express or implied, including without limitation
+ *  the implied warranties of merchantability, fitness for a particular
+ *  purpose, or noninfringement.  The Regents of the University of
+ *  Michigan shall not be liable for any damages, including special,
+ *  indirect, incidental, or consequential damages, with respect to any
+ *  claim arising out of or in connection with the use of the software,
+ *  even if it has been or is hereafter advised of the possibility of
+ *  such damages.
+ */
+
+#include &lt;linux/nfs_fs.h&gt;
+#include "pnfs.h"
+
+#define NFSDBG_FACILITY         NFSDBG_PNFS_LD
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Dean Hildebrand &lt;dhildebz@umich.edu&gt;");
+MODULE_DESCRIPTION("The NFSv4 file layout driver");
+
+int
+filelayout_initialize_mountpoint(struct nfs_server *nfss)
+{
+	return 0;
+}
+
+int
+filelayout_uninitialize_mountpoint(struct nfs_server *nfss)
+{
+	dprintk("--&gt; %s\n", __func__);
+
+	return 0;
+}
+
+static struct pnfs_layoutdriver_type filelayout_type = {
+	.id = LAYOUT_NFSV4_1_FILES,
+	.name = "LAYOUT_NFSV4_1_FILES",
+	.owner = THIS_MODULE,
+	.initialize_mountpoint   = filelayout_initialize_mountpoint,
+	.uninitialize_mountpoint = filelayout_uninitialize_mountpoint,
+};
+
+static int __init nfs4filelayout_init(void)
+{
+	printk(KERN_INFO "%s: NFSv4 File Layout Driver Registering...\n",
+	       __func__);
+	return pnfs_register_layoutdriver(&amp;filelayout_type);
+}
+
+static void __exit nfs4filelayout_exit(void)
+{
+	printk(KERN_INFO "%s: NFSv4 File Layout Driver Unregistering...\n",
+	       __func__);
+	pnfs_unregister_layoutdriver(&amp;filelayout_type);
+}
+
+module_init(nfs4filelayout_init);
+module_exit(nfs4filelayout_exit);
diff --git a/include/linux/nfs_fs.h b/include/linux/nfs_fs.h
index aba3da2a6227..499872fa895c 100644
--- a/include/linux/nfs_fs.h
+++ b/include/linux/nfs_fs.h
@@ -616,6 +616,7 @@ nfs_fileid_to_ino_t(u64 fileid)
 #define NFSDBG_MOUNT		0x0400
 #define NFSDBG_FSCACHE		0x0800
 #define NFSDBG_PNFS		0x1000
+#define NFSDBG_PNFS_LD		0x2000
 #define NFSDBG_ALL		0xFFFF
 
 #ifdef __KERNEL__</pre><hr><pre>commit c772567d97fa0fca454eea68aeae915ca1bc732b
Author: Dean Hildebrand &lt;dhildebz@umich.edu&gt;
Date:   Wed Oct 20 00:17:55 2010 -0400

    NFSv4.1: pnfsd, pnfs: protocol level pnfs constants
    
    Use only layoutreturn constant for both returns and recalls.
    (return_* works better for recall_type rather the other way around)
    
    Signed-off-by: Dean Hildebrand &lt;dhildebz@umich.edu&gt;
    Signed-off-by: Marc Eshel &lt;eshel@almaden.ibm.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Fred Isaman &lt;iisaman@netapp.com&gt;
    Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/include/linux/nfs4.h b/include/linux/nfs4.h
index 07e40c625972..6c0406e87d5c 100644
--- a/include/linux/nfs4.h
+++ b/include/linux/nfs4.h
@@ -471,6 +471,8 @@ enum lock_type4 {
 #define FATTR4_WORD1_TIME_MODIFY        (1UL &lt;&lt; 21)
 #define FATTR4_WORD1_TIME_MODIFY_SET    (1UL &lt;&lt; 22)
 #define FATTR4_WORD1_MOUNTED_ON_FILEID  (1UL &lt;&lt; 23)
+#define FATTR4_WORD1_FS_LAYOUT_TYPES    (1UL &lt;&lt; 30)
+#define FATTR4_WORD2_LAYOUT_BLKSIZE     (1UL &lt;&lt; 1)
 
 #define NFSPROC4_NULL 0
 #define NFSPROC4_COMPOUND 1
@@ -550,6 +552,49 @@ enum state_protect_how4 {
 	SP4_SSV		= 2
 };
 
+enum pnfs_layouttype {
+	LAYOUT_NFSV4_1_FILES  = 1,
+	LAYOUT_OSD2_OBJECTS = 2,
+	LAYOUT_BLOCK_VOLUME = 3,
+};
+
+/* used for both layout return and recall */
+enum pnfs_layoutreturn_type {
+	RETURN_FILE = 1,
+	RETURN_FSID = 2,
+	RETURN_ALL  = 3
+};
+
+enum pnfs_iomode {
+	IOMODE_READ = 1,
+	IOMODE_RW = 2,
+	IOMODE_ANY = 3,
+};
+
+enum pnfs_notify_deviceid_type4 {
+	NOTIFY_DEVICEID4_CHANGE = 1 &lt;&lt; 1,
+	NOTIFY_DEVICEID4_DELETE = 1 &lt;&lt; 2,
+};
+
+#define NFL4_UFLG_MASK			0x0000003F
+#define NFL4_UFLG_DENSE			0x00000001
+#define NFL4_UFLG_COMMIT_THRU_MDS	0x00000002
+#define NFL4_UFLG_STRIPE_UNIT_SIZE_MASK	0xFFFFFFC0
+
+/* Encoded in the loh_body field of type layouthint4 */
+enum filelayout_hint_care4 {
+	NFLH4_CARE_DENSE		= NFL4_UFLG_DENSE,
+	NFLH4_CARE_COMMIT_THRU_MDS	= NFL4_UFLG_COMMIT_THRU_MDS,
+	NFLH4_CARE_STRIPE_UNIT_SIZE	= 0x00000040,
+	NFLH4_CARE_STRIPE_COUNT		= 0x00000080
+};
+
+#define NFS4_DEVICEID4_SIZE 16
+
+struct nfs4_deviceid {
+	char data[NFS4_DEVICEID4_SIZE];
+};
+
 #endif
 #endif
 </pre><hr><pre>commit 47f9940c55c0bdc65188749cae4e841601f513bb
Author: Meelap Shah &lt;meelap@umich.edu&gt;
Date:   Tue Jul 17 04:04:40 2007 -0700

    knfsd: nfsd4: don't delegate files that have had conflicts
    
    One more incremental delegation policy improvement: don't give out a
    delegation on a file if conflicting access has previously required that a
    delegation be revoked on that file.  (In practice we'll forget about the
    conflict when the struct nfs4_file is removed on close, so this is of limited
    use for now, though it should at least solve a temporary problem with
    self-conflicts on write opens from the same client.)
    
    Signed-off-by: "J. Bruce Fields" &lt;bfields@citi.umich.edu&gt;
    Signed-off-by: Neil Brown &lt;neilb@suse.de&gt;
    Signed-off-by: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Signed-off-by: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;

diff --git a/fs/nfsd/nfs4state.c b/fs/nfsd/nfs4state.c
index 46249886ea86..e4a4c87ec8c6 100644
--- a/fs/nfsd/nfs4state.c
+++ b/fs/nfsd/nfs4state.c
@@ -195,6 +195,8 @@ alloc_init_deleg(struct nfs4_client *clp, struct nfs4_stateid *stp, struct svc_f
 	struct nfs4_callback *cb = &amp;stp-&gt;st_stateowner-&gt;so_client-&gt;cl_callback;
 
 	dprintk("NFSD alloc_init_deleg\n");
+	if (fp-&gt;fi_had_conflict)
+		return NULL;
 	if (num_delegations &gt; max_delegations)
 		return NULL;
 	dp = kmem_cache_alloc(deleg_slab, GFP_KERNEL);
@@ -1002,6 +1004,7 @@ alloc_init_file(struct inode *ino)
 		list_add(&amp;fp-&gt;fi_hash, &amp;file_hashtbl[hashval]);
 		fp-&gt;fi_inode = igrab(ino);
 		fp-&gt;fi_id = current_fileid++;
+		fp-&gt;fi_had_conflict = false;
 		return fp;
 	}
 	return NULL;
@@ -1328,6 +1331,7 @@ do_recall(void *__dp)
 {
 	struct nfs4_delegation *dp = __dp;
 
+	dp-&gt;dl_file-&gt;fi_had_conflict = true;
 	nfsd4_cb_recall(dp);
 	return 0;
 }
diff --git a/include/linux/nfsd/state.h b/include/linux/nfsd/state.h
index 732de9cad4a8..db348f749376 100644
--- a/include/linux/nfsd/state.h
+++ b/include/linux/nfsd/state.h
@@ -224,6 +224,7 @@ struct nfs4_file {
 	struct inode		*fi_inode;
 	u32                     fi_id;      /* used with stateowner-&gt;so_id 
 					     * for stateid_hashtbl hash */
+	bool			fi_had_conflict;
 };
 
 /*</pre><hr><pre>commit c2f1a551dea8b37c2e0cb886885c250fb703e9d8
Author: Meelap Shah &lt;meelap@umich.edu&gt;
Date:   Tue Jul 17 04:04:39 2007 -0700

    knfsd: nfsd4: vary maximum delegation limit based on RAM size
    
    Our original NFSv4 delegation policy was to give out a read delegation on any
    open when it was possible to.
    
    Since the lifetime of a delegation isn't limited to that of an open, a client
    may quite reasonably hang on to a delegation as long as it has the inode
    cached.  This becomes an obvious problem the first time a client's inode cache
    approaches the size of the server's total memory.
    
    Our first quick solution was to add a hard-coded limit.  This patch makes a
    mild incremental improvement by varying that limit according to the server's
    total memory size, allowing at most 4 delegations per megabyte of RAM.
    
    My quick back-of-the-envelope calculation finds that in the worst case (where
    every delegation is for a different inode), a delegation could take about
    1.5K, which would make the worst case usage about 6% of memory.  The new limit
    works out to be about the same as the old on a 1-gig server.
    
    [akpm@linux-foundation.org: Don't needlessly bloat vmlinux]
    [akpm@linux-foundation.org: Make it right for highmem machines]
    Signed-off-by: "J. Bruce Fields" &lt;bfields@citi.umich.edu&gt;
    Signed-off-by: Neil Brown &lt;neilb@suse.de&gt;
    Signed-off-by: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Signed-off-by: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;

diff --git a/fs/nfsd/nfs4state.c b/fs/nfsd/nfs4state.c
index 9cc31eaf3857..46249886ea86 100644
--- a/fs/nfsd/nfs4state.c
+++ b/fs/nfsd/nfs4state.c
@@ -49,6 +49,7 @@
 #include &lt;linux/nfsd/state.h&gt;
 #include &lt;linux/nfsd/xdr4.h&gt;
 #include &lt;linux/namei.h&gt;
+#include &lt;linux/swap.h&gt;
 #include &lt;linux/mutex.h&gt;
 #include &lt;linux/lockd/bind.h&gt;
 #include &lt;linux/module.h&gt;
@@ -150,6 +151,7 @@ get_nfs4_file(struct nfs4_file *fi)
 }
 
 static int num_delegations;
+unsigned int max_delegations;
 
 /*
  * Open owner state (share locks)
@@ -193,7 +195,7 @@ alloc_init_deleg(struct nfs4_client *clp, struct nfs4_stateid *stp, struct svc_f
 	struct nfs4_callback *cb = &amp;stp-&gt;st_stateowner-&gt;so_client-&gt;cl_callback;
 
 	dprintk("NFSD alloc_init_deleg\n");
-	if (num_delegations &gt; STATEID_HASH_SIZE * 4)
+	if (num_delegations &gt; max_delegations)
 		return NULL;
 	dp = kmem_cache_alloc(deleg_slab, GFP_KERNEL);
 	if (dp == NULL)
@@ -3197,6 +3199,27 @@ get_nfs4_grace_period(void)
 	return max(user_lease_time, lease_time) * HZ;
 }
 
+/*
+ * Since the lifetime of a delegation isn't limited to that of an open, a
+ * client may quite reasonably hang on to a delegation as long as it has
+ * the inode cached.  This becomes an obvious problem the first time a
+ * client's inode cache approaches the size of the server's total memory.
+ *
+ * For now we avoid this problem by imposing a hard limit on the number
+ * of delegations, which varies according to the server's memory size.
+ */
+static void
+set_max_delegations(void)
+{
+	/*
+	 * Allow at most 4 delegations per megabyte of RAM.  Quick
+	 * estimates suggest that in the worst case (where every delegation
+	 * is for a different inode), a delegation could take about 1.5K,
+	 * giving a worst case usage of about 6% of memory.
+	 */
+	max_delegations = nr_free_buffer_pages() &gt;&gt; (20 - 2 - PAGE_SHIFT);
+}
+
 /* initialization to perform when the nfsd service is started: */
 
 static void
@@ -3212,6 +3235,7 @@ __nfs4_state_start(void)
 	       grace_time/HZ);
 	laundry_wq = create_singlethread_workqueue("nfsd4");
 	queue_delayed_work(laundry_wq, &amp;laundromat_work, grace_time);
+	set_max_delegations();
 }
 
 int
diff --git a/include/linux/nfsd/nfsd.h b/include/linux/nfsd/nfsd.h
index 0d8420497765..ce5e345a9bce 100644
--- a/include/linux/nfsd/nfsd.h
+++ b/include/linux/nfsd/nfsd.h
@@ -148,6 +148,7 @@ extern int nfsd_max_blksize;
  * NFSv4 State
  */
 #ifdef CONFIG_NFSD_V4
+extern unsigned int max_delegations;
 void nfs4_state_init(void);
 int nfs4_state_start(void);
 void nfs4_state_shutdown(void);
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 1a889c3fec59..e2a10b957f23 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1484,6 +1484,7 @@ unsigned int nr_free_buffer_pages(void)
 {
 	return nr_free_zone_pages(gfp_zone(GFP_USER));
 }
+EXPORT_SYMBOL_GPL(nr_free_buffer_pages);
 
 /*
  * Amount of free RAM allocatable within all zones</pre><hr><pre>commit 31e6306a4046926b598484f1cacf69309382eac6
Author: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
Date:   Sat Jul 30 20:52:55 2011 -0400

    pnfsblock: note written INVAL areas for layoutcommit
    
    Signed-off-by: Peng Tao &lt;peng_tao@emc.com&gt;
    Signed-off-by: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@tonian.com&gt;
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/fs/nfs/blocklayout/blocklayout.c b/fs/nfs/blocklayout/blocklayout.c
index 2e373826db80..21efef7c2fd2 100644
--- a/fs/nfs/blocklayout/blocklayout.c
+++ b/fs/nfs/blocklayout/blocklayout.c
@@ -329,6 +329,30 @@ bl_read_pagelist(struct nfs_read_data *rdata)
 	return PNFS_NOT_ATTEMPTED;
 }
 
+static void mark_extents_written(struct pnfs_block_layout *bl,
+				 __u64 offset, __u32 count)
+{
+	sector_t isect, end;
+	struct pnfs_block_extent *be;
+
+	dprintk("%s(%llu, %u)\n", __func__, offset, count);
+	if (count == 0)
+		return;
+	isect = (offset &amp; (long)(PAGE_CACHE_MASK)) &gt;&gt; SECTOR_SHIFT;
+	end = (offset + count + PAGE_CACHE_SIZE - 1) &amp; (long)(PAGE_CACHE_MASK);
+	end &gt;&gt;= SECTOR_SHIFT;
+	while (isect &lt; end) {
+		sector_t len;
+		be = bl_find_get_extent(bl, isect, NULL);
+		BUG_ON(!be); /* FIXME */
+		len = min(end, be-&gt;be_f_offset + be-&gt;be_length) - isect;
+		if (be-&gt;be_state == PNFS_BLOCK_INVALID_DATA)
+			bl_mark_for_commit(be, isect, len); /* What if fails? */
+		isect += len;
+		bl_put_extent(be);
+	}
+}
+
 /* This is basically copied from mpage_end_io_read */
 static void bl_end_io_write(struct bio *bio, int err)
 {
@@ -355,6 +379,14 @@ static void bl_write_cleanup(struct work_struct *work)
 	dprintk("%s enter\n", __func__);
 	task = container_of(work, struct rpc_task, u.tk_work);
 	wdata = container_of(task, struct nfs_write_data, task);
+	if (!wdata-&gt;task.tk_status) {
+		/* Marks for LAYOUTCOMMIT */
+		/* BUG - this should be called after each bio, not after
+		 * all finish, unless have some way of storing success/failure
+		 */
+		mark_extents_written(BLK_LSEG2EXT(wdata-&gt;lseg),
+				     wdata-&gt;args.offset, wdata-&gt;args.count);
+	}
 	pnfs_ld_write_done(wdata);
 }
 
diff --git a/fs/nfs/blocklayout/blocklayout.h b/fs/nfs/blocklayout/blocklayout.h
index 6a703b79c33d..f27d827960a3 100644
--- a/fs/nfs/blocklayout/blocklayout.h
+++ b/fs/nfs/blocklayout/blocklayout.h
@@ -201,5 +201,7 @@ void clean_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
 				   int status);
 int bl_add_merge_extent(struct pnfs_block_layout *bl,
 			 struct pnfs_block_extent *new);
+int bl_mark_for_commit(struct pnfs_block_extent *be,
+			sector_t offset, sector_t length);
 
 #endif /* FS_NFS_NFS4BLOCKLAYOUT_H */
diff --git a/fs/nfs/blocklayout/extents.c b/fs/nfs/blocklayout/extents.c
index 7521940dcca5..19fa7b0b8c00 100644
--- a/fs/nfs/blocklayout/extents.c
+++ b/fs/nfs/blocklayout/extents.c
@@ -217,6 +217,48 @@ int bl_is_sector_init(struct pnfs_inval_markings *marks, sector_t isect)
 	return rv;
 }
 
+/* Assume start, end already sector aligned */
+static int
+_range_has_tag(struct my_tree *tree, u64 start, u64 end, int32_t tag)
+{
+	struct pnfs_inval_tracking *pos;
+	u64 expect = 0;
+
+	dprintk("%s(%llu, %llu, %i) enter\n", __func__, start, end, tag);
+	list_for_each_entry_reverse(pos, &amp;tree-&gt;mtt_stub, it_link) {
+		if (pos-&gt;it_sector &gt;= end)
+			continue;
+		if (!expect) {
+			if ((pos-&gt;it_sector == end - tree-&gt;mtt_step_size) &amp;&amp;
+			    (pos-&gt;it_tags &amp; (1 &lt;&lt; tag))) {
+				expect = pos-&gt;it_sector - tree-&gt;mtt_step_size;
+				if (pos-&gt;it_sector &lt; tree-&gt;mtt_step_size || expect &lt; start)
+					return 1;
+				continue;
+			} else {
+				return 0;
+			}
+		}
+		if (pos-&gt;it_sector != expect || !(pos-&gt;it_tags &amp; (1 &lt;&lt; tag)))
+			return 0;
+		expect -= tree-&gt;mtt_step_size;
+		if (expect &lt; start)
+			return 1;
+	}
+	return 0;
+}
+
+static int is_range_written(struct pnfs_inval_markings *marks,
+			    sector_t start, sector_t end)
+{
+	int rv;
+
+	spin_lock(&amp;marks-&gt;im_lock);
+	rv = _range_has_tag(&amp;marks-&gt;im_tree, start, end, EXTENT_WRITTEN);
+	spin_unlock(&amp;marks-&gt;im_lock);
+	return rv;
+}
+
 /* Marks sectors in [offest, offset_length) as having been initialized.
  * All lengths are step-aligned, where step is min(pagesize, blocksize).
  * Notes where partial block is initialized, and helps prepare it for
@@ -396,6 +438,59 @@ static void add_to_commitlist(struct pnfs_block_layout *bl,
 	print_clist(clist, bl-&gt;bl_count);
 }
 
+/* Note the range described by offset, length is guaranteed to be contained
+ * within be.
+ */
+int bl_mark_for_commit(struct pnfs_block_extent *be,
+		    sector_t offset, sector_t length)
+{
+	sector_t new_end, end = offset + length;
+	struct pnfs_block_short_extent *new;
+	struct pnfs_block_layout *bl = container_of(be-&gt;be_inval,
+						    struct pnfs_block_layout,
+						    bl_inval);
+
+	new = kmalloc(sizeof(*new), GFP_NOFS);
+	if (!new)
+		return -ENOMEM;
+
+	mark_written_sectors(be-&gt;be_inval, offset, length);
+	/* We want to add the range to commit list, but it must be
+	 * block-normalized, and verified that the normalized range has
+	 * been entirely written to disk.
+	 */
+	new-&gt;bse_f_offset = offset;
+	offset = normalize(offset, bl-&gt;bl_blocksize);
+	if (offset &lt; new-&gt;bse_f_offset) {
+		if (is_range_written(be-&gt;be_inval, offset, new-&gt;bse_f_offset))
+			new-&gt;bse_f_offset = offset;
+		else
+			new-&gt;bse_f_offset = offset + bl-&gt;bl_blocksize;
+	}
+	new_end = normalize_up(end, bl-&gt;bl_blocksize);
+	if (end &lt; new_end) {
+		if (is_range_written(be-&gt;be_inval, end, new_end))
+			end = new_end;
+		else
+			end = new_end - bl-&gt;bl_blocksize;
+	}
+	if (end &lt;= new-&gt;bse_f_offset) {
+		kfree(new);
+		return 0;
+	}
+	new-&gt;bse_length = end - new-&gt;bse_f_offset;
+	new-&gt;bse_devid = be-&gt;be_devid;
+	new-&gt;bse_mdev = be-&gt;be_mdev;
+
+	spin_lock(&amp;bl-&gt;bl_ext_lock);
+	/* new will be freed, either by add_to_commitlist if it decides not
+	 * to use it, or after LAYOUTCOMMIT uses it in the commitlist.
+	 */
+	add_to_commitlist(bl, new);
+	spin_unlock(&amp;bl-&gt;bl_ext_lock);
+	return 0;
+}
+
 static void print_bl_extent(struct pnfs_block_extent *be)
 {
 	dprintk("PRINT EXTENT extent %p\n", be);</pre><hr><pre>commit 650e2d39bd8f6b99f39b5009dbed9fbd3bb65e54
Author: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
Date:   Sat Jul 30 20:52:54 2011 -0400

    pnfsblock: bl_write_pagelist
    
    Note: When upper layer's read/write request cannot be fulfilled, the block
    layout driver shouldn't silently mark the page as error. It should do
    what can be done and  leave the rest to the upper layer. To do so, we
    should set rdata/wdata-&gt;res.count properly.
    
    When upper layer re-send the read/write request to finish the rest
    part of the request, pgbase is the position where we should start at.
    
    [pnfsblock: bl_write_pagelist support functions]
    [pnfsblock: bl_write_pagelist adjust for missing PG_USE_PNFS]
    Signed-off-by: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
    [pnfsblock: handle errors when read or write pagelist.]
    Signed-off-by: Zhang Jingwang &lt;yyalone@gmail.com&gt;
    [pnfs-block: use new write_pagelist api]
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@tonian.com&gt;
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    
    [SQUASHME: pnfsblock: mds_offset is set in the generic layer]
    Signed-off-by: Boaz Harrosh &lt;bharrosh@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@tonian.com&gt;
    
    [pnfsblock: mark IO error with NFS_LAYOUT_{RW|RO}_FAILED]
    Signed-off-by: Peng Tao &lt;peng_tao@emc.com&gt;
    [pnfsblock: SQUASHME: adjust to API change]
    Signed-off-by: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
    [pnfsblock: fixup blksize alignment in bl_setup_layoutcommit]
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@tonian.com&gt;
    [pnfsblock: bl_write_pagelist adjust for missing PG_USE_PNFS]
    Signed-off-by: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
    [pnfsblock: handle errors when read or write pagelist.]
    Signed-off-by: Zhang Jingwang &lt;yyalone@gmail.com&gt;
    [pnfs-block: use new write_pagelist api]
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@tonian.com&gt;
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/fs/nfs/blocklayout/blocklayout.c b/fs/nfs/blocklayout/blocklayout.c
index facb5ba21204..2e373826db80 100644
--- a/fs/nfs/blocklayout/blocklayout.c
+++ b/fs/nfs/blocklayout/blocklayout.c
@@ -74,6 +74,19 @@ static int is_hole(struct pnfs_block_extent *be, sector_t isect)
 		return !bl_is_sector_init(be-&gt;be_inval, isect);
 }
 
+/* Given the be associated with isect, determine if page data can be
+ * written to disk.
+ */
+static int is_writable(struct pnfs_block_extent *be, sector_t isect)
+{
+	if (be-&gt;be_state == PNFS_BLOCK_READWRITE_DATA)
+		return 1;
+	else if (be-&gt;be_state != PNFS_BLOCK_INVALID_DATA)
+		return 0;
+	else
+		return bl_is_sector_init(be-&gt;be_inval, isect);
+}
+
 /* The data we are handed might be spread across several bios.  We need
  * to track when the last one is finished.
  */
@@ -316,11 +329,121 @@ bl_read_pagelist(struct nfs_read_data *rdata)
 	return PNFS_NOT_ATTEMPTED;
 }
 
+/* This is basically copied from mpage_end_io_read */
+static void bl_end_io_write(struct bio *bio, int err)
+{
+	struct parallel_io *par = bio-&gt;bi_private;
+	const int uptodate = test_bit(BIO_UPTODATE, &amp;bio-&gt;bi_flags);
+	struct nfs_write_data *wdata = (struct nfs_write_data *)par-&gt;data;
+
+	if (!uptodate) {
+		if (!wdata-&gt;pnfs_error)
+			wdata-&gt;pnfs_error = -EIO;
+		bl_set_lo_fail(wdata-&gt;lseg);
+	}
+	bio_put(bio);
+	put_parallel(par);
+}
+
+/* Function scheduled for call during bl_end_par_io_write,
+ * it marks sectors as written and extends the commitlist.
+ */
+static void bl_write_cleanup(struct work_struct *work)
+{
+	struct rpc_task *task;
+	struct nfs_write_data *wdata;
+	dprintk("%s enter\n", __func__);
+	task = container_of(work, struct rpc_task, u.tk_work);
+	wdata = container_of(task, struct nfs_write_data, task);
+	pnfs_ld_write_done(wdata);
+}
+
+/* Called when last of bios associated with a bl_write_pagelist call finishes */
+static void
+bl_end_par_io_write(void *data)
+{
+	struct nfs_write_data *wdata = data;
+
+	/* STUB - ignoring error handling */
+	wdata-&gt;task.tk_status = 0;
+	wdata-&gt;verf.committed = NFS_FILE_SYNC;
+	INIT_WORK(&amp;wdata-&gt;task.u.tk_work, bl_write_cleanup);
+	schedule_work(&amp;wdata-&gt;task.u.tk_work);
+}
+
 static enum pnfs_try_status
-bl_write_pagelist(struct nfs_write_data *wdata,
-		  int sync)
+bl_write_pagelist(struct nfs_write_data *wdata, int sync)
 {
-	return PNFS_NOT_ATTEMPTED;
+	int i;
+	struct bio *bio = NULL;
+	struct pnfs_block_extent *be = NULL;
+	sector_t isect, extent_length = 0;
+	struct parallel_io *par;
+	loff_t offset = wdata-&gt;args.offset;
+	size_t count = wdata-&gt;args.count;
+	struct page **pages = wdata-&gt;args.pages;
+	int pg_index = wdata-&gt;args.pgbase &gt;&gt; PAGE_CACHE_SHIFT;
+
+	dprintk("%s enter, %Zu@%lld\n", __func__, count, offset);
+	/* At this point, wdata-&gt;pages is a (sequential) list of nfs_pages.
+	 * We want to write each, and if there is an error remove it from
+	 * list and call
+	 * nfs_retry_request(req) to have it redone using nfs.
+	 * QUEST? Do as block or per req?  Think have to do per block
+	 * as part of end_bio
+	 */
+	par = alloc_parallel(wdata);
+	if (!par)
+		return PNFS_NOT_ATTEMPTED;
+	par-&gt;call_ops = *wdata-&gt;mds_ops;
+	par-&gt;call_ops.rpc_call_done = bl_rpc_do_nothing;
+	par-&gt;pnfs_callback = bl_end_par_io_write;
+	/* At this point, have to be more careful with error handling */
+
+	isect = (sector_t) ((offset &amp; (long)PAGE_CACHE_MASK) &gt;&gt; SECTOR_SHIFT);
+	for (i = pg_index; i &lt; wdata-&gt;npages ; i++) {
+		if (!extent_length) {
+			/* We've used up the previous extent */
+			bl_put_extent(be);
+			bio = bl_submit_bio(WRITE, bio);
+			/* Get the next one */
+			be = bl_find_get_extent(BLK_LSEG2EXT(wdata-&gt;lseg),
+					     isect, NULL);
+			if (!be || !is_writable(be, isect)) {
+				wdata-&gt;pnfs_error = -ENOMEM;
+				goto out;
+			}
+			extent_length = be-&gt;be_length -
+				(isect - be-&gt;be_f_offset);
+		}
+		for (;;) {
+			if (!bio) {
+				bio = bio_alloc(GFP_NOIO, wdata-&gt;npages - i);
+				if (!bio) {
+					wdata-&gt;pnfs_error = -ENOMEM;
+					goto out;
+				}
+				bio-&gt;bi_sector = isect - be-&gt;be_f_offset +
+					be-&gt;be_v_offset;
+				bio-&gt;bi_bdev = be-&gt;be_mdev;
+				bio-&gt;bi_end_io = bl_end_io_write;
+				bio-&gt;bi_private = par;
+			}
+			if (bio_add_page(bio, pages[i], PAGE_SIZE, 0))
+				break;
+			bio = bl_submit_bio(WRITE, bio);
+		}
+		isect += PAGE_CACHE_SECTORS;
+		extent_length -= PAGE_CACHE_SECTORS;
+	}
+	wdata-&gt;res.count = (isect &lt;&lt; SECTOR_SHIFT) - (offset);
+	if (count &lt; wdata-&gt;res.count)
+		wdata-&gt;res.count = count;
+out:
+	bl_put_extent(be);
+	bl_submit_bio(WRITE, bio);
+	put_parallel(par);
+	return PNFS_ATTEMPTED;
 }
 
 /* FIXME - range ignored */</pre><hr><pre>commit 9549ec01b0dcf1c1eb277cba60067236b3f48508
Author: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
Date:   Sat Jul 30 20:52:53 2011 -0400

    pnfsblock: bl_read_pagelist
    
    Note: When upper layer's read/write request cannot be fulfilled, the block
    layout driver shouldn't silently mark the page as error. It should do
    what can be done and  leave the rest to the upper layer. To do so, we
    should set rdata/wdata-&gt;res.count properly.
    
    When upper layer re-send the read/write request to finish the rest
    part of the request, pgbase is the position where we should start at.
    
    [pnfsblock: mark IO error with NFS_LAYOUT_{RW|RO}_FAILED]
    Signed-off-by: Peng Tao &lt;peng_tao@emc.com&gt;
    [pnfsblock: read path error handling]
    Signed-off-by: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
    [pnfsblock: handle errors when read or write pagelist.]
    Signed-off-by: Zhang Jingwang &lt;yyalone@gmail.com&gt;
    [pnfs-block: use new read_pagelist api]
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@tonian.com&gt;
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/fs/nfs/blocklayout/blocklayout.c b/fs/nfs/blocklayout/blocklayout.c
index 6c1bafb8920b..facb5ba21204 100644
--- a/fs/nfs/blocklayout/blocklayout.c
+++ b/fs/nfs/blocklayout/blocklayout.c
@@ -29,10 +29,12 @@
  * of the software, even if it has been or is hereafter advised of the
  * possibility of such damages.
  */
+
 #include &lt;linux/module.h&gt;
 #include &lt;linux/init.h&gt;
 #include &lt;linux/mount.h&gt;
 #include &lt;linux/namei.h&gt;
+#include &lt;linux/bio.h&gt;		/* struct bio */
 
 #include "blocklayout.h"
 
@@ -45,9 +47,272 @@ MODULE_DESCRIPTION("The NFSv4.1 pNFS Block layout driver");
 struct dentry *bl_device_pipe;
 wait_queue_head_t bl_wq;
 
+static void print_page(struct page *page)
+{
+	dprintk("PRINTPAGE page %p\n", page);
+	dprintk("	PagePrivate %d\n", PagePrivate(page));
+	dprintk("	PageUptodate %d\n", PageUptodate(page));
+	dprintk("	PageError %d\n", PageError(page));
+	dprintk("	PageDirty %d\n", PageDirty(page));
+	dprintk("	PageReferenced %d\n", PageReferenced(page));
+	dprintk("	PageLocked %d\n", PageLocked(page));
+	dprintk("	PageWriteback %d\n", PageWriteback(page));
+	dprintk("	PageMappedToDisk %d\n", PageMappedToDisk(page));
+	dprintk("\n");
+}
+
+/* Given the be associated with isect, determine if page data needs to be
+ * initialized.
+ */
+static int is_hole(struct pnfs_block_extent *be, sector_t isect)
+{
+	if (be-&gt;be_state == PNFS_BLOCK_NONE_DATA)
+		return 1;
+	else if (be-&gt;be_state != PNFS_BLOCK_INVALID_DATA)
+		return 0;
+	else
+		return !bl_is_sector_init(be-&gt;be_inval, isect);
+}
+
+/* The data we are handed might be spread across several bios.  We need
+ * to track when the last one is finished.
+ */
+struct parallel_io {
+	struct kref refcnt;
+	struct rpc_call_ops call_ops;
+	void (*pnfs_callback) (void *data);
+	void *data;
+};
+
+static inline struct parallel_io *alloc_parallel(void *data)
+{
+	struct parallel_io *rv;
+
+	rv  = kmalloc(sizeof(*rv), GFP_NOFS);
+	if (rv) {
+		rv-&gt;data = data;
+		kref_init(&amp;rv-&gt;refcnt);
+	}
+	return rv;
+}
+
+static inline void get_parallel(struct parallel_io *p)
+{
+	kref_get(&amp;p-&gt;refcnt);
+}
+
+static void destroy_parallel(struct kref *kref)
+{
+	struct parallel_io *p = container_of(kref, struct parallel_io, refcnt);
+
+	dprintk("%s enter\n", __func__);
+	p-&gt;pnfs_callback(p-&gt;data);
+	kfree(p);
+}
+
+static inline void put_parallel(struct parallel_io *p)
+{
+	kref_put(&amp;p-&gt;refcnt, destroy_parallel);
+}
+
+static struct bio *
+bl_submit_bio(int rw, struct bio *bio)
+{
+	if (bio) {
+		get_parallel(bio-&gt;bi_private);
+		dprintk("%s submitting %s bio %u@%llu\n", __func__,
+			rw == READ ? "read" : "write",
+			bio-&gt;bi_size, (unsigned long long)bio-&gt;bi_sector);
+		submit_bio(rw, bio);
+	}
+	return NULL;
+}
+
+static struct bio *bl_alloc_init_bio(int npg, sector_t isect,
+				     struct pnfs_block_extent *be,
+				     void (*end_io)(struct bio *, int err),
+				     struct parallel_io *par)
+{
+	struct bio *bio;
+
+	bio = bio_alloc(GFP_NOIO, npg);
+	if (!bio)
+		return NULL;
+
+	bio-&gt;bi_sector = isect - be-&gt;be_f_offset + be-&gt;be_v_offset;
+	bio-&gt;bi_bdev = be-&gt;be_mdev;
+	bio-&gt;bi_end_io = end_io;
+	bio-&gt;bi_private = par;
+	return bio;
+}
+
+static struct bio *bl_add_page_to_bio(struct bio *bio, int npg, int rw,
+				      sector_t isect, struct page *page,
+				      struct pnfs_block_extent *be,
+				      void (*end_io)(struct bio *, int err),
+				      struct parallel_io *par)
+{
+retry:
+	if (!bio) {
+		bio = bl_alloc_init_bio(npg, isect, be, end_io, par);
+		if (!bio)
+			return ERR_PTR(-ENOMEM);
+	}
+	if (bio_add_page(bio, page, PAGE_CACHE_SIZE, 0) &lt; PAGE_CACHE_SIZE) {
+		bio = bl_submit_bio(rw, bio);
+		goto retry;
+	}
+	return bio;
+}
+
+static void bl_set_lo_fail(struct pnfs_layout_segment *lseg)
+{
+	if (lseg-&gt;pls_range.iomode == IOMODE_RW) {
+		dprintk("%s Setting layout IOMODE_RW fail bit\n", __func__);
+		set_bit(lo_fail_bit(IOMODE_RW), &amp;lseg-&gt;pls_layout-&gt;plh_flags);
+	} else {
+		dprintk("%s Setting layout IOMODE_READ fail bit\n", __func__);
+		set_bit(lo_fail_bit(IOMODE_READ), &amp;lseg-&gt;pls_layout-&gt;plh_flags);
+	}
+}
+
+/* This is basically copied from mpage_end_io_read */
+static void bl_end_io_read(struct bio *bio, int err)
+{
+	struct parallel_io *par = bio-&gt;bi_private;
+	const int uptodate = test_bit(BIO_UPTODATE, &amp;bio-&gt;bi_flags);
+	struct bio_vec *bvec = bio-&gt;bi_io_vec + bio-&gt;bi_vcnt - 1;
+	struct nfs_read_data *rdata = (struct nfs_read_data *)par-&gt;data;
+
+	do {
+		struct page *page = bvec-&gt;bv_page;
+
+		if (--bvec &gt;= bio-&gt;bi_io_vec)
+			prefetchw(&amp;bvec-&gt;bv_page-&gt;flags);
+		if (uptodate)
+			SetPageUptodate(page);
+	} while (bvec &gt;= bio-&gt;bi_io_vec);
+	if (!uptodate) {
+		if (!rdata-&gt;pnfs_error)
+			rdata-&gt;pnfs_error = -EIO;
+		bl_set_lo_fail(rdata-&gt;lseg);
+	}
+	bio_put(bio);
+	put_parallel(par);
+}
+
+static void bl_read_cleanup(struct work_struct *work)
+{
+	struct rpc_task *task;
+	struct nfs_read_data *rdata;
+	dprintk("%s enter\n", __func__);
+	task = container_of(work, struct rpc_task, u.tk_work);
+	rdata = container_of(task, struct nfs_read_data, task);
+	pnfs_ld_read_done(rdata);
+}
+
+static void
+bl_end_par_io_read(void *data)
+{
+	struct nfs_read_data *rdata = data;
+
+	INIT_WORK(&amp;rdata-&gt;task.u.tk_work, bl_read_cleanup);
+	schedule_work(&amp;rdata-&gt;task.u.tk_work);
+}
+
+/* We don't want normal .rpc_call_done callback used, so we replace it
+ * with this stub.
+ */
+static void bl_rpc_do_nothing(struct rpc_task *task, void *calldata)
+{
+	return;
+}
+
 static enum pnfs_try_status
 bl_read_pagelist(struct nfs_read_data *rdata)
 {
+	int i, hole;
+	struct bio *bio = NULL;
+	struct pnfs_block_extent *be = NULL, *cow_read = NULL;
+	sector_t isect, extent_length = 0;
+	struct parallel_io *par;
+	loff_t f_offset = rdata-&gt;args.offset;
+	size_t count = rdata-&gt;args.count;
+	struct page **pages = rdata-&gt;args.pages;
+	int pg_index = rdata-&gt;args.pgbase &gt;&gt; PAGE_CACHE_SHIFT;
+
+	dprintk("%s enter nr_pages %u offset %lld count %Zd\n", __func__,
+	       rdata-&gt;npages, f_offset, count);
+
+	par = alloc_parallel(rdata);
+	if (!par)
+		goto use_mds;
+	par-&gt;call_ops = *rdata-&gt;mds_ops;
+	par-&gt;call_ops.rpc_call_done = bl_rpc_do_nothing;
+	par-&gt;pnfs_callback = bl_end_par_io_read;
+	/* At this point, we can no longer jump to use_mds */
+
+	isect = (sector_t) (f_offset &gt;&gt; SECTOR_SHIFT);
+	/* Code assumes extents are page-aligned */
+	for (i = pg_index; i &lt; rdata-&gt;npages; i++) {
+		if (!extent_length) {
+			/* We've used up the previous extent */
+			bl_put_extent(be);
+			bl_put_extent(cow_read);
+			bio = bl_submit_bio(READ, bio);
+			/* Get the next one */
+			be = bl_find_get_extent(BLK_LSEG2EXT(rdata-&gt;lseg),
+					     isect, &amp;cow_read);
+			if (!be) {
+				rdata-&gt;pnfs_error = -EIO;
+				goto out;
+			}
+			extent_length = be-&gt;be_length -
+				(isect - be-&gt;be_f_offset);
+			if (cow_read) {
+				sector_t cow_length = cow_read-&gt;be_length -
+					(isect - cow_read-&gt;be_f_offset);
+				extent_length = min(extent_length, cow_length);
+			}
+		}
+		hole = is_hole(be, isect);
+		if (hole &amp;&amp; !cow_read) {
+			bio = bl_submit_bio(READ, bio);
+			/* Fill hole w/ zeroes w/o accessing device */
+			dprintk("%s Zeroing page for hole\n", __func__);
+			zero_user_segment(pages[i], 0, PAGE_CACHE_SIZE);
+			print_page(pages[i]);
+			SetPageUptodate(pages[i]);
+		} else {
+			struct pnfs_block_extent *be_read;
+
+			be_read = (hole &amp;&amp; cow_read) ? cow_read : be;
+			bio = bl_add_page_to_bio(bio, rdata-&gt;npages - i, READ,
+						 isect, pages[i], be_read,
+						 bl_end_io_read, par);
+			if (IS_ERR(bio)) {
+				rdata-&gt;pnfs_error = PTR_ERR(bio);
+				goto out;
+			}
+		}
+		isect += PAGE_CACHE_SECTORS;
+		extent_length -= PAGE_CACHE_SECTORS;
+	}
+	if ((isect &lt;&lt; SECTOR_SHIFT) &gt;= rdata-&gt;inode-&gt;i_size) {
+		rdata-&gt;res.eof = 1;
+		rdata-&gt;res.count = rdata-&gt;inode-&gt;i_size - f_offset;
+	} else {
+		rdata-&gt;res.count = (isect &lt;&lt; SECTOR_SHIFT) - f_offset;
+	}
+out:
+	bl_put_extent(be);
+	bl_put_extent(cow_read);
+	bl_submit_bio(READ, bio);
+	put_parallel(par);
+	return PNFS_ATTEMPTED;
+
+ use_mds:
+	dprintk("Giving up and using normal NFS\n");
 	return PNFS_NOT_ATTEMPTED;
 }
 </pre><hr><pre>commit b2be7811dd94816f3df76708c8eb7f55bf7289e2
Author: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
Date:   Sat Jul 30 20:52:52 2011 -0400

    pnfsblock: cleanup_layoutcommit
    
    In blocklayout driver. There are two things happening
    while layoutcommit/cleanup.
    1. the modified extents are encoded.
    2. On cleanup the extents are put back on the layout rw
       extents list, for reads.
    
    In the new system where actual xdr encoding is done in
    encode_layoutcommit() directly into xdr buffer, these are
    the new commit stages:
    
    1. On setup_layoutcommit, the range is adjusted as before
       and a structure is allocated for communication with
       bl_encode_layoutcommit &amp;&amp; bl_cleanup_layoutcommit
       (Generic layer provides a void-star to hang it on)
    
    2. bl_encode_layoutcommit is called to do the actual
       encoding directly into xdr. The commit-extent-list is not
       freed and is stored on above structure.
       FIXME: The code is not yet converted to the new XDR cleanup
    
    3. On cleanup the commit-extent-list is put back by a call
       to set_to_rw() as before, but with no need for XDR decoding
       of the list as before. And the commit-extent-list is freed.
       Finally allocated structure is freed.
    
    [rm inode and pnfs_layout_hdr args from cleanup_layoutcommit()]
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    [pnfsblock: introduce bl_committing list]
    Signed-off-by: Peng Tao &lt;peng_tao@emc.com&gt;
    [pnfsblock: SQUASHME: adjust to API change]
    Signed-off-by: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
    [blocklayout: encode_layoutcommit implementation]
    Signed-off-by: Boaz Harrosh &lt;bharrosh@panasas.com&gt;
    [pnfsblock: fix bug setting up layoutcommit.]
    Signed-off-by: Tao Guo &lt;guotao@nrchpc.ac.cn&gt;
    [pnfsblock: cleanup_layoutcommit wants a status parameter]
    Signed-off-by: Boaz Harrosh &lt;bharrosh@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@tonian.com&gt;
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/fs/nfs/blocklayout/blocklayout.c b/fs/nfs/blocklayout/blocklayout.c
index d096835cfd6b..6c1bafb8920b 100644
--- a/fs/nfs/blocklayout/blocklayout.c
+++ b/fs/nfs/blocklayout/blocklayout.c
@@ -162,6 +162,10 @@ bl_encode_layoutcommit(struct pnfs_layout_hdr *lo, struct xdr_stream *xdr,
 static void
 bl_cleanup_layoutcommit(struct nfs4_layoutcommit_data *lcdata)
 {
+	struct pnfs_layout_hdr *lo = NFS_I(lcdata-&gt;args.inode)-&gt;layout;
+
+	dprintk("%s enter\n", __func__);
+	clean_pnfs_block_layoutupdate(BLK_LO2EXT(lo), &amp;lcdata-&gt;args, lcdata-&gt;res.status);
 }
 
 static void free_blk_mountid(struct block_mount_id *mid)
diff --git a/fs/nfs/blocklayout/blocklayout.h b/fs/nfs/blocklayout/blocklayout.h
index 3caaefce85a5..6a703b79c33d 100644
--- a/fs/nfs/blocklayout/blocklayout.h
+++ b/fs/nfs/blocklayout/blocklayout.h
@@ -196,6 +196,9 @@ int bl_is_sector_init(struct pnfs_inval_markings *marks, sector_t isect);
 int encode_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
 				   struct xdr_stream *xdr,
 				   const struct nfs4_layoutcommit_args *arg);
+void clean_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
+				   const struct nfs4_layoutcommit_args *arg,
+				   int status);
 int bl_add_merge_extent(struct pnfs_block_layout *bl,
 			 struct pnfs_block_extent *new);
 
diff --git a/fs/nfs/blocklayout/extents.c b/fs/nfs/blocklayout/extents.c
index 84bf24087720..7521940dcca5 100644
--- a/fs/nfs/blocklayout/extents.c
+++ b/fs/nfs/blocklayout/extents.c
@@ -329,6 +329,73 @@ static void print_clist(struct list_head *list, unsigned int count)
 	}
 }
 
+/* Note: In theory, we should do more checking that devid's match between
+ * old and new, but if they don't, the lists are too corrupt to salvage anyway.
+ */
+/* Note this is very similar to bl_add_merge_extent */
+static void add_to_commitlist(struct pnfs_block_layout *bl,
+			      struct pnfs_block_short_extent *new)
+{
+	struct list_head *clist = &amp;bl-&gt;bl_commit;
+	struct pnfs_block_short_extent *old, *save;
+	sector_t end = new-&gt;bse_f_offset + new-&gt;bse_length;
+
+	dprintk("%s enter\n", __func__);
+	print_short_extent(new);
+	print_clist(clist, bl-&gt;bl_count);
+	bl-&gt;bl_count++;
+	/* Scan for proper place to insert, extending new to the left
+	 * as much as possible.
+	 */
+	list_for_each_entry_safe(old, save, clist, bse_node) {
+		if (new-&gt;bse_f_offset &lt; old-&gt;bse_f_offset)
+			break;
+		if (end &lt;= old-&gt;bse_f_offset + old-&gt;bse_length) {
+			/* Range is already in list */
+			bl-&gt;bl_count--;
+			kfree(new);
+			return;
+		} else if (new-&gt;bse_f_offset &lt;=
+				old-&gt;bse_f_offset + old-&gt;bse_length) {
+			/* new overlaps or abuts existing be */
+			if (new-&gt;bse_mdev == old-&gt;bse_mdev) {
+				/* extend new to fully replace old */
+				new-&gt;bse_length += new-&gt;bse_f_offset -
+						old-&gt;bse_f_offset;
+				new-&gt;bse_f_offset = old-&gt;bse_f_offset;
+				list_del(&amp;old-&gt;bse_node);
+				bl-&gt;bl_count--;
+				kfree(old);
+			}
+		}
+	}
+	/* Note that if we never hit the above break, old will not point to a
+	 * valid extent.  However, in that case &amp;old-&gt;bse_node==list.
+	 */
+	list_add_tail(&amp;new-&gt;bse_node, &amp;old-&gt;bse_node);
+	/* Scan forward for overlaps.  If we find any, extend new and
+	 * remove the overlapped extent.
+	 */
+	old = list_prepare_entry(new, clist, bse_node);
+	list_for_each_entry_safe_continue(old, save, clist, bse_node) {
+		if (end &lt; old-&gt;bse_f_offset)
+			break;
+		/* new overlaps or abuts old */
+		if (new-&gt;bse_mdev == old-&gt;bse_mdev) {
+			if (end &lt; old-&gt;bse_f_offset + old-&gt;bse_length) {
+				/* extend new to fully cover old */
+				end = old-&gt;bse_f_offset + old-&gt;bse_length;
+				new-&gt;bse_length = end - new-&gt;bse_f_offset;
+			}
+			list_del(&amp;old-&gt;bse_node);
+			bl-&gt;bl_count--;
+			kfree(old);
+		}
+	}
+	dprintk("%s: after merging\n", __func__);
+	print_clist(clist, bl-&gt;bl_count);
+}
+
 static void print_bl_extent(struct pnfs_block_extent *be)
 {
 	dprintk("PRINT EXTENT extent %p\n", be);
@@ -539,6 +606,34 @@ bl_find_get_extent(struct pnfs_block_layout *bl, sector_t isect,
 	return ret;
 }
 
+/* Similar to bl_find_get_extent, but called with lock held, and ignores cow */
+static struct pnfs_block_extent *
+bl_find_get_extent_locked(struct pnfs_block_layout *bl, sector_t isect)
+{
+	struct pnfs_block_extent *be, *ret = NULL;
+	int i;
+
+	dprintk("%s enter with isect %llu\n", __func__, (u64)isect);
+	for (i = 0; i &lt; EXTENT_LISTS; i++) {
+		if (ret)
+			break;
+		list_for_each_entry_reverse(be, &amp;bl-&gt;bl_extents[i], be_node) {
+			if (isect &gt;= be-&gt;be_f_offset + be-&gt;be_length)
+				break;
+			if (isect &gt;= be-&gt;be_f_offset) {
+				/* We have found an extent */
+				dprintk("%s Get %p (%i)\n", __func__, be,
+					atomic_read(&amp;be-&gt;be_refcnt.refcount));
+				kref_get(&amp;be-&gt;be_refcnt);
+				ret = be;
+				break;
+			}
+		}
+	}
+	print_bl_extent(ret);
+	return ret;
+}
+
 int
 encode_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
 			       struct xdr_stream *xdr,
@@ -628,3 +723,118 @@ _front_merge(struct pnfs_block_extent *be, struct list_head *head,
 	kfree(storage);
 	return be;
 }
+
+static u64
+set_to_rw(struct pnfs_block_layout *bl, u64 offset, u64 length)
+{
+	u64 rv = offset + length;
+	struct pnfs_block_extent *be, *e1, *e2, *e3, *new, *old;
+	struct pnfs_block_extent *children[3];
+	struct pnfs_block_extent *merge1 = NULL, *merge2 = NULL;
+	int i = 0, j;
+
+	dprintk("%s(%llu, %llu)\n", __func__, offset, length);
+	/* Create storage for up to three new extents e1, e2, e3 */
+	e1 = kmalloc(sizeof(*e1), GFP_ATOMIC);
+	e2 = kmalloc(sizeof(*e2), GFP_ATOMIC);
+	e3 = kmalloc(sizeof(*e3), GFP_ATOMIC);
+	/* BUG - we are ignoring any failure */
+	if (!e1 || !e2 || !e3)
+		goto out_nosplit;
+
+	spin_lock(&amp;bl-&gt;bl_ext_lock);
+	be = bl_find_get_extent_locked(bl, offset);
+	rv = be-&gt;be_f_offset + be-&gt;be_length;
+	if (be-&gt;be_state != PNFS_BLOCK_INVALID_DATA) {
+		spin_unlock(&amp;bl-&gt;bl_ext_lock);
+		goto out_nosplit;
+	}
+	/* Add e* to children, bumping e*'s krefs */
+	if (be-&gt;be_f_offset != offset) {
+		_prep_new_extent(e1, be, be-&gt;be_f_offset,
+				 offset - be-&gt;be_f_offset,
+				 PNFS_BLOCK_INVALID_DATA);
+		children[i++] = e1;
+		print_bl_extent(e1);
+	} else
+		merge1 = e1;
+	_prep_new_extent(e2, be, offset,
+			 min(length, be-&gt;be_f_offset + be-&gt;be_length - offset),
+			 PNFS_BLOCK_READWRITE_DATA);
+	children[i++] = e2;
+	print_bl_extent(e2);
+	if (offset + length &lt; be-&gt;be_f_offset + be-&gt;be_length) {
+		_prep_new_extent(e3, be, e2-&gt;be_f_offset + e2-&gt;be_length,
+				 be-&gt;be_f_offset + be-&gt;be_length -
+				 offset - length,
+				 PNFS_BLOCK_INVALID_DATA);
+		children[i++] = e3;
+		print_bl_extent(e3);
+	} else
+		merge2 = e3;
+
+	/* Remove be from list, and insert the e* */
+	/* We don't get refs on e*, since this list is the base reference
+	 * set when init'ed.
+	 */
+	if (i &lt; 3)
+		children[i] = NULL;
+	new = children[0];
+	list_replace(&amp;be-&gt;be_node, &amp;new-&gt;be_node);
+	bl_put_extent(be);
+	new = _front_merge(new, &amp;bl-&gt;bl_extents[RW_EXTENT], merge1);
+	for (j = 1; j &lt; i; j++) {
+		old = new;
+		new = children[j];
+		list_add(&amp;new-&gt;be_node, &amp;old-&gt;be_node);
+	}
+	if (merge2) {
+		/* This is a HACK, should just create a _back_merge function */
+		new = list_entry(new-&gt;be_node.next,
+				 struct pnfs_block_extent, be_node);
+		new = _front_merge(new, &amp;bl-&gt;bl_extents[RW_EXTENT], merge2);
+	}
+	spin_unlock(&amp;bl-&gt;bl_ext_lock);
+
+	/* Since we removed the base reference above, be is now scheduled for
+	 * destruction.
+	 */
+	bl_put_extent(be);
+	dprintk("%s returns %llu after split\n", __func__, rv);
+	return rv;
+
+ out_nosplit:
+	kfree(e1);
+	kfree(e2);
+	kfree(e3);
+	dprintk("%s returns %llu without splitting\n", __func__, rv);
+	return rv;
+}
+
+void
+clean_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
+			      const struct nfs4_layoutcommit_args *arg,
+			      int status)
+{
+	struct pnfs_block_short_extent *lce, *save;
+
+	dprintk("%s status %d\n", __func__, status);
+	list_for_each_entry_safe(lce, save, &amp;bl-&gt;bl_committing, bse_node) {
+		if (likely(!status)) {
+			u64 offset = lce-&gt;bse_f_offset;
+			u64 end = offset + lce-&gt;bse_length;
+
+			do {
+				offset = set_to_rw(bl, offset, end - offset);
+			} while (offset &lt; end);
+			list_del(&amp;lce-&gt;bse_node);
+
+			kfree(lce);
+		} else {
+			list_del(&amp;lce-&gt;bse_node);
+			spin_lock(&amp;bl-&gt;bl_ext_lock);
+			add_to_commitlist(bl, lce);
+			spin_unlock(&amp;bl-&gt;bl_ext_lock);
+		}
+	}
+}</pre><hr><pre>commit 90ace12ac42f65d1f077c5ef5ec2efafdcac338f
Author: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
Date:   Sat Jul 30 20:52:51 2011 -0400

    pnfsblock: encode_layoutcommit
    
    In blocklayout driver. There are two things happening
    while layoutcommit/cleanup.
    1. the modified extents are encoded.
    2. On cleanup the extents are put back on the layout rw
       extents list, for reads.
    
    In the new system where actual xdr encoding is done in
    encode_layoutcommit() directly into xdr buffer, these are
    the new commit stages:
    
    1. On setup_layoutcommit, the range is adjusted as before
       and a structure is allocated for communication with
       bl_encode_layoutcommit &amp;&amp; bl_cleanup_layoutcommit
       (Generic layer provides a void-star to hang it on)
    
    2. bl_encode_layoutcommit is called to do the actual
       encoding directly into xdr. The commit-extent-list is not
       freed and is stored on above structure.
       FIXME: The code is not yet converted to the new XDR cleanup
    
    3. On cleanup the commit-extent-list is put back by a call
       to set_to_rw() as before, but with no need for XDR decoding
       of the list as before. And the commit-extent-list is freed.
       Finally allocated structure is freed.
    
    [rm inode and pnfs_layout_hdr args from cleanup_layoutcommit()]
    [pnfsblock: get rid of deprecated xdr macros]
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    Signed-off-by: Peng Tao &lt;peng_tao@emc.com&gt;
    Signed-off-by: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
    [blocklayout: encode_layoutcommit implementation]
    Signed-off-by: Boaz Harrosh &lt;bharrosh@panasas.com&gt;
    [pnfsblock: fix bug setting up layoutcommit.]
    Signed-off-by: Tao Guo &lt;guotao@nrchpc.ac.cn&gt;
    [pnfsblock: prevent commit list corruption]
    [pnfsblock: fix layoutcommit with an empty opaque]
    Signed-off-by: Fred Isaman &lt;iisaman@citi.umich.edu&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@panasas.com&gt;
    Signed-off-by: Benny Halevy &lt;bhalevy@tonian.com&gt;
    Signed-off-by: Jim Rees &lt;rees@umich.edu&gt;
    Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/fs/nfs/blocklayout/blocklayout.c b/fs/nfs/blocklayout/blocklayout.c
index 8c29a189f09b..d096835cfd6b 100644
--- a/fs/nfs/blocklayout/blocklayout.c
+++ b/fs/nfs/blocklayout/blocklayout.c
@@ -155,6 +155,8 @@ static void
 bl_encode_layoutcommit(struct pnfs_layout_hdr *lo, struct xdr_stream *xdr,
 		       const struct nfs4_layoutcommit_args *arg)
 {
+	dprintk("%s enter\n", __func__);
+	encode_pnfs_block_layoutupdate(BLK_LO2EXT(lo), xdr, arg);
 }
 
 static void
diff --git a/fs/nfs/blocklayout/blocklayout.h b/fs/nfs/blocklayout/blocklayout.h
index fcf47b55b5ce..3caaefce85a5 100644
--- a/fs/nfs/blocklayout/blocklayout.h
+++ b/fs/nfs/blocklayout/blocklayout.h
@@ -91,6 +91,15 @@ struct pnfs_block_extent {
 	struct pnfs_inval_markings *be_inval; /* tracks INVAL-&gt;RW transition */
 };
 
+/* Shortened extent used by LAYOUTCOMMIT */
+struct pnfs_block_short_extent {
+	struct list_head bse_node;
+	struct nfs4_deviceid bse_devid;
+	struct block_device *bse_mdev;
+	sector_t	bse_f_offset;	/* the starting offset in the file */
+	sector_t	bse_length;	/* the size of the extent */
+};
+
 static inline void
 BL_INIT_INVAL_MARKS(struct pnfs_inval_markings *marks, sector_t blocksize)
 {
@@ -184,6 +193,9 @@ int bl_mark_sectors_init(struct pnfs_inval_markings *marks,
 void bl_put_extent(struct pnfs_block_extent *be);
 struct pnfs_block_extent *bl_alloc_extent(void);
 int bl_is_sector_init(struct pnfs_inval_markings *marks, sector_t isect);
+int encode_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
+				   struct xdr_stream *xdr,
+				   const struct nfs4_layoutcommit_args *arg);
 int bl_add_merge_extent(struct pnfs_block_layout *bl,
 			 struct pnfs_block_extent *new);
 
diff --git a/fs/nfs/blocklayout/extents.c b/fs/nfs/blocklayout/extents.c
index 292aadfd4d46..84bf24087720 100644
--- a/fs/nfs/blocklayout/extents.c
+++ b/fs/nfs/blocklayout/extents.c
@@ -286,6 +286,49 @@ int bl_mark_sectors_init(struct pnfs_inval_markings *marks,
 	return -ENOMEM;
 }
 
+/* Marks sectors in [offest, offset+length) as having been written to disk.
+ * All lengths should be block aligned.
+ */
+static int mark_written_sectors(struct pnfs_inval_markings *marks,
+				sector_t offset, sector_t length)
+{
+	int status;
+
+	dprintk("%s(offset=%llu,len=%llu) enter\n", __func__,
+		(u64)offset, (u64)length);
+	spin_lock(&amp;marks-&gt;im_lock);
+	status = _set_range(&amp;marks-&gt;im_tree, EXTENT_WRITTEN, offset, length);
+	spin_unlock(&amp;marks-&gt;im_lock);
+	return status;
+}
+
+static void print_short_extent(struct pnfs_block_short_extent *be)
+{
+	dprintk("PRINT SHORT EXTENT extent %p\n", be);
+	if (be) {
+		dprintk("        be_f_offset %llu\n", (u64)be-&gt;bse_f_offset);
+		dprintk("        be_length   %llu\n", (u64)be-&gt;bse_length);
+	}
+}
+
+static void print_clist(struct list_head *list, unsigned int count)
+{
+	struct pnfs_block_short_extent *be;
+	unsigned int i = 0;
+
+	ifdebug(FACILITY) {
+		printk(KERN_DEBUG "****************\n");
+		printk(KERN_DEBUG "Extent list looks like:\n");
+		list_for_each_entry(be, list, bse_node) {
+			i++;
+			print_short_extent(be);
+		}
+		if (i != count)
+			printk(KERN_DEBUG "\n\nExpected %u entries\n\n\n", count);
+		printk(KERN_DEBUG "****************\n");
+	}
+}
+
 static void print_bl_extent(struct pnfs_block_extent *be)
 {
 	dprintk("PRINT EXTENT extent %p\n", be);
@@ -378,65 +421,67 @@ bl_add_merge_extent(struct pnfs_block_layout *bl,
 	/* Scan for proper place to insert, extending new to the left
 	 * as much as possible.
 	 */
-	list_for_each_entry_safe(be, tmp, list, be_node) {
-		if (new-&gt;be_f_offset &lt; be-&gt;be_f_offset)
+	list_for_each_entry_safe_reverse(be, tmp, list, be_node) {
+		if (new-&gt;be_f_offset &gt;= be-&gt;be_f_offset + be-&gt;be_length)
 			break;
-		if (end &lt;= be-&gt;be_f_offset + be-&gt;be_length) {
-			/* new is a subset of existing be*/
+		if (new-&gt;be_f_offset &gt;= be-&gt;be_f_offset) {
+			if (end &lt;= be-&gt;be_f_offset + be-&gt;be_length) {
+				/* new is a subset of existing be*/
+				if (extents_consistent(be, new)) {
+					dprintk("%s: new is subset, ignoring\n",
+						__func__);
+					bl_put_extent(new);
+					return 0;
+				} else {
+					goto out_err;
+				}
+			} else {
+				/* |&lt;--   be   --&gt;|
+				 *          |&lt;--   new   --&gt;| */
+				if (extents_consistent(be, new)) {
+					/* extend new to fully replace be */
+					new-&gt;be_length += new-&gt;be_f_offset -
+						be-&gt;be_f_offset;
+					new-&gt;be_f_offset = be-&gt;be_f_offset;
+					new-&gt;be_v_offset = be-&gt;be_v_offset;
+					dprintk("%s: removing %p\n", __func__, be);
+					list_del(&amp;be-&gt;be_node);
+					bl_put_extent(be);
+				} else {
+					goto out_err;
+				}
+			}
+		} else if (end &gt;= be-&gt;be_f_offset + be-&gt;be_length) {
+			/* new extent overlap existing be */
 			if (extents_consistent(be, new)) {
-				dprintk("%s: new is subset, ignoring\n",
-					__func__);
-				bl_put_extent(new);
-				return 0;
-			} else
+				/* extend new to fully replace be */
+				dprintk("%s: removing %p\n", __func__, be);
+				list_del(&amp;be-&gt;be_node);
+				bl_put_extent(be);
+			} else {
 				goto out_err;
-		} else if (new-&gt;be_f_offset &lt;=
-				be-&gt;be_f_offset + be-&gt;be_length) {
-			/* new overlaps or abuts existing be */
-			if (extents_consistent(be, new)) {
+			}
+		} else if (end &gt; be-&gt;be_f_offset) {
+			/*           |&lt;--   be   --&gt;|
+			 *|&lt;--   new   --&gt;| */
+			if (extents_consistent(new, be)) {
 				/* extend new to fully replace be */
-				new-&gt;be_length += new-&gt;be_f_offset -
-						  be-&gt;be_f_offset;
-				new-&gt;be_f_offset = be-&gt;be_f_offset;
-				new-&gt;be_v_offset = be-&gt;be_v_offset;
+				new-&gt;be_length += be-&gt;be_f_offset + be-&gt;be_length -
+					new-&gt;be_f_offset - new-&gt;be_length;
 				dprintk("%s: removing %p\n", __func__, be);
 				list_del(&amp;be-&gt;be_node);
 				bl_put_extent(be);
-			} else if (new-&gt;be_f_offset !=
-				   be-&gt;be_f_offset + be-&gt;be_length)
+			} else {
 				goto out_err;
+			}
 		}
 	}
 	/* Note that if we never hit the above break, be will not point to a
 	 * valid extent.  However, in that case &amp;be-&gt;be_node==list.
 	 */
-	list_add_tail(&amp;new-&gt;be_node, &amp;be-&gt;be_node);
+	list_add(&amp;new-&gt;be_node, &amp;be-&gt;be_node);
 	dprintk("%s: inserting new\n", __func__);
 	print_elist(list);
-	/* Scan forward for overlaps.  If we find any, extend new and
-	 * remove the overlapped extent.
-	 */
-	be = list_prepare_entry(new, list, be_node);
-	list_for_each_entry_safe_continue(be, tmp, list, be_node) {
-		if (end &lt; be-&gt;be_f_offset)
-			break;
-		/* new overlaps or abuts existing be */
-		if (extents_consistent(be, new)) {
-			if (end &lt; be-&gt;be_f_offset + be-&gt;be_length) {
-				/* extend new to fully cover be */
-				end = be-&gt;be_f_offset + be-&gt;be_length;
-				new-&gt;be_length = end - new-&gt;be_f_offset;
-			}
-			dprintk("%s: removing %p\n", __func__, be);
-			list_del(&amp;be-&gt;be_node);
-			bl_put_extent(be);
-		} else if (end != be-&gt;be_f_offset) {
-			list_del(&amp;new-&gt;be_node);
-			goto out_err;
-		}
-	}
-	dprintk("%s: after merging\n", __func__);
-	print_elist(list);
 	/* FIXME - The per-list consistency checks have all been done,
 	 * should now check cross-list consistency.
 	 */
@@ -494,6 +539,49 @@ bl_find_get_extent(struct pnfs_block_layout *bl, sector_t isect,
 	return ret;
 }
 
+int
+encode_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
+			       struct xdr_stream *xdr,
+			       const struct nfs4_layoutcommit_args *arg)
+{
+	struct pnfs_block_short_extent *lce, *save;
+	unsigned int count = 0;
+	__be32 *p, *xdr_start;
+
+	dprintk("%s enter\n", __func__);
+	/* BUG - creation of bl_commit is buggy - need to wait for
+	 * entire block to be marked WRITTEN before it can be added.
+	 */
+	spin_lock(&amp;bl-&gt;bl_ext_lock);
+	/* Want to adjust for possible truncate */
+	/* We now want to adjust argument range */
+
+	/* XDR encode the ranges found */
+	xdr_start = xdr_reserve_space(xdr, 8);
+	if (!xdr_start)
+		goto out;
+	list_for_each_entry_safe(lce, save, &amp;bl-&gt;bl_commit, bse_node) {
+		p = xdr_reserve_space(xdr, 7 * 4 + sizeof(lce-&gt;bse_devid.data));
+		if (!p)
+			break;
+		p = xdr_encode_opaque_fixed(p, lce-&gt;bse_devid.data, NFS4_DEVICEID4_SIZE);
+		p = xdr_encode_hyper(p, lce-&gt;bse_f_offset &lt;&lt; SECTOR_SHIFT);
+		p = xdr_encode_hyper(p, lce-&gt;bse_length &lt;&lt; SECTOR_SHIFT);
+		p = xdr_encode_hyper(p, 0LL);
+		*p++ = cpu_to_be32(PNFS_BLOCK_READWRITE_DATA);
+		list_del(&amp;lce-&gt;bse_node);
+		list_add_tail(&amp;lce-&gt;bse_node, &amp;bl-&gt;bl_committing);
+		bl-&gt;bl_count--;
+		count++;
+	}
+	xdr_start[0] = cpu_to_be32((xdr-&gt;p - xdr_start - 1) * 4);
+	xdr_start[1] = cpu_to_be32(count);
+out:
+	spin_unlock(&amp;bl-&gt;bl_ext_lock);
+	dprintk("%s found %i ranges\n", __func__, count);
+	return 0;
+}
+
 /* Helper function to set_to_rw that initialize a new extent */
 static void
 _prep_new_extent(struct pnfs_block_extent *new,</pre>
    <div class="pagination">
        <a href='4_5.html'>&lt;&lt;Prev</a><a href='4.html'>1</a><a href='4_2.html'>2</a><a href='4_3.html'>3</a><a href='4_4.html'>4</a><a href='4_5.html'>5</a><span>[6]</span><a href='4_7.html'>7</a><a href='4_8.html'>8</a><a href='4_9.html'>9</a><a href='4_10.html'>10</a><a href='4_11.html'>11</a><a href='4_12.html'>12</a><a href='4_13.html'>13</a><a href='4_14.html'>14</a><a href='4_15.html'>15</a><a href='4_16.html'>16</a><a href='4_17.html'>17</a><a href='4_18.html'>18</a><a href='4_19.html'>19</a><a href='4_20.html'>20</a><a href='4_21.html'>21</a><a href='4_22.html'>22</a><a href='4_23.html'>23</a><a href='4_24.html'>24</a><a href='4_25.html'>25</a><a href='4_26.html'>26</a><a href='4_27.html'>27</a><a href='4_28.html'>28</a><a href='4_29.html'>29</a><a href='4_30.html'>30</a><a href='4_31.html'>31</a><a href='4_32.html'>32</a><a href='4_33.html'>33</a><a href='4_34.html'>34</a><a href='4_35.html'>35</a><a href='4_36.html'>36</a><a href='4_37.html'>37</a><a href='4_38.html'>38</a><a href='4_39.html'>39</a><a href='4_40.html'>40</a><a href='4_41.html'>41</a><a href='4_42.html'>42</a><a href='4_43.html'>43</a><a href='4_44.html'>44</a><a href='4_45.html'>45</a><a href='4_46.html'>46</a><a href='4_47.html'>47</a><a href='4_48.html'>48</a><a href='4_49.html'>49</a><a href='4_50.html'>50</a><a href='4_51.html'>51</a><a href='4_52.html'>52</a><a href='4_53.html'>53</a><a href='4_54.html'>54</a><a href='4_55.html'>55</a><a href='4_56.html'>56</a><a href='4_57.html'>57</a><a href='4_7.html'>Next&gt;&gt;</a>
    <div>
</body>
