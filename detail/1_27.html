<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_26.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><span>[27]</span><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_28.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit 5b9554dc5bf008ae7f68a52e3d7e76c0920938a2
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Jul 5 20:01:52 2016 -0400

    ext4: validate s_reserved_gdt_blocks on mount
    
    If s_reserved_gdt_blocks is extremely large, it's possible for
    ext4_init_block_bitmap(), which is called when ext4 sets up an
    uninitialized block bitmap, to corrupt random kernel memory.  Add the
    same checks which e2fsck has --- it must never be larger than
    blocksize / sizeof(__u32) --- and then add a backup check in
    ext4_init_block_bitmap() in case the superblock gets modified after
    the file system is mounted.
    
    Reported-by: Vegard Nossum &lt;vegard.nossum@oracle.com&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/balloc.c b/fs/ext4/balloc.c
index 0b8105b3293d..799a92bdf577 100644
--- a/fs/ext4/balloc.c
+++ b/fs/ext4/balloc.c
@@ -208,6 +208,9 @@ static int ext4_init_block_bitmap(struct super_block *sb,
 	memset(bh-&gt;b_data, 0, sb-&gt;s_blocksize);
 
 	bit_max = ext4_num_base_meta_clusters(sb, block_group);
+	if ((bit_max &gt;&gt; 3) &gt;= bh-&gt;b_size)
+		return -EFSCORRUPTED;
+
 	for (bit = 0; bit &lt; bit_max; bit++)
 		ext4_set_bit(bit, bh-&gt;b_data);
 
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 5664ee66b301..13c49af7a06a 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -3416,6 +3416,13 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 		goto failed_mount;
 	}
 
+	if (le16_to_cpu(sbi-&gt;s_es-&gt;s_reserved_gdt_blocks) &gt; (blocksize / 4)) {
+		ext4_msg(sb, KERN_ERR,
+			 "Number of reserved GDT blocks insanely large: %d",
+			 le16_to_cpu(sbi-&gt;s_es-&gt;s_reserved_gdt_blocks));
+		goto failed_mount;
+	}
+
 	if (sbi-&gt;s_mount_opt &amp; EXT4_MOUNT_DAX) {
 		err = bdev_dax_supported(sb, blocksize);
 		if (err)</pre><hr><pre>commit 86a574de4590ffe6fd3f3ca34cdcf655a78e36ec
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Jul 3 17:01:26 2016 -0400

    random: strengthen input validation for RNDADDTOENTCNT
    
    Don't allow RNDADDTOENTCNT or RNDADDENTROPY to accept a negative
    entropy value.  It doesn't make any sense to subtract from the entropy
    counter, and it can trigger a warning:
    
    random: negative entropy/overflow: pool input count -40000
    ------------[ cut here ]------------
    WARNING: CPU: 3 PID: 6828 at drivers/char/random.c:670[&lt;      none
     &gt;] credit_entropy_bits+0x21e/0xad0 drivers/char/random.c:670
    Modules linked in:
    CPU: 3 PID: 6828 Comm: a.out Not tainted 4.7.0-rc4+ #4
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
     ffffffff880b58e0 ffff88005dd9fcb0 ffffffff82cc838f ffffffff87158b40
     fffffbfff1016b1c 0000000000000000 0000000000000000 ffffffff87158b40
     ffffffff83283dae 0000000000000009 ffff88005dd9fcf8 ffffffff8136d27f
    Call Trace:
     [&lt;     inline     &gt;] __dump_stack lib/dump_stack.c:15
     [&lt;ffffffff82cc838f&gt;] dump_stack+0x12e/0x18f lib/dump_stack.c:51
     [&lt;ffffffff8136d27f&gt;] __warn+0x19f/0x1e0 kernel/panic.c:516
     [&lt;ffffffff8136d48c&gt;] warn_slowpath_null+0x2c/0x40 kernel/panic.c:551
     [&lt;ffffffff83283dae&gt;] credit_entropy_bits+0x21e/0xad0 drivers/char/random.c:670
     [&lt;     inline     &gt;] credit_entropy_bits_safe drivers/char/random.c:734
     [&lt;ffffffff8328785d&gt;] random_ioctl+0x21d/0x250 drivers/char/random.c:1546
     [&lt;     inline     &gt;] vfs_ioctl fs/ioctl.c:43
     [&lt;ffffffff8185316c&gt;] do_vfs_ioctl+0x18c/0xff0 fs/ioctl.c:674
     [&lt;     inline     &gt;] SYSC_ioctl fs/ioctl.c:689
     [&lt;ffffffff8185405f&gt;] SyS_ioctl+0x8f/0xc0 fs/ioctl.c:680
     [&lt;ffffffff86a995c0&gt;] entry_SYSCALL_64_fastpath+0x23/0xc1
    arch/x86/entry/entry_64.S:207
    ---[ end trace 5d4902b2ba842f1f ]---
    
    This was triggered using the test program:
    
    // autogenerated by syzkaller (http://github.com/google/syzkaller)
    
    int main() {
            int fd = open("/dev/random", O_RDWR);
            int val = -5000;
            ioctl(fd, RNDADDTOENTCNT, &amp;val);
            return 0;
    }
    
    It's harmless in that (a) only root can trigger it, and (b) after
    complaining the code never does let the entropy count go negative, but
    it's better to simply not allow this userspace from passing in a
    negative entropy value altogether.
    
    Google-Bug-Id: #29575089
    Reported-By: Dmitry Vyukov &lt;dvyukov@google.com&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index 783dee11cdc9..8d0af74f6569 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -738,15 +738,18 @@ static void credit_entropy_bits(struct entropy_store *r, int nbits)
 	}
 }
 
-static void credit_entropy_bits_safe(struct entropy_store *r, int nbits)
+static int credit_entropy_bits_safe(struct entropy_store *r, int nbits)
 {
 	const int nbits_max = (int)(~0U &gt;&gt; (ENTROPY_SHIFT + 1));
 
+	if (nbits &lt; 0)
+		return -EINVAL;
+
 	/* Cap the value to avoid overflows */
 	nbits = min(nbits,  nbits_max);
-	nbits = max(nbits, -nbits_max);
 
 	credit_entropy_bits(r, nbits);
+	return 0;
 }
 
 /*********************************************************************
@@ -1823,8 +1826,7 @@ static long random_ioctl(struct file *f, unsigned int cmd, unsigned long arg)
 			return -EPERM;
 		if (get_user(ent_count, p))
 			return -EFAULT;
-		credit_entropy_bits_safe(&amp;input_pool, ent_count);
-		return 0;
+		return credit_entropy_bits_safe(&amp;input_pool, ent_count);
 	case RNDADDENTROPY:
 		if (!capable(CAP_SYS_ADMIN))
 			return -EPERM;
@@ -1838,8 +1840,7 @@ static long random_ioctl(struct file *f, unsigned int cmd, unsigned long arg)
 				    size);
 		if (retval &lt; 0)
 			return retval;
-		credit_entropy_bits_safe(&amp;input_pool, ent_count);
-		return 0;
+		return credit_entropy_bits_safe(&amp;input_pool, ent_count);
 	case RNDZAPENTCNT:
 	case RNDCLEARPOOL:
 		/*</pre><hr><pre>commit c92e040d575a7389d72e7e6f25e2033bfb867f8b
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed May 4 13:29:18 2016 -0400

    random: add backtracking protection to the CRNG
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index 2a30d9718a1b..783dee11cdc9 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -438,7 +438,8 @@ static int crng_init_cnt = 0;
 #define CRNG_INIT_CNT_THRESH (2*CHACHA20_KEY_SIZE)
 static void _extract_crng(struct crng_state *crng,
 			  __u8 out[CHACHA20_BLOCK_SIZE]);
-static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE]);
+static void _crng_backtrack_protect(struct crng_state *crng,
+				    __u8 tmp[CHACHA20_BLOCK_SIZE], int used);
 static void process_random_ready_list(void);
 
 /**********************************************************************
@@ -826,8 +827,11 @@ static void crng_reseed(struct crng_state *crng, struct entropy_store *r)
 		num = extract_entropy(r, &amp;buf, 32, 16, 0);
 		if (num == 0)
 			return;
-	} else
+	} else {
 		_extract_crng(&amp;primary_crng, buf.block);
+		_crng_backtrack_protect(&amp;primary_crng, buf.block,
+					CHACHA20_KEY_SIZE);
+	}
 	spin_lock_irqsave(&amp;primary_crng.lock, flags);
 	for (i = 0; i &lt; 8; i++) {
 		unsigned long	rv;
@@ -889,9 +893,46 @@ static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE])
 	_extract_crng(crng, out);
 }
 
+/*
+ * Use the leftover bytes from the CRNG block output (if there is
+ * enough) to mutate the CRNG key to provide backtracking protection.
+ */
+static void _crng_backtrack_protect(struct crng_state *crng,
+				    __u8 tmp[CHACHA20_BLOCK_SIZE], int used)
+{
+	unsigned long	flags;
+	__u32		*s, *d;
+	int		i;
+
+	used = round_up(used, sizeof(__u32));
+	if (used + CHACHA20_KEY_SIZE &gt; CHACHA20_BLOCK_SIZE) {
+		extract_crng(tmp);
+		used = 0;
+	}
+	spin_lock_irqsave(&amp;crng-&gt;lock, flags);
+	s = (__u32 *) &amp;tmp[used];
+	d = &amp;crng-&gt;state[4];
+	for (i=0; i &lt; 8; i++)
+		*d++ ^= *s++;
+	spin_unlock_irqrestore(&amp;crng-&gt;lock, flags);
+}
+
+static void crng_backtrack_protect(__u8 tmp[CHACHA20_BLOCK_SIZE], int used)
+{
+	struct crng_state *crng = NULL;
+
+#ifdef CONFIG_NUMA
+	if (crng_node_pool)
+		crng = crng_node_pool[numa_node_id()];
+	if (crng == NULL)
+#endif
+		crng = &amp;primary_crng;
+	_crng_backtrack_protect(crng, tmp, used);
+}
+
 static ssize_t extract_crng_user(void __user *buf, size_t nbytes)
 {
-	ssize_t ret = 0, i;
+	ssize_t ret = 0, i = CHACHA20_BLOCK_SIZE;
 	__u8 tmp[CHACHA20_BLOCK_SIZE];
 	int large_request = (nbytes &gt; 256);
 
@@ -916,6 +957,7 @@ static ssize_t extract_crng_user(void __user *buf, size_t nbytes)
 		buf += i;
 		ret += i;
 	}
+	crng_backtrack_protect(tmp, i);
 
 	/* Wipe data just written to memory */
 	memzero_explicit(tmp, sizeof(tmp));
@@ -1473,8 +1515,10 @@ void get_random_bytes(void *buf, int nbytes)
 	if (nbytes &gt; 0) {
 		extract_crng(tmp);
 		memcpy(buf, tmp, nbytes);
-		memzero_explicit(tmp, nbytes);
-	}
+		crng_backtrack_protect(tmp, nbytes);
+	} else
+		crng_backtrack_protect(tmp, CHACHA20_BLOCK_SIZE);
+	memzero_explicit(tmp, sizeof(tmp));
 }
 EXPORT_SYMBOL(get_random_bytes);
 </pre><hr><pre>commit 1e7f583af67be4ff091d0aeb863c649efd7a9112
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon May 2 02:04:41 2016 -0400

    random: make /dev/urandom scalable for silly userspace programs
    
    On a system with a 4 socket (NUMA) system where a large number of
    application threads were all trying to read from /dev/urandom, this
    can result in the system spending 80% of its time contending on the
    global urandom spinlock.  The application should have used its own
    PRNG, but let's try to help it from running, lemming-like, straight
    over the locking cliff.
    
    Reported-by: Andi Kleen &lt;ak@linux.intel.com&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index dc2a9c2d8dcf..2a30d9718a1b 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -436,6 +436,8 @@ static int crng_init = 0;
 #define crng_ready() (likely(crng_init &gt; 0))
 static int crng_init_cnt = 0;
 #define CRNG_INIT_CNT_THRESH (2*CHACHA20_KEY_SIZE)
+static void _extract_crng(struct crng_state *crng,
+			  __u8 out[CHACHA20_BLOCK_SIZE]);
 static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE]);
 static void process_random_ready_list(void);
 
@@ -756,6 +758,16 @@ static void credit_entropy_bits_safe(struct entropy_store *r, int nbits)
 
 static DECLARE_WAIT_QUEUE_HEAD(crng_init_wait);
 
+#ifdef CONFIG_NUMA
+/*
+ * Hack to deal with crazy userspace progams when they are all trying
+ * to access /dev/urandom in parallel.  The programs are almost
+ * certainly doing something terribly wrong, but we'll work around
+ * their brain damage.
+ */
+static struct crng_state **crng_node_pool __read_mostly;
+#endif
+
 static void crng_initialize(struct crng_state *crng)
 {
 	int		i;
@@ -815,7 +827,7 @@ static void crng_reseed(struct crng_state *crng, struct entropy_store *r)
 		if (num == 0)
 			return;
 	} else
-		extract_crng(buf.block);
+		_extract_crng(&amp;primary_crng, buf.block);
 	spin_lock_irqsave(&amp;primary_crng.lock, flags);
 	for (i = 0; i &lt; 8; i++) {
 		unsigned long	rv;
@@ -835,19 +847,26 @@ static void crng_reseed(struct crng_state *crng, struct entropy_store *r)
 	spin_unlock_irqrestore(&amp;primary_crng.lock, flags);
 }
 
+static inline void maybe_reseed_primary_crng(void)
+{
+	if (crng_init &gt; 2 &amp;&amp;
+	    time_after(jiffies, primary_crng.init_time + CRNG_RESEED_INTERVAL))
+		crng_reseed(&amp;primary_crng, &amp;input_pool);
+}
+
 static inline void crng_wait_ready(void)
 {
 	wait_event_interruptible(crng_init_wait, crng_ready());
 }
 
-static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE])
+static void _extract_crng(struct crng_state *crng,
+			  __u8 out[CHACHA20_BLOCK_SIZE])
 {
 	unsigned long v, flags;
-	struct crng_state *crng = &amp;primary_crng;
 
 	if (crng_init &gt; 1 &amp;&amp;
 	    time_after(jiffies, crng-&gt;init_time + CRNG_RESEED_INTERVAL))
-		crng_reseed(crng, &amp;input_pool);
+		crng_reseed(crng, crng == &amp;primary_crng ? &amp;input_pool : NULL);
 	spin_lock_irqsave(&amp;crng-&gt;lock, flags);
 	if (arch_get_random_long(&amp;v))
 		crng-&gt;state[14] ^= v;
@@ -857,6 +876,19 @@ static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE])
 	spin_unlock_irqrestore(&amp;crng-&gt;lock, flags);
 }
 
+static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE])
+{
+	struct crng_state *crng = NULL;
+
+#ifdef CONFIG_NUMA
+	if (crng_node_pool)
+		crng = crng_node_pool[numa_node_id()];
+	if (crng == NULL)
+#endif
+		crng = &amp;primary_crng;
+	_extract_crng(crng, out);
+}
+
 static ssize_t extract_crng_user(void __user *buf, size_t nbytes)
 {
 	ssize_t ret = 0, i;
@@ -1575,9 +1607,31 @@ static void init_std_data(struct entropy_store *r)
  */
 static int rand_initialize(void)
 {
+#ifdef CONFIG_NUMA
+	int i;
+	int num_nodes = num_possible_nodes();
+	struct crng_state *crng;
+	struct crng_state **pool;
+#endif
+
 	init_std_data(&amp;input_pool);
 	init_std_data(&amp;blocking_pool);
 	crng_initialize(&amp;primary_crng);
+
+#ifdef CONFIG_NUMA
+	pool = kmalloc(num_nodes * sizeof(void *),
+		       GFP_KERNEL|__GFP_NOFAIL|__GFP_ZERO);
+	for (i=0; i &lt; num_nodes; i++) {
+		crng = kmalloc_node(sizeof(struct crng_state),
+				    GFP_KERNEL | __GFP_NOFAIL, i);
+		spin_lock_init(&amp;crng-&gt;lock);
+		crng_initialize(crng);
+		pool[i] = crng;
+
+	}
+	mb();
+	crng_node_pool = pool;
+#endif
 	return 0;
 }
 early_initcall(rand_initialize);</pre><hr><pre>commit e192be9d9a30555aae2ca1dc3aad37cba484cd4a
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Jun 12 18:13:36 2016 -0400

    random: replace non-blocking pool with a Chacha20-based CRNG
    
    The CRNG is faster, and we don't pretend to track entropy usage in the
    CRNG any more.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/crypto/chacha20_generic.c b/crypto/chacha20_generic.c
index da9c89968223..1cab83146e33 100644
--- a/crypto/chacha20_generic.c
+++ b/crypto/chacha20_generic.c
@@ -15,72 +15,11 @@
 #include &lt;linux/module.h&gt;
 #include &lt;crypto/chacha20.h&gt;
 
-static inline u32 rotl32(u32 v, u8 n)
-{
-	return (v &lt;&lt; n) | (v &gt;&gt; (sizeof(v) * 8 - n));
-}
-
 static inline u32 le32_to_cpuvp(const void *p)
 {
 	return le32_to_cpup(p);
 }
 
-static void chacha20_block(u32 *state, void *stream)
-{
-	u32 x[16], *out = stream;
-	int i;
-
-	for (i = 0; i &lt; ARRAY_SIZE(x); i++)
-		x[i] = state[i];
-
-	for (i = 0; i &lt; 20; i += 2) {
-		x[0]  += x[4];    x[12] = rotl32(x[12] ^ x[0],  16);
-		x[1]  += x[5];    x[13] = rotl32(x[13] ^ x[1],  16);
-		x[2]  += x[6];    x[14] = rotl32(x[14] ^ x[2],  16);
-		x[3]  += x[7];    x[15] = rotl32(x[15] ^ x[3],  16);
-
-		x[8]  += x[12];   x[4]  = rotl32(x[4]  ^ x[8],  12);
-		x[9]  += x[13];   x[5]  = rotl32(x[5]  ^ x[9],  12);
-		x[10] += x[14];   x[6]  = rotl32(x[6]  ^ x[10], 12);
-		x[11] += x[15];   x[7]  = rotl32(x[7]  ^ x[11], 12);
-
-		x[0]  += x[4];    x[12] = rotl32(x[12] ^ x[0],   8);
-		x[1]  += x[5];    x[13] = rotl32(x[13] ^ x[1],   8);
-		x[2]  += x[6];    x[14] = rotl32(x[14] ^ x[2],   8);
-		x[3]  += x[7];    x[15] = rotl32(x[15] ^ x[3],   8);
-
-		x[8]  += x[12];   x[4]  = rotl32(x[4]  ^ x[8],   7);
-		x[9]  += x[13];   x[5]  = rotl32(x[5]  ^ x[9],   7);
-		x[10] += x[14];   x[6]  = rotl32(x[6]  ^ x[10],  7);
-		x[11] += x[15];   x[7]  = rotl32(x[7]  ^ x[11],  7);
-
-		x[0]  += x[5];    x[15] = rotl32(x[15] ^ x[0],  16);
-		x[1]  += x[6];    x[12] = rotl32(x[12] ^ x[1],  16);
-		x[2]  += x[7];    x[13] = rotl32(x[13] ^ x[2],  16);
-		x[3]  += x[4];    x[14] = rotl32(x[14] ^ x[3],  16);
-
-		x[10] += x[15];   x[5]  = rotl32(x[5]  ^ x[10], 12);
-		x[11] += x[12];   x[6]  = rotl32(x[6]  ^ x[11], 12);
-		x[8]  += x[13];   x[7]  = rotl32(x[7]  ^ x[8],  12);
-		x[9]  += x[14];   x[4]  = rotl32(x[4]  ^ x[9],  12);
-
-		x[0]  += x[5];    x[15] = rotl32(x[15] ^ x[0],   8);
-		x[1]  += x[6];    x[12] = rotl32(x[12] ^ x[1],   8);
-		x[2]  += x[7];    x[13] = rotl32(x[13] ^ x[2],   8);
-		x[3]  += x[4];    x[14] = rotl32(x[14] ^ x[3],   8);
-
-		x[10] += x[15];   x[5]  = rotl32(x[5]  ^ x[10],  7);
-		x[11] += x[12];   x[6]  = rotl32(x[6]  ^ x[11],  7);
-		x[8]  += x[13];   x[7]  = rotl32(x[7]  ^ x[8],   7);
-		x[9]  += x[14];   x[4]  = rotl32(x[4]  ^ x[9],   7);
-	}
-
-	for (i = 0; i &lt; ARRAY_SIZE(x); i++)
-		out[i] = cpu_to_le32(x[i] + state[i]);
-
-	state[12]++;
-}
-
 static void chacha20_docrypt(u32 *state, u8 *dst, const u8 *src,
 			     unsigned int bytes)
 {
diff --git a/drivers/char/random.c b/drivers/char/random.c
index a6253e89663c..dc2a9c2d8dcf 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -261,6 +261,7 @@
 #include &lt;linux/syscalls.h&gt;
 #include &lt;linux/completion.h&gt;
 #include &lt;linux/uuid.h&gt;
+#include &lt;crypto/chacha20.h&gt;
 
 #include &lt;asm/processor.h&gt;
 #include &lt;asm/uaccess.h&gt;
@@ -413,6 +414,31 @@ static struct fasync_struct *fasync;
 static DEFINE_SPINLOCK(random_ready_list_lock);
 static LIST_HEAD(random_ready_list);
 
+struct crng_state {
+	__u32		state[16];
+	unsigned long	init_time;
+	spinlock_t	lock;
+};
+
+struct crng_state primary_crng = {
+	.lock = __SPIN_LOCK_UNLOCKED(primary_crng.lock),
+};
+
+/*
+ * crng_init =  0 --&gt; Uninitialized
+ *		1 --&gt; Initialized
+ *		2 --&gt; Initialized from input_pool
+ *
+ * crng_init is protected by primary_crng-&gt;lock, and only increases
+ * its value (from 0-&gt;1-&gt;2).
+ */
+static int crng_init = 0;
+#define crng_ready() (likely(crng_init &gt; 0))
+static int crng_init_cnt = 0;
+#define CRNG_INIT_CNT_THRESH (2*CHACHA20_KEY_SIZE)
+static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE]);
+static void process_random_ready_list(void);
+
 /**********************************************************************
  *
  * OS independent entropy store.   Here are the functions which handle
@@ -442,10 +468,15 @@ struct entropy_store {
 	__u8 last_data[EXTRACT_SIZE];
 };
 
+static ssize_t extract_entropy(struct entropy_store *r, void *buf,
+			       size_t nbytes, int min, int rsvd);
+static ssize_t _extract_entropy(struct entropy_store *r, void *buf,
+				size_t nbytes, int fips);
+
+static void crng_reseed(struct crng_state *crng, struct entropy_store *r);
 static void push_to_pool(struct work_struct *work);
 static __u32 input_pool_data[INPUT_POOL_WORDS];
 static __u32 blocking_pool_data[OUTPUT_POOL_WORDS];
-static __u32 nonblocking_pool_data[OUTPUT_POOL_WORDS];
 
 static struct entropy_store input_pool = {
 	.poolinfo = &amp;poolinfo_table[0],
@@ -466,16 +497,6 @@ static struct entropy_store blocking_pool = {
 					push_to_pool),
 };
 
-static struct entropy_store nonblocking_pool = {
-	.poolinfo = &amp;poolinfo_table[1],
-	.name = "nonblocking",
-	.pull = &amp;input_pool,
-	.lock = __SPIN_LOCK_UNLOCKED(nonblocking_pool.lock),
-	.pool = nonblocking_pool_data,
-	.push_work = __WORK_INITIALIZER(nonblocking_pool.push_work,
-					push_to_pool),
-};
-
 static __u32 const twist_table[8] = {
 	0x00000000, 0x3b6e20c8, 0x76dc4190, 0x4db26158,
 	0xedb88320, 0xd6d6a3e8, 0x9b64c2b0, 0xa00ae278 };
@@ -678,12 +699,6 @@ static void credit_entropy_bits(struct entropy_store *r, int nbits)
 	if (!r-&gt;initialized &amp;&amp; r-&gt;entropy_total &gt; 128) {
 		r-&gt;initialized = 1;
 		r-&gt;entropy_total = 0;
-		if (r == &amp;nonblocking_pool) {
-			prandom_reseed_late();
-			process_random_ready_list();
-			wake_up_all(&amp;urandom_init_wait);
-			pr_notice("random: %s pool is initialized\n", r-&gt;name);
-		}
 	}
 
 	trace_credit_entropy_bits(r-&gt;name, nbits,
@@ -693,30 +708,27 @@ static void credit_entropy_bits(struct entropy_store *r, int nbits)
 	if (r == &amp;input_pool) {
 		int entropy_bits = entropy_count &gt;&gt; ENTROPY_SHIFT;
 
+		if (crng_init &lt; 2 &amp;&amp; entropy_bits &gt;= 128) {
+			crng_reseed(&amp;primary_crng, r);
+			entropy_bits = r-&gt;entropy_count &gt;&gt; ENTROPY_SHIFT;
+		}
+
 		/* should we wake readers? */
 		if (entropy_bits &gt;= random_read_wakeup_bits) {
 			wake_up_interruptible(&amp;random_read_wait);
 			kill_fasync(&amp;fasync, SIGIO, POLL_IN);
 		}
 		/* If the input pool is getting full, send some
-		 * entropy to the two output pools, flipping back and
-		 * forth between them, until the output pools are 75%
-		 * full.
+		 * entropy to the blocking pool until it is 75% full.
 		 */
 		if (entropy_bits &gt; random_write_wakeup_bits &amp;&amp;
 		    r-&gt;initialized &amp;&amp;
 		    r-&gt;entropy_total &gt;= 2*random_read_wakeup_bits) {
-			static struct entropy_store *last = &amp;blocking_pool;
 			struct entropy_store *other = &amp;blocking_pool;
 
-			if (last == &amp;blocking_pool)
-				other = &amp;nonblocking_pool;
 			if (other-&gt;entropy_count &lt;=
-			    3 * other-&gt;poolinfo-&gt;poolfracbits / 4)
-				last = other;
-			if (last-&gt;entropy_count &lt;=
-			    3 * last-&gt;poolinfo-&gt;poolfracbits / 4) {
-				schedule_work(&amp;last-&gt;push_work);
+			    3 * other-&gt;poolinfo-&gt;poolfracbits / 4) {
+				schedule_work(&amp;other-&gt;push_work);
 				r-&gt;entropy_total = 0;
 			}
 		}
@@ -734,6 +746,152 @@ static void credit_entropy_bits_safe(struct entropy_store *r, int nbits)
 	credit_entropy_bits(r, nbits);
 }
 
+/*********************************************************************
+ *
+ * CRNG using CHACHA20
+ *
+ *********************************************************************/
+
+#define CRNG_RESEED_INTERVAL (300*HZ)
+
+static DECLARE_WAIT_QUEUE_HEAD(crng_init_wait);
+
+static void crng_initialize(struct crng_state *crng)
+{
+	int		i;
+	unsigned long	rv;
+
+	memcpy(&amp;crng-&gt;state[0], "expand 32-byte k", 16);
+	if (crng == &amp;primary_crng)
+		_extract_entropy(&amp;input_pool, &amp;crng-&gt;state[4],
+				 sizeof(__u32) * 12, 0);
+	else
+		get_random_bytes(&amp;crng-&gt;state[4], sizeof(__u32) * 12);
+	for (i = 4; i &lt; 16; i++) {
+		if (!arch_get_random_seed_long(&amp;rv) &amp;&amp;
+		    !arch_get_random_long(&amp;rv))
+			rv = random_get_entropy();
+		crng-&gt;state[i] ^= rv;
+	}
+	crng-&gt;init_time = jiffies - CRNG_RESEED_INTERVAL - 1;
+}
+
+static int crng_fast_load(const char *cp, size_t len)
+{
+	unsigned long flags;
+	char *p;
+
+	if (!spin_trylock_irqsave(&amp;primary_crng.lock, flags))
+		return 0;
+	if (crng_ready()) {
+		spin_unlock_irqrestore(&amp;primary_crng.lock, flags);
+		return 0;
+	}
+	p = (unsigned char *) &amp;primary_crng.state[4];
+	while (len &gt; 0 &amp;&amp; crng_init_cnt &lt; CRNG_INIT_CNT_THRESH) {
+		p[crng_init_cnt % CHACHA20_KEY_SIZE] ^= *cp;
+		cp++; crng_init_cnt++; len--;
+	}
+	if (crng_init_cnt &gt;= CRNG_INIT_CNT_THRESH) {
+		crng_init = 1;
+		wake_up_interruptible(&amp;crng_init_wait);
+		pr_notice("random: fast init done\n");
+	}
+	spin_unlock_irqrestore(&amp;primary_crng.lock, flags);
+	return 1;
+}
+
+static void crng_reseed(struct crng_state *crng, struct entropy_store *r)
+{
+	unsigned long	flags;
+	int		i, num;
+	union {
+		__u8	block[CHACHA20_BLOCK_SIZE];
+		__u32	key[8];
+	} buf;
+
+	if (r) {
+		num = extract_entropy(r, &amp;buf, 32, 16, 0);
+		if (num == 0)
+			return;
+	} else
+		extract_crng(buf.block);
+	spin_lock_irqsave(&amp;primary_crng.lock, flags);
+	for (i = 0; i &lt; 8; i++) {
+		unsigned long	rv;
+		if (!arch_get_random_seed_long(&amp;rv) &amp;&amp;
+		    !arch_get_random_long(&amp;rv))
+			rv = random_get_entropy();
+		crng-&gt;state[i+4] ^= buf.key[i] ^ rv;
+	}
+	memzero_explicit(&amp;buf, sizeof(buf));
+	crng-&gt;init_time = jiffies;
+	if (crng == &amp;primary_crng &amp;&amp; crng_init &lt; 2) {
+		crng_init = 2;
+		process_random_ready_list();
+		wake_up_interruptible(&amp;crng_init_wait);
+		pr_notice("random: crng init done\n");
+	}
+	spin_unlock_irqrestore(&amp;primary_crng.lock, flags);
+}
+
+static inline void crng_wait_ready(void)
+{
+	wait_event_interruptible(crng_init_wait, crng_ready());
+}
+
+static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE])
+{
+	unsigned long v, flags;
+	struct crng_state *crng = &amp;primary_crng;
+
+	if (crng_init &gt; 1 &amp;&amp;
+	    time_after(jiffies, crng-&gt;init_time + CRNG_RESEED_INTERVAL))
+		crng_reseed(crng, &amp;input_pool);
+	spin_lock_irqsave(&amp;crng-&gt;lock, flags);
+	if (arch_get_random_long(&amp;v))
+		crng-&gt;state[14] ^= v;
+	chacha20_block(&amp;crng-&gt;state[0], out);
+	if (crng-&gt;state[12] == 0)
+		crng-&gt;state[13]++;
+	spin_unlock_irqrestore(&amp;crng-&gt;lock, flags);
+}
+
+static ssize_t extract_crng_user(void __user *buf, size_t nbytes)
+{
+	ssize_t ret = 0, i;
+	__u8 tmp[CHACHA20_BLOCK_SIZE];
+	int large_request = (nbytes &gt; 256);
+
+	while (nbytes) {
+		if (large_request &amp;&amp; need_resched()) {
+			if (signal_pending(current)) {
+				if (ret == 0)
+					ret = -ERESTARTSYS;
+				break;
+			}
+			schedule();
+		}
+
+		extract_crng(tmp);
+		i = min_t(int, nbytes, CHACHA20_BLOCK_SIZE);
+		if (copy_to_user(buf, tmp, i)) {
+			ret = -EFAULT;
+			break;
+		}
+
+		nbytes -= i;
+		buf += i;
+		ret += i;
+	}
+
+	/* Wipe data just written to memory */
+	memzero_explicit(tmp, sizeof(tmp));
+
+	return ret;
+}
+
+
 /*********************************************************************
  *
  * Entropy input management
@@ -750,12 +908,12 @@ struct timer_rand_state {
 #define INIT_TIMER_RAND_STATE { INITIAL_JIFFIES, };
 
 /*
- * Add device- or boot-specific data to the input and nonblocking
- * pools to help initialize them to unique values.
+ * Add device- or boot-specific data to the input pool to help
+ * initialize it.
  *
- * None of this adds any entropy, it is meant to avoid the
- * problem of the nonblocking pool having similar initial state
- * across largely identical devices.
+ * None of this adds any entropy; it is meant to avoid the problem of
+ * the entropy pool having similar initial state across largely
+ * identical devices.
  */
 void add_device_randomness(const void *buf, unsigned int size)
 {
@@ -767,11 +925,6 @@ void add_device_randomness(const void *buf, unsigned int size)
 	_mix_pool_bytes(&amp;input_pool, buf, size);
 	_mix_pool_bytes(&amp;input_pool, &amp;time, sizeof(time));
 	spin_unlock_irqrestore(&amp;input_pool.lock, flags);
-
-	spin_lock_irqsave(&amp;nonblocking_pool.lock, flags);
-	_mix_pool_bytes(&amp;nonblocking_pool, buf, size);
-	_mix_pool_bytes(&amp;nonblocking_pool, &amp;time, sizeof(time));
-	spin_unlock_irqrestore(&amp;nonblocking_pool.lock, flags);
 }
 EXPORT_SYMBOL(add_device_randomness);
 
@@ -802,7 +955,7 @@ static void add_timer_randomness(struct timer_rand_state *state, unsigned num)
 	sample.jiffies = jiffies;
 	sample.cycles = random_get_entropy();
 	sample.num = num;
-	r = nonblocking_pool.initialized ? &amp;input_pool : &amp;nonblocking_pool;
+	r = &amp;input_pool;
 	mix_pool_bytes(r, &amp;sample, sizeof(sample));
 
 	/*
@@ -918,11 +1071,21 @@ void add_interrupt_randomness(int irq, int irq_flags)
 	fast_mix(fast_pool);
 	add_interrupt_bench(cycles);
 
+	if (!crng_ready()) {
+		if ((fast_pool-&gt;count &gt;= 64) &amp;&amp;
+		    crng_fast_load((char *) fast_pool-&gt;pool,
+				   sizeof(fast_pool-&gt;pool))) {
+			fast_pool-&gt;count = 0;
+			fast_pool-&gt;last = now;
+		}
+		return;
+	}
+
 	if ((fast_pool-&gt;count &lt; 64) &amp;&amp;
 	    !time_after(now, fast_pool-&gt;last + HZ))
 		return;
 
-	r = nonblocking_pool.initialized ? &amp;input_pool : &amp;nonblocking_pool;
+	r = &amp;input_pool;
 	if (!spin_trylock(&amp;r-&gt;lock))
 		return;
 
@@ -966,9 +1129,6 @@ EXPORT_SYMBOL_GPL(add_disk_randomness);
  *
  *********************************************************************/
 
-static ssize_t extract_entropy(struct entropy_store *r, void *buf,
-			       size_t nbytes, int min, int rsvd);
-
 /*
  * This utility inline function is responsible for transferring entropy
  * from the primary pool to the secondary extraction pool. We make
@@ -1143,6 +1303,36 @@ static void extract_buf(struct entropy_store *r, __u8 *out)
 	memzero_explicit(&amp;hash, sizeof(hash));
 }
 
+static ssize_t _extract_entropy(struct entropy_store *r, void *buf,
+				size_t nbytes, int fips)
+{
+	ssize_t ret = 0, i;
+	__u8 tmp[EXTRACT_SIZE];
+	unsigned long flags;
+
+	while (nbytes) {
+		extract_buf(r, tmp);
+
+		if (fips) {
+			spin_lock_irqsave(&amp;r-&gt;lock, flags);
+			if (!memcmp(tmp, r-&gt;last_data, EXTRACT_SIZE))
+				panic("Hardware RNG duplicated output!\n");
+			memcpy(r-&gt;last_data, tmp, EXTRACT_SIZE);
+			spin_unlock_irqrestore(&amp;r-&gt;lock, flags);
+		}
+		i = min_t(int, nbytes, EXTRACT_SIZE);
+		memcpy(buf, tmp, i);
+		nbytes -= i;
+		buf += i;
+		ret += i;
+	}
+
+	/* Wipe data just returned from memory */
+	memzero_explicit(tmp, sizeof(tmp));
+
+	return ret;
+}
+
 /*
  * This function extracts randomness from the "entropy pool", and
  * returns it in a buffer.
@@ -1155,7 +1345,6 @@ static void extract_buf(struct entropy_store *r, __u8 *out)
 static ssize_t extract_entropy(struct entropy_store *r, void *buf,
 				 size_t nbytes, int min, int reserved)
 {
-	ssize_t ret = 0, i;
 	__u8 tmp[EXTRACT_SIZE];
 	unsigned long flags;
 
@@ -1179,27 +1368,7 @@ static ssize_t extract_entropy(struct entropy_store *r, void *buf,
 	xfer_secondary_pool(r, nbytes);
 	nbytes = account(r, nbytes, min, reserved);
 
-	while (nbytes) {
-		extract_buf(r, tmp);
-
-		if (fips_enabled) {
-			spin_lock_irqsave(&amp;r-&gt;lock, flags);
-			if (!memcmp(tmp, r-&gt;last_data, EXTRACT_SIZE))
-				panic("Hardware RNG duplicated output!\n");
-			memcpy(r-&gt;last_data, tmp, EXTRACT_SIZE);
-			spin_unlock_irqrestore(&amp;r-&gt;lock, flags);
-		}
-		i = min_t(int, nbytes, EXTRACT_SIZE);
-		memcpy(buf, tmp, i);
-		nbytes -= i;
-		buf += i;
-		ret += i;
-	}
-
-	/* Wipe data just returned from memory */
-	memzero_explicit(tmp, sizeof(tmp));
-
-	return ret;
+	return _extract_entropy(r, buf, nbytes, fips_enabled);
 }
 
 /*
@@ -1254,15 +1423,26 @@ static ssize_t extract_entropy_user(struct entropy_store *r, void __user *buf,
  */
 void get_random_bytes(void *buf, int nbytes)
 {
+	__u8 tmp[CHACHA20_BLOCK_SIZE];
+
 #if DEBUG_RANDOM_BOOT &gt; 0
-	if (unlikely(nonblocking_pool.initialized == 0))
+	if (!crng_ready())
 		printk(KERN_NOTICE "random: %pF get_random_bytes called "
-		       "with %d bits of entropy available\n",
-		       (void *) _RET_IP_,
-		       nonblocking_pool.entropy_total);
+		       "with crng_init = %d\n", (void *) _RET_IP_, crng_init);
 #endif
 	trace_get_random_bytes(nbytes, _RET_IP_);
-	extract_entropy(&amp;nonblocking_pool, buf, nbytes, 0, 0);
+
+	while (nbytes &gt;= CHACHA20_BLOCK_SIZE) {
+		extract_crng(buf);
+		buf += CHACHA20_BLOCK_SIZE;
+		nbytes -= CHACHA20_BLOCK_SIZE;
+	}
+
+	if (nbytes &gt; 0) {
+		extract_crng(tmp);
+		memcpy(buf, tmp, nbytes);
+		memzero_explicit(tmp, nbytes);
+	}
 }
 EXPORT_SYMBOL(get_random_bytes);
 
@@ -1280,7 +1460,7 @@ int add_random_ready_callback(struct random_ready_callback *rdy)
 	unsigned long flags;
 	int err = -EALREADY;
 
-	if (likely(nonblocking_pool.initialized))
+	if (crng_ready())
 		return err;
 
 	owner = rdy-&gt;owner;
@@ -1288,7 +1468,7 @@ int add_random_ready_callback(struct random_ready_callback *rdy)
 		return -ENOENT;
 
 	spin_lock_irqsave(&amp;random_ready_list_lock, flags);
-	if (nonblocking_pool.initialized)
+	if (crng_ready())
 		goto out;
 
 	owner = NULL;
@@ -1352,7 +1532,7 @@ void get_random_bytes_arch(void *buf, int nbytes)
 	}
 
 	if (nbytes)
-		extract_entropy(&amp;nonblocking_pool, p, nbytes, 0, 0);
+		get_random_bytes(p, nbytes);
 }
 EXPORT_SYMBOL(get_random_bytes_arch);
 
@@ -1397,7 +1577,7 @@ static int rand_initialize(void)
 {
 	init_std_data(&amp;input_pool);
 	init_std_data(&amp;blocking_pool);
-	init_std_data(&amp;nonblocking_pool);
+	crng_initialize(&amp;primary_crng);
 	return 0;
 }
 early_initcall(rand_initialize);
@@ -1459,22 +1639,22 @@ random_read(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
 static ssize_t
 urandom_read(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
 {
+	unsigned long flags;
 	static int maxwarn = 10;
 	int ret;
 
-	if (unlikely(nonblocking_pool.initialized == 0) &amp;&amp;
-	    maxwarn &gt; 0) {
+	if (!crng_ready() &amp;&amp; maxwarn &gt; 0) {
 		maxwarn--;
 		printk(KERN_NOTICE "random: %s: uninitialized urandom read "
-		       "(%zd bytes read, %d bits of entropy available)\n",
-		       current-&gt;comm, nbytes, nonblocking_pool.entropy_total);
+		       "(%zd bytes read)\n",
+		       current-&gt;comm, nbytes);
+		spin_lock_irqsave(&amp;primary_crng.lock, flags);
+		crng_init_cnt = 0;
+		spin_unlock_irqrestore(&amp;primary_crng.lock, flags);
 	}
-
 	nbytes = min_t(size_t, nbytes, INT_MAX &gt;&gt; (ENTROPY_SHIFT + 3));
-	ret = extract_entropy_user(&amp;nonblocking_pool, buf, nbytes);
-
-	trace_urandom_read(8 * nbytes, ENTROPY_BITS(&amp;nonblocking_pool),
-			   ENTROPY_BITS(&amp;input_pool));
+	ret = extract_crng_user(buf, nbytes);
+	trace_urandom_read(8 * nbytes, 0, ENTROPY_BITS(&amp;input_pool));
 	return ret;
 }
 
@@ -1520,10 +1700,7 @@ static ssize_t random_write(struct file *file, const char __user *buffer,
 {
 	size_t ret;
 
-	ret = write_pool(&amp;blocking_pool, buffer, count);
-	if (ret)
-		return ret;
-	ret = write_pool(&amp;nonblocking_pool, buffer, count);
+	ret = write_pool(&amp;input_pool, buffer, count);
 	if (ret)
 		return ret;
 
@@ -1574,7 +1751,6 @@ static long random_ioctl(struct file *f, unsigned int cmd, unsigned long arg)
 		if (!capable(CAP_SYS_ADMIN))
 			return -EPERM;
 		input_pool.entropy_count = 0;
-		nonblocking_pool.entropy_count = 0;
 		blocking_pool.entropy_count = 0;
 		return 0;
 	default:
@@ -1616,11 +1792,10 @@ SYSCALL_DEFINE3(getrandom, char __user *, buf, size_t, count,
 	if (flags &amp; GRND_RANDOM)
 		return _random_read(flags &amp; GRND_NONBLOCK, buf, count);
 
-	if (unlikely(nonblocking_pool.initialized == 0)) {
+	if (!crng_ready()) {
 		if (flags &amp; GRND_NONBLOCK)
 			return -EAGAIN;
-		wait_event_interruptible(urandom_init_wait,
-					 nonblocking_pool.initialized);
+		crng_wait_ready();
 		if (signal_pending(current))
 			return -ERESTARTSYS;
 	}
@@ -1856,18 +2031,17 @@ void add_hwgenerator_randomness(const char *buffer, size_t count,
 {
 	struct entropy_store *poolp = &amp;input_pool;
 
-	if (unlikely(nonblocking_pool.initialized == 0))
-		poolp = &amp;nonblocking_pool;
-	else {
-		/* Suspend writing if we're above the trickle
-		 * threshold.  We'll be woken up again once below
-		 * random_write_wakeup_thresh, or when the calling
-		 * thread is about to terminate.
-		 */
-		wait_event_interruptible(random_write_wait,
-					 kthread_should_stop() ||
-			ENTROPY_BITS(&amp;input_pool) &lt;= random_write_wakeup_bits);
+	if (!crng_ready()) {
+		crng_fast_load(buffer, count);
+		return;
 	}
+
+	/* Suspend writing if we're above the trickle threshold.
+	 * We'll be woken up again once below random_write_wakeup_thresh,
+	 * or when the calling thread is about to terminate.
+	 */
+	wait_event_interruptible(random_write_wait, kthread_should_stop() ||
+			ENTROPY_BITS(&amp;input_pool) &lt;= random_write_wakeup_bits);
 	mix_pool_bytes(poolp, buffer, count);
 	credit_entropy_bits(poolp, entropy);
 }
diff --git a/include/crypto/chacha20.h b/include/crypto/chacha20.h
index 274bbaeeed0f..20d20f681a72 100644
--- a/include/crypto/chacha20.h
+++ b/include/crypto/chacha20.h
@@ -16,6 +16,7 @@ struct chacha20_ctx {
 	u32 key[8];
 };
 
+void chacha20_block(u32 *state, void *stream);
 void crypto_chacha20_init(u32 *state, struct chacha20_ctx *ctx, u8 *iv);
 int crypto_chacha20_setkey(struct crypto_tfm *tfm, const u8 *key,
 			   unsigned int keysize);
diff --git a/lib/Makefile b/lib/Makefile
index 499fb354d627..34e205facfa3 100644
--- a/lib/Makefile
+++ b/lib/Makefile
@@ -22,7 +22,7 @@ KCOV_INSTRUMENT_hweight.o := n
 lib-y := ctype.o string.o vsprintf.o cmdline.o \
 	 rbtree.o radix-tree.o dump_stack.o timerqueue.o\
 	 idr.o int_sqrt.o extable.o \
-	 sha1.o md5.o irq_regs.o argv_split.o \
+	 sha1.o chacha20.o md5.o irq_regs.o argv_split.o \
 	 flex_proportions.o ratelimit.o show_mem.o \
 	 is_single_threaded.o plist.o decompress.o kobject_uevent.o \
 	 earlycpio.o seq_buf.o nmi_backtrace.o nodemask.o
diff --git a/lib/chacha20.c b/lib/chacha20.c
new file mode 100644
index 000000000000..250ceed9ec9a
--- /dev/null
+++ b/lib/chacha20.c
@@ -0,0 +1,79 @@
+/*
+ * ChaCha20 256-bit cipher algorithm, RFC7539
+ *
+ * Copyright (C) 2015 Martin Willi
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include &lt;linux/kernel.h&gt;
+#include &lt;linux/export.h&gt;
+#include &lt;linux/bitops.h&gt;
+#include &lt;linux/cryptohash.h&gt;
+#include &lt;asm/unaligned.h&gt;
+#include &lt;crypto/chacha20.h&gt;
+
+static inline u32 rotl32(u32 v, u8 n)
+{
+	return (v &lt;&lt; n) | (v &gt;&gt; (sizeof(v) * 8 - n));
+}
+
+extern void chacha20_block(u32 *state, void *stream)
+{
+	u32 x[16], *out = stream;
+	int i;
+
+	for (i = 0; i &lt; ARRAY_SIZE(x); i++)
+		x[i] = state[i];
+
+	for (i = 0; i &lt; 20; i += 2) {
+		x[0]  += x[4];    x[12] = rotl32(x[12] ^ x[0],  16);
+		x[1]  += x[5];    x[13] = rotl32(x[13] ^ x[1],  16);
+		x[2]  += x[6];    x[14] = rotl32(x[14] ^ x[2],  16);
+		x[3]  += x[7];    x[15] = rotl32(x[15] ^ x[3],  16);
+
+		x[8]  += x[12];   x[4]  = rotl32(x[4]  ^ x[8],  12);
+		x[9]  += x[13];   x[5]  = rotl32(x[5]  ^ x[9],  12);
+		x[10] += x[14];   x[6]  = rotl32(x[6]  ^ x[10], 12);
+		x[11] += x[15];   x[7]  = rotl32(x[7]  ^ x[11], 12);
+
+		x[0]  += x[4];    x[12] = rotl32(x[12] ^ x[0],   8);
+		x[1]  += x[5];    x[13] = rotl32(x[13] ^ x[1],   8);
+		x[2]  += x[6];    x[14] = rotl32(x[14] ^ x[2],   8);
+		x[3]  += x[7];    x[15] = rotl32(x[15] ^ x[3],   8);
+
+		x[8]  += x[12];   x[4]  = rotl32(x[4]  ^ x[8],   7);
+		x[9]  += x[13];   x[5]  = rotl32(x[5]  ^ x[9],   7);
+		x[10] += x[14];   x[6]  = rotl32(x[6]  ^ x[10],  7);
+		x[11] += x[15];   x[7]  = rotl32(x[7]  ^ x[11],  7);
+
+		x[0]  += x[5];    x[15] = rotl32(x[15] ^ x[0],  16);
+		x[1]  += x[6];    x[12] = rotl32(x[12] ^ x[1],  16);
+		x[2]  += x[7];    x[13] = rotl32(x[13] ^ x[2],  16);
+		x[3]  += x[4];    x[14] = rotl32(x[14] ^ x[3],  16);
+
+		x[10] += x[15];   x[5]  = rotl32(x[5]  ^ x[10], 12);
+		x[11] += x[12];   x[6]  = rotl32(x[6]  ^ x[11], 12);
+		x[8]  += x[13];   x[7]  = rotl32(x[7]  ^ x[8],  12);
+		x[9]  += x[14];   x[4]  = rotl32(x[4]  ^ x[9],  12);
+
+		x[0]  += x[5];    x[15] = rotl32(x[15] ^ x[0],   8);
+		x[1]  += x[6];    x[12] = rotl32(x[12] ^ x[1],   8);
+		x[2]  += x[7];    x[13] = rotl32(x[13] ^ x[2],   8);
+		x[3]  += x[4];    x[14] = rotl32(x[14] ^ x[3],   8);
+
+		x[10] += x[15];   x[5]  = rotl32(x[5]  ^ x[10],  7);
+		x[11] += x[12];   x[6]  = rotl32(x[6]  ^ x[11],  7);
+		x[8]  += x[13];   x[7]  = rotl32(x[7]  ^ x[8],   7);
+		x[9]  += x[14];   x[4]  = rotl32(x[4]  ^ x[9],   7);
+	}
+
+	for (i = 0; i &lt; ARRAY_SIZE(x); i++)
+		out[i] = cpu_to_le32(x[i] + state[i]);
+
+	state[12]++;
+}
+EXPORT_SYMBOL(chacha20_block);</pre><hr><pre>commit 78d962510796fdf39ccc5efd23d2eea2eca1ed99
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Jun 26 18:25:01 2016 -0400

    ext4: respect the nobarrier mount option in nojournal mode
    
    Also, if we are going to issue the barrier, we should do this after we
    write out the parent directories if necessary.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Reviewed-by: Jan Kara &lt;jack@suse.cz&gt;

diff --git a/fs/ext4/fsync.c b/fs/ext4/fsync.c
index 8850254136ae..5c4372512ef7 100644
--- a/fs/ext4/fsync.c
+++ b/fs/ext4/fsync.c
@@ -106,9 +106,11 @@ int ext4_sync_file(struct file *file, loff_t start, loff_t end, int datasync)
 	}
 
 	if (!journal) {
-		ret = generic_file_fsync(file, start, end, datasync);
+		ret = __generic_file_fsync(file, start, end, datasync);
 		if (!ret &amp;&amp; !hlist_empty(&amp;inode-&gt;i_dentry))
 			ret = ext4_sync_parent(inode);
+		if (test_opt(inode-&gt;i_sb, BARRIER))
+			goto issue_flush;
 		goto out;
 	}
 
@@ -140,6 +142,7 @@ int ext4_sync_file(struct file *file, loff_t start, loff_t end, int datasync)
 		needs_barrier = true;
 	ret = jbd2_complete_transaction(journal, commit_tid);
 	if (needs_barrier) {
+	issue_flush:
 		err = blkdev_issue_flush(inode-&gt;i_sb-&gt;s_bdev, GFP_KERNEL, NULL);
 		if (!ret)
 			ret = err;</pre><hr><pre>commit d08854f5bcf3ea0cabc6fd2fc49c2d97e00c7c88
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Jun 26 18:24:01 2016 -0400

    ext4: optimize ext4_should_retry_alloc() to improve ENOSPC performance
    
    If there are no pending blocks to be released after a commit, forcing
    a journal commit has no hope of helping.  It's possible that a commit
    had just completed, so if there are now free blocks available for
    allocation, it's worth retrying the commit.
    
    Reported-by: Chao Yu &lt;yuchao0@huawei.com&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/balloc.c b/fs/ext4/balloc.c
index 3020fd70c392..0b8105b3293d 100644
--- a/fs/ext4/balloc.c
+++ b/fs/ext4/balloc.c
@@ -610,7 +610,9 @@ int ext4_should_retry_alloc(struct super_block *sb, int *retries)
 
 	jbd_debug(1, "%s: retrying operation after ENOSPC\n", sb-&gt;s_id);
 
-	jbd2_journal_force_commit_nested(EXT4_SB(sb)-&gt;s_journal);
+	smp_mb();
+	if (EXT4_SB(sb)-&gt;s_mb_free_pending)
+		jbd2_journal_force_commit_nested(EXT4_SB(sb)-&gt;s_journal);
 	return 1;
 }
 
diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index b84aa1ca480a..96c73e6fec6e 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -1430,6 +1430,7 @@ struct ext4_sb_info {
 	unsigned short *s_mb_offsets;
 	unsigned int *s_mb_maxs;
 	unsigned int s_group_info_size;
+	unsigned int s_mb_free_pending;
 
 	/* tunables */
 	unsigned long s_stripe;
diff --git a/fs/ext4/ext4_jbd2.h b/fs/ext4/ext4_jbd2.h
index 09c1ef38cbe6..b1d52c14098e 100644
--- a/fs/ext4/ext4_jbd2.h
+++ b/fs/ext4/ext4_jbd2.h
@@ -175,6 +175,13 @@ struct ext4_journal_cb_entry {
  * There is no guaranteed calling order of multiple registered callbacks on
  * the same transaction.
  */
+static inline void _ext4_journal_callback_add(handle_t *handle,
+			struct ext4_journal_cb_entry *jce)
+{
+	/* Add the jce to transaction's private list */
+	list_add_tail(&amp;jce-&gt;jce_list, &amp;handle-&gt;h_transaction-&gt;t_private_list);
+}
+
 static inline void ext4_journal_callback_add(handle_t *handle,
 			void (*func)(struct super_block *sb,
 				     struct ext4_journal_cb_entry *jce,
@@ -187,10 +194,11 @@ static inline void ext4_journal_callback_add(handle_t *handle,
 	/* Add the jce to transaction's private list */
 	jce-&gt;jce_func = func;
 	spin_lock(&amp;sbi-&gt;s_md_lock);
-	list_add_tail(&amp;jce-&gt;jce_list, &amp;handle-&gt;h_transaction-&gt;t_private_list);
+	_ext4_journal_callback_add(handle, jce);
 	spin_unlock(&amp;sbi-&gt;s_md_lock);
 }
 
+
 /**
  * ext4_journal_callback_del: delete a registered callback
  * @handle: active journal transaction handle on which callback was registered
diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c
index c1ab3ec30423..77249e1f5c3a 100644
--- a/fs/ext4/mballoc.c
+++ b/fs/ext4/mballoc.c
@@ -2627,6 +2627,7 @@ int ext4_mb_init(struct super_block *sb)
 
 	spin_lock_init(&amp;sbi-&gt;s_md_lock);
 	spin_lock_init(&amp;sbi-&gt;s_bal_lock);
+	sbi-&gt;s_mb_free_pending = 0;
 
 	sbi-&gt;s_mb_max_to_scan = MB_DEFAULT_MAX_TO_SCAN;
 	sbi-&gt;s_mb_min_to_scan = MB_DEFAULT_MIN_TO_SCAN;
@@ -2814,6 +2815,9 @@ static void ext4_free_data_callback(struct super_block *sb,
 	/* we expect to find existing buddy because it's pinned */
 	BUG_ON(err != 0);
 
+	spin_lock(&amp;EXT4_SB(sb)-&gt;s_md_lock);
+	EXT4_SB(sb)-&gt;s_mb_free_pending -= entry-&gt;efd_count;
+	spin_unlock(&amp;EXT4_SB(sb)-&gt;s_md_lock);
 
 	db = e4b.bd_info;
 	/* there are blocks to put in buddy to make them really free */
@@ -4583,6 +4587,7 @@ ext4_mb_free_metadata(handle_t *handle, struct ext4_buddy *e4b,
 {
 	ext4_group_t group = e4b-&gt;bd_group;
 	ext4_grpblk_t cluster;
+	ext4_grpblk_t clusters = new_entry-&gt;efd_count;
 	struct ext4_free_data *entry;
 	struct ext4_group_info *db = e4b-&gt;bd_info;
 	struct super_block *sb = e4b-&gt;bd_sb;
@@ -4649,8 +4654,11 @@ ext4_mb_free_metadata(handle_t *handle, struct ext4_buddy *e4b,
 		}
 	}
 	/* Add the extent to transaction's private list */
-	ext4_journal_callback_add(handle, ext4_free_data_callback,
-				  &amp;new_entry-&gt;efd_jce);
+	new_entry-&gt;efd_jce.jce_func = ext4_free_data_callback;
+	spin_lock(&amp;sbi-&gt;s_md_lock);
+	_ext4_journal_callback_add(handle, &amp;new_entry-&gt;efd_jce);
+	sbi-&gt;s_mb_free_pending += clusters;
+	spin_unlock(&amp;sbi-&gt;s_md_lock);
 	return 0;
 }
 </pre><hr><pre>commit 9b4d008787f864f17d008c9c15bbe8a0f7e2fc24
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Jun 13 10:10:51 2016 -0400

    random: print a warning for the first ten uninitialized random users
    
    Since systemd is consistently using /dev/urandom before it is
    initialized, we can't see the other potentially dangerous users of
    /dev/urandom immediately after boot.  So print the first ten such
    complaints instead.
    
    Cc: stable@kernel.org
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index 4e2627a8d226..d057438266bb 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -1458,12 +1458,16 @@ random_read(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
 static ssize_t
 urandom_read(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
 {
+	static int maxwarn = 10;
 	int ret;
 
-	if (unlikely(nonblocking_pool.initialized == 0))
-		printk_once(KERN_NOTICE "random: %s urandom read "
-			    "with %d bits of entropy available\n",
-			    current-&gt;comm, nonblocking_pool.entropy_total);
+	if (unlikely(nonblocking_pool.initialized == 0) &amp;&amp;
+	    maxwarn &gt; 0) {
+		maxwarn--;
+		printk(KERN_NOTICE "random: %s: uninitialized urandom read "
+		       "(%zd bytes read, %d bits of entropy available)\n",
+		       current-&gt;comm, nbytes, nonblocking_pool.entropy_total);
+	}
 
 	nbytes = min_t(size_t, nbytes, INT_MAX &gt;&gt; (ENTROPY_SHIFT + 3));
 	ret = extract_entropy_user(&amp;nonblocking_pool, buf, nbytes);</pre><hr><pre>commit 3371f3da08cff4b75c1f2dce742d460539d6566d
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Jun 12 18:11:51 2016 -0400

    random: initialize the non-blocking pool via add_hwgenerator_randomness()
    
    If we have a hardware RNG and are using the in-kernel rngd, we should
    use this to initialize the non-blocking pool so that getrandom(2)
    doesn't block unnecessarily.
    
    Cc: stable@kernel.org
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index 0158d3bff7e5..4e2627a8d226 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -1849,12 +1849,18 @@ void add_hwgenerator_randomness(const char *buffer, size_t count,
 {
 	struct entropy_store *poolp = &amp;input_pool;
 
-	/* Suspend writing if we're above the trickle threshold.
-	 * We'll be woken up again once below random_write_wakeup_thresh,
-	 * or when the calling thread is about to terminate.
-	 */
-	wait_event_interruptible(random_write_wait, kthread_should_stop() ||
+	if (unlikely(nonblocking_pool.initialized == 0))
+		poolp = &amp;nonblocking_pool;
+	else {
+		/* Suspend writing if we're above the trickle
+		 * threshold.  We'll be woken up again once below
+		 * random_write_wakeup_thresh, or when the calling
+		 * thread is about to terminate.
+		 */
+		wait_event_interruptible(random_write_wait,
+					 kthread_should_stop() ||
 			ENTROPY_BITS(&amp;input_pool) &lt;= random_write_wakeup_bits);
+	}
 	mix_pool_bytes(poolp, buffer, count);
 	credit_entropy_bits(poolp, entropy);
 }</pre><hr><pre>commit 7827a7f6ebfcb7f388dc47fddd48567a314701ba
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sat Apr 30 00:49:54 2016 -0400

    ext4: clean up error handling when orphan list is corrupted
    
    Instead of just printing warning messages, if the orphan list is
    corrupted, declare the file system is corrupted.  If there are any
    reserved inodes in the orphaned inode list, declare the file system
    corrupted and stop right away to avoid doing more potential damage to
    the file system.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/ialloc.c b/fs/ext4/ialloc.c
index c2caf2df3695..3da4cf8d18b6 100644
--- a/fs/ext4/ialloc.c
+++ b/fs/ext4/ialloc.c
@@ -1150,25 +1150,20 @@ struct inode *ext4_orphan_get(struct super_block *sb, unsigned long ino)
 	unsigned long max_ino = le32_to_cpu(EXT4_SB(sb)-&gt;s_es-&gt;s_inodes_count);
 	ext4_group_t block_group;
 	int bit;
-	struct buffer_head *bitmap_bh;
+	struct buffer_head *bitmap_bh = NULL;
 	struct inode *inode = NULL;
-	long err = -EIO;
+	int err = -EFSCORRUPTED;
 
-	/* Error cases - e2fsck has already cleaned up for us */
-	if (ino &gt; max_ino) {
-		ext4_warning(sb, "bad orphan ino %lu!  e2fsck was run?", ino);
-		err = -EFSCORRUPTED;
-		goto error;
-	}
+	if (ino &lt; EXT4_FIRST_INO(sb) || ino &gt; max_ino)
+		goto bad_orphan;
 
 	block_group = (ino - 1) / EXT4_INODES_PER_GROUP(sb);
 	bit = (ino - 1) % EXT4_INODES_PER_GROUP(sb);
 	bitmap_bh = ext4_read_inode_bitmap(sb, block_group);
 	if (IS_ERR(bitmap_bh)) {
-		err = PTR_ERR(bitmap_bh);
-		ext4_warning(sb, "inode bitmap error %ld for orphan %lu",
-			     ino, err);
-		goto error;
+		ext4_error(sb, "inode bitmap error %ld for orphan %lu",
+			   ino, PTR_ERR(bitmap_bh));
+		return (struct inode *) bitmap_bh;
 	}
 
 	/* Having the inode bit set should be a 100% indicator that this
@@ -1179,8 +1174,12 @@ struct inode *ext4_orphan_get(struct super_block *sb, unsigned long ino)
 		goto bad_orphan;
 
 	inode = ext4_iget(sb, ino);
-	if (IS_ERR(inode))
-		goto iget_failed;
+	if (IS_ERR(inode)) {
+		err = PTR_ERR(inode);
+		ext4_error(sb, "couldn't read orphan inode %lu (err %d)",
+			   ino, err);
+		return inode;
+	}
 
 	/*
 	 * If the orphans has i_nlinks &gt; 0 then it should be able to
@@ -1197,29 +1196,25 @@ struct inode *ext4_orphan_get(struct super_block *sb, unsigned long ino)
 	brelse(bitmap_bh);
 	return inode;
 
-iget_failed:
-	err = PTR_ERR(inode);
-	inode = NULL;
 bad_orphan:
-	ext4_warning(sb, "bad orphan inode %lu!  e2fsck was run?", ino);
-	printk(KERN_WARNING "ext4_test_bit(bit=%d, block=%llu) = %d\n",
-	       bit, (unsigned long long)bitmap_bh-&gt;b_blocknr,
-	       ext4_test_bit(bit, bitmap_bh-&gt;b_data));
-	printk(KERN_WARNING "inode=%p\n", inode);
+	ext4_error(sb, "bad orphan inode %lu", ino);
+	if (bitmap_bh)
+		printk(KERN_ERR "ext4_test_bit(bit=%d, block=%llu) = %d\n",
+		       bit, (unsigned long long)bitmap_bh-&gt;b_blocknr,
+		       ext4_test_bit(bit, bitmap_bh-&gt;b_data));
 	if (inode) {
-		printk(KERN_WARNING "is_bad_inode(inode)=%d\n",
+		printk(KERN_ERR "is_bad_inode(inode)=%d\n",
 		       is_bad_inode(inode));
-		printk(KERN_WARNING "NEXT_ORPHAN(inode)=%u\n",
+		printk(KERN_ERR "NEXT_ORPHAN(inode)=%u\n",
 		       NEXT_ORPHAN(inode));
-		printk(KERN_WARNING "max_ino=%lu\n", max_ino);
-		printk(KERN_WARNING "i_nlink=%u\n", inode-&gt;i_nlink);
+		printk(KERN_ERR "max_ino=%lu\n", max_ino);
+		printk(KERN_ERR "i_nlink=%u\n", inode-&gt;i_nlink);
 		/* Avoid freeing blocks if we got a bad deleted inode */
 		if (inode-&gt;i_nlink == 0)
 			inode-&gt;i_blocks = 0;
 		iput(inode);
 	}
 	brelse(bitmap_bh);
-error:
 	return ERR_PTR(err);
 }
 </pre>
    <div class="pagination">
        <a href='1_26.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><span>[27]</span><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_28.html'>Next&gt;&gt;</a>
    <div>
</body>
