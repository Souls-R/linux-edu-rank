<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_79.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><span>[80]</span><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_81.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit bd2d0210cf22f2bd0cef72eb97cf94fc7d31d8cc
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:10 2010 -0400

    ext4: use bio layer instead of buffer layer in mpage_da_submit_io
    
    Call the block I/O layer directly instad of going through the buffer
    layer.  This should give us much better performance and scalability,
    as well as lowering our CPU utilization when doing buffered writeback.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/Makefile b/fs/ext4/Makefile
index 8867b2a1e5fe..c947e36eda6c 100644
--- a/fs/ext4/Makefile
+++ b/fs/ext4/Makefile
@@ -4,7 +4,7 @@
 
 obj-$(CONFIG_EXT4_FS) += ext4.o
 
-ext4-y	:= balloc.o bitmap.o dir.o file.o fsync.o ialloc.o inode.o \
+ext4-y	:= balloc.o bitmap.o dir.o file.o fsync.o ialloc.o inode.o page-io.o \
 		ioctl.o namei.o super.o symlink.o hash.o resize.o extents.o \
 		ext4_jbd2.o migrate.o mballoc.o block_validity.o move_extent.o
 
diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index 22833691e98c..ca9fda64dd4f 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -168,7 +168,20 @@ struct mpage_da_data {
 	int pages_written;
 	int retval;
 };
-#define	EXT4_IO_UNWRITTEN	0x1
+
+/*
+ * Flags for ext4_io_end-&gt;flags
+ */
+#define	EXT4_IO_END_UNWRITTEN	0x0001
+#define EXT4_IO_END_ERROR	0x0002
+
+struct ext4_io_page {
+	struct page	*p_page;
+	int		p_count;
+};
+
+#define MAX_IO_PAGES 128
+
 typedef struct ext4_io_end {
 	struct list_head	list;		/* per-file finished IO list */
 	struct inode		*inode;		/* file being written to */
@@ -179,8 +192,18 @@ typedef struct ext4_io_end {
 	struct work_struct	work;		/* data work queue */
 	struct kiocb		*iocb;		/* iocb struct for AIO */
 	int			result;		/* error value for AIO */
+	int			num_io_pages;
+	struct ext4_io_page	*pages[MAX_IO_PAGES];
 } ext4_io_end_t;
 
+struct ext4_io_submit {
+	int			io_op;
+	struct bio		*io_bio;
+	ext4_io_end_t		*io_end;
+	struct ext4_io_page	*io_page;
+	sector_t		io_next_block;
+};
+
 /*
  * Special inodes numbers
  */
@@ -2044,6 +2067,17 @@ extern int ext4_move_extents(struct file *o_filp, struct file *d_filp,
 			     __u64 start_orig, __u64 start_donor,
 			     __u64 len, __u64 *moved_len);
 
+/* page-io.c */
+extern int __init init_ext4_pageio(void);
+extern void exit_ext4_pageio(void);
+extern void ext4_free_io_end(ext4_io_end_t *io);
+extern ext4_io_end_t *ext4_init_io_end(struct inode *inode, gfp_t flags);
+extern int ext4_end_io_nolock(ext4_io_end_t *io);
+extern void ext4_io_submit(struct ext4_io_submit *io);
+extern int ext4_bio_write_page(struct ext4_io_submit *io,
+			       struct page *page,
+			       int len,
+			       struct writeback_control *wbc);
 
 /* BH_Uninit flag: blocks are allocated but uninitialized on disk */
 enum ext4_state_bits {
diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c
index a0e623055955..a1e20c8c4e0c 100644
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@ -3202,7 +3202,7 @@ ext4_ext_handle_uninitialized_extents(handle_t *handle, struct inode *inode,
 		 * completed
 		 */
 		if (io)
-			io-&gt;flag = EXT4_IO_UNWRITTEN;
+			io-&gt;flag = EXT4_IO_END_UNWRITTEN;
 		else
 			ext4_set_inode_state(inode, EXT4_STATE_DIO_UNWRITTEN);
 		if (ext4_should_dioread_nolock(inode))
@@ -3494,7 +3494,7 @@ int ext4_ext_map_blocks(handle_t *handle, struct inode *inode,
 		 */
 		if ((flags &amp; EXT4_GET_BLOCKS_PRE_IO)) {
 			if (io)
-				io-&gt;flag = EXT4_IO_UNWRITTEN;
+				io-&gt;flag = EXT4_IO_END_UNWRITTEN;
 			else
 				ext4_set_inode_state(inode,
 						     EXT4_STATE_DIO_UNWRITTEN);
diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index c65d647378f9..58604fe11f4f 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -2016,8 +2016,10 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd,
 	struct buffer_head *bh, *page_bufs = NULL;
 	int journal_data = ext4_should_journal_data(inode);
 	sector_t pblock = 0, cur_logical = 0;
+	struct ext4_io_submit io_submit;
 
 	BUG_ON(mpd-&gt;next_page &lt;= mpd-&gt;first_page);
+	memset(&amp;io_submit, 0, sizeof(io_submit));
 	/*
 	 * We need to start from the first_page to the next_page - 1
 	 * to make sure we also write the mapped dirty buffer_heads.
@@ -2109,16 +2111,16 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd,
 				/* mark the buffer_heads as dirty &amp; uptodate */
 				block_commit_write(page, 0, len);
 
-			if (journal_data &amp;&amp; PageChecked(page))
+			/*
+			 * Delalloc doesn't support data journalling,
+			 * but eventually maybe we'll lift this
+			 * restriction.
+			 */
+			if (unlikely(journal_data &amp;&amp; PageChecked(page)))
 				err = __ext4_journalled_writepage(page, len);
-			else if (buffer_uninit(page_bufs)) {
-				ext4_set_bh_endio(page_bufs, inode);
-				err = block_write_full_page_endio(page,
-					noalloc_get_block_write,
-					mpd-&gt;wbc, ext4_end_io_buffer_write);
-			} else
-				err = block_write_full_page(page,
-					    noalloc_get_block_write, mpd-&gt;wbc);
+			else
+				err = ext4_bio_write_page(&amp;io_submit, page,
+							  len, mpd-&gt;wbc);
 
 			if (!err)
 				mpd-&gt;pages_written++;
@@ -2131,6 +2133,7 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd,
 		}
 		pagevec_release(&amp;pvec);
 	}
+	ext4_io_submit(&amp;io_submit);
 	return ret;
 }
 
@@ -3426,15 +3429,6 @@ ext4_readpages(struct file *file, struct address_space *mapping,
 	return mpage_readpages(mapping, pages, nr_pages, ext4_get_block);
 }
 
-static void ext4_free_io_end(ext4_io_end_t *io)
-{
-	BUG_ON(!io);
-	if (io-&gt;page)
-		put_page(io-&gt;page);
-	iput(io-&gt;inode);
-	kfree(io);
-}
-
 static void ext4_invalidatepage_free_endio(struct page *page, unsigned long offset)
 {
 	struct buffer_head *head, *bh;
@@ -3639,68 +3633,6 @@ static void dump_completed_IO(struct inode * inode)
 #endif
 }
 
-/*
- * check a range of space and convert unwritten extents to written.
- */
-static int ext4_end_io_nolock(ext4_io_end_t *io)
-{
-	struct inode *inode = io-&gt;inode;
-	loff_t offset = io-&gt;offset;
-	ssize_t size = io-&gt;size;
-	int ret = 0;
-
-	ext4_debug("ext4_end_io_nolock: io 0x%p from inode %lu,list-&gt;next 0x%p,"
-		   "list-&gt;prev 0x%p\n",
-	           io, inode-&gt;i_ino, io-&gt;list.next, io-&gt;list.prev);
-
-	if (list_empty(&amp;io-&gt;list))
-		return ret;
-
-	if (io-&gt;flag != EXT4_IO_UNWRITTEN)
-		return ret;
-
-	ret = ext4_convert_unwritten_extents(inode, offset, size);
-	if (ret &lt; 0) {
-		printk(KERN_EMERG "%s: failed to convert unwritten"
-			"extents to written extents, error is %d"
-			" io is still on inode %lu aio dio list\n",
-                       __func__, ret, inode-&gt;i_ino);
-		return ret;
-	}
-
-	if (io-&gt;iocb)
-		aio_complete(io-&gt;iocb, io-&gt;result, 0);
-	/* clear the DIO AIO unwritten flag */
-	io-&gt;flag = 0;
-	return ret;
-}
-
-/*
- * work on completed aio dio IO, to convert unwritten extents to extents
- */
-static void ext4_end_io_work(struct work_struct *work)
-{
-	ext4_io_end_t		*io = container_of(work, ext4_io_end_t, work);
-	struct inode		*inode = io-&gt;inode;
-	struct ext4_inode_info	*ei = EXT4_I(inode);
-	unsigned long		flags;
-	int			ret;
-
-	mutex_lock(&amp;inode-&gt;i_mutex);
-	ret = ext4_end_io_nolock(io);
-	if (ret &lt; 0) {
-		mutex_unlock(&amp;inode-&gt;i_mutex);
-		return;
-	}
-
-	spin_lock_irqsave(&amp;ei-&gt;i_completed_io_lock, flags);
-	if (!list_empty(&amp;io-&gt;list))
-		list_del_init(&amp;io-&gt;list);
-	spin_unlock_irqrestore(&amp;ei-&gt;i_completed_io_lock, flags);
-	mutex_unlock(&amp;inode-&gt;i_mutex);
-	ext4_free_io_end(io);
-}
-
 /*
  * This function is called from ext4_sync_file().
  *
@@ -3756,28 +3688,6 @@ int flush_completed_IO(struct inode *inode)
 	return (ret2 &lt; 0) ? ret2 : 0;
 }
 
-static ext4_io_end_t *ext4_init_io_end (struct inode *inode, gfp_t flags)
-{
-	ext4_io_end_t *io = NULL;
-
-	io = kmalloc(sizeof(*io), flags);
-
-	if (io) {
-		igrab(inode);
-		io-&gt;inode = inode;
-		io-&gt;flag = 0;
-		io-&gt;offset = 0;
-		io-&gt;size = 0;
-		io-&gt;page = NULL;
-		io-&gt;iocb = NULL;
-		io-&gt;result = 0;
-		INIT_WORK(&amp;io-&gt;work, ext4_end_io_work);
-		INIT_LIST_HEAD(&amp;io-&gt;list);
-	}
-
-	return io;
-}
-
 static void ext4_end_io_dio(struct kiocb *iocb, loff_t offset,
 			    ssize_t size, void *private, int ret,
 			    bool is_async)
@@ -3797,7 +3707,7 @@ static void ext4_end_io_dio(struct kiocb *iocb, loff_t offset,
 		  size);
 
 	/* if not aio dio with unwritten extents, just free io and return */
-	if (io_end-&gt;flag != EXT4_IO_UNWRITTEN){
+	if (!(io_end-&gt;flag &amp; EXT4_IO_END_UNWRITTEN)) {
 		ext4_free_io_end(io_end);
 		iocb-&gt;private = NULL;
 out:
@@ -3842,7 +3752,7 @@ static void ext4_end_io_buffer_write(struct buffer_head *bh, int uptodate)
 		goto out;
 	}
 
-	io_end-&gt;flag = EXT4_IO_UNWRITTEN;
+	io_end-&gt;flag = EXT4_IO_END_UNWRITTEN;
 	inode = io_end-&gt;inode;
 
 	/* Add the io_end to per-inode completed io list*/
diff --git a/fs/ext4/page-io.c b/fs/ext4/page-io.c
new file mode 100644
index 000000000000..b972ca50f851
--- /dev/null
+++ b/fs/ext4/page-io.c
@@ -0,0 +1,430 @@
+/*
+ * linux/fs/ext4/page-io.c
+ *
+ * This contains the new page_io functions for ext4
+ *
+ * Written by Theodore Ts'o, 2010.
+ */
+
+#include &lt;linux/module.h&gt;
+#include &lt;linux/fs.h&gt;
+#include &lt;linux/time.h&gt;
+#include &lt;linux/jbd2.h&gt;
+#include &lt;linux/highuid.h&gt;
+#include &lt;linux/pagemap.h&gt;
+#include &lt;linux/quotaops.h&gt;
+#include &lt;linux/string.h&gt;
+#include &lt;linux/buffer_head.h&gt;
+#include &lt;linux/writeback.h&gt;
+#include &lt;linux/pagevec.h&gt;
+#include &lt;linux/mpage.h&gt;
+#include &lt;linux/namei.h&gt;
+#include &lt;linux/uio.h&gt;
+#include &lt;linux/bio.h&gt;
+#include &lt;linux/workqueue.h&gt;
+#include &lt;linux/kernel.h&gt;
+#include &lt;linux/slab.h&gt;
+
+#include "ext4_jbd2.h"
+#include "xattr.h"
+#include "acl.h"
+#include "ext4_extents.h"
+
+static struct kmem_cache *io_page_cachep, *io_end_cachep;
+
+int __init init_ext4_pageio(void)
+{
+	io_page_cachep = KMEM_CACHE(ext4_io_page, SLAB_RECLAIM_ACCOUNT);
+	if (io_page_cachep == NULL)
+		return -ENOMEM;
+	io_end_cachep = KMEM_CACHE(ext4_io_end, SLAB_RECLAIM_ACCOUNT);
+	if (io_page_cachep == NULL) {
+		kmem_cache_destroy(io_page_cachep);
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+void exit_ext4_pageio(void)
+{
+	kmem_cache_destroy(io_end_cachep);
+	kmem_cache_destroy(io_page_cachep);
+}
+
+void ext4_free_io_end(ext4_io_end_t *io)
+{
+	int i;
+
+	BUG_ON(!io);
+	if (io-&gt;page)
+		put_page(io-&gt;page);
+	for (i = 0; i &lt; io-&gt;num_io_pages; i++) {
+		if (--io-&gt;pages[i]-&gt;p_count == 0) {
+			struct page *page = io-&gt;pages[i]-&gt;p_page;
+
+			end_page_writeback(page);
+			put_page(page);
+			kmem_cache_free(io_page_cachep, io-&gt;pages[i]);
+		}
+	}
+	io-&gt;num_io_pages = 0;
+	iput(io-&gt;inode);
+	kmem_cache_free(io_end_cachep, io);
+}
+
+/*
+ * check a range of space and convert unwritten extents to written.
+ */
+int ext4_end_io_nolock(ext4_io_end_t *io)
+{
+	struct inode *inode = io-&gt;inode;
+	loff_t offset = io-&gt;offset;
+	ssize_t size = io-&gt;size;
+	int ret = 0;
+
+	ext4_debug("ext4_end_io_nolock: io 0x%p from inode %lu,list-&gt;next 0x%p,"
+		   "list-&gt;prev 0x%p\n",
+		   io, inode-&gt;i_ino, io-&gt;list.next, io-&gt;list.prev);
+
+	if (list_empty(&amp;io-&gt;list))
+		return ret;
+
+	if (!(io-&gt;flag &amp; EXT4_IO_END_UNWRITTEN))
+		return ret;
+
+	ret = ext4_convert_unwritten_extents(inode, offset, size);
+	if (ret &lt; 0) {
+		printk(KERN_EMERG "%s: failed to convert unwritten "
+			"extents to written extents, error is %d "
+			"io is still on inode %lu aio dio list\n",
+		       __func__, ret, inode-&gt;i_ino);
+		return ret;
+	}
+
+	if (io-&gt;iocb)
+		aio_complete(io-&gt;iocb, io-&gt;result, 0);
+	/* clear the DIO AIO unwritten flag */
+	io-&gt;flag &amp;= ~EXT4_IO_END_UNWRITTEN;
+	return ret;
+}
+
+/*
+ * work on completed aio dio IO, to convert unwritten extents to extents
+ */
+static void ext4_end_io_work(struct work_struct *work)
+{
+	ext4_io_end_t		*io = container_of(work, ext4_io_end_t, work);
+	struct inode		*inode = io-&gt;inode;
+	struct ext4_inode_info	*ei = EXT4_I(inode);
+	unsigned long		flags;
+	int			ret;
+
+	mutex_lock(&amp;inode-&gt;i_mutex);
+	ret = ext4_end_io_nolock(io);
+	if (ret &lt; 0) {
+		mutex_unlock(&amp;inode-&gt;i_mutex);
+		return;
+	}
+
+	spin_lock_irqsave(&amp;ei-&gt;i_completed_io_lock, flags);
+	if (!list_empty(&amp;io-&gt;list))
+		list_del_init(&amp;io-&gt;list);
+	spin_unlock_irqrestore(&amp;ei-&gt;i_completed_io_lock, flags);
+	mutex_unlock(&amp;inode-&gt;i_mutex);
+	ext4_free_io_end(io);
+}
+
+ext4_io_end_t *ext4_init_io_end(struct inode *inode, gfp_t flags)
+{
+	ext4_io_end_t *io = NULL;
+
+	io = kmem_cache_alloc(io_end_cachep, flags);
+	if (io) {
+		memset(io, 0, sizeof(*io));
+		io-&gt;inode = igrab(inode);
+		BUG_ON(!io-&gt;inode);
+		INIT_WORK(&amp;io-&gt;work, ext4_end_io_work);
+		INIT_LIST_HEAD(&amp;io-&gt;list);
+	}
+	return io;
+}
+
+/*
+ * Print an buffer I/O error compatible with the fs/buffer.c.  This
+ * provides compatibility with dmesg scrapers that look for a specific
+ * buffer I/O error message.  We really need a unified error reporting
+ * structure to userspace ala Digital Unix's uerf system, but it's
+ * probably not going to happen in my lifetime, due to LKML politics...
+ */
+static void buffer_io_error(struct buffer_head *bh)
+{
+	char b[BDEVNAME_SIZE];
+	printk(KERN_ERR "Buffer I/O error on device %s, logical block %llu\n",
+			bdevname(bh-&gt;b_bdev, b),
+			(unsigned long long)bh-&gt;b_blocknr);
+}
+
+static void ext4_end_bio(struct bio *bio, int error)
+{
+	ext4_io_end_t *io_end = bio-&gt;bi_private;
+	struct workqueue_struct *wq;
+	struct inode *inode;
+	unsigned long flags;
+	ext4_fsblk_t err_block;
+	int i;
+
+	BUG_ON(!io_end);
+	inode = io_end-&gt;inode;
+	bio-&gt;bi_private = NULL;
+	bio-&gt;bi_end_io = NULL;
+	if (test_bit(BIO_UPTODATE, &amp;bio-&gt;bi_flags))
+		error = 0;
+	err_block = bio-&gt;bi_sector &gt;&gt; (inode-&gt;i_blkbits - 9);
+	bio_put(bio);
+
+	if (!(inode-&gt;i_sb-&gt;s_flags &amp; MS_ACTIVE)) {
+		pr_err("sb umounted, discard end_io request for inode %lu\n",
+			io_end-&gt;inode-&gt;i_ino);
+		ext4_free_io_end(io_end);
+		return;
+	}
+
+	if (error) {
+		io_end-&gt;flag |= EXT4_IO_END_ERROR;
+		ext4_warning(inode-&gt;i_sb, "I/O error writing to inode %lu "
+			     "(offset %llu size %ld starting block %llu)",
+			     inode-&gt;i_ino,
+			     (unsigned long long) io_end-&gt;offset,
+			     (long) io_end-&gt;size,
+			     (unsigned long long) err_block);
+	}
+
+	for (i = 0; i &lt; io_end-&gt;num_io_pages; i++) {
+		struct page *page = io_end-&gt;pages[i]-&gt;p_page;
+		struct buffer_head *bh, *head;
+		int partial_write = 0;
+
+		head = page_buffers(page);
+		if (error)
+			SetPageError(page);
+		BUG_ON(!head);
+		if (head-&gt;b_size == PAGE_CACHE_SIZE)
+			clear_buffer_dirty(head);
+		else {
+			loff_t offset;
+			loff_t io_end_offset = io_end-&gt;offset + io_end-&gt;size;
+
+			offset = (sector_t) page-&gt;index &lt;&lt; PAGE_CACHE_SHIFT;
+			bh = head;
+			do {
+				if ((offset &gt;= io_end-&gt;offset) &amp;&amp;
+				    (offset+bh-&gt;b_size &lt;= io_end_offset)) {
+					if (error)
+						buffer_io_error(bh);
+
+					clear_buffer_dirty(bh);
+				}
+				if (buffer_delay(bh))
+					partial_write = 1;
+				else if (!buffer_mapped(bh))
+					clear_buffer_dirty(bh);
+				else if (buffer_dirty(bh))
+					partial_write = 1;
+				offset += bh-&gt;b_size;
+				bh = bh-&gt;b_this_page;
+			} while (bh != head);
+		}
+
+		if (--io_end-&gt;pages[i]-&gt;p_count == 0) {
+			struct page *page = io_end-&gt;pages[i]-&gt;p_page;
+
+			end_page_writeback(page);
+			put_page(page);
+			kmem_cache_free(io_page_cachep, io_end-&gt;pages[i]);
+		}
+
+		/*
+		 * If this is a partial write which happened to make
+		 * all buffers uptodate then we can optimize away a
+		 * bogus readpage() for the next read(). Here we
+		 * 'discover' whether the page went uptodate as a
+		 * result of this (potentially partial) write.
+		 */
+		if (!partial_write)
+			SetPageUptodate(page);
+	}
+
+	io_end-&gt;num_io_pages = 0;
+
+	/* Add the io_end to per-inode completed io list*/
+	spin_lock_irqsave(&amp;EXT4_I(inode)-&gt;i_completed_io_lock, flags);
+	list_add_tail(&amp;io_end-&gt;list, &amp;EXT4_I(inode)-&gt;i_completed_io_list);
+	spin_unlock_irqrestore(&amp;EXT4_I(inode)-&gt;i_completed_io_lock, flags);
+
+	wq = EXT4_SB(inode-&gt;i_sb)-&gt;dio_unwritten_wq;
+	/* queue the work to convert unwritten extents to written */
+	queue_work(wq, &amp;io_end-&gt;work);
+}
+
+void ext4_io_submit(struct ext4_io_submit *io)
+{
+	struct bio *bio = io-&gt;io_bio;
+
+	if (bio) {
+		bio_get(io-&gt;io_bio);
+		submit_bio(io-&gt;io_op, io-&gt;io_bio);
+		BUG_ON(bio_flagged(io-&gt;io_bio, BIO_EOPNOTSUPP));
+		bio_put(io-&gt;io_bio);
+	}
+	io-&gt;io_bio = 0;
+	io-&gt;io_op = 0;
+	io-&gt;io_end = 0;
+}
+
+static int io_submit_init(struct ext4_io_submit *io,
+			  struct inode *inode,
+			  struct writeback_control *wbc,
+			  struct buffer_head *bh)
+{
+	ext4_io_end_t *io_end;
+	struct page *page = bh-&gt;b_page;
+	int nvecs = bio_get_nr_vecs(bh-&gt;b_bdev);
+	struct bio *bio;
+
+	io_end = ext4_init_io_end(inode, GFP_NOFS);
+	if (!io_end)
+		return -ENOMEM;
+	do {
+		bio = bio_alloc(GFP_NOIO, nvecs);
+		nvecs &gt;&gt;= 1;
+	} while (bio == NULL);
+
+	bio-&gt;bi_sector = bh-&gt;b_blocknr * (bh-&gt;b_size &gt;&gt; 9);
+	bio-&gt;bi_bdev = bh-&gt;b_bdev;
+	bio-&gt;bi_private = io-&gt;io_end = io_end;
+	bio-&gt;bi_end_io = ext4_end_bio;
+
+	io_end-&gt;inode = inode;
+	io_end-&gt;offset = (page-&gt;index &lt;&lt; PAGE_CACHE_SHIFT) + bh_offset(bh);
+
+	io-&gt;io_bio = bio;
+	io-&gt;io_op = (wbc-&gt;sync_mode == WB_SYNC_ALL ?
+			WRITE_SYNC_PLUG : WRITE);
+	io-&gt;io_next_block = bh-&gt;b_blocknr;
+	return 0;
+}
+
+static int io_submit_add_bh(struct ext4_io_submit *io,
+			    struct ext4_io_page *io_page,
+			    struct inode *inode,
+			    struct writeback_control *wbc,
+			    struct buffer_head *bh)
+{
+	ext4_io_end_t *io_end;
+	int ret;
+
+	if (buffer_new(bh)) {
+		clear_buffer_new(bh);
+		unmap_underlying_metadata(bh-&gt;b_bdev, bh-&gt;b_blocknr);
+	}
+
+	if (!buffer_mapped(bh) || buffer_delay(bh)) {
+		if (!buffer_mapped(bh))
+			clear_buffer_dirty(bh);
+		if (io-&gt;io_bio)
+			ext4_io_submit(io);
+		return 0;
+	}
+
+	if (io-&gt;io_bio &amp;&amp; bh-&gt;b_blocknr != io-&gt;io_next_block) {
+submit_and_retry:
+		ext4_io_submit(io);
+	}
+	if (io-&gt;io_bio == NULL) {
+		ret = io_submit_init(io, inode, wbc, bh);
+		if (ret)
+			return ret;
+	}
+	io_end = io-&gt;io_end;
+	if ((io_end-&gt;num_io_pages &gt;= MAX_IO_PAGES) &amp;&amp;
+	    (io_end-&gt;pages[io_end-&gt;num_io_pages-1] != io_page))
+		goto submit_and_retry;
+	if (buffer_uninit(bh))
+		io-&gt;io_end-&gt;flag |= EXT4_IO_END_UNWRITTEN;
+	io-&gt;io_end-&gt;size += bh-&gt;b_size;
+	io-&gt;io_next_block++;
+	ret = bio_add_page(io-&gt;io_bio, bh-&gt;b_page, bh-&gt;b_size, bh_offset(bh));
+	if (ret != bh-&gt;b_size)
+		goto submit_and_retry;
+	if ((io_end-&gt;num_io_pages == 0) ||
+	    (io_end-&gt;pages[io_end-&gt;num_io_pages-1] != io_page)) {
+		io_end-&gt;pages[io_end-&gt;num_io_pages++] = io_page;
+		io_page-&gt;p_count++;
+	}
+	return 0;
+}
+
+int ext4_bio_write_page(struct ext4_io_submit *io,
+			struct page *page,
+			int len,
+			struct writeback_control *wbc)
+{
+	struct inode *inode = page-&gt;mapping-&gt;host;
+	unsigned block_start, block_end, blocksize;
+	struct ext4_io_page *io_page;
+	struct buffer_head *bh, *head;
+	int ret = 0;
+
+	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;
+
+	BUG_ON(PageWriteback(page));
+	set_page_writeback(page);
+	ClearPageError(page);
+
+	io_page = kmem_cache_alloc(io_page_cachep, GFP_NOFS);
+	if (!io_page) {
+		set_page_dirty(page);
+		unlock_page(page);
+		return -ENOMEM;
+	}
+	io_page-&gt;p_page = page;
+	io_page-&gt;p_count = 0;
+	get_page(page);
+
+	for (bh = head = page_buffers(page), block_start = 0;
+	     bh != head || !block_start;
+	     block_start = block_end, bh = bh-&gt;b_this_page) {
+		block_end = block_start + blocksize;
+		if (block_start &gt;= len) {
+			clear_buffer_dirty(bh);
+			set_buffer_uptodate(bh);
+			continue;
+		}
+		ret = io_submit_add_bh(io, io_page, inode, wbc, bh);
+		if (ret) {
+			/*
+			 * We only get here on ENOMEM.  Not much else
+			 * we can do but mark the page as dirty, and
+			 * better luck next time.
+			 */
+			set_page_dirty(page);
+			break;
+		}
+	}
+	unlock_page(page);
+	/*
+	 * If the page was truncated before we could do the writeback,
+	 * or we had a memory allocation error while trying to write
+	 * the first buffer head, we won't have submitted any pages for
+	 * I/O.  In that case we need to make sure we've cleared the
+	 * PageWriteback bit from the page to prevent the system from
+	 * wedging later on.
+	 */
+	if (io_page-&gt;p_count == 0) {
+		put_page(page);
+		end_page_writeback(page);
+		kmem_cache_free(io_page_cachep, io_page);
+	}
+	return ret;
+}
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 8a24e9be7cb0..e13b3c3534d7 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -4769,9 +4769,12 @@ static int __init init_ext4_fs(void)
 	int err;
 
 	ext4_check_flag_values();
-	err = init_ext4_system_zone();
+	err = init_ext4_pageio();
 	if (err)
 		return err;
+	err = init_ext4_system_zone();
+	if (err)
+		goto out5;
 	ext4_kset = kset_create_and_add("ext4", NULL, fs_kobj);
 	if (!ext4_kset)
 		goto out4;
@@ -4812,6 +4815,8 @@ static int __init init_ext4_fs(void)
 	kset_unregister(ext4_kset);
 out4:
 	exit_ext4_system_zone();
+out5:
+	exit_ext4_pageio();
 	return err;
 }
 
@@ -4827,6 +4832,7 @@ static void __exit exit_ext4_fs(void)
 	remove_proc_entry("fs/ext4", NULL);
 	kset_unregister(ext4_kset);
 	exit_ext4_system_zone();
+	exit_ext4_pageio();
 }
 
 MODULE_AUTHOR("Remy Card, Stephen Tweedie, Andrew Morton, Andreas Dilger, Theodore Ts'o and others");</pre><hr><pre>commit 1de3e3df917459422cb2aecac440febc8879d410
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:10 2010 -0400

    ext4: move mpage_put_bnr_to_bhs()'s functionality to mpage_da_submit_io()
    
    This massively simplifies the ext4_da_writepages() code path by
    completely removing mpage_put_bnr_bhs(), which is almost 100 lines of
    code iterating over a set of pages using pagevec_lookup(), and folds
    that functionality into mpage_da_submit_io()'s existing
    pagevec_lookup() loop.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 5da6cfcecd83..c65d647378f9 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -2003,7 +2003,8 @@ static void ext4_da_page_release_reservation(struct page *page,
  *
  * As pages are already locked by write_cache_pages(), we can't use it
  */
-static int mpage_da_submit_io(struct mpage_da_data *mpd)
+static int mpage_da_submit_io(struct mpage_da_data *mpd,
+			      struct ext4_map_blocks *map)
 {
 	struct pagevec pvec;
 	unsigned long index, end;
@@ -2014,6 +2015,7 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 	unsigned int len, block_start;
 	struct buffer_head *bh, *page_bufs = NULL;
 	int journal_data = ext4_should_journal_data(inode);
+	sector_t pblock = 0, cur_logical = 0;
 
 	BUG_ON(mpd-&gt;next_page &lt;= mpd-&gt;first_page);
 	/*
@@ -2031,7 +2033,7 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 		if (nr_pages == 0)
 			break;
 		for (i = 0; i &lt; nr_pages; i++) {
-			int commit_write = 0;
+			int commit_write = 0, redirty_page = 0;
 			struct page *page = pvec.pages[i];
 
 			index = page-&gt;index;
@@ -2042,6 +2044,12 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 				len = size &amp; ~PAGE_CACHE_MASK;
 			else
 				len = PAGE_CACHE_SIZE;
+			if (map) {
+				cur_logical = index &lt;&lt; (PAGE_CACHE_SHIFT -
+							inode-&gt;i_blkbits);
+				pblock = map-&gt;m_pblk + (cur_logical -
+							map-&gt;m_lblk);
+			}
 			index++;
 
 			BUG_ON(!PageLocked(page));
@@ -2068,13 +2076,34 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 			bh = page_bufs = page_buffers(page);
 			block_start = 0;
 			do {
-				/* redirty page if block allocation undone */
-				if (!bh || buffer_delay(bh) ||
-				    buffer_unwritten(bh))
+				if (!bh)
 					goto redirty_page;
+				if (map &amp;&amp; (cur_logical &gt;= map-&gt;m_lblk) &amp;&amp;
+				    (cur_logical &lt;= (map-&gt;m_lblk +
+						     (map-&gt;m_len - 1)))) {
+					if (buffer_delay(bh)) {
+						clear_buffer_delay(bh);
+						bh-&gt;b_blocknr = pblock;
+					}
+					if (buffer_unwritten(bh) ||
+					    buffer_mapped(bh))
+						BUG_ON(bh-&gt;b_blocknr != pblock);
+					if (map-&gt;m_flags &amp; EXT4_MAP_UNINIT)
+						set_buffer_uninit(bh);
+					clear_buffer_unwritten(bh);
+				}
+
+				/* redirty page if block allocation undone */
+				if (buffer_delay(bh) || buffer_unwritten(bh))
+					redirty_page = 1;
 				bh = bh-&gt;b_this_page;
 				block_start += bh-&gt;b_size;
-			} while ((bh != page_bufs) &amp;&amp; (block_start &lt; len));
+				cur_logical++;
+				pblock++;
+			} while (bh != page_bufs);
+
+			if (redirty_page)
+				goto redirty_page;
 
 			if (commit_write)
 				/* mark the buffer_heads as dirty &amp; uptodate */
@@ -2105,91 +2134,6 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 	return ret;
 }
 
-/*
- * mpage_put_bnr_to_bhs - walk blocks and assign them actual numbers
- *
- * the function goes through all passed space and put actual disk
- * block numbers into buffer heads, dropping BH_Delay and BH_Unwritten
- */
-static void mpage_put_bnr_to_bhs(struct mpage_da_data *mpd,
-				 struct ext4_map_blocks *map)
-{
-	struct inode *inode = mpd-&gt;inode;
-	struct address_space *mapping = inode-&gt;i_mapping;
-	int blocks = map-&gt;m_len;
-	sector_t pblock = map-&gt;m_pblk, cur_logical;
-	struct buffer_head *head, *bh;
-	pgoff_t index, end;
-	struct pagevec pvec;
-	int nr_pages, i;
-
-	index = map-&gt;m_lblk &gt;&gt; (PAGE_CACHE_SHIFT - inode-&gt;i_blkbits);
-	end = (map-&gt;m_lblk + blocks - 1) &gt;&gt; (PAGE_CACHE_SHIFT - inode-&gt;i_blkbits);
-	cur_logical = index &lt;&lt; (PAGE_CACHE_SHIFT - inode-&gt;i_blkbits);
-
-	pagevec_init(&amp;pvec, 0);
-
-	while (index &lt;= end) {
-		/* XXX: optimize tail */
-		nr_pages = pagevec_lookup(&amp;pvec, mapping, index, PAGEVEC_SIZE);
-		if (nr_pages == 0)
-			break;
-		for (i = 0; i &lt; nr_pages; i++) {
-			struct page *page = pvec.pages[i];
-
-			index = page-&gt;index;
-			if (index &gt; end)
-				break;
-			index++;
-
-			BUG_ON(!PageLocked(page));
-			BUG_ON(PageWriteback(page));
-			BUG_ON(!page_has_buffers(page));
-
-			bh = page_buffers(page);
-			head = bh;
-
-			/* skip blocks out of the range */
-			do {
-				if (cur_logical &gt;= map-&gt;m_lblk)
-					break;
-				cur_logical++;
-			} while ((bh = bh-&gt;b_this_page) != head);
-
-			do {
-				if (cur_logical &gt; map-&gt;m_lblk + (blocks - 1))
-					break;
-
-				if (buffer_delay(bh) || buffer_unwritten(bh)) {
-
-					BUG_ON(bh-&gt;b_bdev != inode-&gt;i_sb-&gt;s_bdev);
-
-					if (buffer_delay(bh)) {
-						clear_buffer_delay(bh);
-						bh-&gt;b_blocknr = pblock;
-					} else {
-						/*
-						 * unwritten already should have
-						 * blocknr assigned. Verify that
-						 */
-						clear_buffer_unwritten(bh);
-						BUG_ON(bh-&gt;b_blocknr != pblock);
-					}
-
-				} else if (buffer_mapped(bh))
-					BUG_ON(bh-&gt;b_blocknr != pblock);
-
-				if (map-&gt;m_flags &amp; EXT4_MAP_UNINIT)
-					set_buffer_uninit(bh);
-				cur_logical++;
-				pblock++;
-			} while ((bh = bh-&gt;b_this_page) != head);
-		}
-		pagevec_release(&amp;pvec);
-	}
-}
-
-
 static void ext4_da_block_invalidatepages(struct mpage_da_data *mpd,
 					sector_t logical, long blk_cnt)
 {
@@ -2252,7 +2196,7 @@ static void ext4_print_free_blocks(struct inode *inode)
 static void mpage_da_map_and_submit(struct mpage_da_data *mpd)
 {
 	int err, blks, get_blocks_flags;
-	struct ext4_map_blocks map;
+	struct ext4_map_blocks map, *mapp = NULL;
 	sector_t next = mpd-&gt;b_blocknr;
 	unsigned max_blocks = mpd-&gt;b_size &gt;&gt; mpd-&gt;inode-&gt;i_blkbits;
 	loff_t disksize = EXT4_I(mpd-&gt;inode)-&gt;i_disksize;
@@ -2343,6 +2287,7 @@ static void mpage_da_map_and_submit(struct mpage_da_data *mpd)
 	}
 	BUG_ON(blks == 0);
 
+	mapp = &amp;map;
 	if (map.m_flags &amp; EXT4_MAP_NEW) {
 		struct block_device *bdev = mpd-&gt;inode-&gt;i_sb-&gt;s_bdev;
 		int i;
@@ -2351,14 +2296,6 @@ static void mpage_da_map_and_submit(struct mpage_da_data *mpd)
 			unmap_underlying_metadata(bdev, map.m_pblk + i);
 	}
 
-	/*
-	 * If blocks are delayed marked, we need to
-	 * put actual blocknr and drop delayed bit
-	 */
-	if ((mpd-&gt;b_state &amp; (1 &lt;&lt; BH_Delay)) ||
-	    (mpd-&gt;b_state &amp; (1 &lt;&lt; BH_Unwritten)))
-		mpage_put_bnr_to_bhs(mpd, &amp;map);
-
 	if (ext4_should_order_data(mpd-&gt;inode)) {
 		err = ext4_jbd2_file_inode(handle, mpd-&gt;inode);
 		if (err)
@@ -2382,7 +2319,7 @@ static void mpage_da_map_and_submit(struct mpage_da_data *mpd)
 	}
 
 submit_io:
-	mpage_da_submit_io(mpd);
+	mpage_da_submit_io(mpd, mapp);
 	mpd-&gt;io_done = 1;
 }
 </pre><hr><pre>commit 3ecdb3a193a5f224f084c04a63aa28cdccf4d7d0
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:10 2010 -0400

    ext4: inline walk_page_buffers() into mpage_da_submit_io
    
    Expand the call:
    
      if (walk_page_buffers(NULL, page_bufs, 0, len, NULL,
                            ext4_bh_delay_or_unwritten))
            goto redirty_page
    
    into mpage_da_submit_io().
    
    This will allow us to merge in mpage_put_bnr_to_bhs() in the next
    patch.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 97a0c35219ae..5da6cfcecd83 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -2011,8 +2011,8 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 	struct inode *inode = mpd-&gt;inode;
 	struct address_space *mapping = inode-&gt;i_mapping;
 	loff_t size = i_size_read(inode);
-	unsigned int len;
-	struct buffer_head *page_bufs = NULL;
+	unsigned int len, block_start;
+	struct buffer_head *bh, *page_bufs = NULL;
 	int journal_data = ext4_should_journal_data(inode);
 
 	BUG_ON(mpd-&gt;next_page &lt;= mpd-&gt;first_page);
@@ -2064,15 +2064,17 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 				}
 				commit_write = 1;
 			}
-			page_bufs = page_buffers(page);
-			if (walk_page_buffers(NULL, page_bufs, 0, len, NULL,
-					      ext4_bh_delay_or_unwritten)) {
-				/*
-				 * We couldn't do block allocation for
-				 * some reason.
-				 */
-				goto redirty_page;
-			}
+
+			bh = page_bufs = page_buffers(page);
+			block_start = 0;
+			do {
+				/* redirty page if block allocation undone */
+				if (!bh || buffer_delay(bh) ||
+				    buffer_unwritten(bh))
+					goto redirty_page;
+				bh = bh-&gt;b_this_page;
+				block_start += bh-&gt;b_size;
+			} while ((bh != page_bufs) &amp;&amp; (block_start &lt; len));
 
 			if (commit_write)
 				/* mark the buffer_heads as dirty &amp; uptodate */</pre><hr><pre>commit cb20d5188366f04d96d2e07b1240cc92170ade40
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:09 2010 -0400

    ext4: inline ext4_writepage() into mpage_da_submit_io()
    
    As a prepratory step to switching to bio_submit, inline
    ext4_writepage() into mpage_da_submit() and then simplify things a
    bit.  This makes it clearer what mpage_da_submit needs to do.
    
    Also, move the ClearPageChecked(page) call into
    __ext4_journalled_writepage(), as a minor bit of cleanup refactoring.
    
    This also allows us to pull i_size_read() and
    ext4_should_journal_data() out of the loop, which should be a very
    minor CPU savings.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index a08ec795995f..97a0c35219ae 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -60,7 +60,12 @@ static inline int ext4_begin_ordered_truncate(struct inode *inode,
 }
 
 static void ext4_invalidatepage(struct page *page, unsigned long offset);
-static int ext4_writepage(struct page *page, struct writeback_control *wbc);
+static int noalloc_get_block_write(struct inode *inode, sector_t iblock,
+				   struct buffer_head *bh_result, int create);
+static int ext4_set_bh_endio(struct buffer_head *bh, struct inode *inode);
+static void ext4_end_io_buffer_write(struct buffer_head *bh, int uptodate);
+static int __ext4_journalled_writepage(struct page *page, unsigned int len);
+static int ext4_bh_delay_or_unwritten(handle_t *handle, struct buffer_head *bh);
 
 /*
  * Test whether an inode is a fast symlink.
@@ -2000,12 +2005,15 @@ static void ext4_da_page_release_reservation(struct page *page,
  */
 static int mpage_da_submit_io(struct mpage_da_data *mpd)
 {
-	long pages_skipped;
 	struct pagevec pvec;
 	unsigned long index, end;
 	int ret = 0, err, nr_pages, i;
 	struct inode *inode = mpd-&gt;inode;
 	struct address_space *mapping = inode-&gt;i_mapping;
+	loff_t size = i_size_read(inode);
+	unsigned int len;
+	struct buffer_head *page_bufs = NULL;
+	int journal_data = ext4_should_journal_data(inode);
 
 	BUG_ON(mpd-&gt;next_page &lt;= mpd-&gt;first_page);
 	/*
@@ -2023,28 +2031,69 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 		if (nr_pages == 0)
 			break;
 		for (i = 0; i &lt; nr_pages; i++) {
+			int commit_write = 0;
 			struct page *page = pvec.pages[i];
 
 			index = page-&gt;index;
 			if (index &gt; end)
 				break;
+
+			if (index == size &gt;&gt; PAGE_CACHE_SHIFT)
+				len = size &amp; ~PAGE_CACHE_MASK;
+			else
+				len = PAGE_CACHE_SIZE;
 			index++;
 
 			BUG_ON(!PageLocked(page));
 			BUG_ON(PageWriteback(page));
 
-			pages_skipped = mpd-&gt;wbc-&gt;pages_skipped;
-			err = ext4_writepage(page, mpd-&gt;wbc);
-			if (!err &amp;&amp; (pages_skipped == mpd-&gt;wbc-&gt;pages_skipped))
+			/*
+			 * If the page does not have buffers (for
+			 * whatever reason), try to create them using
+			 * block_prepare_write.  If this fails,
+			 * redirty the page and move on.
+			 */
+			if (!page_has_buffers(page)) {
+				if (block_prepare_write(page, 0, len,
+						noalloc_get_block_write)) {
+				redirty_page:
+					redirty_page_for_writepage(mpd-&gt;wbc,
+								   page);
+					unlock_page(page);
+					continue;
+				}
+				commit_write = 1;
+			}
+			page_bufs = page_buffers(page);
+			if (walk_page_buffers(NULL, page_bufs, 0, len, NULL,
+					      ext4_bh_delay_or_unwritten)) {
 				/*
-				 * have successfully written the page
-				 * without skipping the same
+				 * We couldn't do block allocation for
+				 * some reason.
 				 */
+				goto redirty_page;
+			}
+
+			if (commit_write)
+				/* mark the buffer_heads as dirty &amp; uptodate */
+				block_commit_write(page, 0, len);
+
+			if (journal_data &amp;&amp; PageChecked(page))
+				err = __ext4_journalled_writepage(page, len);
+			else if (buffer_uninit(page_bufs)) {
+				ext4_set_bh_endio(page_bufs, inode);
+				err = block_write_full_page_endio(page,
+					noalloc_get_block_write,
+					mpd-&gt;wbc, ext4_end_io_buffer_write);
+			} else
+				err = block_write_full_page(page,
+					    noalloc_get_block_write, mpd-&gt;wbc);
+
+			if (!err)
 				mpd-&gt;pages_written++;
 			/*
 			 * In error case, we have to continue because
 			 * remaining pages are still locked
-			 * XXX: unlock and re-dirty them?
 			 */
 			if (ret == 0)
 				ret = err;
@@ -2627,6 +2676,7 @@ static int __ext4_journalled_writepage(struct page *page,
 	int ret = 0;
 	int err;
 
+	ClearPageChecked(page);
 	page_bufs = page_buffers(page);
 	BUG_ON(!page_bufs);
 	walk_page_buffers(handle, page_bufs, 0, len, NULL, bget_one);
@@ -2749,14 +2799,12 @@ static int ext4_writepage(struct page *page,
 		/* now mark the buffer_heads as dirty and uptodate */
 		block_commit_write(page, 0, len);
 
-	if (PageChecked(page) &amp;&amp; ext4_should_journal_data(inode)) {
+	if (PageChecked(page) &amp;&amp; ext4_should_journal_data(inode))
 		/*
 		 * It's mmapped pagecache.  Add buffers and journal it.  There
 		 * doesn't seem much point in redirtying the page here.
 		 */
-		ClearPageChecked(page);
 		return __ext4_journalled_writepage(page, len);
-	}
 
 	if (buffer_uninit(page_bufs)) {
 		ext4_set_bh_endio(page_bufs, inode);</pre><hr><pre>commit a42afc5f56f319107e987aa6adf2f65d93d527c7
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:09 2010 -0400

    ext4: simplify ext4_writepage()
    
    The actual code in ext4_writepage() is unnecessarily convoluted.
    Simplify it so it is easier to understand, but otherwise logically
    equivalent.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 55961ff4efc2..a08ec795995f 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -2704,7 +2704,7 @@ static void ext4_end_io_buffer_write(struct buffer_head *bh, int uptodate);
 static int ext4_writepage(struct page *page,
 			  struct writeback_control *wbc)
 {
-	int ret = 0;
+	int ret = 0, commit_write = 0;
 	loff_t size;
 	unsigned int len;
 	struct buffer_head *page_bufs = NULL;
@@ -2717,60 +2717,37 @@ static int ext4_writepage(struct page *page,
 	else
 		len = PAGE_CACHE_SIZE;
 
-	if (page_has_buffers(page)) {
-		page_bufs = page_buffers(page);
-		if (walk_page_buffers(NULL, page_bufs, 0, len, NULL,
-					ext4_bh_delay_or_unwritten)) {
-			/*
-			 * We don't want to do  block allocation
-			 * So redirty the page and return
-			 * We may reach here when we do a journal commit
-			 * via journal_submit_inode_data_buffers.
-			 * If we don't have mapping block we just ignore
-			 * them. We can also reach here via shrink_page_list
-			 */
+	/*
+	 * If the page does not have buffers (for whatever reason),
+	 * try to create them using block_prepare_write.  If this
+	 * fails, redirty the page and move on.
+	 */
+	if (!page_buffers(page)) {
+		if (block_prepare_write(page, 0, len,
+					noalloc_get_block_write)) {
+		redirty_page:
 			redirty_page_for_writepage(wbc, page);
 			unlock_page(page);
 			return 0;
 		}
-	} else {
+		commit_write = 1;
+	}
+	page_bufs = page_buffers(page);
+	if (walk_page_buffers(NULL, page_bufs, 0, len, NULL,
+			      ext4_bh_delay_or_unwritten)) {
 		/*
-		 * The test for page_has_buffers() is subtle:
-		 * We know the page is dirty but it lost buffers. That means
-		 * that at some moment in time after write_begin()/write_end()
-		 * has been called all buffers have been clean and thus they
-		 * must have been written at least once. So they are all
-		 * mapped and we can happily proceed with mapping them
-		 * and writing the page.
-		 *
-		 * Try to initialize the buffer_heads and check whether
-		 * all are mapped and non delay. We don't want to
-		 * do block allocation here.
+		 * We don't want to do block allocation So redirty the
+		 * page and return We may reach here when we do a
+		 * journal commit via
+		 * journal_submit_inode_data_buffers.  If we don't
+		 * have mapping block we just ignore them. We can also
+		 * reach here via shrink_page_list
 		 */
-		ret = block_prepare_write(page, 0, len,
-					  noalloc_get_block_write);
-		if (!ret) {
-			page_bufs = page_buffers(page);
-			/* check whether all are mapped and non delay */
-			if (walk_page_buffers(NULL, page_bufs, 0, len, NULL,
-						ext4_bh_delay_or_unwritten)) {
-				redirty_page_for_writepage(wbc, page);
-				unlock_page(page);
-				return 0;
-			}
-		} else {
-			/*
-			 * We can't do block allocation here
-			 * so just redity the page and unlock
-			 * and return
-			 */
-			redirty_page_for_writepage(wbc, page);
-			unlock_page(page);
-			return 0;
-		}
+		goto redirty_page;
+	}
+	if (commit_write)
 		/* now mark the buffer_heads as dirty and uptodate */
 		block_commit_write(page, 0, len);
-	}
 
 	if (PageChecked(page) &amp;&amp; ext4_should_journal_data(inode)) {
 		/*
@@ -2781,7 +2758,7 @@ static int ext4_writepage(struct page *page,
 		return __ext4_journalled_writepage(page, len);
 	}
 
-	if (page_bufs &amp;&amp; buffer_uninit(page_bufs)) {
+	if (buffer_uninit(page_bufs)) {
 		ext4_set_bh_endio(page_bufs, inode);
 		ret = block_write_full_page_endio(page, noalloc_get_block_write,
 					    wbc, ext4_end_io_buffer_write);</pre><hr><pre>commit 5a87b7a5da250c9be6d757758425dfeaf8ed3179
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:09 2010 -0400

    ext4: call mpage_da_submit_io() from mpage_da_map_blocks()
    
    Eventually we need to completely reorganize the ext4 writepage
    callpath, but for now, we simplify things a little by calling
    mpage_da_submit_io() from mpage_da_map_blocks(), since all of the
    places where we call mpage_da_map_blocks() it is followed up by a call
    to mpage_da_submit_io().
    
    We're also a wee bit better with respect to error handling, but there
    are still a number of issues where it's not clear what the right thing
    is to do with ext4 functions deep in the writeback codepath fails.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 670ab15e4f9a..55961ff4efc2 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -60,6 +60,7 @@ static inline int ext4_begin_ordered_truncate(struct inode *inode,
 }
 
 static void ext4_invalidatepage(struct page *page, unsigned long offset);
+static int ext4_writepage(struct page *page, struct writeback_control *wbc);
 
 /*
  * Test whether an inode is a fast symlink.
@@ -2033,7 +2034,7 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd)
 			BUG_ON(PageWriteback(page));
 
 			pages_skipped = mpd-&gt;wbc-&gt;pages_skipped;
-			err = mapping-&gt;a_ops-&gt;writepage(page, mpd-&gt;wbc);
+			err = ext4_writepage(page, mpd-&gt;wbc);
 			if (!err &amp;&amp; (pages_skipped == mpd-&gt;wbc-&gt;pages_skipped))
 				/*
 				 * have successfully written the page
@@ -2189,14 +2190,15 @@ static void ext4_print_free_blocks(struct inode *inode)
 }
 
 /*
- * mpage_da_map_blocks - go through given space
+ * mpage_da_map_and_submit - go through given space, map them
+ *       if necessary, and then submit them for I/O
  *
  * @mpd - bh describing space
  *
  * The function skips space we know is already mapped to disk blocks.
  *
  */
-static int mpage_da_map_blocks(struct mpage_da_data *mpd)
+static void mpage_da_map_and_submit(struct mpage_da_data *mpd)
 {
 	int err, blks, get_blocks_flags;
 	struct ext4_map_blocks map;
@@ -2206,18 +2208,14 @@ static int mpage_da_map_blocks(struct mpage_da_data *mpd)
 	handle_t *handle = NULL;
 
 	/*
-	 * We consider only non-mapped and non-allocated blocks
+	 * If the blocks are mapped already, or we couldn't accumulate
+	 * any blocks, then proceed immediately to the submission stage.
 	 */
-	if ((mpd-&gt;b_state  &amp; (1 &lt;&lt; BH_Mapped)) &amp;&amp;
-		!(mpd-&gt;b_state &amp; (1 &lt;&lt; BH_Delay)) &amp;&amp;
-		!(mpd-&gt;b_state &amp; (1 &lt;&lt; BH_Unwritten)))
-		return 0;
-
-	/*
-	 * If we didn't accumulate anything to write simply return
-	 */
-	if (!mpd-&gt;b_size)
-		return 0;
+	if ((mpd-&gt;b_size == 0) ||
+	    ((mpd-&gt;b_state  &amp; (1 &lt;&lt; BH_Mapped)) &amp;&amp;
+	     !(mpd-&gt;b_state &amp; (1 &lt;&lt; BH_Delay)) &amp;&amp;
+	     !(mpd-&gt;b_state &amp; (1 &lt;&lt; BH_Unwritten))))
+		goto submit_io;
 
 	handle = ext4_journal_current_handle();
 	BUG_ON(!handle);
@@ -2254,17 +2252,18 @@ static int mpage_da_map_blocks(struct mpage_da_data *mpd)
 
 		err = blks;
 		/*
-		 * If get block returns with error we simply
-		 * return. Later writepage will redirty the page and
-		 * writepages will find the dirty page again
+		 * If get block returns EAGAIN or ENOSPC and there
+		 * appears to be free blocks we will call
+		 * ext4_writepage() for all of the pages which will
+		 * just redirty the pages.
 		 */
 		if (err == -EAGAIN)
-			return 0;
+			goto submit_io;
 
 		if (err == -ENOSPC &amp;&amp;
 		    ext4_count_free_blocks(sb)) {
 			mpd-&gt;retval = err;
-			return 0;
+			goto submit_io;
 		}
 
 		/*
@@ -2289,7 +2288,7 @@ static int mpage_da_map_blocks(struct mpage_da_data *mpd)
 		/* invalidate all the pages */
 		ext4_da_block_invalidatepages(mpd, next,
 				mpd-&gt;b_size &gt;&gt; mpd-&gt;inode-&gt;i_blkbits);
-		return err;
+		return;
 	}
 	BUG_ON(blks == 0);
 
@@ -2312,7 +2311,8 @@ static int mpage_da_map_blocks(struct mpage_da_data *mpd)
 	if (ext4_should_order_data(mpd-&gt;inode)) {
 		err = ext4_jbd2_file_inode(handle, mpd-&gt;inode);
 		if (err)
-			return err;
+			/* This only happens if the journal is aborted */
+			return;
 	}
 
 	/*
@@ -2323,10 +2323,16 @@ static int mpage_da_map_blocks(struct mpage_da_data *mpd)
 		disksize = i_size_read(mpd-&gt;inode);
 	if (disksize &gt; EXT4_I(mpd-&gt;inode)-&gt;i_disksize) {
 		ext4_update_i_disksize(mpd-&gt;inode, disksize);
-		return ext4_mark_inode_dirty(handle, mpd-&gt;inode);
+		err = ext4_mark_inode_dirty(handle, mpd-&gt;inode);
+		if (err)
+			ext4_error(mpd-&gt;inode-&gt;i_sb,
+				   "Failed to mark inode %lu dirty",
+				   mpd-&gt;inode-&gt;i_ino);
 	}
 
-	return 0;
+submit_io:
+	mpage_da_submit_io(mpd);
+	mpd-&gt;io_done = 1;
 }
 
 #define BH_FLAGS ((1 &lt;&lt; BH_Uptodate) | (1 &lt;&lt; BH_Mapped) | \
@@ -2403,9 +2409,7 @@ static void mpage_add_bh_to_extent(struct mpage_da_data *mpd,
 	 * We couldn't merge the block to our extent, so we
 	 * need to flush current  extent and start new one
 	 */
-	if (mpage_da_map_blocks(mpd) == 0)
-		mpage_da_submit_io(mpd);
-	mpd-&gt;io_done = 1;
+	mpage_da_map_and_submit(mpd);
 	return;
 }
 
@@ -2437,15 +2441,13 @@ static int __mpage_da_writepage(struct page *page,
 	if (mpd-&gt;next_page != page-&gt;index) {
 		/*
 		 * Nope, we can't. So, we map non-allocated blocks
-		 * and start IO on them using writepage()
+		 * and start IO on them
 		 */
 		if (mpd-&gt;next_page != mpd-&gt;first_page) {
-			if (mpage_da_map_blocks(mpd) == 0)
-				mpage_da_submit_io(mpd);
+			mpage_da_map_and_submit(mpd);
 			/*
 			 * skip rest of the page in the page_vec
 			 */
-			mpd-&gt;io_done = 1;
 			redirty_page_for_writepage(wbc, page);
 			unlock_page(page);
 			return MPAGE_DA_EXTENT_TAIL;
@@ -3071,9 +3073,7 @@ static int ext4_da_writepages(struct address_space *mapping,
 		 * them for I/O.
 		 */
 		if (!mpd.io_done &amp;&amp; mpd.next_page != mpd.first_page) {
-			if (mpage_da_map_blocks(&amp;mpd) == 0)
-				mpage_da_submit_io(&amp;mpd);
-			mpd.io_done = 1;
+			mpage_da_map_and_submit(&amp;mpd);
 			ret = MPAGE_DA_EXTENT_TAIL;
 		}
 		trace_ext4_da_write_pages(inode, &amp;mpd);</pre><hr><pre>commit 16828088f9e518158edecb6cde7e6fa38e4c889b
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:09 2010 -0400

    ext4: use KMEM_CACHE instead of kmem_cache_create
    
    Also remove the SLAB_RECLAIM_ACCOUNT flag from the system zone kmem
    cache.  This slab tends to be fairly static, so it shouldn't be marked
    as likely to have free pages that can be reclaimed.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/block_validity.c b/fs/ext4/block_validity.c
index 3db5084db9bd..68bab70dd139 100644
--- a/fs/ext4/block_validity.c
+++ b/fs/ext4/block_validity.c
@@ -31,8 +31,7 @@ static struct kmem_cache *ext4_system_zone_cachep;
 
 int __init init_ext4_system_zone(void)
 {
-	ext4_system_zone_cachep = KMEM_CACHE(ext4_system_zone,
-					     SLAB_RECLAIM_ACCOUNT);
+	ext4_system_zone_cachep = KMEM_CACHE(ext4_system_zone, 0);
 	if (ext4_system_zone_cachep == NULL)
 		return -ENOMEM;
 	return 0;
diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c
index 3f62df50f483..d732ef5a835d 100644
--- a/fs/ext4/mballoc.c
+++ b/fs/ext4/mballoc.c
@@ -2706,26 +2706,20 @@ static void ext4_remove_debugfs_entry(void)
 
 int __init init_ext4_mballoc(void)
 {
-	ext4_pspace_cachep =
-		kmem_cache_create("ext4_prealloc_space",
-				     sizeof(struct ext4_prealloc_space),
-				     0, SLAB_RECLAIM_ACCOUNT, NULL);
+	ext4_pspace_cachep = KMEM_CACHE(ext4_prealloc_space,
+					SLAB_RECLAIM_ACCOUNT);
 	if (ext4_pspace_cachep == NULL)
 		return -ENOMEM;
 
-	ext4_ac_cachep =
-		kmem_cache_create("ext4_alloc_context",
-				     sizeof(struct ext4_allocation_context),
-				     0, SLAB_RECLAIM_ACCOUNT, NULL);
+	ext4_ac_cachep = KMEM_CACHE(ext4_allocation_context,
+				    SLAB_RECLAIM_ACCOUNT);
 	if (ext4_ac_cachep == NULL) {
 		kmem_cache_destroy(ext4_pspace_cachep);
 		return -ENOMEM;
 	}
 
-	ext4_free_ext_cachep =
-		kmem_cache_create("ext4_free_block_extents",
-				     sizeof(struct ext4_free_data),
-				     0, SLAB_RECLAIM_ACCOUNT, NULL);
+	ext4_free_ext_cachep = KMEM_CACHE(ext4_free_data,
+					  SLAB_RECLAIM_ACCOUNT);
 	if (ext4_free_ext_cachep == NULL) {
 		kmem_cache_destroy(ext4_pspace_cachep);
 		kmem_cache_destroy(ext4_ac_cachep);</pre><hr><pre>commit 7845c0497536c566bfef08db1a38ae1ad2c25464
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:08 2010 -0400

    ext4: use search_dirblock() in ext4_dx_find_entry()
    
    Use the search_dirblock() in ext4_dx_find_entry().  It makes the code
    easier to read, and it takes advantage of common code.  It also saves
    100 bytes or so of text space.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Cc: Brad Spengler &lt;spender@grsecurity.net&gt;

diff --git a/fs/ext4/namei.c b/fs/ext4/namei.c
index 213523803dff..86a7870babbd 100644
--- a/fs/ext4/namei.c
+++ b/fs/ext4/namei.c
@@ -974,39 +974,30 @@ static struct buffer_head * ext4_dx_find_entry(struct inode *dir, const struct q
 	struct super_block * sb = dir-&gt;i_sb;
 	struct dx_hash_info	hinfo;
 	struct dx_frame frames[2], *frame;
-	struct ext4_dir_entry_2 *de, *top;
 	struct buffer_head *bh;
 	ext4_lblk_t block;
 	int retval;
-	int namelen = d_name-&gt;len;
-	const u8 *name = d_name-&gt;name;
 
 	if (!(frame = dx_probe(d_name, dir, &amp;hinfo, frames, err)))
 		return NULL;
 	do {
 		block = dx_get_block(frame-&gt;at);
-		if (!(bh = ext4_bread (NULL,dir, block, 0, err)))
+		if (!(bh = ext4_bread(NULL, dir, block, 0, err)))
 			goto errout;
-		de = (struct ext4_dir_entry_2 *) bh-&gt;b_data;
-		top = (struct ext4_dir_entry_2 *) ((char *) de + sb-&gt;s_blocksize -
-				       EXT4_DIR_REC_LEN(0));
-		for (; de &lt; top; de = ext4_next_entry(de, sb-&gt;s_blocksize)) {
-			int off = (block &lt;&lt; EXT4_BLOCK_SIZE_BITS(sb))
-				  + ((char *) de - bh-&gt;b_data);
-
-			if (!ext4_check_dir_entry(dir, de, bh, off)) {
-				brelse(bh);
-				*err = ERR_BAD_DX_DIR;
-				goto errout;
-			}
 
-			if (ext4_match(namelen, name, de)) {
-				*res_dir = de;
-				dx_release(frames);
-				return bh;
-			}
+		retval = search_dirblock(bh, dir, d_name,
+					 block &lt;&lt; EXT4_BLOCK_SIZE_BITS(sb),
+					 res_dir);
+		if (retval == 1) { 	/* Success! */
+			dx_release(frames);
+			return bh;
 		}
 		brelse(bh);
+		if (retval == -1) {
+			*err = ERR_BAD_DX_DIR;
+			goto errout;
+		}
+
 		/* Check to see if we should continue to search */
 		retval = ext4_htree_next_block(dir, hinfo.hash, frame,
 					       frames, NULL);</pre><hr><pre>commit 8941ec8bb6443d28d5c25311870aeaa809cf1538
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:08 2010 -0400

    ext4: avoid uninitialized memory references in ext3_htree_next_block()
    
    If the first block of htree directory is missing '.' or '..' but is
    otherwise a valid directory, and we do a lookup for '.' or '..', it's
    possible to dereference an uninitialized memory pointer in
    ext4_htree_next_block().
    
    We avoid this by moving the special case from ext4_dx_find_entry() to
    ext4_find_entry(); this also means we can optimize ext4_find_entry()
    slightly when NFS looks up "..".
    
    Thanks to Brad Spengler for pointing a Clang warning that led me to
    look more closely at this code.  The warning was harmless, but it was
    useful in pointing out code that was too ugly to live.  This warning was
    also reported by Roman Borisov.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Cc: Brad Spengler &lt;spender@grsecurity.net&gt;

diff --git a/fs/ext4/namei.c b/fs/ext4/namei.c
index 314c0d3b3fa9..213523803dff 100644
--- a/fs/ext4/namei.c
+++ b/fs/ext4/namei.c
@@ -856,6 +856,7 @@ static struct buffer_head * ext4_find_entry (struct inode *dir,
 	struct buffer_head *bh_use[NAMEI_RA_SIZE];
 	struct buffer_head *bh, *ret = NULL;
 	ext4_lblk_t start, block, b;
+	const u8 *name = d_name-&gt;name;
 	int ra_max = 0;		/* Number of bh's in the readahead
 				   buffer, bh_use[] */
 	int ra_ptr = 0;		/* Current index into readahead
@@ -870,6 +871,16 @@ static struct buffer_head * ext4_find_entry (struct inode *dir,
 	namelen = d_name-&gt;len;
 	if (namelen &gt; EXT4_NAME_LEN)
 		return NULL;
+	if ((namelen &lt;= 2) &amp;&amp; (name[0] == '.') &amp;&amp;
+	    (name[1] == '.' || name[1] == '0')) {
+		/*
+		 * "." or ".." will only be in the first block
+		 * NFS may look up ".."; "." should be handled by the VFS
+		 */
+		block = start = 0;
+		nblocks = 1;
+		goto restart;
+	}
 	if (is_dx(dir)) {
 		bh = ext4_dx_find_entry(dir, d_name, res_dir, &amp;err);
 		/*
@@ -960,9 +971,8 @@ static struct buffer_head * ext4_find_entry (struct inode *dir,
 static struct buffer_head * ext4_dx_find_entry(struct inode *dir, const struct qstr *d_name,
 		       struct ext4_dir_entry_2 **res_dir, int *err)
 {
-	struct super_block * sb;
+	struct super_block * sb = dir-&gt;i_sb;
 	struct dx_hash_info	hinfo;
-	u32 hash;
 	struct dx_frame frames[2], *frame;
 	struct ext4_dir_entry_2 *de, *top;
 	struct buffer_head *bh;
@@ -971,18 +981,8 @@ static struct buffer_head * ext4_dx_find_entry(struct inode *dir, const struct q
 	int namelen = d_name-&gt;len;
 	const u8 *name = d_name-&gt;name;
 
-	sb = dir-&gt;i_sb;
-	/* NFS may look up ".." - look at dx_root directory block */
-	if (namelen &gt; 2 || name[0] != '.'||(name[1] != '.' &amp;&amp; name[1] != '\0')){
-		if (!(frame = dx_probe(d_name, dir, &amp;hinfo, frames, err)))
-			return NULL;
-	} else {
-		frame = frames;
-		frame-&gt;bh = NULL;			/* for dx_release() */
-		frame-&gt;at = (struct dx_entry *)frames;	/* hack for zero entry*/
-		dx_set_block(frame-&gt;at, 0);		/* dx_root block is 0 */
-	}
-	hash = hinfo.hash;
+	if (!(frame = dx_probe(d_name, dir, &amp;hinfo, frames, err)))
+		return NULL;
 	do {
 		block = dx_get_block(frame-&gt;at);
 		if (!(bh = ext4_bread (NULL,dir, block, 0, err)))
@@ -1008,7 +1008,7 @@ static struct buffer_head * ext4_dx_find_entry(struct inode *dir, const struct q
 		}
 		brelse(bh);
 		/* Check to see if we should continue to search */
-		retval = ext4_htree_next_block(dir, hash, frame,
+		retval = ext4_htree_next_block(dir, hinfo.hash, frame,
 					       frames, NULL);
 		if (retval &lt; 0) {
 			ext4_warning(sb,</pre><hr><pre>commit 5c2178e785244341d1e6f2bc3b62f20a337cc44f
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:30:04 2010 -0400

    jbd2: Add sanity check for attempts to start handle during umount
    
    An attempt to modify the file system during the call to
    jbd2_destroy_journal() can lead to a system lockup.  So add some
    checking to make it much more obvious when this happens to and to
    determine where the offending code is located.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/jbd2/checkpoint.c b/fs/jbd2/checkpoint.c
index 5247e7ffdcb4..524800dce207 100644
--- a/fs/jbd2/checkpoint.c
+++ b/fs/jbd2/checkpoint.c
@@ -299,6 +299,16 @@ static int __process_buffer(journal_t *journal, struct journal_head *jh,
 		transaction-&gt;t_chp_stats.cs_forced_to_close++;
 		spin_unlock(&amp;journal-&gt;j_list_lock);
 		jbd_unlock_bh_state(bh);
+		if (unlikely(journal-&gt;j_flags &amp; JBD2_UNMOUNT))
+			/*
+			 * The journal thread is dead; so starting and
+			 * waiting for a commit to finish will cause
+			 * us to wait for a _very_ long time.
+			 */
+			printk(KERN_ERR "JBD2: %s: "
+			       "Waiting for Godot: block %llu\n",
+			       journal-&gt;j_devname,
+			       (unsigned long long) bh-&gt;b_blocknr);
 		jbd2_log_start_commit(journal, tid);
 		jbd2_log_wait_commit(journal, tid);
 		ret = 1;
diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index f3479d6e0a83..6bf0a242613e 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -156,6 +156,7 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 	 */
 repeat:
 	read_lock(&amp;journal-&gt;j_state_lock);
+	BUG_ON(journal-&gt;j_flags &amp; JBD2_UNMOUNT);
 	if (is_journal_aborted(journal) ||
 	    (journal-&gt;j_errno != 0 &amp;&amp; !(journal-&gt;j_flags &amp; JBD2_ACK_ERR))) {
 		read_unlock(&amp;journal-&gt;j_state_lock);</pre>
    <div class="pagination">
        <a href='1_79.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><span>[80]</span><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_81.html'>Next&gt;&gt;</a>
    <div>
</body>
