<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_48.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><span>[49]</span><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_50.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit 960fd856fdc3b08b3638f3f9b6b4bfceb77660c7
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Jul 5 23:11:16 2013 -0400

    ext4: fix ext4_get_group_number()
    
    The function ext4_get_group_number() was introduced as an optimization
    in commit bd86298e60b8.  Unfortunately, this commit incorrectly
    calculate the group number for file systems with a 1k block size (when
    s_first_data_block is 1 instead of zero).  This could cause the
    following kernel BUG:
    
    [  568.877799] ------------[ cut here ]------------
    [  568.877833] kernel BUG at fs/ext4/mballoc.c:3728!
    [  568.877840] Oops: Exception in kernel mode, sig: 5 [#1]
    [  568.877845] SMP NR_CPUS=32 NUMA pSeries
    [  568.877852] Modules linked in: binfmt_misc
    [  568.877861] CPU: 1 PID: 3516 Comm: fs_mark Not tainted 3.10.0-03216-g7c6809f-dirty #1
    [  568.877867] task: c0000001fb0b8000 ti: c0000001fa954000 task.ti: c0000001fa954000
    [  568.877873] NIP: c0000000002f42a4 LR: c0000000002f4274 CTR: c000000000317ef8
    [  568.877879] REGS: c0000001fa956ed0 TRAP: 0700   Not tainted  (3.10.0-03216-g7c6809f-dirty)
    [  568.877884] MSR: 8000000000029032 &lt;SF,EE,ME,IR,DR,RI&gt;  CR: 24000428  XER: 00000000
    [  568.877902] SOFTE: 1
    [  568.877905] CFAR: c0000000002b5464
    [  568.877908]
    GPR00: 0000000000000001 c0000001fa957150 c000000000c6a408 c0000001fb588000
    GPR04: 0000000000003fff c0000001fa9571c0 c0000001fa9571c4 000138098c50625f
    GPR08: 1301200000000000 0000000000000002 0000000000000001 0000000000000000
    GPR12: 0000000024000422 c00000000f33a300 0000000000008000 c0000001fa9577f0
    GPR16: c0000001fb7d0100 c000000000c29190 c0000000007f46e8 c000000000a14672
    GPR20: 0000000000000001 0000000000000008 ffffffffffffffff 0000000000000000
    GPR24: 0000000000000100 c0000001fa957278 c0000001fdb2bc78 c0000001fa957288
    GPR28: 0000000000100100 c0000001fa957288 c0000001fb588000 c0000001fdb2bd10
    [  568.877993] NIP [c0000000002f42a4] .ext4_mb_release_group_pa+0xec/0x1c0
    [  568.877999] LR [c0000000002f4274] .ext4_mb_release_group_pa+0xbc/0x1c0
    [  568.878004] Call Trace:
    [  568.878008] [c0000001fa957150] [c0000000002f4274] .ext4_mb_release_group_pa+0xbc/0x1c0 (unreliable)
    [  568.878017] [c0000001fa957200] [c0000000002fb070] .ext4_mb_discard_lg_preallocations+0x394/0x444
    [  568.878025] [c0000001fa957340] [c0000000002fb45c] .ext4_mb_release_context+0x33c/0x734
    [  568.878032] [c0000001fa957440] [c0000000002fbcf8] .ext4_mb_new_blocks+0x4a4/0x5f4
    [  568.878039] [c0000001fa957510] [c0000000002ef56c] .ext4_ext_map_blocks+0xc28/0x1178
    [  568.878047] [c0000001fa957640] [c0000000002c1a94] .ext4_map_blocks+0x2c8/0x490
    [  568.878054] [c0000001fa957730] [c0000000002c536c] .ext4_writepages+0x738/0xc60
    [  568.878062] [c0000001fa957950] [c000000000168a78] .do_writepages+0x5c/0x80
    [  568.878069] [c0000001fa9579d0] [c00000000015d1c4] .__filemap_fdatawrite_range+0x88/0xb0
    [  568.878078] [c0000001fa957aa0] [c00000000015d23c] .filemap_write_and_wait_range+0x50/0xfc
    [  568.878085] [c0000001fa957b30] [c0000000002b8edc] .ext4_sync_file+0x220/0x3c4
    [  568.878092] [c0000001fa957be0] [c0000000001f849c] .vfs_fsync_range+0x64/0x80
    [  568.878098] [c0000001fa957c70] [c0000000001f84f0] .vfs_fsync+0x38/0x4c
    [  568.878105] [c0000001fa957d00] [c0000000001f87f4] .do_fsync+0x54/0x90
    [  568.878111] [c0000001fa957db0] [c0000000001f8894] .SyS_fsync+0x28/0x3c
    [  568.878120] [c0000001fa957e30] [c000000000009c88] syscall_exit+0x0/0x7c
    [  568.878125] Instruction dump:
    [  568.878130] 60000000 813d0034 81610070 38000000 7f8b4800 419e001c 813f007c 7d2bfe70
    [  568.878144] 7d604a78 7c005850 54000ffe 7c0007b4 &lt;0b000000&gt; e8a10076 e87f0090 7fa4eb78
    [  568.878160] ---[ end trace 594d911d9654770b ]---
    
    In addition fix the STD_GROUP optimization so that it works for
    bigalloc file systems as well.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Reported-by: Li Zhong &lt;lizhongfs@gmail.com&gt;
    Reviewed-by: Lukas Czerner &lt;lczerner@redhat.com&gt;
    Cc: stable@vger.kernel.org  # 3.10

diff --git a/fs/ext4/balloc.c b/fs/ext4/balloc.c
index 58339393fa6e..ddd715e42a5c 100644
--- a/fs/ext4/balloc.c
+++ b/fs/ext4/balloc.c
@@ -38,8 +38,8 @@ ext4_group_t ext4_get_group_number(struct super_block *sb,
 	ext4_group_t group;
 
 	if (test_opt2(sb, STD_GROUP_SIZE))
-		group = (le32_to_cpu(EXT4_SB(sb)-&gt;s_es-&gt;s_first_data_block) +
-			 block) &gt;&gt;
+		group = (block -
+			 le32_to_cpu(EXT4_SB(sb)-&gt;s_es-&gt;s_first_data_block)) &gt;&gt;
 			(EXT4_BLOCK_SIZE_BITS(sb) + EXT4_CLUSTER_BITS(sb) + 3);
 	else
 		ext4_get_group_no_and_offset(sb, block, &amp;group, NULL);
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 85b3dd60169b..8862d4ddf71f 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -3624,10 +3624,6 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	sbi-&gt;s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));
 	sbi-&gt;s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));
 
-	/* Do we have standard group size of blocksize * 8 blocks ? */
-	if (sbi-&gt;s_blocks_per_group == blocksize &lt;&lt; 3)
-		set_opt2(sb, STD_GROUP_SIZE);
-
 	for (i = 0; i &lt; 4; i++)
 		sbi-&gt;s_hash_seed[i] = le32_to_cpu(es-&gt;s_hash_seed[i]);
 	sbi-&gt;s_def_hash_version = es-&gt;s_def_hash_version;
@@ -3697,6 +3693,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 		goto failed_mount;
 	}
 
+	/* Do we have standard group size of clustersize * 8 blocks ? */
+	if (sbi-&gt;s_blocks_per_group == clustersize &lt;&lt; 3)
+		set_opt2(sb, STD_GROUP_SIZE);
+
 	/*
 	 * Test whether we have more sectors than will fit in sector_t,
 	 * and whether the max offset is addressable by the page cache.</pre><hr><pre>commit 41a5b913197c3a25fddef1735dc9b3d1fdc57428
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Jul 1 08:12:41 2013 -0400

    jbd2: invalidate handle if jbd2_journal_restart() fails
    
    If jbd2_journal_restart() fails the handle will have been disconnected
    from the current transaction.  In this situation, the handle must not
    be used for for any jbd2 function other than jbd2_journal_stop().
    Enforce this with by treating a handle which has a NULL transaction
    pointer as an aborted handle, and issue a kernel warning if
    jbd2_journal_extent(), jbd2_journal_get_write_access(),
    jbd2_journal_dirty_metadata(), etc. is called with an invalid handle.
    
    This commit also fixes a bug where jbd2_journal_stop() would trip over
    a kernel jbd2 assertion check when trying to free an invalid handle.
    
    Also move the responsibility of setting current-&gt;journal_info to
    start_this_handle(), simplifying the three users of this function.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Reported-by: Younger Liu &lt;younger.liu@huawei.com&gt;
    Cc: Jan Kara &lt;jack@suse.cz&gt;

diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index 383b0fbc6e19..7aa9a32573bb 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -368,6 +368,7 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 		  atomic_read(&amp;transaction-&gt;t_outstanding_credits),
 		  jbd2_log_space_left(journal));
 	read_unlock(&amp;journal-&gt;j_state_lock);
+	current-&gt;journal_info = handle;
 
 	lock_map_acquire(&amp;handle-&gt;h_lockdep_map);
 	jbd2_journal_free_transaction(new_transaction);
@@ -442,14 +443,11 @@ handle_t *jbd2__journal_start(journal_t *journal, int nblocks, int rsv_blocks,
 		handle-&gt;h_rsv_handle = rsv_handle;
 	}
 
-	current-&gt;journal_info = handle;
-
 	err = start_this_handle(journal, handle, gfp_mask);
 	if (err &lt; 0) {
 		if (handle-&gt;h_rsv_handle)
 			jbd2_free_handle(handle-&gt;h_rsv_handle);
 		jbd2_free_handle(handle);
-		current-&gt;journal_info = NULL;
 		return ERR_PTR(err);
 	}
 	handle-&gt;h_type = type;
@@ -511,16 +509,13 @@ int jbd2_journal_start_reserved(handle_t *handle, unsigned int type,
 	}
 
 	handle-&gt;h_journal = NULL;
-	current-&gt;journal_info = handle;
 	/*
 	 * GFP_NOFS is here because callers are likely from writeback or
 	 * similarly constrained call sites
 	 */
 	ret = start_this_handle(journal, handle, GFP_NOFS);
-	if (ret &lt; 0) {
-		current-&gt;journal_info = NULL;
+	if (ret &lt; 0)
 		jbd2_journal_free_reserved(handle);
-	}
 	handle-&gt;h_type = type;
 	handle-&gt;h_line_no = line_no;
 	return ret;
@@ -550,20 +545,21 @@ EXPORT_SYMBOL(jbd2_journal_start_reserved);
 int jbd2_journal_extend(handle_t *handle, int nblocks)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
-	journal_t *journal = transaction-&gt;t_journal;
+	journal_t *journal;
 	int result;
 	int wanted;
 
-	result = -EIO;
+	WARN_ON(!transaction);
 	if (is_handle_aborted(handle))
-		goto out;
+		return -EROFS;
+	journal = transaction-&gt;t_journal;
 
 	result = 1;
 
 	read_lock(&amp;journal-&gt;j_state_lock);
 
 	/* Don't extend a locked-down transaction! */
-	if (handle-&gt;h_transaction-&gt;t_state != T_RUNNING) {
+	if (transaction-&gt;t_state != T_RUNNING) {
 		jbd_debug(3, "denied handle %p %d blocks: "
 			  "transaction not running\n", handle, nblocks);
 		goto error_out;
@@ -589,7 +585,7 @@ int jbd2_journal_extend(handle_t *handle, int nblocks)
 	}
 
 	trace_jbd2_handle_extend(journal-&gt;j_fs_dev-&gt;bd_dev,
-				 handle-&gt;h_transaction-&gt;t_tid,
+				 transaction-&gt;t_tid,
 				 handle-&gt;h_type, handle-&gt;h_line_no,
 				 handle-&gt;h_buffer_credits,
 				 nblocks);
@@ -603,7 +599,6 @@ int jbd2_journal_extend(handle_t *handle, int nblocks)
 	spin_unlock(&amp;transaction-&gt;t_handle_lock);
 error_out:
 	read_unlock(&amp;journal-&gt;j_state_lock);
-out:
 	return result;
 }
 
@@ -626,14 +621,16 @@ int jbd2_journal_extend(handle_t *handle, int nblocks)
 int jbd2__journal_restart(handle_t *handle, int nblocks, gfp_t gfp_mask)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
-	journal_t *journal = transaction-&gt;t_journal;
+	journal_t *journal;
 	tid_t		tid;
 	int		need_to_start, ret;
 
+	WARN_ON(!transaction);
 	/* If we've had an abort of any type, don't even think about
 	 * actually doing the restart! */
 	if (is_handle_aborted(handle))
 		return 0;
+	journal = transaction-&gt;t_journal;
 
 	/*
 	 * First unlink the handle from its current transaction, and start the
@@ -654,6 +651,8 @@ int jbd2__journal_restart(handle_t *handle, int nblocks, gfp_t gfp_mask)
 		wake_up(&amp;journal-&gt;j_wait_updates);
 	tid = transaction-&gt;t_tid;
 	spin_unlock(&amp;transaction-&gt;t_handle_lock);
+	handle-&gt;h_transaction = NULL;
+	current-&gt;journal_info = NULL;
 
 	jbd_debug(2, "restarting handle %p\n", handle);
 	need_to_start = !tid_geq(journal-&gt;j_commit_request, tid);
@@ -783,17 +782,16 @@ do_get_write_access(handle_t *handle, struct journal_head *jh,
 			int force_copy)
 {
 	struct buffer_head *bh;
-	transaction_t *transaction;
+	transaction_t *transaction = handle-&gt;h_transaction;
 	journal_t *journal;
 	int error;
 	char *frozen_buffer = NULL;
 	int need_copy = 0;
 	unsigned long start_lock, time_lock;
 
+	WARN_ON(!transaction);
 	if (is_handle_aborted(handle))
 		return -EROFS;
-
-	transaction = handle-&gt;h_transaction;
 	journal = transaction-&gt;t_journal;
 
 	jbd_debug(5, "journal_head %p, force_copy %d\n", jh, force_copy);
@@ -1052,14 +1050,16 @@ int jbd2_journal_get_write_access(handle_t *handle, struct buffer_head *bh)
 int jbd2_journal_get_create_access(handle_t *handle, struct buffer_head *bh)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
-	journal_t *journal = transaction-&gt;t_journal;
+	journal_t *journal;
 	struct journal_head *jh = jbd2_journal_add_journal_head(bh);
 	int err;
 
 	jbd_debug(5, "journal_head %p\n", jh);
+	WARN_ON(!transaction);
 	err = -EROFS;
 	if (is_handle_aborted(handle))
 		goto out;
+	journal = transaction-&gt;t_journal;
 	err = 0;
 
 	JBUFFER_TRACE(jh, "entry");
@@ -1265,12 +1265,14 @@ void jbd2_buffer_abort_trigger(struct journal_head *jh,
 int jbd2_journal_dirty_metadata(handle_t *handle, struct buffer_head *bh)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
-	journal_t *journal = transaction-&gt;t_journal;
+	journal_t *journal;
 	struct journal_head *jh;
 	int ret = 0;
 
+	WARN_ON(!transaction);
 	if (is_handle_aborted(handle))
-		goto out;
+		return -EROFS;
+	journal = transaction-&gt;t_journal;
 	jh = jbd2_journal_grab_journal_head(bh);
 	if (!jh) {
 		ret = -EUCLEAN;
@@ -1364,7 +1366,7 @@ int jbd2_journal_dirty_metadata(handle_t *handle, struct buffer_head *bh)
 
 	JBUFFER_TRACE(jh, "file as BJ_Metadata");
 	spin_lock(&amp;journal-&gt;j_list_lock);
-	__jbd2_journal_file_buffer(jh, handle-&gt;h_transaction, BJ_Metadata);
+	__jbd2_journal_file_buffer(jh, transaction, BJ_Metadata);
 	spin_unlock(&amp;journal-&gt;j_list_lock);
 out_unlock_bh:
 	jbd_unlock_bh_state(bh);
@@ -1395,12 +1397,17 @@ int jbd2_journal_dirty_metadata(handle_t *handle, struct buffer_head *bh)
 int jbd2_journal_forget (handle_t *handle, struct buffer_head *bh)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
-	journal_t *journal = transaction-&gt;t_journal;
+	journal_t *journal;
 	struct journal_head *jh;
 	int drop_reserve = 0;
 	int err = 0;
 	int was_modified = 0;
 
+	WARN_ON(!transaction);
+	if (is_handle_aborted(handle))
+		return -EROFS;
+	journal = transaction-&gt;t_journal;
+
 	BUFFER_TRACE(bh, "entry");
 
 	jbd_lock_bh_state(bh);
@@ -1427,7 +1434,7 @@ int jbd2_journal_forget (handle_t *handle, struct buffer_head *bh)
 	 */
 	jh-&gt;b_modified = 0;
 
-	if (jh-&gt;b_transaction == handle-&gt;h_transaction) {
+	if (jh-&gt;b_transaction == transaction) {
 		J_ASSERT_JH(jh, !jh-&gt;b_frozen_data);
 
 		/* If we are forgetting a buffer which is already part
@@ -1522,19 +1529,21 @@ int jbd2_journal_forget (handle_t *handle, struct buffer_head *bh)
 int jbd2_journal_stop(handle_t *handle)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
-	journal_t *journal = transaction-&gt;t_journal;
-	int err, wait_for_commit = 0;
+	journal_t *journal;
+	int err = 0, wait_for_commit = 0;
 	tid_t tid;
 	pid_t pid;
 
+	if (!transaction)
+		goto free_and_exit;
+	journal = transaction-&gt;t_journal;
+
 	J_ASSERT(journal_current_handle() == handle);
 
 	if (is_handle_aborted(handle))
 		err = -EIO;
-	else {
+	else
 		J_ASSERT(atomic_read(&amp;transaction-&gt;t_updates) &gt; 0);
-		err = 0;
-	}
 
 	if (--handle-&gt;h_ref &gt; 0) {
 		jbd_debug(4, "h_ref %d -&gt; %d\n", handle-&gt;h_ref + 1,
@@ -1544,7 +1553,7 @@ int jbd2_journal_stop(handle_t *handle)
 
 	jbd_debug(4, "Handle %p going down\n", handle);
 	trace_jbd2_handle_stats(journal-&gt;j_fs_dev-&gt;bd_dev,
-				handle-&gt;h_transaction-&gt;t_tid,
+				transaction-&gt;t_tid,
 				handle-&gt;h_type, handle-&gt;h_line_no,
 				jiffies - handle-&gt;h_start_jiffies,
 				handle-&gt;h_sync, handle-&gt;h_requested_credits,
@@ -1657,6 +1666,7 @@ int jbd2_journal_stop(handle_t *handle)
 
 	if (handle-&gt;h_rsv_handle)
 		jbd2_journal_free_reserved(handle-&gt;h_rsv_handle);
+free_and_exit:
 	jbd2_free_handle(handle);
 	return err;
 }
@@ -2362,10 +2372,12 @@ void jbd2_journal_refile_buffer(journal_t *journal, struct journal_head *jh)
 int jbd2_journal_file_inode(handle_t *handle, struct jbd2_inode *jinode)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
-	journal_t *journal = transaction-&gt;t_journal;
+	journal_t *journal;
 
+	WARN_ON(!transaction);
 	if (is_handle_aborted(handle))
-		return -EIO;
+		return -EROFS;
+	journal = transaction-&gt;t_journal;
 
 	jbd_debug(4, "Adding inode %lu, tid:%d\n", jinode-&gt;i_vfs_inode-&gt;i_ino,
 			transaction-&gt;t_tid);
diff --git a/include/linux/jbd2.h b/include/linux/jbd2.h
index 0302f3f14063..d5b50a19463c 100644
--- a/include/linux/jbd2.h
+++ b/include/linux/jbd2.h
@@ -1266,7 +1266,7 @@ static inline int is_journal_aborted(journal_t *journal)
 
 static inline int is_handle_aborted(handle_t *handle)
 {
-	if (handle-&gt;h_aborted)
+	if (handle-&gt;h_aborted || !handle-&gt;h_transaction)
 		return 1;
 	return is_journal_aborted(handle-&gt;h_transaction-&gt;t_journal);
 }</pre><hr><pre>commit 21ddd568c133024196d394c43923f55cad1e7bd0
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Jul 1 08:12:40 2013 -0400

    ext4: translate flag bits to strings in tracepoints
    
    Translate the bitfields used in various flags argument to strings to
    make the tracepoint output more human-readable.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c
index 937593e2f006..575faa090253 100644
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@ -4380,7 +4380,7 @@ int ext4_ext_map_blocks(handle_t *handle, struct inode *inode,
 	}
 
 out3:
-	trace_ext4_ext_map_blocks_exit(inode, map, err ? err : allocated);
+	trace_ext4_ext_map_blocks_exit(inode, flags, map, err ? err : allocated);
 
 	return err ? err : allocated;
 }
diff --git a/fs/ext4/indirect.c b/fs/ext4/indirect.c
index 963d23dc1028..87b30cd357e7 100644
--- a/fs/ext4/indirect.c
+++ b/fs/ext4/indirect.c
@@ -624,7 +624,7 @@ int ext4_ind_map_blocks(handle_t *handle, struct inode *inode,
 		partial--;
 	}
 out:
-	trace_ext4_ind_map_blocks_exit(inode, map, err);
+	trace_ext4_ind_map_blocks_exit(inode, flags, map, err);
 	return err;
 }
 
diff --git a/include/trace/events/ext4.h b/include/trace/events/ext4.h
index 72f523eb82e0..2068db241f22 100644
--- a/include/trace/events/ext4.h
+++ b/include/trace/events/ext4.h
@@ -19,6 +19,57 @@ struct extent_status;
 
 #define EXT4_I(inode) (container_of(inode, struct ext4_inode_info, vfs_inode))
 
+#define show_mballoc_flags(flags) __print_flags(flags, "|",	\
+	{ EXT4_MB_HINT_MERGE,		"HINT_MERGE" },		\
+	{ EXT4_MB_HINT_RESERVED,	"HINT_RESV" },		\
+	{ EXT4_MB_HINT_METADATA,	"HINT_MDATA" },		\
+	{ EXT4_MB_HINT_FIRST,		"HINT_FIRST" },		\
+	{ EXT4_MB_HINT_BEST,		"HINT_BEST" },		\
+	{ EXT4_MB_HINT_DATA,		"HINT_DATA" },		\
+	{ EXT4_MB_HINT_NOPREALLOC,	"HINT_NOPREALLOC" },	\
+	{ EXT4_MB_HINT_GROUP_ALLOC,	"HINT_GRP_ALLOC" },	\
+	{ EXT4_MB_HINT_GOAL_ONLY,	"HINT_GOAL_ONLY" },	\
+	{ EXT4_MB_HINT_TRY_GOAL,	"HINT_TRY_GOAL" },	\
+	{ EXT4_MB_DELALLOC_RESERVED,	"DELALLOC_RESV" },	\
+	{ EXT4_MB_STREAM_ALLOC,		"STREAM_ALLOC" },	\
+	{ EXT4_MB_USE_ROOT_BLOCKS,	"USE_ROOT_BLKS" },	\
+	{ EXT4_MB_USE_RESERVED,		"USE_RESV" })
+
+#define show_map_flags(flags) __print_flags(flags, "|",			\
+	{ EXT4_GET_BLOCKS_CREATE,		"CREATE" },		\
+	{ EXT4_GET_BLOCKS_UNINIT_EXT,		"UNINIT" },		\
+	{ EXT4_GET_BLOCKS_DELALLOC_RESERVE,	"DELALLOC" },		\
+	{ EXT4_GET_BLOCKS_PRE_IO,		"PRE_IO" },		\
+	{ EXT4_GET_BLOCKS_CONVERT,		"CONVERT" },		\
+	{ EXT4_GET_BLOCKS_METADATA_NOFAIL,	"METADATA_NOFAIL" },	\
+	{ EXT4_GET_BLOCKS_NO_NORMALIZE,		"NO_NORMALIZE" },	\
+	{ EXT4_GET_BLOCKS_KEEP_SIZE,		"KEEP_SIZE" },		\
+	{ EXT4_GET_BLOCKS_NO_LOCK,		"NO_LOCK" },		\
+	{ EXT4_GET_BLOCKS_NO_PUT_HOLE,		"NO_PUT_HOLE" })
+
+#define show_mflags(flags) __print_flags(flags, "",	\
+	{ EXT4_MAP_NEW,		"N" },			\
+	{ EXT4_MAP_MAPPED,	"M" },			\
+	{ EXT4_MAP_UNWRITTEN,	"U" },			\
+	{ EXT4_MAP_BOUNDARY,	"B" },			\
+	{ EXT4_MAP_UNINIT,	"u" },			\
+	{ EXT4_MAP_FROM_CLUSTER, "C" })
+
+#define show_free_flags(flags) __print_flags(flags, "|",	\
+	{ EXT4_FREE_BLOCKS_METADATA,		"METADATA" },	\
+	{ EXT4_FREE_BLOCKS_FORGET,		"FORGET" },	\
+	{ EXT4_FREE_BLOCKS_VALIDATED,		"VALIDATED" },	\
+	{ EXT4_FREE_BLOCKS_NO_QUOT_UPDATE,	"NO_QUOTA" },	\
+	{ EXT4_FREE_BLOCKS_NOFREE_FIRST_CLUSTER,"1ST_CLUSTER" },\
+	{ EXT4_FREE_BLOCKS_NOFREE_LAST_CLUSTER,	"LAST_CLUSTER" })
+
+#define show_extent_status(status) __print_flags(status, "",	\
+	{ (1 &lt;&lt; 3),	"W" }, 					\
+	{ (1 &lt;&lt; 2),	"U" },					\
+	{ (1 &lt;&lt; 1),	"D" },					\
+	{ (1 &lt;&lt; 0),	"H" })
+
+
 TRACE_EVENT(ext4_free_inode,
 	TP_PROTO(struct inode *inode),
 
@@ -373,10 +424,10 @@ TRACE_EVENT(ext4_da_write_pages_extent,
 		__entry-&gt;flags		= map-&gt;m_flags;
 	),
 
-	TP_printk("dev %d,%d ino %lu lblk %llu len %u flags 0x%04x",
+	TP_printk("dev %d,%d ino %lu lblk %llu len %u flags %s",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino, __entry-&gt;lblk, __entry-&gt;len,
-		  __entry-&gt;flags)
+		  show_mflags(__entry-&gt;flags))
 );
 
 TRACE_EVENT(ext4_writepages_result,
@@ -691,10 +742,10 @@ TRACE_EVENT(ext4_request_blocks,
 		__entry-&gt;flags	= ar-&gt;flags;
 	),
 
-	TP_printk("dev %d,%d ino %lu flags %u len %u lblk %u goal %llu "
+	TP_printk("dev %d,%d ino %lu flags %s len %u lblk %u goal %llu "
 		  "lleft %u lright %u pleft %llu pright %llu ",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
-		  (unsigned long) __entry-&gt;ino, __entry-&gt;flags,
+		  (unsigned long) __entry-&gt;ino, show_mballoc_flags(__entry-&gt;flags),
 		  __entry-&gt;len, __entry-&gt;logical, __entry-&gt;goal,
 		  __entry-&gt;lleft, __entry-&gt;lright, __entry-&gt;pleft,
 		  __entry-&gt;pright)
@@ -733,10 +784,10 @@ TRACE_EVENT(ext4_allocate_blocks,
 		__entry-&gt;flags	= ar-&gt;flags;
 	),
 
-	TP_printk("dev %d,%d ino %lu flags %u len %u block %llu lblk %u "
+	TP_printk("dev %d,%d ino %lu flags %s len %u block %llu lblk %u "
 		  "goal %llu lleft %u lright %u pleft %llu pright %llu",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
-		  (unsigned long) __entry-&gt;ino, __entry-&gt;flags,
+		  (unsigned long) __entry-&gt;ino, show_mballoc_flags(__entry-&gt;flags),
 		  __entry-&gt;len, __entry-&gt;block, __entry-&gt;logical,
 		  __entry-&gt;goal,  __entry-&gt;lleft, __entry-&gt;lright,
 		  __entry-&gt;pleft, __entry-&gt;pright)
@@ -766,11 +817,11 @@ TRACE_EVENT(ext4_free_blocks,
 		__entry-&gt;mode		= inode-&gt;i_mode;
 	),
 
-	TP_printk("dev %d,%d ino %lu mode 0%o block %llu count %lu flags %d",
+	TP_printk("dev %d,%d ino %lu mode 0%o block %llu count %lu flags %s",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino,
 		  __entry-&gt;mode, __entry-&gt;block, __entry-&gt;count,
-		  __entry-&gt;flags)
+		  show_free_flags(__entry-&gt;flags))
 );
 
 TRACE_EVENT(ext4_sync_file_enter,
@@ -921,7 +972,7 @@ TRACE_EVENT(ext4_mballoc_alloc,
 	),
 
 	TP_printk("dev %d,%d inode %lu orig %u/%d/%u@%u goal %u/%d/%u@%u "
-		  "result %u/%d/%u@%u blks %u grps %u cr %u flags 0x%04x "
+		  "result %u/%d/%u@%u blks %u grps %u cr %u flags %s "
 		  "tail %u broken %u",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino,
@@ -932,7 +983,7 @@ TRACE_EVENT(ext4_mballoc_alloc,
 		  __entry-&gt;result_group, __entry-&gt;result_start,
 		  __entry-&gt;result_len, __entry-&gt;result_logical,
 		  __entry-&gt;found, __entry-&gt;groups, __entry-&gt;cr,
-		  __entry-&gt;flags, __entry-&gt;tail,
+		  show_mballoc_flags(__entry-&gt;flags), __entry-&gt;tail,
 		  __entry-&gt;buddy ? 1 &lt;&lt; __entry-&gt;buddy : 0)
 );
 
@@ -1546,10 +1597,10 @@ DECLARE_EVENT_CLASS(ext4__map_blocks_enter,
 		__entry-&gt;flags	= flags;
 	),
 
-	TP_printk("dev %d,%d ino %lu lblk %u len %u flags %u",
+	TP_printk("dev %d,%d ino %lu lblk %u len %u flags %s",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino,
-		  __entry-&gt;lblk, __entry-&gt;len, __entry-&gt;flags)
+		  __entry-&gt;lblk, __entry-&gt;len, show_map_flags(__entry-&gt;flags))
 );
 
 DEFINE_EVENT(ext4__map_blocks_enter, ext4_ext_map_blocks_enter,
@@ -1567,47 +1618,53 @@ DEFINE_EVENT(ext4__map_blocks_enter, ext4_ind_map_blocks_enter,
 );
 
 DECLARE_EVENT_CLASS(ext4__map_blocks_exit,
-	TP_PROTO(struct inode *inode, struct ext4_map_blocks *map, int ret),
+	TP_PROTO(struct inode *inode, unsigned flags, struct ext4_map_blocks *map,
+		 int ret),
 
-	TP_ARGS(inode, map, ret),
+	TP_ARGS(inode, flags, map, ret),
 
 	TP_STRUCT__entry(
 		__field(	dev_t,		dev		)
 		__field(	ino_t,		ino		)
+		__field(	unsigned int,	flags		)
 		__field(	ext4_fsblk_t,	pblk		)
 		__field(	ext4_lblk_t,	lblk		)
 		__field(	unsigned int,	len		)
-		__field(	unsigned int,	flags		)
+		__field(	unsigned int,	mflags		)
 		__field(	int,		ret		)
 	),
 
 	TP_fast_assign(
 		__entry-&gt;dev    = inode-&gt;i_sb-&gt;s_dev;
 		__entry-&gt;ino    = inode-&gt;i_ino;
+		__entry-&gt;flags	= flags;
 		__entry-&gt;pblk	= map-&gt;m_pblk;
 		__entry-&gt;lblk	= map-&gt;m_lblk;
 		__entry-&gt;len	= map-&gt;m_len;
-		__entry-&gt;flags	= map-&gt;m_flags;
+		__entry-&gt;mflags	= map-&gt;m_flags;
 		__entry-&gt;ret	= ret;
 	),
 
-	TP_printk("dev %d,%d ino %lu lblk %u pblk %llu len %u flags %x ret %d",
+	TP_printk("dev %d,%d ino %lu flags %s lblk %u pblk %llu len %u "
+		  "mflags %s ret %d",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino,
-		  __entry-&gt;lblk, __entry-&gt;pblk,
-		  __entry-&gt;len, __entry-&gt;flags, __entry-&gt;ret)
+		  show_map_flags(__entry-&gt;flags), __entry-&gt;lblk, __entry-&gt;pblk,
+		  __entry-&gt;len, show_mflags(__entry-&gt;mflags), __entry-&gt;ret)
 );
 
 DEFINE_EVENT(ext4__map_blocks_exit, ext4_ext_map_blocks_exit,
-	TP_PROTO(struct inode *inode, struct ext4_map_blocks *map, int ret),
+	TP_PROTO(struct inode *inode, unsigned flags,
+		 struct ext4_map_blocks *map, int ret),
 
-	TP_ARGS(inode, map, ret)
+	TP_ARGS(inode, flags, map, ret)
 );
 
 DEFINE_EVENT(ext4__map_blocks_exit, ext4_ind_map_blocks_exit,
-	TP_PROTO(struct inode *inode, struct ext4_map_blocks *map, int ret),
+	TP_PROTO(struct inode *inode, unsigned flags,
+		 struct ext4_map_blocks *map, int ret),
 
-	TP_ARGS(inode, map, ret)
+	TP_ARGS(inode, flags, map, ret)
 );
 
 TRACE_EVENT(ext4_ext_load_extent,
@@ -1779,12 +1836,12 @@ TRACE_EVENT(ext4_ext_handle_uninitialized_extents,
 		__entry-&gt;newblk		= newblock;
 	),
 
-	TP_printk("dev %d,%d ino %lu m_lblk %u m_pblk %llu m_len %u flags %x "
+	TP_printk("dev %d,%d ino %lu m_lblk %u m_pblk %llu m_len %u flags %s "
 		  "allocated %d newblock %llu",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino,
 		  (unsigned) __entry-&gt;lblk, (unsigned long long) __entry-&gt;pblk,
-		  __entry-&gt;len, __entry-&gt;flags,
+		  __entry-&gt;len, show_map_flags(__entry-&gt;flags),
 		  (unsigned int) __entry-&gt;allocated,
 		  (unsigned long long) __entry-&gt;newblk)
 );
@@ -1812,10 +1869,10 @@ TRACE_EVENT(ext4_get_implied_cluster_alloc_exit,
 		__entry-&gt;ret	= ret;
 	),
 
-	TP_printk("dev %d,%d m_lblk %u m_pblk %llu m_len %u m_flags %u ret %d",
+	TP_printk("dev %d,%d m_lblk %u m_pblk %llu m_len %u m_flags %s ret %d",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  __entry-&gt;lblk, (unsigned long long) __entry-&gt;pblk,
-		  __entry-&gt;len, __entry-&gt;flags, __entry-&gt;ret)
+		  __entry-&gt;len, show_mflags(__entry-&gt;flags), __entry-&gt;ret)
 );
 
 TRACE_EVENT(ext4_ext_put_in_cache,
@@ -2146,7 +2203,7 @@ TRACE_EVENT(ext4_es_insert_extent,
 		__field(	ext4_lblk_t,	lblk		)
 		__field(	ext4_lblk_t,	len		)
 		__field(	ext4_fsblk_t,	pblk		)
-		__field(	unsigned long long, status	)
+		__field(	char, status	)
 	),
 
 	TP_fast_assign(
@@ -2155,14 +2212,14 @@ TRACE_EVENT(ext4_es_insert_extent,
 		__entry-&gt;lblk	= es-&gt;es_lblk;
 		__entry-&gt;len	= es-&gt;es_len;
 		__entry-&gt;pblk	= ext4_es_pblock(es);
-		__entry-&gt;status	= ext4_es_status(es);
+		__entry-&gt;status	= ext4_es_status(es) &gt;&gt; 60;
 	),
 
-	TP_printk("dev %d,%d ino %lu es [%u/%u) mapped %llu status %llx",
+	TP_printk("dev %d,%d ino %lu es [%u/%u) mapped %llu status %s",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino,
 		  __entry-&gt;lblk, __entry-&gt;len,
-		  __entry-&gt;pblk, __entry-&gt;status)
+		  __entry-&gt;pblk, show_extent_status(__entry-&gt;status))
 );
 
 TRACE_EVENT(ext4_es_remove_extent,
@@ -2223,7 +2280,7 @@ TRACE_EVENT(ext4_es_find_delayed_extent_range_exit,
 		__field(	ext4_lblk_t,	lblk		)
 		__field(	ext4_lblk_t,	len		)
 		__field(	ext4_fsblk_t,	pblk		)
-		__field(	unsigned long long, status	)
+		__field(	char, status	)
 	),
 
 	TP_fast_assign(
@@ -2232,14 +2289,14 @@ TRACE_EVENT(ext4_es_find_delayed_extent_range_exit,
 		__entry-&gt;lblk	= es-&gt;es_lblk;
 		__entry-&gt;len	= es-&gt;es_len;
 		__entry-&gt;pblk	= ext4_es_pblock(es);
-		__entry-&gt;status	= ext4_es_status(es);
+		__entry-&gt;status	= ext4_es_status(es) &gt;&gt; 60;
 	),
 
-	TP_printk("dev %d,%d ino %lu es [%u/%u) mapped %llu status %llx",
+	TP_printk("dev %d,%d ino %lu es [%u/%u) mapped %llu status %s",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino,
 		  __entry-&gt;lblk, __entry-&gt;len,
-		  __entry-&gt;pblk, __entry-&gt;status)
+		  __entry-&gt;pblk, show_extent_status(__entry-&gt;status))
 );
 
 TRACE_EVENT(ext4_es_lookup_extent_enter,
@@ -2276,7 +2333,7 @@ TRACE_EVENT(ext4_es_lookup_extent_exit,
 		__field(	ext4_lblk_t,	lblk		)
 		__field(	ext4_lblk_t,	len		)
 		__field(	ext4_fsblk_t,	pblk		)
-		__field(	unsigned long long,	status	)
+		__field(	char,		status		)
 		__field(	int,		found		)
 	),
 
@@ -2286,16 +2343,16 @@ TRACE_EVENT(ext4_es_lookup_extent_exit,
 		__entry-&gt;lblk	= es-&gt;es_lblk;
 		__entry-&gt;len	= es-&gt;es_len;
 		__entry-&gt;pblk	= ext4_es_pblock(es);
-		__entry-&gt;status	= ext4_es_status(es);
+		__entry-&gt;status	= ext4_es_status(es) &gt;&gt; 60;
 		__entry-&gt;found	= found;
 	),
 
-	TP_printk("dev %d,%d ino %lu found %d [%u/%u) %llu %llx",
+	TP_printk("dev %d,%d ino %lu found %d [%u/%u) %llu %s",
 		  MAJOR(__entry-&gt;dev), MINOR(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino, __entry-&gt;found,
 		  __entry-&gt;lblk, __entry-&gt;len,
 		  __entry-&gt;found ? __entry-&gt;pblk : 0,
-		  __entry-&gt;found ? __entry-&gt;status : 0)
+		  show_extent_status(__entry-&gt;found ? __entry-&gt;status : 0))
 );
 
 TRACE_EVENT(ext4_es_shrink_enter,</pre><hr><pre>commit cb530541182bee14112675046331f20a1c831507
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Jul 1 08:12:40 2013 -0400

    ext4: fix up error handling for mpage_map_and_submit_extent()
    
    The function mpage_released_unused_page() must only be called once;
    otherwise the kernel will BUG() when the second call to
    mpage_released_unused_page() tries to unlock the pages which had been
    unlocked by the first call.
    
    Also restructure the error handling so that we only give up on writing
    the dirty pages in the case of ENOSPC where retrying the allocation
    won't help.  Otherwise, a transient failure, such as a kmalloc()
    failure in calling ext4_map_blocks() might cause us to give up on
    those pages, leading to a scary message in /var/log/messages plus data
    loss.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Reviewed-by: Jan Kara &lt;jack@suse.cz&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 502a9e1f5aa3..0188e65e1f58 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -2153,7 +2153,8 @@ static int mpage_map_one_extent(handle_t *handle, struct mpage_da_data *mpd)
  * guaranteed). After mapping we submit all mapped pages for IO.
  */
 static int mpage_map_and_submit_extent(handle_t *handle,
-				       struct mpage_da_data *mpd)
+				       struct mpage_da_data *mpd,
+				       bool *give_up_on_write)
 {
 	struct inode *inode = mpd-&gt;inode;
 	struct ext4_map_blocks *map = &amp;mpd-&gt;map;
@@ -2167,29 +2168,30 @@ static int mpage_map_and_submit_extent(handle_t *handle,
 		if (err &lt; 0) {
 			struct super_block *sb = inode-&gt;i_sb;
 
+			if (EXT4_SB(sb)-&gt;s_mount_flags &amp; EXT4_MF_FS_ABORTED)
+				goto invalidate_dirty_pages;
 			/*
-			 * Need to commit transaction to free blocks. Let upper
-			 * layers sort it out.
+			 * Let the uper layers retry transient errors.
+			 * In the case of ENOSPC, if ext4_count_free_blocks()
+			 * is non-zero, a commit should free up blocks.
 			 */
-			if (err == -ENOSPC &amp;&amp; ext4_count_free_clusters(sb))
-				return -ENOSPC;
-
-			if (!(EXT4_SB(sb)-&gt;s_mount_flags &amp; EXT4_MF_FS_ABORTED)) {
-				ext4_msg(sb, KERN_CRIT,
-					 "Delayed block allocation failed for "
-					 "inode %lu at logical offset %llu with"
-					 " max blocks %u with error %d",
-					 inode-&gt;i_ino,
-					 (unsigned long long)map-&gt;m_lblk,
-					 (unsigned)map-&gt;m_len, err);
-				ext4_msg(sb, KERN_CRIT,
-					 "This should not happen!! Data will "
-					 "be lost\n");
-				if (err == -ENOSPC)
-					ext4_print_free_blocks(inode);
-			}
-			/* invalidate all the pages */
-			mpage_release_unused_pages(mpd, true);
+			if ((err == -ENOMEM) ||
+			    (err == -ENOSPC &amp;&amp; ext4_count_free_clusters(sb)))
+				return err;
+			ext4_msg(sb, KERN_CRIT,
+				 "Delayed block allocation failed for "
+				 "inode %lu at logical offset %llu with"
+				 " max blocks %u with error %d",
+				 inode-&gt;i_ino,
+				 (unsigned long long)map-&gt;m_lblk,
+				 (unsigned)map-&gt;m_len, -err);
+			ext4_msg(sb, KERN_CRIT,
+				 "This should not happen!! Data will "
+				 "be lost\n");
+			if (err == -ENOSPC)
+				ext4_print_free_blocks(inode);
+		invalidate_dirty_pages:
+			*give_up_on_write = true;
 			return err;
 		}
 		/*
@@ -2377,6 +2379,7 @@ static int ext4_writepages(struct address_space *mapping,
 	struct ext4_sb_info *sbi = EXT4_SB(mapping-&gt;host-&gt;i_sb);
 	bool done;
 	struct blk_plug plug;
+	bool give_up_on_write = false;
 
 	trace_ext4_writepages(inode, wbc);
 
@@ -2494,7 +2497,8 @@ static int ext4_writepages(struct address_space *mapping,
 		ret = mpage_prepare_extent_to_map(&amp;mpd);
 		if (!ret) {
 			if (mpd.map.m_len)
-				ret = mpage_map_and_submit_extent(handle, &amp;mpd);
+				ret = mpage_map_and_submit_extent(handle, &amp;mpd,
+					&amp;give_up_on_write);
 			else {
 				/*
 				 * We scanned the whole range (or exhausted
@@ -2509,7 +2513,7 @@ static int ext4_writepages(struct address_space *mapping,
 		/* Submit prepared bio */
 		ext4_io_submit(&amp;mpd.io_submit);
 		/* Unlock pages we didn't use */
-		mpage_release_unused_pages(&amp;mpd, false);
+		mpage_release_unused_pages(&amp;mpd, give_up_on_write);
 		/* Drop our io_end reference we got from init */
 		ext4_put_io_end(mpd.io_submit.io_end);
 </pre><hr><pre>commit 39c04153fda8c32e85b51c96eb5511a326ad7609
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Jul 1 08:12:40 2013 -0400

    jbd2: fix theoretical race in jbd2__journal_restart
    
    Once we decrement transaction-&gt;t_updates, if this is the last handle
    holding the transaction from closing, and once we release the
    t_handle_lock spinlock, it's possible for the transaction to commit
    and be released.  In practice with normal kernels, this probably won't
    happen, since the commit happens in a separate kernel thread and it's
    unlikely this could all happen within the space of a few CPU cycles.
    
    On the other hand, with a real-time kernel, this could potentially
    happen, so save the tid found in transaction-&gt;t_tid before we release
    t_handle_lock.  It would require an insane configuration, such as one
    where the jbd2 thread was set to a very high real-time priority,
    perhaps because a high priority real-time thread is trying to read or
    write to a file system.  But some people who use real-time kernels
    have been known to do insane things, including controlling
    laser-wielding industrial robots.  :-)
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index dd422e680418..383b0fbc6e19 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -652,10 +652,10 @@ int jbd2__journal_restart(handle_t *handle, int nblocks, gfp_t gfp_mask)
 	}
 	if (atomic_dec_and_test(&amp;transaction-&gt;t_updates))
 		wake_up(&amp;journal-&gt;j_wait_updates);
+	tid = transaction-&gt;t_tid;
 	spin_unlock(&amp;transaction-&gt;t_handle_lock);
 
 	jbd_debug(2, "restarting handle %p\n", handle);
-	tid = transaction-&gt;t_tid;
 	need_to_start = !tid_geq(journal-&gt;j_commit_request, tid);
 	read_unlock(&amp;journal-&gt;j_state_lock);
 	if (need_to_start)</pre><hr><pre>commit 42c832debbbf819f6c4ad8601baa559c44105ba4
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Jul 1 08:12:39 2013 -0400

    ext4: check error return from ext4_write_inline_data_end()
    
    The function ext4_write_inline_data_end() can return an error.  So we
    need to assign it to a signed integer variable to check for an error
    return (since copied is an unsigned int).
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Cc: Zheng Liu &lt;wenqing.lz@taobao.com&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 6d051deafc39..09942341dfae 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -1061,10 +1061,13 @@ static int ext4_write_end(struct file *file,
 		}
 	}
 
-	if (ext4_has_inline_data(inode))
-		copied = ext4_write_inline_data_end(inode, pos, len,
-						    copied, page);
-	else
+	if (ext4_has_inline_data(inode)) {
+		ret = ext4_write_inline_data_end(inode, pos, len,
+						 copied, page);
+		if (ret &lt; 0)
+			goto errout;
+		copied = ret;
+	} else
 		copied = block_write_end(file, mapping, pos,
 					 len, copied, page, fsdata);
 </pre><hr><pre>commit fe52d17cdd343ac43c85cf72940a58865b9d3bfb
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Jul 1 08:12:38 2013 -0400

    jbd2: move superblock checksum calculation to jbd2_write_superblock()
    
    Some of the functions which modify the jbd2 superblock were not
    updating the checksum before calling jbd2_write_superblock().  Move
    the call to jbd2_superblock_csum_set() to jbd2_write_superblock(), so
    that the checksum is calculated consistently.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Cc: Darrick J. Wong &lt;darrick.wong@oracle.com&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/jbd2/journal.c b/fs/jbd2/journal.c
index 915dd575cd46..02c7ad9d7a41 100644
--- a/fs/jbd2/journal.c
+++ b/fs/jbd2/journal.c
@@ -1335,6 +1335,7 @@ static int journal_reset(journal_t *journal)
 static void jbd2_write_superblock(journal_t *journal, int write_op)
 {
 	struct buffer_head *bh = journal-&gt;j_sb_buffer;
+	journal_superblock_t *sb = journal-&gt;j_superblock;
 	int ret;
 
 	trace_jbd2_write_superblock(journal, write_op);
@@ -1356,6 +1357,7 @@ static void jbd2_write_superblock(journal_t *journal, int write_op)
 		clear_buffer_write_io_error(bh);
 		set_buffer_uptodate(bh);
 	}
+	jbd2_superblock_csum_set(journal, sb);
 	get_bh(bh);
 	bh-&gt;b_end_io = end_buffer_write_sync;
 	ret = submit_bh(write_op, bh);
@@ -1452,7 +1454,6 @@ void jbd2_journal_update_sb_errno(journal_t *journal)
 	jbd_debug(1, "JBD2: updating superblock error (errno %d)\n",
 		  journal-&gt;j_errno);
 	sb-&gt;s_errno    = cpu_to_be32(journal-&gt;j_errno);
-	jbd2_superblock_csum_set(journal, sb);
 	read_unlock(&amp;journal-&gt;j_state_lock);
 
 	jbd2_write_superblock(journal, WRITE_SYNC);</pre><hr><pre>commit 981250ca89261f98bdfd2d6be1fcccb96cbbc00d
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Jun 12 11:48:29 2013 -0400

    ext4: don't use EXT4_FREE_BLOCKS_FORGET unnecessarily
    
    Commit 18888cf0883c: "ext4: speed up truncate/unlink by not using
    bforget() unless needed" removed the use of EXT4_FREE_BLOCKS_FORGET in
    the most important codepath for file systems using extents, but a
    similar optimization also can be done for file systems using indirect
    blocks, and for the two special cases in the ext4 extents code.
    
    Cc: Andrey Sidorov &lt;qrxd43@motorola.com&gt;
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c
index 208f664f9ee0..d04f40936397 100644
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@ -2355,6 +2355,15 @@ int ext4_ext_index_trans_blocks(struct inode *inode, int extents)
 	return index;
 }
 
+static inline int get_default_free_blocks_flags(struct inode *inode)
+{
+	if (S_ISDIR(inode-&gt;i_mode) || S_ISLNK(inode-&gt;i_mode))
+		return EXT4_FREE_BLOCKS_METADATA | EXT4_FREE_BLOCKS_FORGET;
+	else if (ext4_should_journal_data(inode))
+		return EXT4_FREE_BLOCKS_FORGET;
+	return 0;
+}
+
 static int ext4_remove_blocks(handle_t *handle, struct inode *inode,
 			      struct ext4_extent *ex,
 			      long long *partial_cluster,
@@ -2363,12 +2372,7 @@ static int ext4_remove_blocks(handle_t *handle, struct inode *inode,
 	struct ext4_sb_info *sbi = EXT4_SB(inode-&gt;i_sb);
 	unsigned short ee_len =  ext4_ext_get_actual_len(ex);
 	ext4_fsblk_t pblk;
-	int flags = 0;
-
-	if (S_ISDIR(inode-&gt;i_mode) || S_ISLNK(inode-&gt;i_mode))
-		flags |= EXT4_FREE_BLOCKS_METADATA | EXT4_FREE_BLOCKS_FORGET;
-	else if (ext4_should_journal_data(inode))
-		flags |= EXT4_FREE_BLOCKS_FORGET;
+	int flags = get_default_free_blocks_flags(inode);
 
 	/*
 	 * For bigalloc file systems, we never free a partial cluster
@@ -2635,10 +2639,7 @@ ext4_ext_rm_leaf(handle_t *handle, struct inode *inode,
 	if (*partial_cluster &gt; 0 &amp;&amp;
 	    (EXT4_B2C(sbi, ext4_ext_pblock(ex) + ex_ee_len - 1) !=
 	     *partial_cluster)) {
-		int flags = EXT4_FREE_BLOCKS_FORGET;
-
-		if (S_ISDIR(inode-&gt;i_mode) || S_ISLNK(inode-&gt;i_mode))
-			flags |= EXT4_FREE_BLOCKS_METADATA;
+		int flags = get_default_free_blocks_flags(inode);
 
 		ext4_free_blocks(handle, inode, NULL,
 				 EXT4_C2B(sbi, *partial_cluster),
@@ -2869,10 +2870,7 @@ int ext4_ext_remove_space(struct inode *inode, ext4_lblk_t start,
 	 * even the first extent, then we should free the blocks in the partial
 	 * cluster as well. */
 	if (partial_cluster &gt; 0 &amp;&amp; path-&gt;p_hdr-&gt;eh_entries == 0) {
-		int flags = EXT4_FREE_BLOCKS_FORGET;
-
-		if (S_ISDIR(inode-&gt;i_mode) || S_ISLNK(inode-&gt;i_mode))
-			flags |= EXT4_FREE_BLOCKS_METADATA;
+		int flags = get_default_free_blocks_flags(inode);
 
 		ext4_free_blocks(handle, inode, NULL,
 				 EXT4_C2B(EXT4_SB(sb), partial_cluster),
diff --git a/fs/ext4/indirect.c b/fs/ext4/indirect.c
index 2a1f8a577e08..963d23dc1028 100644
--- a/fs/ext4/indirect.c
+++ b/fs/ext4/indirect.c
@@ -926,11 +926,13 @@ static int ext4_clear_blocks(handle_t *handle, struct inode *inode,
 			     __le32 *last)
 {
 	__le32 *p;
-	int	flags = EXT4_FREE_BLOCKS_FORGET | EXT4_FREE_BLOCKS_VALIDATED;
+	int	flags = EXT4_FREE_BLOCKS_VALIDATED;
 	int	err;
 
 	if (S_ISDIR(inode-&gt;i_mode) || S_ISLNK(inode-&gt;i_mode))
-		flags |= EXT4_FREE_BLOCKS_METADATA;
+		flags |= EXT4_FREE_BLOCKS_FORGET | EXT4_FREE_BLOCKS_METADATA;
+	else if (ext4_should_journal_data(inode))
+		flags |= EXT4_FREE_BLOCKS_FORGET;
 
 	if (!ext4_data_block_valid(EXT4_SB(inode-&gt;i_sb), block_to_free,
 				   count)) {</pre><hr><pre>commit 2ed5724d5a78a22864ef0bd6af4fcb8a15379f00
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Jun 12 11:43:02 2013 -0400

    ext4: add cond_resched() to ext4_free_blocks() &amp; ext4_mb_regular_allocator()
    
    For a file systems with a very large number of block groups, if all of
    the block group bitmaps are in memory and the file system is
    relatively badly fragmented, it's possible ext4_mb_regular_allocator()
    to take a long time trying to find a good match.  This is especially
    true if the tuning parameter mb_max_to_scan has been sent to a very
    large number.  So add a cond_resched() to avoid soft lockup warnings
    and to provide better system responsiveness.
    
    For ext4_free_blocks(), if we are deleting a large range of blocks,
    and data=journal is enabled so that EXT4_FREE_BLOCKS_FORGET is passed,
    the loop to call sb_find_get_block() and to call ext4_forget() can
    take over 10-15 milliseocnds or more.  So it's better to add a
    cond_resched() here a well.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c
index def84082a9a9..1a9c22b45a01 100644
--- a/fs/ext4/mballoc.c
+++ b/fs/ext4/mballoc.c
@@ -2105,6 +2105,7 @@ ext4_mb_regular_allocator(struct ext4_allocation_context *ac)
 		group = ac-&gt;ac_g_ex.fe_group;
 
 		for (i = 0; i &lt; ngroups; group++, i++) {
+			cond_resched();
 			/*
 			 * Artificially restricted ngroups for non-extent
 			 * files makes group &gt; ngroups possible on first loop.
@@ -4612,10 +4613,11 @@ void ext4_free_blocks(handle_t *handle, struct inode *inode,
 		BUG_ON(bh &amp;&amp; (count &gt; 1));
 
 		for (i = 0; i &lt; count; i++) {
+			cond_resched();
 			if (!bh)
 				tbh = sb_find_get_block(inode-&gt;i_sb,
 							block + i);
-			if (unlikely(!tbh))
+			if (!tbh)
 				continue;
 			ext4_forget(handle, flags &amp; EXT4_FREE_BLOCKS_METADATA,
 				    inode, tbh, block + i);</pre><hr><pre>commit 20970ba65d5a22f2e4efbfa100377722fde56935
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Thu Jun 6 14:00:46 2013 -0400

    ext4: use ext4_da_writepages() for all modes
    
    Rename ext4_da_writepages() to ext4_writepages() and use it for all
    modes.  We still need to iterate over all the pages in the case of
    data=journalling, but in the case of nodelalloc/data=ordered (which is
    what file systems mounted using ext3 backwards compatibility will use)
    this will allow us to use a much more efficient I/O submission path.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 442c5d2e0978..0db830d541ec 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -1799,7 +1799,7 @@ static int __ext4_journalled_writepage(struct page *page,
  * lock so we have to do some magic.
  *
  * This function can get called via...
- *   - ext4_da_writepages after taking page lock (have journal handle)
+ *   - ext4_writepages after taking page lock (have journal handle)
  *   - journal_submit_inode_data_buffers (no journal handle)
  *   - shrink_page_list via the kswapd/direct reclaim (no journal handle)
  *   - grab_page_cache when doing write_begin (have journal handle)
@@ -2217,7 +2217,7 @@ static int mpage_map_and_submit_extent(handle_t *handle,
 
 /*
  * Calculate the total number of credits to reserve for one writepages
- * iteration. This is called from ext4_da_writepages(). We map an extent of
+ * iteration. This is called from ext4_writepages(). We map an extent of
  * upto MAX_WRITEPAGES_EXTENT_LEN blocks and then we go on and finish mapping
  * the last partial page. So in total we can map MAX_WRITEPAGES_EXTENT_LEN +
  * bpp - 1 blocks in bpp different extents.
@@ -2349,8 +2349,17 @@ static int mpage_prepare_extent_to_map(struct mpage_da_data *mpd)
 	return err;
 }
 
-static int ext4_da_writepages(struct address_space *mapping,
-			      struct writeback_control *wbc)
+static int __writepage(struct page *page, struct writeback_control *wbc,
+		       void *data)
+{
+	struct address_space *mapping = data;
+	int ret = ext4_writepage(page, wbc);
+	mapping_set_error(mapping, ret);
+	return ret;
+}
+
+static int ext4_writepages(struct address_space *mapping,
+			   struct writeback_control *wbc)
 {
 	pgoff_t	writeback_index = 0;
 	long nr_to_write = wbc-&gt;nr_to_write;
@@ -2364,7 +2373,7 @@ static int ext4_da_writepages(struct address_space *mapping,
 	bool done;
 	struct blk_plug plug;
 
-	trace_ext4_da_writepages(inode, wbc);
+	trace_ext4_writepages(inode, wbc);
 
 	/*
 	 * No pages to write? This is mainly a kludge to avoid starting
@@ -2374,13 +2383,23 @@ static int ext4_da_writepages(struct address_space *mapping,
 	if (!mapping-&gt;nrpages || !mapping_tagged(mapping, PAGECACHE_TAG_DIRTY))
 		return 0;
 
+	if (ext4_should_journal_data(inode)) {
+		struct blk_plug plug;
+		int ret;
+
+		blk_start_plug(&amp;plug);
+		ret = write_cache_pages(mapping, wbc, __writepage, mapping);
+		blk_finish_plug(&amp;plug);
+		return ret;
+	}
+
 	/*
 	 * If the filesystem has aborted, it is read-only, so return
 	 * right away instead of dumping stack traces later on that
 	 * will obscure the real source of the problem.  We test
 	 * EXT4_MF_FS_ABORTED instead of sb-&gt;s_flag's MS_RDONLY because
 	 * the latter could be true if the filesystem is mounted
-	 * read-only, and in that case, ext4_da_writepages should
+	 * read-only, and in that case, ext4_writepages should
 	 * *never* be called, so if that ever happens, we would want
 	 * the stack trace.
 	 */
@@ -2520,8 +2539,8 @@ static int ext4_da_writepages(struct address_space *mapping,
 		mapping-&gt;writeback_index = mpd.first_page;
 
 out_writepages:
-	trace_ext4_da_writepages_result(inode, wbc, ret,
-					nr_to_write - wbc-&gt;nr_to_write);
+	trace_ext4_writepages_result(inode, wbc, ret,
+				     nr_to_write - wbc-&gt;nr_to_write);
 	return ret;
 }
 
@@ -2769,7 +2788,7 @@ int ext4_alloc_da_blocks(struct inode *inode)
 	 * laptop_mode, not even desirable).  However, to do otherwise
 	 * would require replicating code paths in:
 	 *
-	 * ext4_da_writepages() -&gt;
+	 * ext4_writepages() -&gt;
 	 *    write_cache_pages() ---&gt; (via passed in callback function)
 	 *        __mpage_da_writepage() --&gt;
 	 *           mpage_add_bh_to_extent()
@@ -3213,6 +3232,7 @@ static const struct address_space_operations ext4_aops = {
 	.readpage		= ext4_readpage,
 	.readpages		= ext4_readpages,
 	.writepage		= ext4_writepage,
+	.writepages		= ext4_writepages,
 	.write_begin		= ext4_write_begin,
 	.write_end		= ext4_write_end,
 	.bmap			= ext4_bmap,
@@ -3228,6 +3248,7 @@ static const struct address_space_operations ext4_journalled_aops = {
 	.readpage		= ext4_readpage,
 	.readpages		= ext4_readpages,
 	.writepage		= ext4_writepage,
+	.writepages		= ext4_writepages,
 	.write_begin		= ext4_write_begin,
 	.write_end		= ext4_journalled_write_end,
 	.set_page_dirty		= ext4_journalled_set_page_dirty,
@@ -3243,7 +3264,7 @@ static const struct address_space_operations ext4_da_aops = {
 	.readpage		= ext4_readpage,
 	.readpages		= ext4_readpages,
 	.writepage		= ext4_writepage,
-	.writepages		= ext4_da_writepages,
+	.writepages		= ext4_writepages,
 	.write_begin		= ext4_da_write_begin,
 	.write_end		= ext4_da_write_end,
 	.bmap			= ext4_bmap,
diff --git a/include/trace/events/ext4.h b/include/trace/events/ext4.h
index 832a412e6515..72f523eb82e0 100644
--- a/include/trace/events/ext4.h
+++ b/include/trace/events/ext4.h
@@ -281,7 +281,7 @@ DEFINE_EVENT(ext4__write_end, ext4_da_write_end,
 	TP_ARGS(inode, pos, len, copied)
 );
 
-TRACE_EVENT(ext4_da_writepages,
+TRACE_EVENT(ext4_writepages,
 	TP_PROTO(struct inode *inode, struct writeback_control *wbc),
 
 	TP_ARGS(inode, wbc),
@@ -379,7 +379,7 @@ TRACE_EVENT(ext4_da_write_pages_extent,
 		  __entry-&gt;flags)
 );
 
-TRACE_EVENT(ext4_da_writepages_result,
+TRACE_EVENT(ext4_writepages_result,
 	TP_PROTO(struct inode *inode, struct writeback_control *wbc,
 			int ret, int pages_written),
 </pre>
    <div class="pagination">
        <a href='1_48.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><span>[49]</span><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_50.html'>Next&gt;&gt;</a>
    <div>
</body>
