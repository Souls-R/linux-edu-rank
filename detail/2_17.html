<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Harvard University</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Harvard University</h1>
    <div class="pagination">
        <a href='2_16.html'>&lt;&lt;Prev</a><a href='2.html'>1</a><a href='2_2.html'>2</a><a href='2_3.html'>3</a><a href='2_4.html'>4</a><a href='2_5.html'>5</a><a href='2_6.html'>6</a><a href='2_7.html'>7</a><a href='2_8.html'>8</a><a href='2_9.html'>9</a><a href='2_10.html'>10</a><a href='2_11.html'>11</a><a href='2_12.html'>12</a><a href='2_13.html'>13</a><a href='2_14.html'>14</a><a href='2_15.html'>15</a><a href='2_16.html'>16</a><span>[17]</span><a href='2_18.html'>18</a><a href='2_19.html'>19</a><a href='2_20.html'>20</a><a href='2_21.html'>21</a><a href='2_22.html'>22</a><a href='2_23.html'>23</a><a href='2_24.html'>24</a><a href='2_25.html'>25</a><a href='2_26.html'>26</a><a href='2_27.html'>27</a><a href='2_28.html'>28</a><a href='2_29.html'>29</a><a href='2_30.html'>30</a><a href='2_31.html'>31</a><a href='2_32.html'>32</a><a href='2_33.html'>33</a><a href='2_34.html'>34</a><a href='2_35.html'>35</a><a href='2_36.html'>36</a><a href='2_37.html'>37</a><a href='2_38.html'>38</a><a href='2_39.html'>39</a><a href='2_40.html'>40</a><a href='2_41.html'>41</a><a href='2_42.html'>42</a><a href='2_43.html'>43</a><a href='2_44.html'>44</a><a href='2_45.html'>45</a><a href='2_46.html'>46</a><a href='2_47.html'>47</a><a href='2_48.html'>48</a><a href='2_49.html'>49</a><a href='2_50.html'>50</a><a href='2_51.html'>51</a><a href='2_52.html'>52</a><a href='2_53.html'>53</a><a href='2_54.html'>54</a><a href='2_55.html'>55</a><a href='2_56.html'>56</a><a href='2_57.html'>57</a><a href='2_58.html'>58</a><a href='2_59.html'>59</a><a href='2_60.html'>60</a><a href='2_61.html'>61</a><a href='2_62.html'>62</a><a href='2_63.html'>63</a><a href='2_64.html'>64</a><a href='2_65.html'>65</a><a href='2_66.html'>66</a><a href='2_67.html'>67</a><a href='2_68.html'>68</a><a href='2_69.html'>69</a><a href='2_70.html'>70</a><a href='2_71.html'>71</a><a href='2_72.html'>72</a><a href='2_73.html'>73</a><a href='2_74.html'>74</a><a href='2_75.html'>75</a><a href='2_76.html'>76</a><a href='2_77.html'>77</a><a href='2_78.html'>78</a><a href='2_79.html'>79</a><a href='2_80.html'>80</a><a href='2_81.html'>81</a><a href='2_82.html'>82</a><a href='2_83.html'>83</a><a href='2_84.html'>84</a><a href='2_85.html'>85</a><a href='2_86.html'>86</a><a href='2_87.html'>87</a><a href='2_88.html'>88</a><a href='2_89.html'>89</a><a href='2_90.html'>90</a><a href='2_91.html'>91</a><a href='2_92.html'>92</a><a href='2_93.html'>93</a><a href='2_94.html'>94</a><a href='2_95.html'>95</a><a href='2_96.html'>96</a><a href='2_97.html'>97</a><a href='2_98.html'>98</a><a href='2_99.html'>99</a><a href='2_100.html'>100</a><a href='2_101.html'>101</a><a href='2_102.html'>102</a><a href='2_103.html'>103</a><a href='2_104.html'>104</a><a href='2_105.html'>105</a><a href='2_106.html'>106</a><a href='2_107.html'>107</a><a href='2_108.html'>108</a><a href='2_109.html'>109</a><a href='2_110.html'>110</a><a href='2_111.html'>111</a><a href='2_112.html'>112</a><a href='2_113.html'>113</a><a href='2_114.html'>114</a><a href='2_115.html'>115</a><a href='2_116.html'>116</a><a href='2_117.html'>117</a><a href='2_118.html'>118</a><a href='2_119.html'>119</a><a href='2_120.html'>120</a><a href='2_121.html'>121</a><a href='2_122.html'>122</a><a href='2_123.html'>123</a><a href='2_124.html'>124</a><a href='2_125.html'>125</a><a href='2_126.html'>126</a><a href='2_127.html'>127</a><a href='2_128.html'>128</a><a href='2_129.html'>129</a><a href='2_130.html'>130</a><a href='2_131.html'>131</a><a href='2_132.html'>132</a><a href='2_133.html'>133</a><a href='2_134.html'>134</a><a href='2_135.html'>135</a><a href='2_136.html'>136</a><a href='2_137.html'>137</a><a href='2_138.html'>138</a><a href='2_139.html'>139</a><a href='2_140.html'>140</a><a href='2_18.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit dec3c23c9aa1815f07d98ae0375b4cbc10971e13
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Wed Aug 8 11:20:39 2018 -0400

    USB: net2280: Fix erroneous synchronization change
    
    Commit f16443a034c7 ("USB: gadgetfs, dummy-hcd, net2280: fix locking
    for callbacks") was based on a serious misunderstanding.  It
    introduced regressions into both the dummy-hcd and net2280 drivers.
    
    The problem in dummy-hcd was fixed by commit 7dbd8f4cabd9 ("USB:
    dummy-hcd: Fix erroneous synchronization change"), but the problem in
    net2280 remains.  Namely: the -&gt;disconnect(), -&gt;suspend(), -&gt;resume(),
    and -&gt;reset() callbacks must be invoked without the private lock held;
    otherwise a deadlock will occur when the callback routine tries to
    interact with the UDC driver.
    
    This patch largely is a reversion of the relevant parts of
    f16443a034c7.  It also drops the private lock around the calls to
    -&gt;suspend() and -&gt;resume() (something the earlier patch forgot to do).
    This is safe from races with device interrupts because it occurs
    within the interrupt handler.
    
    Finally, the patch changes where the -&gt;disconnect() callback is
    invoked when net2280_pullup() turns the pullup off.  Rather than
    making the callback from within stop_activity() at a time when dropping
    the private lock could be unsafe, the callback is moved to a point
    after the lock has already been dropped.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Fixes: f16443a034c7 ("USB: gadgetfs, dummy-hcd, net2280: fix locking for callbacks")
    Reported-by: D. Ziesche &lt;dziesche@zes.com&gt;
    Tested-by: D. Ziesche &lt;dziesche@zes.com&gt;
    CC: &lt;stable@vger.kernel.org&gt;
    Signed-off-by: Felipe Balbi &lt;felipe.balbi@linux.intel.com&gt;

diff --git a/drivers/usb/gadget/udc/net2280.c b/drivers/usb/gadget/udc/net2280.c
index 318246d8b2e2..b02ab2a8d927 100644
--- a/drivers/usb/gadget/udc/net2280.c
+++ b/drivers/usb/gadget/udc/net2280.c
@@ -1545,11 +1545,14 @@ static int net2280_pullup(struct usb_gadget *_gadget, int is_on)
 		writel(tmp | BIT(USB_DETECT_ENABLE), &amp;dev-&gt;usb-&gt;usbctl);
 	} else {
 		writel(tmp &amp; ~BIT(USB_DETECT_ENABLE), &amp;dev-&gt;usb-&gt;usbctl);
-		stop_activity(dev, dev-&gt;driver);
+		stop_activity(dev, NULL);
 	}
 
 	spin_unlock_irqrestore(&amp;dev-&gt;lock, flags);
 
+	if (!is_on &amp;&amp; dev-&gt;driver)
+		dev-&gt;driver-&gt;disconnect(&amp;dev-&gt;gadget);
+
 	return 0;
 }
 
@@ -2466,8 +2469,11 @@ static void stop_activity(struct net2280 *dev, struct usb_gadget_driver *driver)
 		nuke(&amp;dev-&gt;ep[i]);
 
 	/* report disconnect; the driver is already quiesced */
-	if (driver)
+	if (driver) {
+		spin_unlock(&amp;dev-&gt;lock);
 		driver-&gt;disconnect(&amp;dev-&gt;gadget);
+		spin_lock(&amp;dev-&gt;lock);
+	}
 
 	usb_reinit(dev);
 }
@@ -3341,6 +3347,8 @@ static void handle_stat0_irqs(struct net2280 *dev, u32 stat)
 		BIT(PCI_RETRY_ABORT_INTERRUPT))
 
 static void handle_stat1_irqs(struct net2280 *dev, u32 stat)
+__releases(dev-&gt;lock)
+__acquires(dev-&gt;lock)
 {
 	struct net2280_ep	*ep;
 	u32			tmp, num, mask, scratch;
@@ -3381,12 +3389,14 @@ static void handle_stat1_irqs(struct net2280 *dev, u32 stat)
 			if (disconnect || reset) {
 				stop_activity(dev, dev-&gt;driver);
 				ep0_start(dev);
+				spin_unlock(&amp;dev-&gt;lock);
 				if (reset)
 					usb_gadget_udc_reset
 						(&amp;dev-&gt;gadget, dev-&gt;driver);
 				else
 					(dev-&gt;driver-&gt;disconnect)
 						(&amp;dev-&gt;gadget);
+				spin_lock(&amp;dev-&gt;lock);
 				return;
 			}
 		}
@@ -3405,6 +3415,7 @@ static void handle_stat1_irqs(struct net2280 *dev, u32 stat)
 	tmp = BIT(SUSPEND_REQUEST_CHANGE_INTERRUPT);
 	if (stat &amp; tmp) {
 		writel(tmp, &amp;dev-&gt;regs-&gt;irqstat1);
+		spin_unlock(&amp;dev-&gt;lock);
 		if (stat &amp; BIT(SUSPEND_REQUEST_INTERRUPT)) {
 			if (dev-&gt;driver-&gt;suspend)
 				dev-&gt;driver-&gt;suspend(&amp;dev-&gt;gadget);
@@ -3415,6 +3426,7 @@ static void handle_stat1_irqs(struct net2280 *dev, u32 stat)
 				dev-&gt;driver-&gt;resume(&amp;dev-&gt;gadget);
 			/* at high speed, note erratum 0133 */
 		}
+		spin_lock(&amp;dev-&gt;lock);
 		stat &amp;= ~tmp;
 	}
 </pre><hr><pre>commit bf594c1070f5c34a2576a725eef69cba2686b98d
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Fri Jun 29 13:52:20 2018 -0400

    USB: gadget: Document that certain ep operations can be called in interrupt context
    
    This documentation patch specifies that certain USB gadget endpoint
    operations may be called in interrupt context:
    
            usb_ep_queue, usb_ep_dequeue, usb_ep_set_halt,
            usb_ep_clear_halt, usb_ep_set_wedge, usb_ep_fifo_status,
            and usb_ep_fifo_flush;
    
    while others must be called in process context:
    
            usb_ep_enable and usb_ep_disable.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Felipe Balbi &lt;felipe.balbi@linux.intel.com&gt;

diff --git a/drivers/usb/gadget/udc/core.c b/drivers/usb/gadget/udc/core.c
index cab5e4f09924..af88b48c1cea 100644
--- a/drivers/usb/gadget/udc/core.c
+++ b/drivers/usb/gadget/udc/core.c
@@ -87,6 +87,8 @@ EXPORT_SYMBOL_GPL(usb_ep_set_maxpacket_limit);
  * configurable, with more generic names like "ep-a".  (remember that for
  * USB, "in" means "towards the USB master".)
  *
+ * This routine must be called in process context.
+ *
  * returns zero, or a negative error code.
  */
 int usb_ep_enable(struct usb_ep *ep)
@@ -119,6 +121,8 @@ EXPORT_SYMBOL_GPL(usb_ep_enable);
  * gadget drivers must call usb_ep_enable() again before queueing
  * requests to the endpoint.
  *
+ * This routine must be called in process context.
+ *
  * returns zero, or a negative error code.
  */
 int usb_ep_disable(struct usb_ep *ep)
@@ -241,6 +245,8 @@ EXPORT_SYMBOL_GPL(usb_ep_free_request);
  * Note that @req's -&gt;complete() callback must never be called from
  * within usb_ep_queue() as that can create deadlock situations.
  *
+ * This routine may be called in interrupt context.
+ *
  * Returns zero, or a negative error code.  Endpoints that are not enabled
  * report errors; errors will also be
  * reported when the usb peripheral is disconnected.
@@ -284,6 +290,8 @@ EXPORT_SYMBOL_GPL(usb_ep_queue);
  * at the head of the queue) except as part of disconnecting from usb. Such
  * restrictions prevent drivers from supporting configuration changes,
  * even to configuration zero (a "chapter 9" requirement).
+ *
+ * This routine may be called in interrupt context.
  */
 int usb_ep_dequeue(struct usb_ep *ep, struct usb_request *req)
 {
@@ -311,6 +319,8 @@ EXPORT_SYMBOL_GPL(usb_ep_dequeue);
  * current altsetting, see usb_ep_clear_halt().  When switching altsettings,
  * it's simplest to use usb_ep_enable() or usb_ep_disable() for the endpoints.
  *
+ * This routine may be called in interrupt context.
+ *
  * Returns zero, or a negative error code.  On success, this call sets
  * underlying hardware state that blocks data transfers.
  * Attempts to halt IN endpoints will fail (returning -EAGAIN) if any
@@ -336,6 +346,8 @@ EXPORT_SYMBOL_GPL(usb_ep_set_halt);
  * for endpoints that aren't reconfigured, after clearing any other state
  * in the endpoint's i/o queue.
  *
+ * This routine may be called in interrupt context.
+ *
  * Returns zero, or a negative error code.  On success, this call clears
  * the underlying hardware state reflecting endpoint halt and data toggle.
  * Note that some hardware can't support this request (like pxa2xx_udc),
@@ -360,6 +372,8 @@ EXPORT_SYMBOL_GPL(usb_ep_clear_halt);
  * requests. If the gadget driver clears the halt status, it will
  * automatically unwedge the endpoint.
  *
+ * This routine may be called in interrupt context.
+ *
  * Returns zero on success, else negative errno.
  */
 int usb_ep_set_wedge(struct usb_ep *ep)
@@ -388,6 +402,8 @@ EXPORT_SYMBOL_GPL(usb_ep_set_wedge);
  * written OUT to it by the host.  Drivers that need precise handling for
  * fault reporting or recovery may need to use this call.
  *
+ * This routine may be called in interrupt context.
+ *
  * This returns the number of such bytes in the fifo, or a negative
  * errno if the endpoint doesn't use a FIFO or doesn't support such
  * precise handling.
@@ -415,6 +431,8 @@ EXPORT_SYMBOL_GPL(usb_ep_fifo_status);
  * an endpoint fifo after abnormal transaction terminations.  The call
  * must never be used except when endpoint is not being used for any
  * protocol translation.
+ *
+ * This routine may be called in interrupt context.
  */
 void usb_ep_fifo_flush(struct usb_ep *ep)
 {</pre><hr><pre>commit 8f9cc83c06d44081d7c7e179f778cbeb4d074fa7
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Fri Jun 8 16:59:57 2018 -0400

    USB: xhci-hcd: Add get_resuming_ports method
    
    This patch adds support for the new get_resuming_ports HCD method to
    the xhci-hcd driver.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Acked-by: Mathias Nyman &lt;mathias.nyman@linux.intel.com&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;

diff --git a/drivers/usb/host/xhci-hub.c b/drivers/usb/host/xhci-hub.c
index a4b95d019f84..7e2a531ba321 100644
--- a/drivers/usb/host/xhci-hub.c
+++ b/drivers/usb/host/xhci-hub.c
@@ -1684,4 +1684,15 @@ int xhci_bus_resume(struct usb_hcd *hcd)
 	return 0;
 }
 
+unsigned long xhci_get_resuming_ports(struct usb_hcd *hcd)
+{
+	struct xhci_hcd	*xhci = hcd_to_xhci(hcd);
+	struct xhci_bus_state *bus_state;
+
+	bus_state = &amp;xhci-&gt;bus_state[hcd_index(hcd)];
+
+	/* USB3 port wakeups are reported via usb_wakeup_notification() */
+	return bus_state-&gt;resuming_ports;	/* USB2 ports only */
+}
+
 #endif	/* CONFIG_PM */
diff --git a/drivers/usb/host/xhci.c b/drivers/usb/host/xhci.c
index 8c8da2d657fa..2f239cb3deaf 100644
--- a/drivers/usb/host/xhci.c
+++ b/drivers/usb/host/xhci.c
@@ -5081,6 +5081,7 @@ static const struct hc_driver xhci_hc_driver = {
 	.hub_status_data =	xhci_hub_status_data,
 	.bus_suspend =		xhci_bus_suspend,
 	.bus_resume =		xhci_bus_resume,
+	.get_resuming_ports =	xhci_get_resuming_ports,
 
 	/*
 	 * call back when device connected and addressed
diff --git a/drivers/usb/host/xhci.h b/drivers/usb/host/xhci.h
index 939e2f86b595..ece5891240f0 100644
--- a/drivers/usb/host/xhci.h
+++ b/drivers/usb/host/xhci.h
@@ -2110,9 +2110,11 @@ void xhci_hc_died(struct xhci_hcd *xhci);
 #ifdef CONFIG_PM
 int xhci_bus_suspend(struct usb_hcd *hcd);
 int xhci_bus_resume(struct usb_hcd *hcd);
+unsigned long xhci_get_resuming_ports(struct usb_hcd *hcd);
 #else
 #define	xhci_bus_suspend	NULL
 #define	xhci_bus_resume		NULL
+#define	xhci_get_resuming_ports	NULL
 #endif	/* CONFIG_PM */
 
 u32 xhci_port_state_to_neutral(u32 state);</pre><hr><pre>commit 00d423c8d0132915f4204b330343420c271b9142
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Fri Jun 8 16:59:50 2018 -0400

    USB: ehci-hcd: Add get_resuming_ports method
    
    This patch adds support for the new get_resuming_ports HCD method to
    the ehci-hcd driver.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;

diff --git a/drivers/usb/host/ehci-hcd.c b/drivers/usb/host/ehci-hcd.c
index 89c47ae5c7d3..8608ac513fb7 100644
--- a/drivers/usb/host/ehci-hcd.c
+++ b/drivers/usb/host/ehci-hcd.c
@@ -1226,6 +1226,7 @@ static const struct hc_driver ehci_hc_driver = {
 	.bus_resume =		ehci_bus_resume,
 	.relinquish_port =	ehci_relinquish_port,
 	.port_handed_over =	ehci_port_handed_over,
+	.get_resuming_ports =	ehci_get_resuming_ports,
 
 	/*
 	 * device support
diff --git a/drivers/usb/host/ehci-hub.c b/drivers/usb/host/ehci-hub.c
index d7641cbdee43..ce0eaf7d7c12 100644
--- a/drivers/usb/host/ehci-hub.c
+++ b/drivers/usb/host/ehci-hub.c
@@ -512,10 +512,18 @@ static int ehci_bus_resume (struct usb_hcd *hcd)
 	return -ESHUTDOWN;
 }
 
+static unsigned long ehci_get_resuming_ports(struct usb_hcd *hcd)
+{
+	struct ehci_hcd		*ehci = hcd_to_ehci(hcd);
+
+	return ehci-&gt;resuming_ports;
+}
+
 #else
 
 #define ehci_bus_suspend	NULL
 #define ehci_bus_resume		NULL
+#define ehci_get_resuming_ports	NULL
 
 #endif	/* CONFIG_PM */
 </pre><hr><pre>commit 379cacc5e566f7197bdeb1ea3e99219d3e880c0a
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Fri Jun 8 16:59:37 2018 -0400

    USB: Report wakeup events on root-hub ports
    
    When a USB device attached to a root-hub port sends a wakeup request
    to a sleeping system, we do not report the wakeup event to the PM
    core.  This is because a system resume involves waking up all
    suspended USB ports as quickly as possible; without the normal
    USB_RESUME_TIMEOUT delay, the host controller driver doesn't set the
    USB_PORT_STAT_C_SUSPEND flag and so usb_port_resume() doesn't realize
    that a wakeup request was received.
    
    However, some environments (such as Chrome OS) want to have all wakeup
    events reported so they can be ascribed to the appropriate device.  To
    accommodate these environments, this patch adds a new routine to the
    hub driver and a corresponding new HCD method to be used when a root
    hub resumes.  The HCD method returns a bitmap of ports that have
    initiated a wakeup signal but not yet completed resuming.  The hub
    driver can then report to the PM core that the child devices attached
    to these ports initiated a wakeup event.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Suggested-by: Anshuman Gupta &lt;anshuman.gupta@intel.com&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;

diff --git a/drivers/usb/core/hub.c b/drivers/usb/core/hub.c
index fcae521df29b..fef5af7aab92 100644
--- a/drivers/usb/core/hub.c
+++ b/drivers/usb/core/hub.c
@@ -3656,12 +3656,54 @@ static int hub_suspend(struct usb_interface *intf, pm_message_t msg)
 	return 0;
 }
 
+/* Report wakeup requests from the ports of a resuming root hub */
+static void report_wakeup_requests(struct usb_hub *hub)
+{
+	struct usb_device	*hdev = hub-&gt;hdev;
+	struct usb_device	*udev;
+	struct usb_hcd		*hcd;
+	unsigned long		resuming_ports;
+	int			i;
+
+	if (hdev-&gt;parent)
+		return;		/* Not a root hub */
+
+	hcd = bus_to_hcd(hdev-&gt;bus);
+	if (hcd-&gt;driver-&gt;get_resuming_ports) {
+
+		/*
+		 * The get_resuming_ports() method returns a bitmap (origin 0)
+		 * of ports which have started wakeup signaling but have not
+		 * yet finished resuming.  During system resume we will
+		 * resume all the enabled ports, regardless of any wakeup
+		 * signals, which means the wakeup requests would be lost.
+		 * To prevent this, report them to the PM core here.
+		 */
+		resuming_ports = hcd-&gt;driver-&gt;get_resuming_ports(hcd);
+		for (i = 0; i &lt; hdev-&gt;maxchild; ++i) {
+			if (test_bit(i, &amp;resuming_ports)) {
+				udev = hub-&gt;ports[i]-&gt;child;
+				if (udev)
+					pm_wakeup_event(&amp;udev-&gt;dev, 0);
+			}
+		}
+	}
+}
+
 static int hub_resume(struct usb_interface *intf)
 {
 	struct usb_hub *hub = usb_get_intfdata(intf);
 
 	dev_dbg(&amp;intf-&gt;dev, "%s\n", __func__);
 	hub_activate(hub, HUB_RESUME);
+
+	/*
+	 * This should be called only for system resume, not runtime resume.
+	 * We can't tell the difference here, so some wakeup requests will be
+	 * reported at the wrong time or more than once.  This shouldn't
+	 * matter much, so long as they do get reported.
+	 */
+	report_wakeup_requests(hub);
 	return 0;
 }
 
diff --git a/include/linux/usb/hcd.h b/include/linux/usb/hcd.h
index 34a6ded6f319..97e2ddec18b1 100644
--- a/include/linux/usb/hcd.h
+++ b/include/linux/usb/hcd.h
@@ -322,6 +322,7 @@ struct hc_driver {
 	int	(*bus_suspend)(struct usb_hcd *);
 	int	(*bus_resume)(struct usb_hcd *);
 	int	(*start_port_reset)(struct usb_hcd *, unsigned port_num);
+	unsigned long	(*get_resuming_ports)(struct usb_hcd *);
 
 		/* force handover of high-speed port to full-speed companion */
 	void	(*relinquish_port)(struct usb_hcd *, int);</pre><hr><pre>commit cee0321a404fe6b43d1f4364639c8ffe2f2b37d1
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:53 2018 -0700

    tools/memory-model: Remove out-of-date comments and code from lock.cat
    
    lock.cat contains old comments and code referring to the possibility
    of LKR events that are not part of an RMW pair.  This is a holdover
    from when I though we might end up using LKR events to implement
    spin_is_locked().  Reword the comments to remove this assumption and
    replace domain(lk-rmw) in the code with LKR.
    
    Tested-by: Andrea Parri &lt;andrea.parri@amarulasolutions.com&gt;
    [ paulmck: Pulled as lock-nest into previous line as discussed. ]
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Cc: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Cc: David Howells &lt;dhowells@redhat.com&gt;
    Cc: Jade Alglave &lt;j.alglave@ucl.ac.uk&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Luc Maranget &lt;luc.maranget@inria.fr&gt;
    Cc: Nicholas Piggin &lt;npiggin@gmail.com&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-15-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/lock.cat b/tools/memory-model/lock.cat
index 7217cd4941a4..cd002a33ca8a 100644
--- a/tools/memory-model/lock.cat
+++ b/tools/memory-model/lock.cat
@@ -47,18 +47,15 @@ flag ~empty [M \ IW] ; loc ; [ALL-LOCKS] as mixed-lock-accesses
 let lk-rmw = ([LKR] ; po-loc ; [LKW]) \ (po ; po)
 let rmw = rmw | lk-rmw
 
+(* The litmus test is invalid if an LKR/LKW event is not part of an RMW pair *)
+flag ~empty LKW \ range(lk-rmw) as unpaired-LKW
+flag ~empty LKR \ domain(lk-rmw) as unpaired-LKR
+
 (*
- * A paired LKR must always see an unlocked value; spin_lock() calls nested
+ * An LKR must always see an unlocked value; spin_lock() calls nested
  * inside a critical section (for the same lock) always deadlock.
  *)
-empty ([LKW] ; po-loc ; [domain(lk-rmw)]) \ (po-loc ; [UL] ; po-loc)
-	as lock-nest
-
-(* The litmus test is invalid if an LKW event is not part of an RMW pair *)
-flag ~empty LKW \ range(lk-rmw) as unpaired-LKW
-
-(* This will be allowed if we implement spin_is_locked() *)
-flag ~empty LKR \ domain(lk-rmw) as unpaired-LKR
+empty ([LKW] ; po-loc ; [LKR]) \ (po-loc ; [UL] ; po-loc) as lock-nest
 
 (* The final value of a spinlock should not be tested *)
 flag ~empty [FW] ; loc ; [ALL-LOCKS] as lock-final</pre><hr><pre>commit 30b795df11a1a9dd7fc50c1ff4677343b67cb379
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:52 2018 -0700

    tools/memory-model: Improve mixed-access checking in lock.cat
    
    The code in lock.cat which checks for normal read/write accesses to
    spinlock variables doesn't take into account the newly added RL and RU
    events.  Add them into the test, and move the resulting code up near
    the start of the file, since a violation would indicate a pretty
    severe conceptual error in a litmus test.
    
    Tested-by: Andrea Parri &lt;andrea.parri@amarulasolutions.com&gt;
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Cc: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Cc: David Howells &lt;dhowells@redhat.com&gt;
    Cc: Jade Alglave &lt;j.alglave@ucl.ac.uk&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Luc Maranget &lt;luc.maranget@inria.fr&gt;
    Cc: Nicholas Piggin &lt;npiggin@gmail.com&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-14-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/lock.cat b/tools/memory-model/lock.cat
index df74de2148f6..7217cd4941a4 100644
--- a/tools/memory-model/lock.cat
+++ b/tools/memory-model/lock.cat
@@ -32,6 +32,17 @@ include "cross.cat"
  * LKW, LF, RL, and RU have no ordering properties.
  *)
 
+(* Backward compatibility *)
+let RL = try RL with emptyset
+let RU = try RU with emptyset
+
+(* Treat RL as a kind of LF: a read with no ordering properties *)
+let LF = LF | RL
+
+(* There should be no ordinary R or W accesses to spinlocks *)
+let ALL-LOCKS = LKR | LKW | UL | LF | RU
+flag ~empty [M \ IW] ; loc ; [ALL-LOCKS] as mixed-lock-accesses
+
 (* Link Lock-Reads to their RMW-partner Lock-Writes *)
 let lk-rmw = ([LKR] ; po-loc ; [LKW]) \ (po ; po)
 let rmw = rmw | lk-rmw
@@ -49,20 +60,9 @@ flag ~empty LKW \ range(lk-rmw) as unpaired-LKW
 (* This will be allowed if we implement spin_is_locked() *)
 flag ~empty LKR \ domain(lk-rmw) as unpaired-LKR
 
-(* There should be no ordinary R or W accesses to spinlocks *)
-let ALL-LOCKS = LKR | LKW | UL | LF
-flag ~empty [M \ IW] ; loc ; [ALL-LOCKS] as mixed-lock-accesses
-
 (* The final value of a spinlock should not be tested *)
 flag ~empty [FW] ; loc ; [ALL-LOCKS] as lock-final
 
-(* Backward compatibility *)
-let RL = try RL with emptyset
-let RU = try RU with emptyset
-
-(* Treat RL as a kind of LF: a read with no ordering properties *)
-let LF = LF | RL
-
 (*
  * Put lock operations in their appropriate classes, but leave UL out of W
  * until after the co relation has been generated.</pre><hr><pre>commit fd0359dbac3df00d1c6c22769e7d647b16b920cc
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:51 2018 -0700

    tools/memory-model: Improve comments in lock.cat
    
    This patch improves the comments in tools/memory-model/lock.cat.  In
    addition to making the text more uniform and removing redundant
    comments, it adds a description of all the possible locking events
    that herd can generate.
    
    Tested-by: Andrea Parri &lt;andrea.parri@amarulasolutions.com&gt;
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Cc: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Cc: David Howells &lt;dhowells@redhat.com&gt;
    Cc: Jade Alglave &lt;j.alglave@ucl.ac.uk&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Luc Maranget &lt;luc.maranget@inria.fr&gt;
    Cc: Nicholas Piggin &lt;npiggin@gmail.com&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-13-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/lock.cat b/tools/memory-model/lock.cat
index 1f6d67e79065..df74de2148f6 100644
--- a/tools/memory-model/lock.cat
+++ b/tools/memory-model/lock.cat
@@ -4,15 +4,35 @@
  * Copyright (C) 2017 Alan Stern &lt;stern@rowland.harvard.edu&gt;
  *)
 
-(* Generate coherence orders and handle lock operations *)
 (*
- * Warning, crashes with herd7 versions strictly before 7.48.
- * spin_islocked is functional from version 7.49.
+ * Generate coherence orders and handle lock operations
  *
+ * Warning: spin_is_locked() crashes herd7 versions strictly before 7.48.
+ * spin_is_locked() is functional from herd7 version 7.49.
  *)
+
 include "cross.cat"
 
-(* From lock reads to their partner lock writes *)
+(*
+ * The lock-related events generated by herd are as follows:
+ *
+ * LKR		Lock-Read: the read part of a spin_lock() or successful
+ *			spin_trylock() read-modify-write event pair
+ * LKW		Lock-Write: the write part of a spin_lock() or successful
+ *			spin_trylock() RMW event pair
+ * UL		Unlock: a spin_unlock() event
+ * LF		Lock-Fail: a failed spin_trylock() event
+ * RL		Read-Locked: a spin_is_locked() event which returns True
+ * RU		Read-Unlocked: a spin_is_locked() event which returns False
+ *
+ * LKR and LKW events always come paired, like all RMW event sequences.
+ *
+ * LKR, LF, RL, and RU are read events; LKR has Acquire ordering.
+ * LKW and UL are write events; UL has Release ordering.
+ * LKW, LF, RL, and RU have no ordering properties.
+ *)
+
+(* Link Lock-Reads to their RMW-partner Lock-Writes *)
 let lk-rmw = ([LKR] ; po-loc ; [LKW]) \ (po ; po)
 let rmw = rmw | lk-rmw
 
@@ -29,18 +49,16 @@ flag ~empty LKW \ range(lk-rmw) as unpaired-LKW
 (* This will be allowed if we implement spin_is_locked() *)
 flag ~empty LKR \ domain(lk-rmw) as unpaired-LKR
 
-(* There should be no R or W accesses to spinlocks *)
+(* There should be no ordinary R or W accesses to spinlocks *)
 let ALL-LOCKS = LKR | LKW | UL | LF
 flag ~empty [M \ IW] ; loc ; [ALL-LOCKS] as mixed-lock-accesses
 
 (* The final value of a spinlock should not be tested *)
 flag ~empty [FW] ; loc ; [ALL-LOCKS] as lock-final
 
-(*
- * Backward compatibility
- *)
-let RL = try RL with emptyset (* defined herd7 &gt;= 7.49 *)
-let RU = try RU with emptyset (* defined herd7 &gt;= 7.49 *)
+(* Backward compatibility *)
+let RL = try RL with emptyset
+let RU = try RU with emptyset
 
 (* Treat RL as a kind of LF: a read with no ordering properties *)
 let LF = LF | RL
@@ -55,7 +73,6 @@ let W = W | LKW
 let Release = Release | UL
 let Acquire = Acquire | LKR
 
-
 (* Match LKW events to their corresponding UL events *)
 let critical = ([LKW] ; po-loc ; [UL]) \ (po-loc ; [LKW | UL] ; po-loc)
 
@@ -65,7 +82,6 @@ flag ~empty UL \ range(critical) as unmatched-unlock
 let UNMATCHED-LKW = LKW \ domain(critical)
 empty ([UNMATCHED-LKW] ; loc ; [UNMATCHED-LKW]) \ id as unmatched-locks
 
-
 (* rfi for LF events: link each LKW to the LF events in its critical section *)
 let rfi-lf = ([LKW] ; po-loc ; [LF]) \ ([LKW] ; po-loc ; [UL] ; po-loc)
 
@@ -86,18 +102,23 @@ let all-possible-rfe-lf =
 with rfe-lf from cross(all-possible-rfe-lf)
 let rf-lf = rfe-lf | rfi-lf
 
-(* Read from unlock, ie islocked returning false, slightly different *)
+(*
+ * RU, i.e., spin_is_locked() returning False, is slightly different.
+ * We rely on the memory model to rule out cases where spin_is_locked()
+ * within one of the lock's critical sections returns False.
+ *)
 
-(* islocked returning false can read from the last po-previous unlock *)
+(* rfi for RU events: an RU may read from the last po-previous UL *)
 let rfi-ru = ([UL] ; po-loc ; [RU]) \ ([UL] ; po-loc ; [LKW] ; po-loc)
 
-(* any islocked returning false can read from any external unlock *)
+(* rfe for RU events: an RU may read from an external UL or the initial write *)
 let all-possible-rfe-ru =
    let possible-rfe-ru r =
      let pair-to-relation p = p ++ 0
      in map pair-to-relation (((UL|IW) * {r}) &amp; loc &amp; ext)
   in map possible-rfe-ru RU
 
+(* Generate all rf relations for RU events *)
 with rfe-ru from cross(all-possible-rfe-ru)
 let rf-ru = rfe-ru | rfi-ru
 </pre><hr><pre>commit 8559183ccaec97454b2515ac426f113967256cf9
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:50 2018 -0700

    tools/memory-model: Remove duplicated code from lock.cat
    
    This patch simplifies the implementation of spin_is_locked in the
    LKMM.  It capitalizes on the fact that a failed spin_trylock() and a
    spin_is_locked() which returns True have exactly the same semantics
    (those of READ_ONCE) and ordering properties (none).  Therefore the
    two kinds of events can be combined and handled by the same code,
    instead of treated separately as they are currently.
    
    Tested-by: Andrea Parri &lt;andrea.parri@amarulasolutions.com&gt;
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Cc: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Cc: David Howells &lt;dhowells@redhat.com&gt;
    Cc: Jade Alglave &lt;j.alglave@ucl.ac.uk&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Luc Maranget &lt;luc.maranget@inria.fr&gt;
    Cc: Nicholas Piggin &lt;npiggin@gmail.com&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-12-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/lock.cat b/tools/memory-model/lock.cat
index 3b1439edc818..1f6d67e79065 100644
--- a/tools/memory-model/lock.cat
+++ b/tools/memory-model/lock.cat
@@ -41,11 +41,15 @@ flag ~empty [FW] ; loc ; [ALL-LOCKS] as lock-final
  *)
 let RL = try RL with emptyset (* defined herd7 &gt;= 7.49 *)
 let RU = try RU with emptyset (* defined herd7 &gt;= 7.49 *)
+
+(* Treat RL as a kind of LF: a read with no ordering properties *)
+let LF = LF | RL
+
 (*
  * Put lock operations in their appropriate classes, but leave UL out of W
  * until after the co relation has been generated.
  *)
-let R = R | LKR | LF | RL | RU
+let R = R | LKR | LF | RU
 let W = W | LKW
 
 let Release = Release | UL
@@ -80,28 +84,8 @@ let all-possible-rfe-lf =
 
 (* Generate all rf relations for LF events *)
 with rfe-lf from cross(all-possible-rfe-lf)
-
 let rf-lf = rfe-lf | rfi-lf
 
-(* rf for RL events, ie islocked returning true, similar to LF above *)
-
-(* islocked returning true inside a critical section
- * must read from the opening lock
- *)
-let rfi-rl = ([LKW] ; po-loc ; [RL]) \ ([LKW] ; po-loc ; [UL] ; po-loc)
-
-(* islocked returning true outside critical sections can match any
- * external lock.
- *)
-let all-possible-rfe-rl =
-  let possible-rfe-lf r =
-    let pair-to-relation p = p ++ 0
-    in map pair-to-relation ((LKW * {r}) &amp; loc &amp; ext)
-  in map possible-rfe-lf (RL \ range(rfi-rl))
-
-with rfe-rl from cross(all-possible-rfe-rl)
-let rf-rl = rfe-rl | rfi-rl
-
 (* Read from unlock, ie islocked returning false, slightly different *)
 
 (* islocked returning false can read from the last po-previous unlock *)
@@ -118,7 +102,7 @@ with rfe-ru from cross(all-possible-rfe-ru)
 let rf-ru = rfe-ru | rfi-ru
 
 (* Final rf relation *)
-let rf = rf | rf-lf | rf-rl | rf-ru
+let rf = rf | rf-lf | rf-ru
 
 (* Generate all co relations, including LKW events but not UL *)
 let co0 = co0 | ([IW] ; loc ; [LKW]) |</pre><hr><pre>commit 9d036883a17969caf8796d1fce813af0ab016986
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:40 2018 -0700

    tools/memory-model: Redefine rb in terms of rcu-fence
    
    This patch reorganizes the definition of rb in the Linux Kernel Memory
    Consistency Model.  The relation is now expressed in terms of
    rcu-fence, which consists of a sequence of gp and rscs links separated
    by rcu-link links, in which the number of occurrences of gp is &gt;= the
    number of occurrences of rscs.
    
    Arguments similar to those published in
    http://diy.inria.fr/linux/long.pdf show that rcu-fence behaves like an
    inter-CPU strong fence.  Furthermore, the definition of rb in terms of
    rcu-fence is highly analogous to the definition of pb in terms of
    strong-fence, which can help explain why rcu-path expresses a form of
    temporal ordering.
    
    This change should not affect the semantics of the memory model, just
    its internal organization.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Reviewed-by: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Reviewed-by: Andrea Parri &lt;parri.andrea@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: akiyks@gmail.com
    Cc: dhowells@redhat.com
    Cc: j.alglave@ucl.ac.uk
    Cc: linux-arch@vger.kernel.org
    Cc: luc.maranget@inria.fr
    Cc: npiggin@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-2-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/Documentation/explanation.txt b/tools/memory-model/Documentation/explanation.txt
index 1a387d703212..1b09f3175a1f 100644
--- a/tools/memory-model/Documentation/explanation.txt
+++ b/tools/memory-model/Documentation/explanation.txt
@@ -27,7 +27,7 @@ Explanation of the Linux-Kernel Memory Consistency Model
   19. AND THEN THERE WAS ALPHA
   20. THE HAPPENS-BEFORE RELATION: hb
   21. THE PROPAGATES-BEFORE RELATION: pb
-  22. RCU RELATIONS: rcu-link, gp-link, rscs-link, and rb
+  22. RCU RELATIONS: rcu-link, gp, rscs, rcu-fence, and rb
   23. ODDS AND ENDS
 
 
@@ -1451,8 +1451,8 @@ they execute means that it cannot have cycles.  This requirement is
 the content of the LKMM's "propagation" axiom.
 
 
-RCU RELATIONS: rcu-link, gp-link, rscs-link, and rb
----------------------------------------------------
+RCU RELATIONS: rcu-link, gp, rscs, rcu-fence, and rb
+----------------------------------------------------
 
 RCU (Read-Copy-Update) is a powerful synchronization mechanism.  It
 rests on two concepts: grace periods and read-side critical sections.
@@ -1537,49 +1537,100 @@ relation, and the details don't matter unless you want to comb through
 a somewhat lengthy formal proof.  Pretty much all you need to know
 about rcu-link is the information in the preceding paragraph.
 
-The LKMM goes on to define the gp-link and rscs-link relations.  They
-bring grace periods and read-side critical sections into the picture,
-in the following way:
+The LKMM also defines the gp and rscs relations.  They bring grace
+periods and read-side critical sections into the picture, in the
+following way:
 
-	E -&gt;gp-link F means there is a synchronize_rcu() fence event S
-	and an event X such that E -&gt;po S, either S -&gt;po X or S = X,
-	and X -&gt;rcu-link F.  In other words, E and F are linked by a
-	grace period followed by an instance of rcu-link.
+	E -&gt;gp F means there is a synchronize_rcu() fence event S such
+	that E -&gt;po S and either S -&gt;po F or S = F.  In simple terms,
+	there is a grace period po-between E and F.
 
-	E -&gt;rscs-link F means there is a critical section delimited by
-	an rcu_read_lock() fence L and an rcu_read_unlock() fence U,
-	and an event X such that E -&gt;po U, either L -&gt;po X or L = X,
-	and X -&gt;rcu-link F.  Roughly speaking, this says that some
-	event in the same critical section as E is linked by rcu-link
-	to F.
+	E -&gt;rscs F means there is a critical section delimited by an
+	rcu_read_lock() fence L and an rcu_read_unlock() fence U, such
+	that E -&gt;po U and either L -&gt;po F or L = F.  You can think of
+	this as saying that E and F are in the same critical section
+	(in fact, it also allows E to be po-before the start of the
+	critical section and F to be po-after the end).
 
 If we think of the rcu-link relation as standing for an extended
-"before", then E -&gt;gp-link F says that E executes before a grace
-period which ends before F executes.  (In fact it covers more than
-this, because it also includes cases where E executes before a grace
-period and some store propagates to F's CPU before F executes and
-doesn't propagate to some other CPU until after the grace period
-ends.)  Similarly, E -&gt;rscs-link F says that E is part of (or before
-the start of) a critical section which starts before F executes.
+"before", then X -&gt;gp Y -&gt;rcu-link Z says that X executes before a
+grace period which ends before Z executes.  (In fact it covers more
+than this, because it also includes cases where X executes before a
+grace period and some store propagates to Z's CPU before Z executes
+but doesn't propagate to some other CPU until after the grace period
+ends.)  Similarly, X -&gt;rscs Y -&gt;rcu-link Z says that X is part of (or
+before the start of) a critical section which starts before Z
+executes.
+
+The LKMM goes on to define the rcu-fence relation as a sequence of gp
+and rscs links separated by rcu-link links, in which the number of gp
+links is &gt;= the number of rscs links.  For example:
+
+	X -&gt;gp Y -&gt;rcu-link Z -&gt;rscs T -&gt;rcu-link U -&gt;gp V
+
+would imply that X -&gt;rcu-fence V, because this sequence contains two
+gp links and only one rscs link.  (It also implies that X -&gt;rcu-fence T
+and Z -&gt;rcu-fence V.)  On the other hand:
+
+	X -&gt;rscs Y -&gt;rcu-link Z -&gt;rscs T -&gt;rcu-link U -&gt;gp V
+
+does not imply X -&gt;rcu-fence V, because the sequence contains only
+one gp link but two rscs links.
+
+The rcu-fence relation is important because the Grace Period Guarantee
+means that rcu-fence acts kind of like a strong fence.  In particular,
+if W is a write and we have W -&gt;rcu-fence Z, the Guarantee says that W
+will propagate to every CPU before Z executes.
+
+To prove this in full generality requires some intellectual effort.
+We'll consider just a very simple case:
+
+	W -&gt;gp X -&gt;rcu-link Y -&gt;rscs Z.
+
+This formula means that there is a grace period G and a critical
+section C such that:
+
+	1. W is po-before G;
+
+	2. X is equal to or po-after G;
+
+	3. X comes "before" Y in some sense;
+
+	4. Y is po-before the end of C;
+
+	5. Z is equal to or po-after the start of C.
+
+From 2 - 4 we deduce that the grace period G ends before the critical
+section C.  Then the second part of the Grace Period Guarantee says
+not only that G starts before C does, but also that W (which executes
+on G's CPU before G starts) must propagate to every CPU before C
+starts.  In particular, W propagates to every CPU before Z executes
+(or finishes executing, in the case where Z is equal to the
+rcu_read_lock() fence event which starts C.)  This sort of reasoning
+can be expanded to handle all the situations covered by rcu-fence.
+
+Finally, the LKMM defines the RCU-before (rb) relation in terms of
+rcu-fence.  This is done in essentially the same way as the pb
+relation was defined in terms of strong-fence.  We will omit the
+details; the end result is that E -&gt;rb F implies E must execute before
+F, just as E -&gt;pb F does (and for much the same reasons).
 
 Putting this all together, the LKMM expresses the Grace Period
-Guarantee by requiring that there are no cycles consisting of gp-link
-and rscs-link links in which the number of gp-link instances is &gt;= the
-number of rscs-link instances.  It does this by defining the rb
-relation to link events E and F whenever it is possible to pass from E
-to F by a sequence of gp-link and rscs-link links with at least as
-many of the former as the latter.  The LKMM's "rcu" axiom then says
-that there are no events E with E -&gt;rb E.
-
-Justifying this axiom takes some intellectual effort, but it is in
-fact a valid formalization of the Grace Period Guarantee.  We won't
-attempt to go through the detailed argument, but the following
-analysis gives a taste of what is involved.  Suppose we have a
-violation of the first part of the Guarantee: A critical section
-starts before a grace period, and some store propagates to the
-critical section's CPU before the end of the critical section but
-doesn't propagate to some other CPU until after the end of the grace
-period.
+Guarantee by requiring that the rb relation does not contain a cycle.
+Equivalently, this "rcu" axiom requires that there are no events E and
+F with E -&gt;rcu-link F -&gt;rcu-fence E.  Or to put it a third way, the
+axiom requires that there are no cycles consisting of gp and rscs
+alternating with rcu-link, where the number of gp links is &gt;= the
+number of rscs links.
+
+Justifying the axiom isn't easy, but it is in fact a valid
+formalization of the Grace Period Guarantee.  We won't attempt to go
+through the detailed argument, but the following analysis gives a
+taste of what is involved.  Suppose we have a violation of the first
+part of the Guarantee: A critical section starts before a grace
+period, and some store propagates to the critical section's CPU before
+the end of the critical section but doesn't propagate to some other
+CPU until after the end of the grace period.
 
 Putting symbols to these ideas, let L and U be the rcu_read_lock() and
 rcu_read_unlock() fence events delimiting the critical section in
@@ -1606,11 +1657,14 @@ by rcu-link, yielding:
 
 	S -&gt;po X -&gt;rcu-link Z -&gt;po U.
 
-The formulas say that S is po-between F and X, hence F -&gt;gp-link Z
-via X.  They also say that Z comes before the end of the critical
-section and E comes after its start, hence Z -&gt;rscs-link F via E.  But
-now we have a forbidden cycle: F -&gt;gp-link Z -&gt;rscs-link F.  Thus the
-"rcu" axiom rules out this violation of the Grace Period Guarantee.
+The formulas say that S is po-between F and X, hence F -&gt;gp X.  They
+also say that Z comes before the end of the critical section and E
+comes after its start, hence Z -&gt;rscs E.  From all this we obtain:
+
+	F -&gt;gp X -&gt;rcu-link Z -&gt;rscs E -&gt;rcu-link F,
+
+a forbidden cycle.  Thus the "rcu" axiom rules out this violation of
+the Grace Period Guarantee.
 
 For something a little more down-to-earth, let's see how the axiom
 works out in practice.  Consider the RCU code example from above, this
@@ -1639,15 +1693,15 @@ time with statement labels added to the memory access instructions:
 If r2 = 0 at the end then P0's store at X overwrites the value that
 P1's load at Z reads from, so we have Z -&gt;fre X and thus Z -&gt;rcu-link X.
 In addition, there is a synchronize_rcu() between Y and Z, so therefore
-we have Y -&gt;gp-link X.
+we have Y -&gt;gp Z.
 
 If r1 = 1 at the end then P1's load at Y reads from P0's store at W,
 so we have W -&gt;rcu-link Y.  In addition, W and X are in the same critical
-section, so therefore we have X -&gt;rscs-link Y.
+section, so therefore we have X -&gt;rscs W.
 
-This gives us a cycle, Y -&gt;gp-link X -&gt;rscs-link Y, with one gp-link
-and one rscs-link, violating the "rcu" axiom.  Hence the outcome is
-not allowed by the LKMM, as we would expect.
+Then X -&gt;rscs W -&gt;rcu-link Y -&gt;gp Z -&gt;rcu-link X is a forbidden cycle,
+violating the "rcu" axiom.  Hence the outcome is not allowed by the
+LKMM, as we would expect.
 
 For contrast, let's see what can happen in a more complicated example:
 
@@ -1683,15 +1737,11 @@ For contrast, let's see what can happen in a more complicated example:
 	}
 
 If r0 = r1 = r2 = 1 at the end, then similar reasoning to before shows
-that W -&gt;rscs-link Y via X, Y -&gt;gp-link U via Z, and U -&gt;rscs-link W
-via V.  And just as before, this gives a cycle:
-
-	W -&gt;rscs-link Y -&gt;gp-link U -&gt;rscs-link W.
-
-However, this cycle has fewer gp-link instances than rscs-link
-instances, and consequently the outcome is not forbidden by the LKMM.
-The following instruction timing diagram shows how it might actually
-occur:
+that W -&gt;rscs X -&gt;rcu-link Y -&gt;gp Z -&gt;rcu-link U -&gt;rscs V -&gt;rcu-link W.
+However this cycle is not forbidden, because the sequence of relations
+contains fewer instances of gp (one) than of rscs (two).  Consequently
+the outcome is allowed by the LKMM.  The following instruction timing
+diagram shows how it might actually occur:
 
 P0			P1			P2
 --------------------	--------------------	--------------------
diff --git a/tools/memory-model/linux-kernel.cat b/tools/memory-model/linux-kernel.cat
index cdf682859d4e..1e5c4653dd12 100644
--- a/tools/memory-model/linux-kernel.cat
+++ b/tools/memory-model/linux-kernel.cat
@@ -102,20 +102,27 @@ let rscs = po ; crit^-1 ; po?
  *)
 let rcu-link = hb* ; pb* ; prop
 
-(* Chains that affect the RCU grace-period guarantee *)
-let gp-link = gp ; rcu-link
-let rscs-link = rscs ; rcu-link
-
 (*
- * A cycle containing at least as many grace periods as RCU read-side
- * critical sections is forbidden.
+ * Any sequence containing at least as many grace periods as RCU read-side
+ * critical sections (joined by rcu-link) acts as a generalized strong fence.
  *)
-let rec rb =
-	gp-link |
-	(gp-link ; rscs-link) |
-	(rscs-link ; gp-link) |
-	(rb ; rb) |
-	(gp-link ; rb ; rscs-link) |
-	(rscs-link ; rb ; gp-link)
+let rec rcu-fence = gp |
+	(gp ; rcu-link ; rscs) |
+	(rscs ; rcu-link ; gp) |
+	(gp ; rcu-link ; rcu-fence ; rcu-link ; rscs) |
+	(rscs ; rcu-link ; rcu-fence ; rcu-link ; gp) |
+	(rcu-fence ; rcu-link ; rcu-fence)
+
+(* rb orders instructions just as pb does *)
+let rb = prop ; rcu-fence ; hb* ; pb*
 
 irreflexive rb as rcu
+
+(*
+ * The happens-before, propagation, and rcu constraints are all
+ * expressions of temporal ordering.  They could be replaced by
+ * a single constraint on an "executes-before" relation, xb:
+ *
+ * let xb = hb | pb | rb
+ * acyclic xb as executes-before
+ *)</pre>
    <div class="pagination">
        <a href='2_16.html'>&lt;&lt;Prev</a><a href='2.html'>1</a><a href='2_2.html'>2</a><a href='2_3.html'>3</a><a href='2_4.html'>4</a><a href='2_5.html'>5</a><a href='2_6.html'>6</a><a href='2_7.html'>7</a><a href='2_8.html'>8</a><a href='2_9.html'>9</a><a href='2_10.html'>10</a><a href='2_11.html'>11</a><a href='2_12.html'>12</a><a href='2_13.html'>13</a><a href='2_14.html'>14</a><a href='2_15.html'>15</a><a href='2_16.html'>16</a><span>[17]</span><a href='2_18.html'>18</a><a href='2_19.html'>19</a><a href='2_20.html'>20</a><a href='2_21.html'>21</a><a href='2_22.html'>22</a><a href='2_23.html'>23</a><a href='2_24.html'>24</a><a href='2_25.html'>25</a><a href='2_26.html'>26</a><a href='2_27.html'>27</a><a href='2_28.html'>28</a><a href='2_29.html'>29</a><a href='2_30.html'>30</a><a href='2_31.html'>31</a><a href='2_32.html'>32</a><a href='2_33.html'>33</a><a href='2_34.html'>34</a><a href='2_35.html'>35</a><a href='2_36.html'>36</a><a href='2_37.html'>37</a><a href='2_38.html'>38</a><a href='2_39.html'>39</a><a href='2_40.html'>40</a><a href='2_41.html'>41</a><a href='2_42.html'>42</a><a href='2_43.html'>43</a><a href='2_44.html'>44</a><a href='2_45.html'>45</a><a href='2_46.html'>46</a><a href='2_47.html'>47</a><a href='2_48.html'>48</a><a href='2_49.html'>49</a><a href='2_50.html'>50</a><a href='2_51.html'>51</a><a href='2_52.html'>52</a><a href='2_53.html'>53</a><a href='2_54.html'>54</a><a href='2_55.html'>55</a><a href='2_56.html'>56</a><a href='2_57.html'>57</a><a href='2_58.html'>58</a><a href='2_59.html'>59</a><a href='2_60.html'>60</a><a href='2_61.html'>61</a><a href='2_62.html'>62</a><a href='2_63.html'>63</a><a href='2_64.html'>64</a><a href='2_65.html'>65</a><a href='2_66.html'>66</a><a href='2_67.html'>67</a><a href='2_68.html'>68</a><a href='2_69.html'>69</a><a href='2_70.html'>70</a><a href='2_71.html'>71</a><a href='2_72.html'>72</a><a href='2_73.html'>73</a><a href='2_74.html'>74</a><a href='2_75.html'>75</a><a href='2_76.html'>76</a><a href='2_77.html'>77</a><a href='2_78.html'>78</a><a href='2_79.html'>79</a><a href='2_80.html'>80</a><a href='2_81.html'>81</a><a href='2_82.html'>82</a><a href='2_83.html'>83</a><a href='2_84.html'>84</a><a href='2_85.html'>85</a><a href='2_86.html'>86</a><a href='2_87.html'>87</a><a href='2_88.html'>88</a><a href='2_89.html'>89</a><a href='2_90.html'>90</a><a href='2_91.html'>91</a><a href='2_92.html'>92</a><a href='2_93.html'>93</a><a href='2_94.html'>94</a><a href='2_95.html'>95</a><a href='2_96.html'>96</a><a href='2_97.html'>97</a><a href='2_98.html'>98</a><a href='2_99.html'>99</a><a href='2_100.html'>100</a><a href='2_101.html'>101</a><a href='2_102.html'>102</a><a href='2_103.html'>103</a><a href='2_104.html'>104</a><a href='2_105.html'>105</a><a href='2_106.html'>106</a><a href='2_107.html'>107</a><a href='2_108.html'>108</a><a href='2_109.html'>109</a><a href='2_110.html'>110</a><a href='2_111.html'>111</a><a href='2_112.html'>112</a><a href='2_113.html'>113</a><a href='2_114.html'>114</a><a href='2_115.html'>115</a><a href='2_116.html'>116</a><a href='2_117.html'>117</a><a href='2_118.html'>118</a><a href='2_119.html'>119</a><a href='2_120.html'>120</a><a href='2_121.html'>121</a><a href='2_122.html'>122</a><a href='2_123.html'>123</a><a href='2_124.html'>124</a><a href='2_125.html'>125</a><a href='2_126.html'>126</a><a href='2_127.html'>127</a><a href='2_128.html'>128</a><a href='2_129.html'>129</a><a href='2_130.html'>130</a><a href='2_131.html'>131</a><a href='2_132.html'>132</a><a href='2_133.html'>133</a><a href='2_134.html'>134</a><a href='2_135.html'>135</a><a href='2_136.html'>136</a><a href='2_137.html'>137</a><a href='2_138.html'>138</a><a href='2_139.html'>139</a><a href='2_140.html'>140</a><a href='2_18.html'>Next&gt;&gt;</a>
    <div>
</body>
