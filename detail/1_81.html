<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_80.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><span>[81]</span><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_82.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit 58590b06d79f7ce5ab64ff3b6d537180fa50dc84
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Oct 27 21:23:12 2010 -0400

    ext4: fix EOFBLOCKS_FL handling
    
    It turns out we have several problems with how EOFBLOCKS_FL is
    handled.  First of all, there was a fencepost error where we were not
    clearing the EOFBLOCKS_FL when fill in the last uninitialized block,
    but rather when we allocate the next block _after_ the uninitalized
    block.  Secondly we were not testing to see if we needed to clear the
    EOFBLOCKS_FL when writing to the file O_DIRECT or when were converting
    an uninitialized block (which is the most common case).
    
    Google-Bug-Id: 2928259
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c
index 06328d3e5717..820278410220 100644
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@ -3180,6 +3180,57 @@ static void unmap_underlying_metadata_blocks(struct block_device *bdev,
                 unmap_underlying_metadata(bdev, block + i);
 }
 
+/*
+ * Handle EOFBLOCKS_FL flag, clearing it if necessary
+ */
+static int check_eofblocks_fl(handle_t *handle, struct inode *inode,
+			      struct ext4_map_blocks *map,
+			      struct ext4_ext_path *path,
+			      unsigned int len)
+{
+	int i, depth;
+	struct ext4_extent_header *eh;
+	struct ext4_extent *ex, *last_ex;
+
+	if (!ext4_test_inode_flag(inode, EXT4_INODE_EOFBLOCKS))
+		return 0;
+
+	depth = ext_depth(inode);
+	eh = path[depth].p_hdr;
+	ex = path[depth].p_ext;
+
+	if (unlikely(!eh-&gt;eh_entries)) {
+		EXT4_ERROR_INODE(inode, "eh-&gt;eh_entries == 0 and "
+				 "EOFBLOCKS_FL set");
+		return -EIO;
+	}
+	last_ex = EXT_LAST_EXTENT(eh);
+	/*
+	 * We should clear the EOFBLOCKS_FL flag if we are writing the
+	 * last block in the last extent in the file.  We test this by
+	 * first checking to see if the caller to
+	 * ext4_ext_get_blocks() was interested in the last block (or
+	 * a block beyond the last block) in the current extent.  If
+	 * this turns out to be false, we can bail out from this
+	 * function immediately.
+	 */
+	if (map-&gt;m_lblk + len &lt; le32_to_cpu(last_ex-&gt;ee_block) +
+	    ext4_ext_get_actual_len(last_ex))
+		return 0;
+	/*
+	 * If the caller does appear to be planning to write at or
+	 * beyond the end of the current extent, we then test to see
+	 * if the current extent is the last extent in the file, by
+	 * checking to make sure it was reached via the rightmost node
+	 * at each level of the tree.
+	 */
+	for (i = depth-1; i &gt;= 0; i--)
+		if (path[i].p_idx != EXT_LAST_INDEX(path[i].p_hdr))
+			return 0;
+	ext4_clear_inode_flag(inode, EXT4_INODE_EOFBLOCKS);
+	return ext4_mark_inode_dirty(handle, inode);
+}
+
 static int
 ext4_ext_handle_uninitialized_extents(handle_t *handle, struct inode *inode,
 			struct ext4_map_blocks *map,
@@ -3217,8 +3268,12 @@ ext4_ext_handle_uninitialized_extents(handle_t *handle, struct inode *inode,
 	if ((flags &amp; EXT4_GET_BLOCKS_CONVERT)) {
 		ret = ext4_convert_unwritten_extents_endio(handle, inode,
 							path);
-		if (ret &gt;= 0)
+		if (ret &gt;= 0) {
 			ext4_update_inode_fsync_trans(handle, inode, 1);
+			err = check_eofblocks_fl(handle, inode, map, path,
+						 map-&gt;m_len);
+		} else
+			err = ret;
 		goto out2;
 	}
 	/* buffered IO case */
@@ -3244,8 +3299,13 @@ ext4_ext_handle_uninitialized_extents(handle_t *handle, struct inode *inode,
 
 	/* buffered write, writepage time, convert*/
 	ret = ext4_ext_convert_to_initialized(handle, inode, map, path);
-	if (ret &gt;= 0)
+	if (ret &gt;= 0) {
 		ext4_update_inode_fsync_trans(handle, inode, 1);
+		err = check_eofblocks_fl(handle, inode, map, path, map-&gt;m_len);
+		if (err &lt; 0)
+			goto out2;
+	}
+
 out:
 	if (ret &lt;= 0) {
 		err = ret;
@@ -3292,6 +3352,7 @@ ext4_ext_handle_uninitialized_extents(handle_t *handle, struct inode *inode,
 	}
 	return err ? err : allocated;
 }
+
 /*
  * Block allocation/map/preallocation routine for extents based files
  *
@@ -3315,9 +3376,9 @@ int ext4_ext_map_blocks(handle_t *handle, struct inode *inode,
 {
 	struct ext4_ext_path *path = NULL;
 	struct ext4_extent_header *eh;
-	struct ext4_extent newex, *ex, *last_ex;
+	struct ext4_extent newex, *ex;
 	ext4_fsblk_t newblock;
-	int i, err = 0, depth, ret, cache_type;
+	int err = 0, depth, ret, cache_type;
 	unsigned int allocated = 0;
 	struct ext4_allocation_request ar;
 	ext4_io_end_t *io = EXT4_I(inode)-&gt;cur_aio_dio;
@@ -3497,31 +3558,10 @@ int ext4_ext_map_blocks(handle_t *handle, struct inode *inode,
 			map-&gt;m_flags |= EXT4_MAP_UNINIT;
 	}
 
-	if (unlikely(ext4_test_inode_flag(inode, EXT4_INODE_EOFBLOCKS))) {
-		if (unlikely(!eh-&gt;eh_entries)) {
-			EXT4_ERROR_INODE(inode,
-					 "eh-&gt;eh_entries == 0 and "
-					 "EOFBLOCKS_FL set");
-			err = -EIO;
-			goto out2;
-		}
-		last_ex = EXT_LAST_EXTENT(eh);
-		/*
-		 * If the current leaf block was reached by looking at
-		 * the last index block all the way down the tree, and
-		 * we are extending the inode beyond the last extent
-		 * in the current leaf block, then clear the
-		 * EOFBLOCKS_FL flag.
-		 */
-		for (i = depth-1; i &gt;= 0; i--) {
-			if (path[i].p_idx != EXT_LAST_INDEX(path[i].p_hdr))
-				break;
-		}
-		if ((i &lt; 0) &amp;&amp;
-		    (map-&gt;m_lblk + ar.len &gt; le32_to_cpu(last_ex-&gt;ee_block) +
-		     ext4_ext_get_actual_len(last_ex)))
-			ext4_clear_inode_flag(inode, EXT4_INODE_EOFBLOCKS);
-	}
+	err = check_eofblocks_fl(handle, inode, map, path, ar.len);
+	if (err)
+		goto out2;
+
 	err = ext4_ext_insert_extent(handle, inode, path, &amp;newex, flags);
 	if (err) {
 		/* free data blocks we just allocated */</pre><hr><pre>commit 6d0bf00512b3b1b5d09d9a44919983eec1cc6fd0
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Aug 9 17:28:38 2010 -0400

    ext4: clean up compiler warning in start_this_handle()
    
    Fix the compiler warning:
    
      fs/jbd2/transaction.c: In function ‘start_this_handle’:
      fs/jbd2/transaction.c:98: warning: unused variable ‘ts’
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index d95cc9d0401d..f3479d6e0a83 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -81,6 +81,32 @@ jbd2_get_transaction(journal_t *journal, transaction_t *transaction)
  * of that one update.
  */
 
+/*
+ * Update transiaction's maximum wait time, if debugging is enabled.
+ *
+ * In order for t_max_wait to be reliable, it must be protected by a
+ * lock.  But doing so will mean that start_this_handle() can not be
+ * run in parallel on SMP systems, which limits our scalability.  So
+ * unless debugging is enabled, we no longer update t_max_wait, which
+ * means that maximum wait time reported by the jbd2_run_stats
+ * tracepoint will always be zero.
+ */
+static inline void update_t_max_wait(transaction_t *transaction)
+{
+#ifdef CONFIG_JBD2_DEBUG
+	unsigned long ts = jiffies;
+
+	if (jbd2_journal_enable_debug &amp;&amp;
+	    time_after(transaction-&gt;t_start, ts)) {
+		ts = jbd2_time_diff(ts, transaction-&gt;t_start);
+		spin_lock(&amp;transaction-&gt;t_handle_lock);
+		if (ts &gt; transaction-&gt;t_max_wait)
+			transaction-&gt;t_max_wait = ts;
+		spin_unlock(&amp;transaction-&gt;t_handle_lock);
+	}
+#endif
+}
+
 /*
  * start_this_handle: Given a handle, deal with any locking or stalling
  * needed to make sure that there is enough journal space for the handle
@@ -95,7 +121,6 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 	int needed;
 	int nblocks = handle-&gt;h_buffer_credits;
 	transaction_t *new_transaction = NULL;
-	unsigned long ts = jiffies;
 
 	if (nblocks &gt; journal-&gt;j_max_transaction_buffers) {
 		printk(KERN_ERR "JBD: %s wants too many credits (%d &gt; %d)\n",
@@ -241,25 +266,8 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 
 	/* OK, account for the buffers that this operation expects to
 	 * use and add the handle to the running transaction. 
-	 *
-	 * In order for t_max_wait to be reliable, it must be
-	 * protected by a lock.  But doing so will mean that
-	 * start_this_handle() can not be run in parallel on SMP
-	 * systems, which limits our scalability.  So we only enable
-	 * it when debugging is enabled.  We may want to use a
-	 * separate flag, eventually, so we can enable this
-	 * independently of debugging.
 	 */
-#ifdef CONFIG_JBD2_DEBUG
-	if (jbd2_journal_enable_debug &amp;&amp;
-	    time_after(transaction-&gt;t_start, ts)) {
-		ts = jbd2_time_diff(ts, transaction-&gt;t_start);
-		spin_lock(&amp;transaction-&gt;t_handle_lock);
-		if (ts &gt; transaction-&gt;t_max_wait)
-			transaction-&gt;t_max_wait = ts;
-		spin_unlock(&amp;transaction-&gt;t_handle_lock);
-	}
-#endif
+	update_t_max_wait(transaction);
 	handle-&gt;h_transaction = transaction;
 	atomic_inc(&amp;transaction-&gt;t_updates);
 	atomic_inc(&amp;transaction-&gt;t_handle_count);</pre><hr><pre>commit 8dd420466c7bfc459fa04680bd5690bfc41a4553
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Aug 3 21:38:29 2010 -0400

    jbd2: Remove t_handle_lock from start_this_handle()
    
    This should remove the last exclusive lock from start_this_handle(),
    so that we should now be able to start multiple transactions at the
    same time on large SMP systems.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/jbd2/commit.c b/fs/jbd2/commit.c
index 67bb0a2f35e5..f52e5e8049f1 100644
--- a/fs/jbd2/commit.c
+++ b/fs/jbd2/commit.c
@@ -1004,7 +1004,8 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	 * File the transaction statistics
 	 */
 	stats.ts_tid = commit_transaction-&gt;t_tid;
-	stats.run.rs_handle_count = commit_transaction-&gt;t_handle_count;
+	stats.run.rs_handle_count =
+		atomic_read(&amp;commit_transaction-&gt;t_handle_count);
 	trace_jbd2_run_stats(journal-&gt;j_fs_dev-&gt;bd_dev,
 			     commit_transaction-&gt;t_tid, &amp;stats.run);
 
diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index 663065142b42..0752bcda535f 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -57,6 +57,7 @@ jbd2_get_transaction(journal_t *journal, transaction_t *transaction)
 	spin_lock_init(&amp;transaction-&gt;t_handle_lock);
 	atomic_set(&amp;transaction-&gt;t_updates, 0);
 	atomic_set(&amp;transaction-&gt;t_outstanding_credits, 0);
+	atomic_set(&amp;transaction-&gt;t_handle_count, 0);
 	INIT_LIST_HEAD(&amp;transaction-&gt;t_inode_list);
 	INIT_LIST_HEAD(&amp;transaction-&gt;t_private_list);
 
@@ -180,8 +181,8 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 	 * buffers requested by this operation, we need to stall pending a log
 	 * checkpoint to free some more log space.
 	 */
-	spin_lock(&amp;transaction-&gt;t_handle_lock);
-	needed = atomic_read(&amp;transaction-&gt;t_outstanding_credits) + nblocks;
+	needed = atomic_add_return(nblocks,
+				   &amp;transaction-&gt;t_outstanding_credits);
 
 	if (needed &gt; journal-&gt;j_max_transaction_buffers) {
 		/*
@@ -192,7 +193,7 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 		DEFINE_WAIT(wait);
 
 		jbd_debug(2, "Handle %p starting new commit...\n", handle);
-		spin_unlock(&amp;transaction-&gt;t_handle_lock);
+		atomic_sub(nblocks, &amp;transaction-&gt;t_outstanding_credits);
 		prepare_to_wait(&amp;journal-&gt;j_wait_transaction_locked, &amp;wait,
 				TASK_UNINTERRUPTIBLE);
 		__jbd2_log_start_commit(journal, transaction-&gt;t_tid);
@@ -229,7 +230,7 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 	 */
 	if (__jbd2_log_space_left(journal) &lt; jbd_space_needed(journal)) {
 		jbd_debug(2, "Handle %p waiting for checkpoint...\n", handle);
-		spin_unlock(&amp;transaction-&gt;t_handle_lock);
+		atomic_sub(nblocks, &amp;transaction-&gt;t_outstanding_credits);
 		read_unlock(&amp;journal-&gt;j_state_lock);
 		write_lock(&amp;journal-&gt;j_state_lock);
 		if (__jbd2_log_space_left(journal) &lt; jbd_space_needed(journal))
@@ -239,23 +240,33 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 	}
 
 	/* OK, account for the buffers that this operation expects to
-	 * use and add the handle to the running transaction. */
-
-	if (time_after(transaction-&gt;t_start, ts)) {
+	 * use and add the handle to the running transaction. 
+	 *
+	 * In order for t_max_wait to be reliable, it must be
+	 * protected by a lock.  But doing so will mean that
+	 * start_this_handle() can not be run in parallel on SMP
+	 * systems, which limits our scalability.  So we only enable
+	 * it when debugging is enabled.  We may want to use a
+	 * separate flag, eventually, so we can enable this
+	 * independently of debugging.
+	 */
+#ifdef CONFIG_JBD2_DEBUG
+	if (jbd2_journal_enable_debug &amp;&amp;
+	    time_after(transaction-&gt;t_start, ts)) {
 		ts = jbd2_time_diff(ts, transaction-&gt;t_start);
+		spin_lock(&amp;transaction-&gt;t_handle_lock);
 		if (ts &gt; transaction-&gt;t_max_wait)
 			transaction-&gt;t_max_wait = ts;
+		spin_unlock(&amp;transaction-&gt;t_handle_lock);
 	}
-
+#endif
 	handle-&gt;h_transaction = transaction;
-	atomic_add(nblocks, &amp;transaction-&gt;t_outstanding_credits);
 	atomic_inc(&amp;transaction-&gt;t_updates);
-	transaction-&gt;t_handle_count++;
+	atomic_inc(&amp;transaction-&gt;t_handle_count);
 	jbd_debug(4, "Handle %p given %d credits (total %d, free %d)\n",
 		  handle, nblocks,
 		  atomic_read(&amp;transaction-&gt;t_outstanding_credits),
 		  __jbd2_log_space_left(journal));
-	spin_unlock(&amp;transaction-&gt;t_handle_lock);
 	read_unlock(&amp;journal-&gt;j_state_lock);
 
 	lock_map_acquire(&amp;handle-&gt;h_lockdep_map);
diff --git a/include/linux/jbd2.h b/include/linux/jbd2.h
index 15d5743ccfbb..01743b5446ff 100644
--- a/include/linux/jbd2.h
+++ b/include/linux/jbd2.h
@@ -629,7 +629,7 @@ struct transaction_s
 	/*
 	 * How many handles used this transaction? [t_handle_lock]
 	 */
-	int t_handle_count;
+	atomic_t		t_handle_count;
 
 	/*
 	 * This transaction is being forced and some process is</pre><hr><pre>commit a931da6ac9331a6c80dd91c199105806f2336188
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Aug 3 21:35:12 2010 -0400

    jbd2: Change j_state_lock to be a rwlock_t
    
    Lockstat reports have shown that j_state_lock is a major source of
    lock contention, especially on systems with more than 4 CPU cores.  So
    change it to be a read/write spinlock.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 533b607f9cb5..ab2247d642c6 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -5066,7 +5066,7 @@ struct inode *ext4_iget(struct super_block *sb, unsigned long ino)
 		transaction_t *transaction;
 		tid_t tid;
 
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		read_lock(&amp;journal-&gt;j_state_lock);
 		if (journal-&gt;j_running_transaction)
 			transaction = journal-&gt;j_running_transaction;
 		else
@@ -5075,7 +5075,7 @@ struct inode *ext4_iget(struct super_block *sb, unsigned long ino)
 			tid = transaction-&gt;t_tid;
 		else
 			tid = journal-&gt;j_commit_sequence;
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
 		ei-&gt;i_sync_tid = tid;
 		ei-&gt;i_datasync_tid = tid;
 	}
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 3fd65eb66ccd..81cb3fc1218e 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -3232,7 +3232,7 @@ static void ext4_init_journal_params(struct super_block *sb, journal_t *journal)
 	journal-&gt;j_min_batch_time = sbi-&gt;s_min_batch_time;
 	journal-&gt;j_max_batch_time = sbi-&gt;s_max_batch_time;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	if (test_opt(sb, BARRIER))
 		journal-&gt;j_flags |= JBD2_BARRIER;
 	else
@@ -3241,7 +3241,7 @@ static void ext4_init_journal_params(struct super_block *sb, journal_t *journal)
 		journal-&gt;j_flags |= JBD2_ABORT_ON_SYNCDATA_ERR;
 	else
 		journal-&gt;j_flags &amp;= ~JBD2_ABORT_ON_SYNCDATA_ERR;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 }
 
 static journal_t *ext4_get_journal(struct super_block *sb,
diff --git a/fs/jbd2/checkpoint.c b/fs/jbd2/checkpoint.c
index f8cdc02520f9..1c23a0f4e8a3 100644
--- a/fs/jbd2/checkpoint.c
+++ b/fs/jbd2/checkpoint.c
@@ -118,13 +118,13 @@ static int __try_to_free_cp_buf(struct journal_head *jh)
 void __jbd2_log_wait_for_space(journal_t *journal)
 {
 	int nblocks, space_left;
-	assert_spin_locked(&amp;journal-&gt;j_state_lock);
+	/* assert_spin_locked(&amp;journal-&gt;j_state_lock); */
 
 	nblocks = jbd_space_needed(journal);
 	while (__jbd2_log_space_left(journal) &lt; nblocks) {
 		if (journal-&gt;j_flags &amp; JBD2_ABORT)
 			return;
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		mutex_lock(&amp;journal-&gt;j_checkpoint_mutex);
 
 		/*
@@ -138,7 +138,7 @@ void __jbd2_log_wait_for_space(journal_t *journal)
 		 * filesystem, so abort the journal and leave a stack
 		 * trace for forensic evidence.
 		 */
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		write_lock(&amp;journal-&gt;j_state_lock);
 		spin_lock(&amp;journal-&gt;j_list_lock);
 		nblocks = jbd_space_needed(journal);
 		space_left = __jbd2_log_space_left(journal);
@@ -149,7 +149,7 @@ void __jbd2_log_wait_for_space(journal_t *journal)
 			if (journal-&gt;j_committing_transaction)
 				tid = journal-&gt;j_committing_transaction-&gt;t_tid;
 			spin_unlock(&amp;journal-&gt;j_list_lock);
-			spin_unlock(&amp;journal-&gt;j_state_lock);
+			write_unlock(&amp;journal-&gt;j_state_lock);
 			if (chkpt) {
 				jbd2_log_do_checkpoint(journal);
 			} else if (jbd2_cleanup_journal_tail(journal) == 0) {
@@ -167,7 +167,7 @@ void __jbd2_log_wait_for_space(journal_t *journal)
 				WARN_ON(1);
 				jbd2_journal_abort(journal, 0);
 			}
-			spin_lock(&amp;journal-&gt;j_state_lock);
+			write_lock(&amp;journal-&gt;j_state_lock);
 		} else {
 			spin_unlock(&amp;journal-&gt;j_list_lock);
 		}
@@ -474,7 +474,7 @@ int jbd2_cleanup_journal_tail(journal_t *journal)
 	 * next transaction ID we will write, and where it will
 	 * start. */
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	spin_lock(&amp;journal-&gt;j_list_lock);
 	transaction = journal-&gt;j_checkpoint_transactions;
 	if (transaction) {
@@ -496,7 +496,7 @@ int jbd2_cleanup_journal_tail(journal_t *journal)
 	/* If the oldest pinned transaction is at the tail of the log
            already then there's not much we can do right now. */
 	if (journal-&gt;j_tail_sequence == first_tid) {
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		return 1;
 	}
 
@@ -516,7 +516,7 @@ int jbd2_cleanup_journal_tail(journal_t *journal)
 	journal-&gt;j_free += freed;
 	journal-&gt;j_tail_sequence = first_tid;
 	journal-&gt;j_tail = blocknr;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 
 	/*
 	 * If there is an external journal, we need to make sure that
diff --git a/fs/jbd2/commit.c b/fs/jbd2/commit.c
index fbd2c564e916..67bb0a2f35e5 100644
--- a/fs/jbd2/commit.c
+++ b/fs/jbd2/commit.c
@@ -152,9 +152,9 @@ static int journal_submit_commit_record(journal_t *journal,
 		printk(KERN_WARNING
 		       "JBD2: Disabling barriers on %s, "
 		       "not supported by device\n", journal-&gt;j_devname);
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		write_lock(&amp;journal-&gt;j_state_lock);
 		journal-&gt;j_flags &amp;= ~JBD2_BARRIER;
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 
 		/* And try again, without the barrier */
 		lock_buffer(bh);
@@ -182,9 +182,9 @@ static int journal_wait_on_commit_record(journal_t *journal,
 		printk(KERN_WARNING
 		       "JBD2: %s: disabling barries on %s - not supported "
 		       "by device\n", __func__, journal-&gt;j_devname);
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		write_lock(&amp;journal-&gt;j_state_lock);
 		journal-&gt;j_flags &amp;= ~JBD2_BARRIER;
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 
 		lock_buffer(bh);
 		clear_buffer_dirty(bh);
@@ -400,7 +400,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	jbd_debug(1, "JBD: starting commit of transaction %d\n",
 			commit_transaction-&gt;t_tid);
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	commit_transaction-&gt;t_state = T_LOCKED;
 
 	/*
@@ -424,9 +424,9 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 					TASK_UNINTERRUPTIBLE);
 		if (atomic_read(&amp;commit_transaction-&gt;t_updates)) {
 			spin_unlock(&amp;commit_transaction-&gt;t_handle_lock);
-			spin_unlock(&amp;journal-&gt;j_state_lock);
+			write_unlock(&amp;journal-&gt;j_state_lock);
 			schedule();
-			spin_lock(&amp;journal-&gt;j_state_lock);
+			write_lock(&amp;journal-&gt;j_state_lock);
 			spin_lock(&amp;commit_transaction-&gt;t_handle_lock);
 		}
 		finish_wait(&amp;journal-&gt;j_wait_updates, &amp;wait);
@@ -497,7 +497,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	start_time = ktime_get();
 	commit_transaction-&gt;t_log_start = journal-&gt;j_head;
 	wake_up(&amp;journal-&gt;j_wait_transaction_locked);
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 
 	jbd_debug (3, "JBD: commit phase 2\n");
 
@@ -519,9 +519,9 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	 * transaction!  Now comes the tricky part: we need to write out
 	 * metadata.  Loop over the transaction's entire buffer list:
 	 */
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	commit_transaction-&gt;t_state = T_COMMIT;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 
 	trace_jbd2_commit_logging(journal, commit_transaction);
 	stats.run.rs_logging = jiffies;
@@ -978,7 +978,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	 * __jbd2_journal_drop_transaction(). Otherwise we could race with
 	 * other checkpointing code processing the transaction...
 	 */
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	spin_lock(&amp;journal-&gt;j_list_lock);
 	/*
 	 * Now recheck if some buffers did not get attached to the transaction
@@ -986,7 +986,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	 */
 	if (commit_transaction-&gt;t_forget) {
 		spin_unlock(&amp;journal-&gt;j_list_lock);
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		goto restart_loop;
 	}
 
@@ -1038,7 +1038,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 				journal-&gt;j_average_commit_time*3) / 4;
 	else
 		journal-&gt;j_average_commit_time = commit_time;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 
 	if (commit_transaction-&gt;t_checkpoint_list == NULL &amp;&amp;
 	    commit_transaction-&gt;t_checkpoint_io_list == NULL) {
diff --git a/fs/jbd2/journal.c b/fs/jbd2/journal.c
index a79d3345b55a..e7bf0fd9cec7 100644
--- a/fs/jbd2/journal.c
+++ b/fs/jbd2/journal.c
@@ -142,7 +142,7 @@ static int kjournald2(void *arg)
 	/*
 	 * And now, wait forever for commit wakeup events.
 	 */
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 
 loop:
 	if (journal-&gt;j_flags &amp; JBD2_UNMOUNT)
@@ -153,10 +153,10 @@ static int kjournald2(void *arg)
 
 	if (journal-&gt;j_commit_sequence != journal-&gt;j_commit_request) {
 		jbd_debug(1, "OK, requests differ\n");
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		del_timer_sync(&amp;journal-&gt;j_commit_timer);
 		jbd2_journal_commit_transaction(journal);
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		write_lock(&amp;journal-&gt;j_state_lock);
 		goto loop;
 	}
 
@@ -168,9 +168,9 @@ static int kjournald2(void *arg)
 		 * be already stopped.
 		 */
 		jbd_debug(1, "Now suspending kjournald2\n");
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		refrigerator();
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		write_lock(&amp;journal-&gt;j_state_lock);
 	} else {
 		/*
 		 * We assume on resume that commits are already there,
@@ -190,9 +190,9 @@ static int kjournald2(void *arg)
 		if (journal-&gt;j_flags &amp; JBD2_UNMOUNT)
 			should_sleep = 0;
 		if (should_sleep) {
-			spin_unlock(&amp;journal-&gt;j_state_lock);
+			write_unlock(&amp;journal-&gt;j_state_lock);
 			schedule();
-			spin_lock(&amp;journal-&gt;j_state_lock);
+			write_lock(&amp;journal-&gt;j_state_lock);
 		}
 		finish_wait(&amp;journal-&gt;j_wait_commit, &amp;wait);
 	}
@@ -210,7 +210,7 @@ static int kjournald2(void *arg)
 	goto loop;
 
 end_loop:
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 	del_timer_sync(&amp;journal-&gt;j_commit_timer);
 	journal-&gt;j_task = NULL;
 	wake_up(&amp;journal-&gt;j_wait_done_commit);
@@ -233,16 +233,16 @@ static int jbd2_journal_start_thread(journal_t *journal)
 
 static void journal_kill_thread(journal_t *journal)
 {
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	journal-&gt;j_flags |= JBD2_UNMOUNT;
 
 	while (journal-&gt;j_task) {
 		wake_up(&amp;journal-&gt;j_wait_commit);
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		wait_event(journal-&gt;j_wait_done_commit, journal-&gt;j_task == NULL);
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		write_lock(&amp;journal-&gt;j_state_lock);
 	}
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 }
 
 /*
@@ -452,7 +452,7 @@ int __jbd2_log_space_left(journal_t *journal)
 {
 	int left = journal-&gt;j_free;
 
-	assert_spin_locked(&amp;journal-&gt;j_state_lock);
+	/* assert_spin_locked(&amp;journal-&gt;j_state_lock); */
 
 	/*
 	 * Be pessimistic here about the number of those free blocks which
@@ -497,9 +497,9 @@ int jbd2_log_start_commit(journal_t *journal, tid_t tid)
 {
 	int ret;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	ret = __jbd2_log_start_commit(journal, tid);
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 	return ret;
 }
 
@@ -518,7 +518,7 @@ int jbd2_journal_force_commit_nested(journal_t *journal)
 	transaction_t *transaction = NULL;
 	tid_t tid;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	read_lock(&amp;journal-&gt;j_state_lock);
 	if (journal-&gt;j_running_transaction &amp;&amp; !current-&gt;journal_info) {
 		transaction = journal-&gt;j_running_transaction;
 		__jbd2_log_start_commit(journal, transaction-&gt;t_tid);
@@ -526,12 +526,12 @@ int jbd2_journal_force_commit_nested(journal_t *journal)
 		transaction = journal-&gt;j_committing_transaction;
 
 	if (!transaction) {
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
 		return 0;	/* Nothing to retry */
 	}
 
 	tid = transaction-&gt;t_tid;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	read_unlock(&amp;journal-&gt;j_state_lock);
 	jbd2_log_wait_commit(journal, tid);
 	return 1;
 }
@@ -545,7 +545,7 @@ int jbd2_journal_start_commit(journal_t *journal, tid_t *ptid)
 {
 	int ret = 0;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	if (journal-&gt;j_running_transaction) {
 		tid_t tid = journal-&gt;j_running_transaction-&gt;t_tid;
 
@@ -564,7 +564,7 @@ int jbd2_journal_start_commit(journal_t *journal, tid_t *ptid)
 			*ptid = journal-&gt;j_committing_transaction-&gt;t_tid;
 		ret = 1;
 	}
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 	return ret;
 }
 
@@ -576,26 +576,24 @@ int jbd2_log_wait_commit(journal_t *journal, tid_t tid)
 {
 	int err = 0;
 
+	read_lock(&amp;journal-&gt;j_state_lock);
 #ifdef CONFIG_JBD2_DEBUG
-	spin_lock(&amp;journal-&gt;j_state_lock);
 	if (!tid_geq(journal-&gt;j_commit_request, tid)) {
 		printk(KERN_EMERG
 		       "%s: error: j_commit_request=%d, tid=%d\n",
 		       __func__, journal-&gt;j_commit_request, tid);
 	}
-	spin_unlock(&amp;journal-&gt;j_state_lock);
 #endif
-	spin_lock(&amp;journal-&gt;j_state_lock);
 	while (tid_gt(tid, journal-&gt;j_commit_sequence)) {
 		jbd_debug(1, "JBD: want %d, j_commit_sequence=%d\n",
 				  tid, journal-&gt;j_commit_sequence);
 		wake_up(&amp;journal-&gt;j_wait_commit);
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
 		wait_event(journal-&gt;j_wait_done_commit,
 				!tid_gt(tid, journal-&gt;j_commit_sequence));
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		read_lock(&amp;journal-&gt;j_state_lock);
 	}
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	read_unlock(&amp;journal-&gt;j_state_lock);
 
 	if (unlikely(is_journal_aborted(journal))) {
 		printk(KERN_EMERG "journal commit I/O error\n");
@@ -612,7 +610,7 @@ int jbd2_journal_next_log_block(journal_t *journal, unsigned long long *retp)
 {
 	unsigned long blocknr;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	J_ASSERT(journal-&gt;j_free &gt; 1);
 
 	blocknr = journal-&gt;j_head;
@@ -620,7 +618,7 @@ int jbd2_journal_next_log_block(journal_t *journal, unsigned long long *retp)
 	journal-&gt;j_free--;
 	if (journal-&gt;j_head == journal-&gt;j_last)
 		journal-&gt;j_head = journal-&gt;j_first;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 	return jbd2_journal_bmap(journal, blocknr, retp);
 }
 
@@ -840,7 +838,7 @@ static journal_t * journal_init_common (void)
 	mutex_init(&amp;journal-&gt;j_checkpoint_mutex);
 	spin_lock_init(&amp;journal-&gt;j_revoke_lock);
 	spin_lock_init(&amp;journal-&gt;j_list_lock);
-	spin_lock_init(&amp;journal-&gt;j_state_lock);
+	rwlock_init(&amp;journal-&gt;j_state_lock);
 
 	journal-&gt;j_commit_interval = (HZ * JBD2_DEFAULT_MAX_COMMIT_AGE);
 	journal-&gt;j_min_batch_time = 0;
@@ -1106,14 +1104,14 @@ void jbd2_journal_update_superblock(journal_t *journal, int wait)
 		set_buffer_uptodate(bh);
 	}
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	read_lock(&amp;journal-&gt;j_state_lock);
 	jbd_debug(1,"JBD: updating superblock (start %ld, seq %d, errno %d)\n",
 		  journal-&gt;j_tail, journal-&gt;j_tail_sequence, journal-&gt;j_errno);
 
 	sb-&gt;s_sequence = cpu_to_be32(journal-&gt;j_tail_sequence);
 	sb-&gt;s_start    = cpu_to_be32(journal-&gt;j_tail);
 	sb-&gt;s_errno    = cpu_to_be32(journal-&gt;j_errno);
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	read_unlock(&amp;journal-&gt;j_state_lock);
 
 	BUFFER_TRACE(bh, "marking dirty");
 	mark_buffer_dirty(bh);
@@ -1134,12 +1132,12 @@ void jbd2_journal_update_superblock(journal_t *journal, int wait)
 	 * any future commit will have to be careful to update the
 	 * superblock again to re-record the true start of the log. */
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	if (sb-&gt;s_start)
 		journal-&gt;j_flags &amp;= ~JBD2_FLUSHED;
 	else
 		journal-&gt;j_flags |= JBD2_FLUSHED;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 }
 
 /*
@@ -1551,7 +1549,7 @@ int jbd2_journal_flush(journal_t *journal)
 	transaction_t *transaction = NULL;
 	unsigned long old_tail;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 
 	/* Force everything buffered to the log... */
 	if (journal-&gt;j_running_transaction) {
@@ -1564,10 +1562,10 @@ int jbd2_journal_flush(journal_t *journal)
 	if (transaction) {
 		tid_t tid = transaction-&gt;t_tid;
 
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		jbd2_log_wait_commit(journal, tid);
 	} else {
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 	}
 
 	/* ...and flush everything in the log out to disk. */
@@ -1591,12 +1589,12 @@ int jbd2_journal_flush(journal_t *journal)
 	 * the magic code for a fully-recovered superblock.  Any future
 	 * commits of data to the journal will restore the current
 	 * s_start value. */
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	old_tail = journal-&gt;j_tail;
 	journal-&gt;j_tail = 0;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 	jbd2_journal_update_superblock(journal, 1);
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	journal-&gt;j_tail = old_tail;
 
 	J_ASSERT(!journal-&gt;j_running_transaction);
@@ -1604,7 +1602,7 @@ int jbd2_journal_flush(journal_t *journal)
 	J_ASSERT(!journal-&gt;j_checkpoint_transactions);
 	J_ASSERT(journal-&gt;j_head == journal-&gt;j_tail);
 	J_ASSERT(journal-&gt;j_tail_sequence == journal-&gt;j_transaction_sequence);
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 	return 0;
 }
 
@@ -1668,12 +1666,12 @@ void __jbd2_journal_abort_hard(journal_t *journal)
 	printk(KERN_ERR "Aborting journal on device %s.\n",
 	       journal-&gt;j_devname);
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	journal-&gt;j_flags |= JBD2_ABORT;
 	transaction = journal-&gt;j_running_transaction;
 	if (transaction)
 		__jbd2_log_start_commit(journal, transaction-&gt;t_tid);
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 }
 
 /* Soft abort: record the abort error status in the journal superblock,
@@ -1758,12 +1756,12 @@ int jbd2_journal_errno(journal_t *journal)
 {
 	int err;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	read_lock(&amp;journal-&gt;j_state_lock);
 	if (journal-&gt;j_flags &amp; JBD2_ABORT)
 		err = -EROFS;
 	else
 		err = journal-&gt;j_errno;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	read_unlock(&amp;journal-&gt;j_state_lock);
 	return err;
 }
 
@@ -1778,12 +1776,12 @@ int jbd2_journal_clear_err(journal_t *journal)
 {
 	int err = 0;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	if (journal-&gt;j_flags &amp; JBD2_ABORT)
 		err = -EROFS;
 	else
 		journal-&gt;j_errno = 0;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 	return err;
 }
 
@@ -1796,10 +1794,10 @@ int jbd2_journal_clear_err(journal_t *journal)
  */
 void jbd2_journal_ack_err(journal_t *journal)
 {
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	if (journal-&gt;j_errno)
 		journal-&gt;j_flags |= JBD2_ACK_ERR;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 }
 
 int jbd2_journal_blocks_per_page(struct inode *inode)
diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index 9c64c7ec48d4..663065142b42 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -124,36 +124,38 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 
 	jbd_debug(3, "New handle %p going live.\n", handle);
 
-repeat:
-
 	/*
 	 * We need to hold j_state_lock until t_updates has been incremented,
 	 * for proper journal barrier handling
 	 */
-	spin_lock(&amp;journal-&gt;j_state_lock);
-repeat_locked:
+repeat:
+	read_lock(&amp;journal-&gt;j_state_lock);
 	if (is_journal_aborted(journal) ||
 	    (journal-&gt;j_errno != 0 &amp;&amp; !(journal-&gt;j_flags &amp; JBD2_ACK_ERR))) {
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
 		kfree(new_transaction);
 		return -EROFS;
 	}
 
 	/* Wait on the journal's transaction barrier if necessary */
 	if (journal-&gt;j_barrier_count) {
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
 		wait_event(journal-&gt;j_wait_transaction_locked,
 				journal-&gt;j_barrier_count == 0);
 		goto repeat;
 	}
 
 	if (!journal-&gt;j_running_transaction) {
-		if (!new_transaction) {
-			spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
+		if (!new_transaction)
 			goto alloc_transaction;
+		write_lock(&amp;journal-&gt;j_state_lock);
+		if (!journal-&gt;j_running_transaction) {
+			jbd2_get_transaction(journal, new_transaction);
+			new_transaction = NULL;
 		}
-		jbd2_get_transaction(journal, new_transaction);
-		new_transaction = NULL;
+		write_unlock(&amp;journal-&gt;j_state_lock);
+		goto repeat;
 	}
 
 	transaction = journal-&gt;j_running_transaction;
@@ -167,7 +169,7 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 
 		prepare_to_wait(&amp;journal-&gt;j_wait_transaction_locked,
 					&amp;wait, TASK_UNINTERRUPTIBLE);
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
 		schedule();
 		finish_wait(&amp;journal-&gt;j_wait_transaction_locked, &amp;wait);
 		goto repeat;
@@ -194,7 +196,7 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 		prepare_to_wait(&amp;journal-&gt;j_wait_transaction_locked, &amp;wait,
 				TASK_UNINTERRUPTIBLE);
 		__jbd2_log_start_commit(journal, transaction-&gt;t_tid);
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
 		schedule();
 		finish_wait(&amp;journal-&gt;j_wait_transaction_locked, &amp;wait);
 		goto repeat;
@@ -228,8 +230,12 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 	if (__jbd2_log_space_left(journal) &lt; jbd_space_needed(journal)) {
 		jbd_debug(2, "Handle %p waiting for checkpoint...\n", handle);
 		spin_unlock(&amp;transaction-&gt;t_handle_lock);
-		__jbd2_log_wait_for_space(journal);
-		goto repeat_locked;
+		read_unlock(&amp;journal-&gt;j_state_lock);
+		write_lock(&amp;journal-&gt;j_state_lock);
+		if (__jbd2_log_space_left(journal) &lt; jbd_space_needed(journal))
+			__jbd2_log_wait_for_space(journal);
+		write_unlock(&amp;journal-&gt;j_state_lock);
+		goto repeat;
 	}
 
 	/* OK, account for the buffers that this operation expects to
@@ -250,7 +256,7 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 		  atomic_read(&amp;transaction-&gt;t_outstanding_credits),
 		  __jbd2_log_space_left(journal));
 	spin_unlock(&amp;transaction-&gt;t_handle_lock);
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	read_unlock(&amp;journal-&gt;j_state_lock);
 
 	lock_map_acquire(&amp;handle-&gt;h_lockdep_map);
 	kfree(new_transaction);
@@ -362,7 +368,7 @@ int jbd2_journal_extend(handle_t *handle, int nblocks)
 
 	result = 1;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	read_lock(&amp;journal-&gt;j_state_lock);
 
 	/* Don't extend a locked-down transaction! */
 	if (handle-&gt;h_transaction-&gt;t_state != T_RUNNING) {
@@ -394,7 +400,7 @@ int jbd2_journal_extend(handle_t *handle, int nblocks)
 unlock:
 	spin_unlock(&amp;transaction-&gt;t_handle_lock);
 error_out:
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	read_unlock(&amp;journal-&gt;j_state_lock);
 out:
 	return result;
 }
@@ -432,7 +438,7 @@ int jbd2__journal_restart(handle_t *handle, int nblocks, int gfp_mask)
 	J_ASSERT(atomic_read(&amp;transaction-&gt;t_updates) &gt; 0);
 	J_ASSERT(journal_current_handle() == handle);
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	read_lock(&amp;journal-&gt;j_state_lock);
 	spin_lock(&amp;transaction-&gt;t_handle_lock);
 	atomic_sub(handle-&gt;h_buffer_credits,
 		   &amp;transaction-&gt;t_outstanding_credits);
@@ -442,7 +448,7 @@ int jbd2__journal_restart(handle_t *handle, int nblocks, int gfp_mask)
 
 	jbd_debug(2, "restarting handle %p\n", handle);
 	__jbd2_log_start_commit(journal, transaction-&gt;t_tid);
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	read_unlock(&amp;journal-&gt;j_state_lock);
 
 	lock_map_release(&amp;handle-&gt;h_lockdep_map);
 	handle-&gt;h_buffer_credits = nblocks;
@@ -472,7 +478,7 @@ void jbd2_journal_lock_updates(journal_t *journal)
 {
 	DEFINE_WAIT(wait);
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	++journal-&gt;j_barrier_count;
 
 	/* Wait until there are no running updates */
@@ -490,12 +496,12 @@ void jbd2_journal_lock_updates(journal_t *journal)
 		prepare_to_wait(&amp;journal-&gt;j_wait_updates, &amp;wait,
 				TASK_UNINTERRUPTIBLE);
 		spin_unlock(&amp;transaction-&gt;t_handle_lock);
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		schedule();
 		finish_wait(&amp;journal-&gt;j_wait_updates, &amp;wait);
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		write_lock(&amp;journal-&gt;j_state_lock);
 	}
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 
 	/*
 	 * We have now established a barrier against other normal updates, but
@@ -519,9 +525,9 @@ void jbd2_journal_unlock_updates (journal_t *journal)
 	J_ASSERT(journal-&gt;j_barrier_count != 0);
 
 	mutex_unlock(&amp;journal-&gt;j_barrier);
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	--journal-&gt;j_barrier_count;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 	wake_up(&amp;journal-&gt;j_wait_transaction_locked);
 }
 
@@ -1314,9 +1320,9 @@ int jbd2_journal_stop(handle_t *handle)
 
 		journal-&gt;j_last_sync_writer = pid;
 
-		spin_lock(&amp;journal-&gt;j_state_lock);
+		read_lock(&amp;journal-&gt;j_state_lock);
 		commit_time = journal-&gt;j_average_commit_time;
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		read_unlock(&amp;journal-&gt;j_state_lock);
 
 		trans_time = ktime_to_ns(ktime_sub(ktime_get(),
 						   transaction-&gt;t_start_time));
@@ -1748,7 +1754,7 @@ static int journal_unmap_buffer(journal_t *journal, struct buffer_head *bh)
 		goto zap_buffer_unlocked;
 
 	/* OK, we have data buffer in journaled mode */
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	jbd_lock_bh_state(bh);
 	spin_lock(&amp;journal-&gt;j_list_lock);
 
@@ -1801,7 +1807,7 @@ static int journal_unmap_buffer(journal_t *journal, struct buffer_head *bh)
 			jbd2_journal_put_journal_head(jh);
 			spin_unlock(&amp;journal-&gt;j_list_lock);
 			jbd_unlock_bh_state(bh);
-			spin_unlock(&amp;journal-&gt;j_state_lock);
+			write_unlock(&amp;journal-&gt;j_state_lock);
 			return ret;
 		} else {
 			/* There is no currently-running transaction. So the
@@ -1815,7 +1821,7 @@ static int journal_unmap_buffer(journal_t *journal, struct buffer_head *bh)
 				jbd2_journal_put_journal_head(jh);
 				spin_unlock(&amp;journal-&gt;j_list_lock);
 				jbd_unlock_bh_state(bh);
-				spin_unlock(&amp;journal-&gt;j_state_lock);
+				write_unlock(&amp;journal-&gt;j_state_lock);
 				return ret;
 			} else {
 				/* The orphan record's transaction has
@@ -1839,7 +1845,7 @@ static int journal_unmap_buffer(journal_t *journal, struct buffer_head *bh)
 		jbd2_journal_put_journal_head(jh);
 		spin_unlock(&amp;journal-&gt;j_list_lock);
 		jbd_unlock_bh_state(bh);
-		spin_unlock(&amp;journal-&gt;j_state_lock);
+		write_unlock(&amp;journal-&gt;j_state_lock);
 		return 0;
 	} else {
 		/* Good, the buffer belongs to the running transaction.
@@ -1858,7 +1864,7 @@ static int journal_unmap_buffer(journal_t *journal, struct buffer_head *bh)
 zap_buffer_no_jh:
 	spin_unlock(&amp;journal-&gt;j_list_lock);
 	jbd_unlock_bh_state(bh);
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 zap_buffer_unlocked:
 	clear_buffer_dirty(bh);
 	J_ASSERT_BH(bh, !buffer_jbddirty(bh));
@@ -2165,9 +2171,9 @@ int jbd2_journal_begin_ordered_truncate(journal_t *journal,
 	/* Locks are here just to force reading of recent values, it is
 	 * enough that the transaction was not committing before we started
 	 * a transaction adding the inode to orphan list */
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	read_lock(&amp;journal-&gt;j_state_lock);
 	commit_trans = journal-&gt;j_committing_transaction;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	read_unlock(&amp;journal-&gt;j_state_lock);
 	spin_lock(&amp;journal-&gt;j_list_lock);
 	inode_trans = jinode-&gt;i_transaction;
 	spin_unlock(&amp;journal-&gt;j_list_lock);
diff --git a/fs/ocfs2/journal.c b/fs/ocfs2/journal.c
index 47878cf16418..9c1b92ebeb94 100644
--- a/fs/ocfs2/journal.c
+++ b/fs/ocfs2/journal.c
@@ -760,13 +760,13 @@ void ocfs2_set_journal_params(struct ocfs2_super *osb)
 	if (osb-&gt;osb_commit_interval)
 		commit_interval = osb-&gt;osb_commit_interval;
 
-	spin_lock(&amp;journal-&gt;j_state_lock);
+	write_lock(&amp;journal-&gt;j_state_lock);
 	journal-&gt;j_commit_interval = commit_interval;
 	if (osb-&gt;s_mount_opt &amp; OCFS2_MOUNT_BARRIER)
 		journal-&gt;j_flags |= JBD2_BARRIER;
 	else
 		journal-&gt;j_flags &amp;= ~JBD2_BARRIER;
-	spin_unlock(&amp;journal-&gt;j_state_lock);
+	write_unlock(&amp;journal-&gt;j_state_lock);
 }
 
 int ocfs2_journal_init(struct ocfs2_journal *journal, int *dirty)
diff --git a/include/linux/jbd2.h b/include/linux/jbd2.h
index a72ce21de0e1..15d5743ccfbb 100644
--- a/include/linux/jbd2.h
+++ b/include/linux/jbd2.h
@@ -764,7 +764,7 @@ struct journal_s
 	/*
 	 * Protect the various scalars in the journal
 	 */
-	spinlock_t		j_state_lock;
+	rwlock_t		j_state_lock;
 
 	/*
 	 * Number of processes waiting to create a barrier lock [j_state_lock]</pre><hr><pre>commit a51dca9cd3bb4ec5a05bfb6feabf024a5c808a37
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Aug 2 08:43:25 2010 -0400

    jbd2: Use atomic variables to avoid taking t_handle_lock in jbd2_journal_stop
    
    By using an atomic_t for t_updates and t_outstanding credits, this
    should allow us to not need to take transaction t_handle_lock in
    jbd2_journal_stop().
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/jbd2/checkpoint.c b/fs/jbd2/checkpoint.c
index 076d1cc44f95..f8cdc02520f9 100644
--- a/fs/jbd2/checkpoint.c
+++ b/fs/jbd2/checkpoint.c
@@ -775,7 +775,7 @@ void __jbd2_journal_drop_transaction(journal_t *journal, transaction_t *transact
 	J_ASSERT(transaction-&gt;t_log_list == NULL);
 	J_ASSERT(transaction-&gt;t_checkpoint_list == NULL);
 	J_ASSERT(transaction-&gt;t_checkpoint_io_list == NULL);
-	J_ASSERT(transaction-&gt;t_updates == 0);
+	J_ASSERT(atomic_read(&amp;transaction-&gt;t_updates) == 0);
 	J_ASSERT(journal-&gt;j_committing_transaction != transaction);
 	J_ASSERT(journal-&gt;j_running_transaction != transaction);
 
diff --git a/fs/jbd2/commit.c b/fs/jbd2/commit.c
index af056810acb6..fbd2c564e916 100644
--- a/fs/jbd2/commit.c
+++ b/fs/jbd2/commit.c
@@ -417,12 +417,12 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 					      stats.run.rs_locked);
 
 	spin_lock(&amp;commit_transaction-&gt;t_handle_lock);
-	while (commit_transaction-&gt;t_updates) {
+	while (atomic_read(&amp;commit_transaction-&gt;t_updates)) {
 		DEFINE_WAIT(wait);
 
 		prepare_to_wait(&amp;journal-&gt;j_wait_updates, &amp;wait,
 					TASK_UNINTERRUPTIBLE);
-		if (commit_transaction-&gt;t_updates) {
+		if (atomic_read(&amp;commit_transaction-&gt;t_updates)) {
 			spin_unlock(&amp;commit_transaction-&gt;t_handle_lock);
 			spin_unlock(&amp;journal-&gt;j_state_lock);
 			schedule();
@@ -433,7 +433,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	}
 	spin_unlock(&amp;commit_transaction-&gt;t_handle_lock);
 
-	J_ASSERT (commit_transaction-&gt;t_outstanding_credits &lt;=
+	J_ASSERT (atomic_read(&amp;commit_transaction-&gt;t_outstanding_credits) &lt;=
 			journal-&gt;j_max_transaction_buffers);
 
 	/*
@@ -527,11 +527,12 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	stats.run.rs_logging = jiffies;
 	stats.run.rs_flushing = jbd2_time_diff(stats.run.rs_flushing,
 					       stats.run.rs_logging);
-	stats.run.rs_blocks = commit_transaction-&gt;t_outstanding_credits;
+	stats.run.rs_blocks =
+		atomic_read(&amp;commit_transaction-&gt;t_outstanding_credits);
 	stats.run.rs_blocks_logged = 0;
 
 	J_ASSERT(commit_transaction-&gt;t_nr_buffers &lt;=
-		 commit_transaction-&gt;t_outstanding_credits);
+		 atomic_read(&amp;commit_transaction-&gt;t_outstanding_credits));
 
 	err = 0;
 	descriptor = NULL;
@@ -616,7 +617,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 		 * the free space in the log, but this counter is changed
 		 * by jbd2_journal_next_log_block() also.
 		 */
-		commit_transaction-&gt;t_outstanding_credits--;
+		atomic_dec(&amp;commit_transaction-&gt;t_outstanding_credits);
 
 		/* Bump b_count to prevent truncate from stumbling over
                    the shadowed buffer!  @@@ This can go if we ever get
diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index 001e95fb0fe1..9c64c7ec48d4 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -55,6 +55,8 @@ jbd2_get_transaction(journal_t *journal, transaction_t *transaction)
 	transaction-&gt;t_tid = journal-&gt;j_transaction_sequence++;
 	transaction-&gt;t_expires = jiffies + journal-&gt;j_commit_interval;
 	spin_lock_init(&amp;transaction-&gt;t_handle_lock);
+	atomic_set(&amp;transaction-&gt;t_updates, 0);
+	atomic_set(&amp;transaction-&gt;t_outstanding_credits, 0);
 	INIT_LIST_HEAD(&amp;transaction-&gt;t_inode_list);
 	INIT_LIST_HEAD(&amp;transaction-&gt;t_private_list);
 
@@ -177,7 +179,7 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 	 * checkpoint to free some more log space.
 	 */
 	spin_lock(&amp;transaction-&gt;t_handle_lock);
-	needed = transaction-&gt;t_outstanding_credits + nblocks;
+	needed = atomic_read(&amp;transaction-&gt;t_outstanding_credits) + nblocks;
 
 	if (needed &gt; journal-&gt;j_max_transaction_buffers) {
 		/*
@@ -240,11 +242,12 @@ static int start_this_handle(journal_t *journal, handle_t *handle,
 	}
 
 	handle-&gt;h_transaction = transaction;
-	transaction-&gt;t_outstanding_credits += nblocks;
-	transaction-&gt;t_updates++;
+	atomic_add(nblocks, &amp;transaction-&gt;t_outstanding_credits);
+	atomic_inc(&amp;transaction-&gt;t_updates);
 	transaction-&gt;t_handle_count++;
 	jbd_debug(4, "Handle %p given %d credits (total %d, free %d)\n",
-		  handle, nblocks, transaction-&gt;t_outstanding_credits,
+		  handle, nblocks,
+		  atomic_read(&amp;transaction-&gt;t_outstanding_credits),
 		  __jbd2_log_space_left(journal));
 	spin_unlock(&amp;transaction-&gt;t_handle_lock);
 	spin_unlock(&amp;journal-&gt;j_state_lock);
@@ -369,7 +372,7 @@ int jbd2_journal_extend(handle_t *handle, int nblocks)
 	}
 
 	spin_lock(&amp;transaction-&gt;t_handle_lock);
-	wanted = transaction-&gt;t_outstanding_credits + nblocks;
+	wanted = atomic_read(&amp;transaction-&gt;t_outstanding_credits) + nblocks;
 
 	if (wanted &gt; journal-&gt;j_max_transaction_buffers) {
 		jbd_debug(3, "denied handle %p %d blocks: "
@@ -384,7 +387,7 @@ int jbd2_journal_extend(handle_t *handle, int nblocks)
 	}
 
 	handle-&gt;h_buffer_credits += nblocks;
-	transaction-&gt;t_outstanding_credits += nblocks;
+	atomic_add(nblocks, &amp;transaction-&gt;t_outstanding_credits);
 	result = 0;
 
 	jbd_debug(3, "extended handle %p by %d\n", handle, nblocks);
@@ -426,15 +429,14 @@ int jbd2__journal_restart(handle_t *handle, int nblocks, int gfp_mask)
 	 * First unlink the handle from its current transaction, and start the
 	 * commit on that.
 	 */
-	J_ASSERT(transaction-&gt;t_updates &gt; 0);
+	J_ASSERT(atomic_read(&amp;transaction-&gt;t_updates) &gt; 0);
 	J_ASSERT(journal_current_handle() == handle);
 
 	spin_lock(&amp;journal-&gt;j_state_lock);
 	spin_lock(&amp;transaction-&gt;t_handle_lock);
-	transaction-&gt;t_outstanding_credits -= handle-&gt;h_buffer_credits;
-	transaction-&gt;t_updates--;
-
-	if (!transaction-&gt;t_updates)
+	atomic_sub(handle-&gt;h_buffer_credits,
+		   &amp;transaction-&gt;t_outstanding_credits);
+	if (atomic_dec_and_test(&amp;transaction-&gt;t_updates))
 		wake_up(&amp;journal-&gt;j_wait_updates);
 	spin_unlock(&amp;transaction-&gt;t_handle_lock);
 
@@ -481,7 +483,7 @@ void jbd2_journal_lock_updates(journal_t *journal)
 			break;
 
 		spin_lock(&amp;transaction-&gt;t_handle_lock);
-		if (!transaction-&gt;t_updates) {
+		if (!atomic_read(&amp;transaction-&gt;t_updates)) {
 			spin_unlock(&amp;transaction-&gt;t_handle_lock);
 			break;
 		}
@@ -1258,7 +1260,8 @@ int jbd2_journal_stop(handle_t *handle)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
 	journal_t *journal = transaction-&gt;t_journal;
-	int err;
+	int err, wait_for_commit = 0;
+	tid_t tid;
 	pid_t pid;
 
 	J_ASSERT(journal_current_handle() == handle);
@@ -1266,7 +1269,7 @@ int jbd2_journal_stop(handle_t *handle)
 	if (is_handle_aborted(handle))
 		err = -EIO;
 	else {
-		J_ASSERT(transaction-&gt;t_updates &gt; 0);
+		J_ASSERT(atomic_read(&amp;transaction-&gt;t_updates) &gt; 0);
 		err = 0;
 	}
 
@@ -1334,14 +1337,8 @@ int jbd2_journal_stop(handle_t *handle)
 	if (handle-&gt;h_sync)
 		transaction-&gt;t_synchronous_commit = 1;
 	current-&gt;journal_info = NULL;
-	spin_lock(&amp;transaction-&gt;t_handle_lock);
-	transaction-&gt;t_outstanding_credits -= handle-&gt;h_buffer_credits;
-	transaction-&gt;t_updates--;
-	if (!transaction-&gt;t_updates) {
-		wake_up(&amp;journal-&gt;j_wait_updates);
-		if (journal-&gt;j_barrier_count)
-			wake_up(&amp;journal-&gt;j_wait_transaction_locked);
-	}
+	atomic_sub(handle-&gt;h_buffer_credits,
+		   &amp;transaction-&gt;t_outstanding_credits);
 
 	/*
 	 * If the handle is marked SYNC, we need to set another commit
@@ -1350,15 +1347,13 @@ int jbd2_journal_stop(handle_t *handle)
 	 * transaction is too old now.
 	 */
 	if (handle-&gt;h_sync ||
-			transaction-&gt;t_outstanding_credits &gt;
-				journal-&gt;j_max_transaction_buffers ||
-			time_after_eq(jiffies, transaction-&gt;t_expires)) {
+	    (atomic_read(&amp;transaction-&gt;t_outstanding_credits) &gt;
+	     journal-&gt;j_max_transaction_buffers) ||
+	    time_after_eq(jiffies, transaction-&gt;t_expires)) {
 		/* Do this even for aborted journals: an abort still
 		 * completes the commit thread, it just doesn't write
 		 * anything to disk. */
-		tid_t tid = transaction-&gt;t_tid;
 
-		spin_unlock(&amp;transaction-&gt;t_handle_lock);
 		jbd_debug(2, "transaction too old, requesting commit for "
 					"handle %p\n", handle);
 		/* This is non-blocking */
@@ -1369,11 +1364,25 @@ int jbd2_journal_stop(handle_t *handle)
 		 * to wait for the commit to complete.
 		 */
 		if (handle-&gt;h_sync &amp;&amp; !(current-&gt;flags &amp; PF_MEMALLOC))
-			err = jbd2_log_wait_commit(journal, tid);
-	} else {
-		spin_unlock(&amp;transaction-&gt;t_handle_lock);
+			wait_for_commit = 1;
 	}
 
+	/*
+	 * Once we drop t_updates, if it goes to zero the transaction
+	 * could start commiting on us and eventually disappear.  So
+	 * once we do this, we must not dereference transaction
+	 * pointer again.
+	 */
+	tid = transaction-&gt;t_tid;
+	if (atomic_dec_and_test(&amp;transaction-&gt;t_updates)) {
+		wake_up(&amp;journal-&gt;j_wait_updates);
+		if (journal-&gt;j_barrier_count)
+			wake_up(&amp;journal-&gt;j_wait_transaction_locked);
+	}
+
+	if (wait_for_commit)
+		err = jbd2_log_wait_commit(journal, tid);
+
 	lock_map_release(&amp;handle-&gt;h_lockdep_map);
 
 	jbd2_free_handle(handle);
diff --git a/include/linux/jbd2.h b/include/linux/jbd2.h
index 5a72bc75b273..a72ce21de0e1 100644
--- a/include/linux/jbd2.h
+++ b/include/linux/jbd2.h
@@ -601,13 +601,13 @@ struct transaction_s
 	 * Number of outstanding updates running on this transaction
 	 * [t_handle_lock]
 	 */
-	int			t_updates;
+	atomic_t		t_updates;
 
 	/*
 	 * Number of buffers reserved for use by all handles in this transaction
 	 * handle but not yet modified. [t_handle_lock]
 	 */
-	int			t_outstanding_credits;
+	atomic_t		t_outstanding_credits;
 
 	/*
 	 * Forward and backward links for the circular list of all transactions
@@ -1258,8 +1258,8 @@ static inline int jbd_space_needed(journal_t *journal)
 {
 	int nblocks = journal-&gt;j_max_transaction_buffers;
 	if (journal-&gt;j_committing_transaction)
-		nblocks += journal-&gt;j_committing_transaction-&gt;
-					t_outstanding_credits;
+		nblocks += atomic_read(&amp;journal-&gt;j_committing_transaction-&gt;
+				       t_outstanding_credits);
 	return nblocks;
 }
 </pre><hr><pre>commit 8b67f04ab9de5d8f3a71aef72bf02c995a506db5
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Aug 1 23:14:20 2010 -0400

    ext4: Add mount options in superblock
    
    Allow mount options to be stored in the superblock.  Also add default
    mount option bits for nobarrier, block_validity, discard, and nodelalloc.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index 9ca3637eca5f..ed14e1db0832 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -1025,8 +1025,9 @@ struct ext4_super_block {
 	__le32	s_last_error_line;	/* line number where error happened */
 	__le64	s_last_error_block;	/* block involved of last error */
 	__u8	s_last_error_func[32];	/* function where the error happened */
-#define EXT4_S_ERR_END offsetof(struct ext4_super_block, s_reserved)
-	__le32   s_reserved[128];        /* Padding to the end of the block */
+#define EXT4_S_ERR_END offsetof(struct ext4_super_block, s_mount_opts)
+	__u8	s_mount_opts[64];
+	__le32	s_reserved[112];        /* Padding to the end of the block */
 };
 
 #define EXT4_S_ERR_LEN (EXT4_S_ERR_END - EXT4_S_ERR_START)
@@ -1341,6 +1342,10 @@ EXT4_INODE_BIT_FNS(state, state_flags)
 #define EXT4_DEFM_JMODE_DATA	0x0020
 #define EXT4_DEFM_JMODE_ORDERED	0x0040
 #define EXT4_DEFM_JMODE_WBACK	0x0060
+#define EXT4_DEFM_NOBARRIER	0x0100
+#define EXT4_DEFM_BLOCK_VALIDITY 0x0200
+#define EXT4_DEFM_DISCARD	0x0400
+#define EXT4_DEFM_NODELALLOC	0x0800
 
 /*
  * Default journal batch times
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 3e3f6484c223..3fd65eb66ccd 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -1003,10 +1003,10 @@ static int ext4_show_options(struct seq_file *seq, struct vfsmount *vfs)
 		seq_puts(seq, ",journal_checksum");
 	if (test_opt(sb, I_VERSION))
 		seq_puts(seq, ",i_version");
-	if (!test_opt(sb, DELALLOC))
+	if (!test_opt(sb, DELALLOC) &amp;&amp;
+	    !(def_mount_opts &amp; EXT4_DEFM_NODELALLOC))
 		seq_puts(seq, ",nodelalloc");
 
-
 	if (sbi-&gt;s_stripe)
 		seq_printf(seq, ",stripe=%lu", sbi-&gt;s_stripe);
 	/*
@@ -1030,7 +1030,7 @@ static int ext4_show_options(struct seq_file *seq, struct vfsmount *vfs)
 	if (test_opt(sb, NO_AUTO_DA_ALLOC))
 		seq_puts(seq, ",noauto_da_alloc");
 
-	if (test_opt(sb, DISCARD))
+	if (test_opt(sb, DISCARD) &amp;&amp; !(def_mount_opts &amp; EXT4_DEFM_DISCARD))
 		seq_puts(seq, ",discard");
 
 	if (test_opt(sb, NOLOAD))
@@ -1039,6 +1039,10 @@ static int ext4_show_options(struct seq_file *seq, struct vfsmount *vfs)
 	if (test_opt(sb, DIOREAD_NOLOCK))
 		seq_puts(seq, ",dioread_nolock");
 
+	if (test_opt(sb, BLOCK_VALIDITY) &amp;&amp;
+	    !(def_mount_opts &amp; EXT4_DEFM_BLOCK_VALIDITY))
+		seq_puts(seq, ",block_validity");
+
 	ext4_show_quota_options(seq, sb);
 
 	return 0;
@@ -2655,6 +2659,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 		set_opt(sbi-&gt;s_mount_opt, ERRORS_CONT);
 	else
 		set_opt(sbi-&gt;s_mount_opt, ERRORS_RO);
+	if (def_mount_opts &amp; EXT4_DEFM_BLOCK_VALIDITY)
+		set_opt(sbi-&gt;s_mount_opt, BLOCK_VALIDITY);
+	if (def_mount_opts &amp; EXT4_DEFM_DISCARD)
+		set_opt(sbi-&gt;s_mount_opt, DISCARD);
 
 	sbi-&gt;s_resuid = le16_to_cpu(es-&gt;s_def_resuid);
 	sbi-&gt;s_resgid = le16_to_cpu(es-&gt;s_def_resgid);
@@ -2662,15 +2670,23 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	sbi-&gt;s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;
 	sbi-&gt;s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;
 
-	set_opt(sbi-&gt;s_mount_opt, BARRIER);
+	if ((def_mount_opts &amp; EXT4_DEFM_NOBARRIER) == 0)
+		set_opt(sbi-&gt;s_mount_opt, BARRIER);
 
 	/*
 	 * enable delayed allocation by default
 	 * Use -o nodelalloc to turn it off
 	 */
-	if (!IS_EXT3_SB(sb))
+	if (!IS_EXT3_SB(sb) &amp;&amp;
+	    ((def_mount_opts &amp; EXT4_DEFM_NODELALLOC) == 0))
 		set_opt(sbi-&gt;s_mount_opt, DELALLOC);
 
+	if (!parse_options((char *) sbi-&gt;s_es-&gt;s_mount_opts, sb,
+			   &amp;journal_devnum, &amp;journal_ioprio, NULL, 0)) {
+		ext4_msg(sb, KERN_WARNING,
+			 "failed to parse options in superblock: %s",
+			 sbi-&gt;s_es-&gt;s_mount_opts);
+	}
 	if (!parse_options((char *) data, sb, &amp;journal_devnum,
 			   &amp;journal_ioprio, NULL, 0))
 		goto failed_mount;
@@ -3141,7 +3157,8 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 		descr = "out journal";
 
 	ext4_msg(sb, KERN_INFO, "mounted filesystem with%s. "
-		"Opts: %s", descr, orig_data);
+		 "Opts: %s%s%s", descr, sbi-&gt;s_es-&gt;s_mount_opts,
+		 *sbi-&gt;s_es-&gt;s_mount_opts ? "; " : "", orig_data);
 
 	init_timer(&amp;sbi-&gt;s_err_report);
 	sbi-&gt;s_err_report.function = print_daily_error_info;</pre><hr><pre>commit 4538821993f4486c76090dfb377c60c0a0e71ba3
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Thu Jul 29 15:06:10 2010 -0400

    ext4: drop inode from orphan list if ext4_delete_inode() fails
    
    There were some error paths in ext4_delete_inode() which was not
    dropping the inode from the orphan list.  This could lead to a BUG_ON
    on umount when the orphan list is discovered to be non-empty.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index a52d5af99187..533b607f9cb5 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -221,6 +221,7 @@ void ext4_delete_inode(struct inode *inode)
 				     "couldn't extend journal (err %d)", err);
 		stop_handle:
 			ext4_journal_stop(handle);
+			ext4_orphan_del(NULL, inode);
 			goto no_delete;
 		}
 	}</pre><hr><pre>commit f613dfcb3345dacb8cf99b7bb359acc1c18a1157
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Jul 27 11:56:08 2010 -0400

    ext4: check to make make sure bd_dev is set before dereferencing it
    
    There are some drivers which may not set bdev-&gt;bd_dev.  So make sure
    it is non-NULL before dereferencing it.
    
    Google-Bug-Id: 1773557
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index c1036bc8a539..e046eba24782 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -2304,6 +2304,8 @@ static ssize_t session_write_kbytes_show(struct ext4_attr *a,
 {
 	struct super_block *sb = sbi-&gt;s_buddy_cache-&gt;i_sb;
 
+	if (!sb-&gt;s_bdev-&gt;bd_part)
+		return snprintf(buf, PAGE_SIZE, "0\n");
 	return snprintf(buf, PAGE_SIZE, "%lu\n",
 			(part_stat_read(sb-&gt;s_bdev-&gt;bd_part, sectors[1]) -
 			 sbi-&gt;s_sectors_written_start) &gt;&gt; 1);
@@ -2314,6 +2316,8 @@ static ssize_t lifetime_write_kbytes_show(struct ext4_attr *a,
 {
 	struct super_block *sb = sbi-&gt;s_buddy_cache-&gt;i_sb;
 
+	if (!sb-&gt;s_bdev-&gt;bd_part)
+		return snprintf(buf, PAGE_SIZE, "0\n");
 	return snprintf(buf, PAGE_SIZE, "%llu\n",
 			(unsigned long long)(sbi-&gt;s_kbytes_written +
 			((part_stat_read(sb-&gt;s_bdev-&gt;bd_part, sectors[1]) -
@@ -2575,8 +2579,9 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	sbi-&gt;s_resgid = EXT4_DEF_RESGID;
 	sbi-&gt;s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;
 	sbi-&gt;s_sb_block = sb_block;
-	sbi-&gt;s_sectors_written_start = part_stat_read(sb-&gt;s_bdev-&gt;bd_part,
-						      sectors[1]);
+	if (sb-&gt;s_bdev-&gt;bd_part)
+		sbi-&gt;s_sectors_written_start =
+			part_stat_read(sb-&gt;s_bdev-&gt;bd_part, sectors[1]);
 
 	unlock_kernel();
 
@@ -3492,10 +3497,14 @@ static int ext4_commit_super(struct super_block *sb, int sync)
 	 */
 	if (!(sb-&gt;s_flags &amp; MS_RDONLY))
 		es-&gt;s_wtime = cpu_to_le32(get_seconds());
-	es-&gt;s_kbytes_written =
-		cpu_to_le64(EXT4_SB(sb)-&gt;s_kbytes_written +
+	if (sb-&gt;s_bdev-&gt;bd_part)
+		es-&gt;s_kbytes_written =
+			cpu_to_le64(EXT4_SB(sb)-&gt;s_kbytes_written +
 			    ((part_stat_read(sb-&gt;s_bdev-&gt;bd_part, sectors[1]) -
 			      EXT4_SB(sb)-&gt;s_sectors_written_start) &gt;&gt; 1));
+	else
+		es-&gt;s_kbytes_written =
+			cpu_to_le64(EXT4_SB(sb)-&gt;s_kbytes_written);
 	ext4_free_blocks_count_set(es, percpu_counter_sum_positive(
 					&amp;EXT4_SB(sb)-&gt;s_freeblocks_counter));
 	es-&gt;s_free_inodes_count = cpu_to_le32(percpu_counter_sum_positive(</pre><hr><pre>commit 0c095c7f113e9fd05913d6e1b2cccbe356be039e
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Jul 27 11:56:06 2010 -0400

    ext4: Don't error out the fs if the user tries to make a file too big
    
    If the user attempts to make a non-extent-mapped file to be too large,
    return EFBIG, but don't call ext4_std_err() which will end up marking
    the file system as containing an error.
    
    Thanks to Toshiyuki Okajima-san at Fujitsu for pointing this out.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 46d2079373c9..38ec77fc3279 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -5472,10 +5472,8 @@ int ext4_setattr(struct dentry *dentry, struct iattr *attr)
 		if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))) {
 			struct ext4_sb_info *sbi = EXT4_SB(inode-&gt;i_sb);
 
-			if (attr-&gt;ia_size &gt; sbi-&gt;s_bitmap_maxbytes) {
-				error = -EFBIG;
-				goto err_out;
-			}
+			if (attr-&gt;ia_size &gt; sbi-&gt;s_bitmap_maxbytes)
+				return -EFBIG;
 		}
 	}
 </pre><hr><pre>commit 47def82672b3ba4e7c5e9a4fe48a556f8684d0d6
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Jul 27 11:56:05 2010 -0400

    jbd2: Remove __GFP_NOFAIL from jbd2 layer
    
    __GFP_NOFAIL is going away, so add our own retry loop.  Also add
    jbd2__journal_start() and jbd2__journal_restart() which take a gfp
    mask, so that file systems can optionally (re)start transaction
    handles using GFP_KERNEL.  If they do this, then they need to be
    prepared to handle receiving an PTR_ERR(-ENOMEM) error, and be ready
    to reflect that error up to userspace.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/jbd2/journal.c b/fs/jbd2/journal.c
index f7bf15787d68..a79d3345b55a 100644
--- a/fs/jbd2/journal.c
+++ b/fs/jbd2/journal.c
@@ -41,6 +41,7 @@
 #include &lt;linux/hash.h&gt;
 #include &lt;linux/log2.h&gt;
 #include &lt;linux/vmalloc.h&gt;
+#include &lt;linux/backing-dev.h&gt;
 
 #define CREATE_TRACE_POINTS
 #include &lt;trace/events/jbd2.h&gt;
@@ -48,8 +49,6 @@
 #include &lt;asm/uaccess.h&gt;
 #include &lt;asm/page.h&gt;
 
-EXPORT_SYMBOL(jbd2_journal_start);
-EXPORT_SYMBOL(jbd2_journal_restart);
 EXPORT_SYMBOL(jbd2_journal_extend);
 EXPORT_SYMBOL(jbd2_journal_stop);
 EXPORT_SYMBOL(jbd2_journal_lock_updates);
@@ -311,7 +310,17 @@ int jbd2_journal_write_metadata_buffer(transaction_t *transaction,
 	 */
 	J_ASSERT_BH(bh_in, buffer_jbddirty(bh_in));
 
-	new_bh = alloc_buffer_head(GFP_NOFS|__GFP_NOFAIL);
+retry_alloc:
+	new_bh = alloc_buffer_head(GFP_NOFS);
+	if (!new_bh) {
+		/*
+		 * Failure is not an option, but __GFP_NOFAIL is going
+		 * away; so we retry ourselves here.
+		 */
+		congestion_wait(BLK_RW_ASYNC, HZ/50);
+		goto retry_alloc;
+	}
+
 	/* keep subsequent assertions sane */
 	new_bh-&gt;b_state = 0;
 	init_buffer(new_bh, NULL, NULL);
diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index e214d68620ac..001e95fb0fe1 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -26,6 +26,8 @@
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/highmem.h&gt;
 #include &lt;linux/hrtimer.h&gt;
+#include &lt;linux/backing-dev.h&gt;
+#include &lt;linux/module.h&gt;
 
 static void __jbd2_journal_temp_unlink_buffer(struct journal_head *jh);
 
@@ -83,30 +85,38 @@ jbd2_get_transaction(journal_t *journal, transaction_t *transaction)
  * transaction's buffer credits.
  */
 
-static int start_this_handle(journal_t *journal, handle_t *handle)
+static int start_this_handle(journal_t *journal, handle_t *handle,
+			     int gfp_mask)
 {
 	transaction_t *transaction;
 	int needed;
 	int nblocks = handle-&gt;h_buffer_credits;
 	transaction_t *new_transaction = NULL;
-	int ret = 0;
 	unsigned long ts = jiffies;
 
 	if (nblocks &gt; journal-&gt;j_max_transaction_buffers) {
 		printk(KERN_ERR "JBD: %s wants too many credits (%d &gt; %d)\n",
 		       current-&gt;comm, nblocks,
 		       journal-&gt;j_max_transaction_buffers);
-		ret = -ENOSPC;
-		goto out;
+		return -ENOSPC;
 	}
 
 alloc_transaction:
 	if (!journal-&gt;j_running_transaction) {
-		new_transaction = kzalloc(sizeof(*new_transaction),
-						GFP_NOFS|__GFP_NOFAIL);
+		new_transaction = kzalloc(sizeof(*new_transaction), gfp_mask);
 		if (!new_transaction) {
-			ret = -ENOMEM;
-			goto out;
+			/*
+			 * If __GFP_FS is not present, then we may be
+			 * being called from inside the fs writeback
+			 * layer, so we MUST NOT fail.  Since
+			 * __GFP_NOFAIL is going away, we will arrange
+			 * to retry the allocation ourselves.
+			 */
+			if ((gfp_mask &amp; __GFP_FS) == 0) {
+				congestion_wait(BLK_RW_ASYNC, HZ/50);
+				goto alloc_transaction;
+			}
+			return -ENOMEM;
 		}
 	}
 
@@ -123,8 +133,8 @@ static int start_this_handle(journal_t *journal, handle_t *handle)
 	if (is_journal_aborted(journal) ||
 	    (journal-&gt;j_errno != 0 &amp;&amp; !(journal-&gt;j_flags &amp; JBD2_ACK_ERR))) {
 		spin_unlock(&amp;journal-&gt;j_state_lock);
-		ret = -EROFS;
-		goto out;
+		kfree(new_transaction);
+		return -EROFS;
 	}
 
 	/* Wait on the journal's transaction barrier if necessary */
@@ -240,10 +250,8 @@ static int start_this_handle(journal_t *journal, handle_t *handle)
 	spin_unlock(&amp;journal-&gt;j_state_lock);
 
 	lock_map_acquire(&amp;handle-&gt;h_lockdep_map);
-out:
-	if (unlikely(new_transaction))		/* It's usually NULL */
-		kfree(new_transaction);
-	return ret;
+	kfree(new_transaction);
+	return 0;
 }
 
 static struct lock_class_key jbd2_handle_key;
@@ -278,7 +286,7 @@ static handle_t *new_handle(int nblocks)
  *
  * Return a pointer to a newly allocated handle, or NULL on failure
  */
-handle_t *jbd2_journal_start(journal_t *journal, int nblocks)
+handle_t *jbd2__journal_start(journal_t *journal, int nblocks, int gfp_mask)
 {
 	handle_t *handle = journal_current_handle();
 	int err;
@@ -298,7 +306,7 @@ handle_t *jbd2_journal_start(journal_t *journal, int nblocks)
 
 	current-&gt;journal_info = handle;
 
-	err = start_this_handle(journal, handle);
+	err = start_this_handle(journal, handle, gfp_mask);
 	if (err &lt; 0) {
 		jbd2_free_handle(handle);
 		current-&gt;journal_info = NULL;
@@ -308,6 +316,15 @@ handle_t *jbd2_journal_start(journal_t *journal, int nblocks)
 out:
 	return handle;
 }
+EXPORT_SYMBOL(jbd2__journal_start);
+
+
+handle_t *jbd2_journal_start(journal_t *journal, int nblocks)
+{
+	return jbd2__journal_start(journal, nblocks, GFP_NOFS);
+}
+EXPORT_SYMBOL(jbd2_journal_start);
+
 
 /**
  * int jbd2_journal_extend() - extend buffer credits.
@@ -394,8 +411,7 @@ int jbd2_journal_extend(handle_t *handle, int nblocks)
  * transaction capabable of guaranteeing the requested number of
  * credits.
  */
-
-int jbd2_journal_restart(handle_t *handle, int nblocks)
+int jbd2__journal_restart(handle_t *handle, int nblocks, int gfp_mask)
 {
 	transaction_t *transaction = handle-&gt;h_transaction;
 	journal_t *journal = transaction-&gt;t_journal;
@@ -428,10 +444,17 @@ int jbd2_journal_restart(handle_t *handle, int nblocks)
 
 	lock_map_release(&amp;handle-&gt;h_lockdep_map);
 	handle-&gt;h_buffer_credits = nblocks;
-	ret = start_this_handle(journal, handle);
+	ret = start_this_handle(journal, handle, gfp_mask);
 	return ret;
 }
+EXPORT_SYMBOL(jbd2__journal_restart);
+
 
+int jbd2_journal_restart(handle_t *handle, int nblocks)
+{
+	return jbd2__journal_restart(handle, nblocks, GFP_NOFS);
+}
+EXPORT_SYMBOL(jbd2_journal_restart);
 
 /**
  * void jbd2_journal_lock_updates () - establish a transaction barrier.
diff --git a/include/linux/jbd2.h b/include/linux/jbd2.h
index a4d2e9f7088a..5a72bc75b273 100644
--- a/include/linux/jbd2.h
+++ b/include/linux/jbd2.h
@@ -1081,7 +1081,9 @@ static inline handle_t *journal_current_handle(void)
  */
 
 extern handle_t *jbd2_journal_start(journal_t *, int nblocks);
-extern int	 jbd2_journal_restart (handle_t *, int nblocks);
+extern handle_t *jbd2__journal_start(journal_t *, int nblocks, int gfp_mask);
+extern int	 jbd2_journal_restart(handle_t *, int nblocks);
+extern int	 jbd2__journal_restart(handle_t *, int nblocks, int gfp_mask);
 extern int	 jbd2_journal_extend (handle_t *, int nblocks);
 extern int	 jbd2_journal_get_write_access(handle_t *, struct buffer_head *);
 extern int	 jbd2_journal_get_create_access (handle_t *, struct buffer_head *);</pre>
    <div class="pagination">
        <a href='1_80.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><span>[81]</span><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_82.html'>Next&gt;&gt;</a>
    <div>
</body>
