<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_88.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><span>[89]</span><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_90.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit f3ce8064b388ccf420012c5a4907aae4f13fe9d0
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Sep 28 15:58:29 2009 -0400

    ext4: EXT4_IOC_MOVE_EXT: Check for different original and donor inodes first
    
    Move the check to make sure the original and donor inodes are
    different earlier, to avoid a potential deadlock by trying to lock the
    same inode twice.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/move_extent.c b/fs/ext4/move_extent.c
index 5332fd4c4028..25b6b1457360 100644
--- a/fs/ext4/move_extent.c
+++ b/fs/ext4/move_extent.c
@@ -1001,14 +1001,6 @@ mext_check_arguments(struct inode *orig_inode,
 		return -EINVAL;
 	}
 
-	/* orig and donor should be different file */
-	if (orig_inode-&gt;i_ino == donor_inode-&gt;i_ino) {
-		ext4_debug("ext4 move extent: The argument files should not "
-			"be same file [ino:orig %lu, donor %lu]\n",
-			orig_inode-&gt;i_ino, donor_inode-&gt;i_ino);
-		return -EINVAL;
-	}
-
 	/* Ext4 move extent supports only extent based file */
 	if (!(EXT4_I(orig_inode)-&gt;i_flags &amp; EXT4_EXTENTS_FL)) {
 		ext4_debug("ext4 move extent: orig file is not extents "
@@ -1232,6 +1224,14 @@ ext4_move_extents(struct file *o_filp, struct file *d_filp,
 	int block_len_in_page;
 	int uninit;
 
+	/* orig and donor should be different file */
+	if (orig_inode-&gt;i_ino == donor_inode-&gt;i_ino) {
+		ext4_debug("ext4 move extent: The argument files should not "
+			"be same file [ino:orig %lu, donor %lu]\n",
+			orig_inode-&gt;i_ino, donor_inode-&gt;i_ino);
+		return -EINVAL;
+	}
+
 	/* protect orig and donor against a truncate */
 	ret1 = mext_inode_double_lock(orig_inode, donor_inode);
 	if (ret1 &lt; 0)</pre><hr><pre>commit 55138e0bc29c0751e2152df9ad35deea542f29b3
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Sep 29 13:31:31 2009 -0400

    ext4: Adjust ext4_da_writepages() to write out larger contiguous chunks
    
    Work around problems in the writeback code to force out writebacks in
    larger chunks than just 4mb, which is just too small.  This also works
    around limitations in the ext4 block allocator, which can't allocate
    more than 2048 blocks at a time.  So we need to defeat the round-robin
    characteristics of the writeback code and try to write out as many
    blocks in one inode before allowing the writeback code to move on to
    another inode.  We add a a new per-filesystem tunable,
    max_writeback_mb_bump, which caps this to a default of 128mb per
    inode.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index e227eea23f05..a58438e18d0b 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -942,6 +942,7 @@ struct ext4_sb_info {
 	unsigned int s_mb_stats;
 	unsigned int s_mb_order2_reqs;
 	unsigned int s_mb_group_prealloc;
+	unsigned int s_max_writeback_mb_bump;
 	/* where last allocation was done - for stream allocation */
 	unsigned long s_mb_last_group;
 	unsigned long s_mb_last_start;
diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 5fb72a98ccbe..20e2d704dc2e 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -1144,6 +1144,64 @@ static int check_block_validity(struct inode *inode, const char *msg,
 	return 0;
 }
 
+/*
+ * Return the number of dirty pages in the given inode starting at
+ * page frame idx.
+ */
+static pgoff_t ext4_num_dirty_pages(struct inode *inode, pgoff_t idx,
+				    unsigned int max_pages)
+{
+	struct address_space *mapping = inode-&gt;i_mapping;
+	pgoff_t	index;
+	struct pagevec pvec;
+	pgoff_t num = 0;
+	int i, nr_pages, done = 0;
+
+	if (max_pages == 0)
+		return 0;
+	pagevec_init(&amp;pvec, 0);
+	while (!done) {
+		index = idx;
+		nr_pages = pagevec_lookup_tag(&amp;pvec, mapping, &amp;index,
+					      PAGECACHE_TAG_DIRTY,
+					      (pgoff_t)PAGEVEC_SIZE);
+		if (nr_pages == 0)
+			break;
+		for (i = 0; i &lt; nr_pages; i++) {
+			struct page *page = pvec.pages[i];
+			struct buffer_head *bh, *head;
+
+			lock_page(page);
+			if (unlikely(page-&gt;mapping != mapping) ||
+			    !PageDirty(page) ||
+			    PageWriteback(page) ||
+			    page-&gt;index != idx) {
+				done = 1;
+				unlock_page(page);
+				break;
+			}
+			head = page_buffers(page);
+			bh = head;
+			do {
+				if (!buffer_delay(bh) &amp;&amp;
+				    !buffer_unwritten(bh)) {
+					done = 1;
+					break;
+				}
+			} while ((bh = bh-&gt;b_this_page) != head);
+			unlock_page(page);
+			if (done)
+				break;
+			idx++;
+			num++;
+			if (num &gt;= max_pages)
+				break;
+		}
+		pagevec_release(&amp;pvec);
+	}
+	return num;
+}
+
 /*
  * The ext4_get_blocks() function tries to look up the requested blocks,
  * and returns if the blocks are already mapped.
@@ -2743,8 +2801,10 @@ static int ext4_da_writepages(struct address_space *mapping,
 	int no_nrwrite_index_update;
 	int pages_written = 0;
 	long pages_skipped;
+	unsigned int max_pages;
 	int range_cyclic, cycled = 1, io_done = 0;
-	int needed_blocks, ret = 0, nr_to_writebump = 0;
+	int needed_blocks, ret = 0;
+	long desired_nr_to_write, nr_to_writebump = 0;
 	loff_t range_start = wbc-&gt;range_start;
 	struct ext4_sb_info *sbi = EXT4_SB(mapping-&gt;host-&gt;i_sb);
 
@@ -2771,16 +2831,6 @@ static int ext4_da_writepages(struct address_space *mapping,
 	if (unlikely(sbi-&gt;s_mount_flags &amp; EXT4_MF_FS_ABORTED))
 		return -EROFS;
 
-	/*
-	 * Make sure nr_to_write is &gt;= sbi-&gt;s_mb_stream_request
-	 * This make sure small files blocks are allocated in
-	 * single attempt. This ensure that small files
-	 * get less fragmented.
-	 */
-	if (wbc-&gt;nr_to_write &lt; sbi-&gt;s_mb_stream_request) {
-		nr_to_writebump = sbi-&gt;s_mb_stream_request - wbc-&gt;nr_to_write;
-		wbc-&gt;nr_to_write = sbi-&gt;s_mb_stream_request;
-	}
 	if (wbc-&gt;range_start == 0 &amp;&amp; wbc-&gt;range_end == LLONG_MAX)
 		range_whole = 1;
 
@@ -2795,6 +2845,36 @@ static int ext4_da_writepages(struct address_space *mapping,
 	} else
 		index = wbc-&gt;range_start &gt;&gt; PAGE_CACHE_SHIFT;
 
+	/*
+	 * This works around two forms of stupidity.  The first is in
+	 * the writeback code, which caps the maximum number of pages
+	 * written to be 1024 pages.  This is wrong on multiple
+	 * levels; different architectues have a different page size,
+	 * which changes the maximum amount of data which gets
+	 * written.  Secondly, 4 megabytes is way too small.  XFS
+	 * forces this value to be 16 megabytes by multiplying
+	 * nr_to_write parameter by four, and then relies on its
+	 * allocator to allocate larger extents to make them
+	 * contiguous.  Unfortunately this brings us to the second
+	 * stupidity, which is that ext4's mballoc code only allocates
+	 * at most 2048 blocks.  So we force contiguous writes up to
+	 * the number of dirty blocks in the inode, or
+	 * sbi-&gt;max_writeback_mb_bump whichever is smaller.
+	 */
+	max_pages = sbi-&gt;s_max_writeback_mb_bump &lt;&lt; (20 - PAGE_CACHE_SHIFT);
+	if (!range_cyclic &amp;&amp; range_whole)
+		desired_nr_to_write = wbc-&gt;nr_to_write * 8;
+	else
+		desired_nr_to_write = ext4_num_dirty_pages(inode, index,
+							   max_pages);
+	if (desired_nr_to_write &gt; max_pages)
+		desired_nr_to_write = max_pages;
+
+	if (wbc-&gt;nr_to_write &lt; desired_nr_to_write) {
+		nr_to_writebump = desired_nr_to_write - wbc-&gt;nr_to_write;
+		wbc-&gt;nr_to_write = desired_nr_to_write;
+	}
+
 	mpd.wbc = wbc;
 	mpd.inode = mapping-&gt;host;
 
@@ -2914,7 +2994,8 @@ static int ext4_da_writepages(struct address_space *mapping,
 out_writepages:
 	if (!no_nrwrite_index_update)
 		wbc-&gt;no_nrwrite_index_update = 0;
-	wbc-&gt;nr_to_write -= nr_to_writebump;
+	if (wbc-&gt;nr_to_write &gt; nr_to_writebump)
+		wbc-&gt;nr_to_write -= nr_to_writebump;
 	wbc-&gt;range_start = range_start;
 	trace_ext4_da_writepages_result(inode, wbc, ret, pages_written);
 	return ret;
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index df539ba27779..16817737ba52 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -2197,6 +2197,7 @@ EXT4_RW_ATTR_SBI_UI(mb_min_to_scan, s_mb_min_to_scan);
 EXT4_RW_ATTR_SBI_UI(mb_order2_req, s_mb_order2_reqs);
 EXT4_RW_ATTR_SBI_UI(mb_stream_req, s_mb_stream_request);
 EXT4_RW_ATTR_SBI_UI(mb_group_prealloc, s_mb_group_prealloc);
+EXT4_RW_ATTR_SBI_UI(max_writeback_mb_bump, s_max_writeback_mb_bump);
 
 static struct attribute *ext4_attrs[] = {
 	ATTR_LIST(delayed_allocation_blocks),
@@ -2210,6 +2211,7 @@ static struct attribute *ext4_attrs[] = {
 	ATTR_LIST(mb_order2_req),
 	ATTR_LIST(mb_stream_req),
 	ATTR_LIST(mb_group_prealloc),
+	ATTR_LIST(max_writeback_mb_bump),
 	NULL,
 };
 
@@ -2679,6 +2681,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	}
 
 	sbi-&gt;s_stripe = ext4_get_stripe_size(sbi);
+	sbi-&gt;s_max_writeback_mb_bump = 128;
 
 	/*
 	 * set up enough so that it can read an inode
diff --git a/include/trace/events/ext4.h b/include/trace/events/ext4.h
index c1bd8f1e8b94..7c6bbb7198a3 100644
--- a/include/trace/events/ext4.h
+++ b/include/trace/events/ext4.h
@@ -236,6 +236,7 @@ TRACE_EVENT(ext4_da_writepages,
 		__field(	char,	for_kupdate		)
 		__field(	char,	for_reclaim		)
 		__field(	char,	range_cyclic		)
+		__field(       pgoff_t,	writeback_index		)
 	),
 
 	TP_fast_assign(
@@ -249,15 +250,17 @@ TRACE_EVENT(ext4_da_writepages,
 		__entry-&gt;for_kupdate	= wbc-&gt;for_kupdate;
 		__entry-&gt;for_reclaim	= wbc-&gt;for_reclaim;
 		__entry-&gt;range_cyclic	= wbc-&gt;range_cyclic;
+		__entry-&gt;writeback_index = inode-&gt;i_mapping-&gt;writeback_index;
 	),
 
-	TP_printk("dev %s ino %lu nr_to_write %ld pages_skipped %ld range_start %llu range_end %llu nonblocking %d for_kupdate %d for_reclaim %d range_cyclic %d",
+	TP_printk("dev %s ino %lu nr_to_write %ld pages_skipped %ld range_start %llu range_end %llu nonblocking %d for_kupdate %d for_reclaim %d range_cyclic %d writeback_index %lu",
 		  jbd2_dev_to_name(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino, __entry-&gt;nr_to_write,
 		  __entry-&gt;pages_skipped, __entry-&gt;range_start,
 		  __entry-&gt;range_end, __entry-&gt;nonblocking,
 		  __entry-&gt;for_kupdate, __entry-&gt;for_reclaim,
-		  __entry-&gt;range_cyclic)
+		  __entry-&gt;range_cyclic,
+		  (unsigned long) __entry-&gt;writeback_index)
 );
 
 TRACE_EVENT(ext4_da_write_pages,
@@ -309,6 +312,7 @@ TRACE_EVENT(ext4_da_writepages_result,
 		__field(	char,	encountered_congestion	)
 		__field(	char,	more_io			)	
 		__field(	char,	no_nrwrite_index_update )
+		__field(       pgoff_t,	writeback_index		)
 	),
 
 	TP_fast_assign(
@@ -320,14 +324,16 @@ TRACE_EVENT(ext4_da_writepages_result,
 		__entry-&gt;encountered_congestion	= wbc-&gt;encountered_congestion;
 		__entry-&gt;more_io	= wbc-&gt;more_io;
 		__entry-&gt;no_nrwrite_index_update = wbc-&gt;no_nrwrite_index_update;
+		__entry-&gt;writeback_index = inode-&gt;i_mapping-&gt;writeback_index;
 	),
 
-	TP_printk("dev %s ino %lu ret %d pages_written %d pages_skipped %ld congestion %d more_io %d no_nrwrite_index_update %d",
+	TP_printk("dev %s ino %lu ret %d pages_written %d pages_skipped %ld congestion %d more_io %d no_nrwrite_index_update %d writeback_index %lu",
 		  jbd2_dev_to_name(__entry-&gt;dev),
 		  (unsigned long) __entry-&gt;ino, __entry-&gt;ret,
 		  __entry-&gt;pages_written, __entry-&gt;pages_skipped,
 		  __entry-&gt;encountered_congestion, __entry-&gt;more_io,
-		  __entry-&gt;no_nrwrite_index_update)
+		  __entry-&gt;no_nrwrite_index_update,
+		  (unsigned long) __entry-&gt;writeback_index)
 );
 
 TRACE_EVENT(ext4_da_write_begin,</pre><hr><pre>commit 71780577306fd1e76c7a92e3b308db624d03adb9
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Sep 28 00:06:20 2009 -0400

    ext4: Fix hueristic which avoids group preallocation for closed files
    
    The hueristic was designed to avoid using locality group preallocation
    when writing the last segment of a closed file.  Fix it by move
    setting size to the maximum of size and isize until after we check
    whether size == isize.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c
index e9c61896d605..c73d43995b13 100644
--- a/fs/ext4/mballoc.c
+++ b/fs/ext4/mballoc.c
@@ -4189,7 +4189,6 @@ static void ext4_mb_group_or_file(struct ext4_allocation_context *ac)
 	size = ac-&gt;ac_o_ex.fe_logical + ac-&gt;ac_o_ex.fe_len;
 	isize = (i_size_read(ac-&gt;ac_inode) + ac-&gt;ac_sb-&gt;s_blocksize - 1)
 		&gt;&gt; bsbits;
-	size = max(size, isize);
 
 	if ((size == isize) &amp;&amp;
 	    !ext4_fs_is_busy(sbi) &amp;&amp;
@@ -4199,6 +4198,7 @@ static void ext4_mb_group_or_file(struct ext4_allocation_context *ac)
 	}
 
 	/* don't use group allocation for large files */
+	size = max(size, isize);
 	if (size &gt;= sbi-&gt;s_mb_stream_request) {
 		ac-&gt;ac_flags |= EXT4_MB_STREAM_ALLOC;
 		return;</pre><hr><pre>commit 1693918e0b6988cf5eb93b7da34f30e94360a379
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sat Sep 26 17:43:59 2009 -0400

    ext4: Use ext4_msg() for ext4_da_writepage() errors
    
    This allows the user to see what filesystem was involved with a
    particular ext4_da_writepage() error.  Also, use KERN_CRIT which is
    more appropriate than KERN_EMERG.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 064746fad581..5fb72a98ccbe 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -2092,18 +2092,18 @@ static void ext4_da_block_invalidatepages(struct mpage_da_data *mpd,
 static void ext4_print_free_blocks(struct inode *inode)
 {
 	struct ext4_sb_info *sbi = EXT4_SB(inode-&gt;i_sb);
-	printk(KERN_EMERG "Total free blocks count %lld\n",
-			ext4_count_free_blocks(inode-&gt;i_sb));
-	printk(KERN_EMERG "Free/Dirty block details\n");
-	printk(KERN_EMERG "free_blocks=%lld\n",
-			(long long)percpu_counter_sum(&amp;sbi-&gt;s_freeblocks_counter));
-	printk(KERN_EMERG "dirty_blocks=%lld\n",
-			(long long)percpu_counter_sum(&amp;sbi-&gt;s_dirtyblocks_counter));
-	printk(KERN_EMERG "Block reservation details\n");
-	printk(KERN_EMERG "i_reserved_data_blocks=%u\n",
-			EXT4_I(inode)-&gt;i_reserved_data_blocks);
-	printk(KERN_EMERG "i_reserved_meta_blocks=%u\n",
-			EXT4_I(inode)-&gt;i_reserved_meta_blocks);
+	printk(KERN_CRIT "Total free blocks count %lld\n",
+	       ext4_count_free_blocks(inode-&gt;i_sb));
+	printk(KERN_CRIT "Free/Dirty block details\n");
+	printk(KERN_CRIT "free_blocks=%lld\n",
+	       (long long) percpu_counter_sum(&amp;sbi-&gt;s_freeblocks_counter));
+	printk(KERN_CRIT "dirty_blocks=%lld\n",
+	       (long long) percpu_counter_sum(&amp;sbi-&gt;s_dirtyblocks_counter));
+	printk(KERN_CRIT "Block reservation details\n");
+	printk(KERN_CRIT "i_reserved_data_blocks=%u\n",
+	       EXT4_I(inode)-&gt;i_reserved_data_blocks);
+	printk(KERN_CRIT "i_reserved_meta_blocks=%u\n",
+	       EXT4_I(inode)-&gt;i_reserved_meta_blocks);
 	return;
 }
 
@@ -2189,14 +2189,14 @@ static int mpage_da_map_blocks(struct mpage_da_data *mpd)
 		 * writepage and writepages will again try to write
 		 * the same.
 		 */
-		printk(KERN_EMERG "%s block allocation failed for inode %lu "
-				  "at logical offset %llu with max blocks "
-				  "%zd with error %d\n",
-				  __func__, mpd-&gt;inode-&gt;i_ino,
-				  (unsigned long long)next,
-				  mpd-&gt;b_size &gt;&gt; mpd-&gt;inode-&gt;i_blkbits, err);
-		printk(KERN_EMERG "This should not happen.!! "
-					"Data will be lost\n");
+		ext4_msg(mpd-&gt;inode-&gt;i_sb, KERN_CRIT,
+			 "delayed block allocation failed for inode %lu at "
+			 "logical offset %llu with max blocks %zd with "
+			 "error %d\n", mpd-&gt;inode-&gt;i_ino,
+			 (unsigned long long) next,
+			 mpd-&gt;b_size &gt;&gt; mpd-&gt;inode-&gt;i_blkbits, err);
+		printk(KERN_CRIT "This should not happen!!  "
+		       "Data will be lost\n");
 		if (err == -ENOSPC) {
 			ext4_print_free_blocks(mpd-&gt;inode);
 		}
@@ -2822,10 +2822,9 @@ static int ext4_da_writepages(struct address_space *mapping,
 		handle = ext4_journal_start(inode, needed_blocks);
 		if (IS_ERR(handle)) {
 			ret = PTR_ERR(handle);
-			printk(KERN_CRIT "%s: jbd2_start: "
+			ext4_msg(inode-&gt;i_sb, KERN_CRIT, "%s: jbd2_start: "
 			       "%ld pages, ino %lu; err %d\n", __func__,
 				wbc-&gt;nr_to_write, inode-&gt;i_ino, ret);
-			dump_stack();
 			goto out_writepages;
 		}
 
@@ -2897,9 +2896,10 @@ static int ext4_da_writepages(struct address_space *mapping,
 		goto retry;
 	}
 	if (pages_skipped != wbc-&gt;pages_skipped)
-		printk(KERN_EMERG "This should not happen leaving %s "
-				"with nr_to_write = %ld ret = %d\n",
-				__func__, wbc-&gt;nr_to_write, ret);
+		ext4_msg(inode-&gt;i_sb, KERN_CRIT,
+			 "This should not happen leaving %s "
+			 "with nr_to_write = %ld ret = %d\n",
+			 __func__, wbc-&gt;nr_to_write, ret);
 
 	/* Update index */
 	index += pages_written;</pre><hr><pre>commit 5534fb5bb35a62a94e0bd1fa2421f7fb6e894f10
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Thu Sep 17 09:34:16 2009 -0400

    ext4: Fix the alloc on close after a truncate hueristic
    
    In an attempt to avoid doing an unneeded flush after opening a
    (previously non-existent) file with O_CREAT|O_TRUNC, the code only
    triggered the hueristic if ei-&gt;disksize was non-zero.  Turns out that
    the VFS doesn't call -&gt;truncate() if the file doesn't exist, and
    ei-&gt;disksize is always zero even if the file previously existed.  So
    remove the test, since it isn't necessary and in fact disabled the
    hueristic.
    
    Thanks to Clemens Eisserer that he was seeing problems with files
    written using kwrite and eclipse after sudden crashes caused by a
    buggy Intel video driver.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 9887a0c562d5..4abd683b963d 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -3973,8 +3973,7 @@ void ext4_truncate(struct inode *inode)
 	if (!ext4_can_truncate(inode))
 		return;
 
-	if (ei-&gt;i_disksize &amp;&amp; inode-&gt;i_size == 0 &amp;&amp;
-	    !test_opt(inode-&gt;i_sb, NO_AUTO_DA_ALLOC))
+	if (inode-&gt;i_size == 0 &amp;&amp; !test_opt(inode-&gt;i_sb, NO_AUTO_DA_ALLOC))
 		ei-&gt;i_state |= EXT4_STATE_DA_ALLOC_CLOSE;
 
 	if (EXT4_I(inode)-&gt;i_flags &amp; EXT4_EXTENTS_FL) {</pre><hr><pre>commit fb40ba0d98968bc3454731360363d725b4f1064c
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Wed Sep 16 19:30:40 2009 -0400

    ext4: Add a tracepoint for ext4_alloc_da_blocks()
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index a5b4ce40cc66..9887a0c562d5 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -3128,6 +3128,8 @@ static void ext4_da_invalidatepage(struct page *page, unsigned long offset)
  */
 int ext4_alloc_da_blocks(struct inode *inode)
 {
+	trace_ext4_alloc_da_blocks(inode);
+
 	if (!EXT4_I(inode)-&gt;i_reserved_data_blocks &amp;&amp;
 	    !EXT4_I(inode)-&gt;i_reserved_meta_blocks)
 		return 0;
diff --git a/include/trace/events/ext4.h b/include/trace/events/ext4.h
index 6fe6ce9ee071..c1bd8f1e8b94 100644
--- a/include/trace/events/ext4.h
+++ b/include/trace/events/ext4.h
@@ -10,6 +10,9 @@
 struct ext4_allocation_context;
 struct ext4_allocation_request;
 struct ext4_prealloc_space;
+struct ext4_inode_info;
+
+#define EXT4_I(inode) (container_of(inode, struct ext4_inode_info, vfs_inode))
 
 TRACE_EVENT(ext4_free_inode,
 	TP_PROTO(struct inode *inode),
@@ -710,6 +713,30 @@ TRACE_EVENT(ext4_sync_fs,
 		  __entry-&gt;wait)
 );
 
+TRACE_EVENT(ext4_alloc_da_blocks,
+	TP_PROTO(struct inode *inode),
+
+	TP_ARGS(inode),
+
+	TP_STRUCT__entry(
+		__field(	dev_t,	dev			)
+		__field(	ino_t,	ino			)
+		__field( unsigned int,	data_blocks	)
+		__field( unsigned int,	meta_blocks	)
+	),
+
+	TP_fast_assign(
+		__entry-&gt;dev	= inode-&gt;i_sb-&gt;s_dev;
+		__entry-&gt;ino	= inode-&gt;i_ino;
+		__entry-&gt;data_blocks = EXT4_I(inode)-&gt;i_reserved_data_blocks;
+		__entry-&gt;meta_blocks = EXT4_I(inode)-&gt;i_reserved_meta_blocks;
+	),
+
+	TP_printk("dev %s ino %lu data_blocks %u meta_blocks %u",
+		  jbd2_dev_to_name(__entry-&gt;dev), (unsigned long) __entry-&gt;ino,
+		  __entry-&gt;data_blocks, __entry-&gt;meta_blocks)
+);
+
 #endif /* _TRACE_EXT4_H */
 
 /* This part must be outside protection */</pre><hr><pre>commit 1b9c12f44c1eb614fd3b8822bfe8f1f5d8e53737
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Thu Sep 17 08:32:22 2009 -0400

    ext4: store EXT4_EXT_MIGRATE in i_state instead of i_flags
    
    EXT4_EXT_MIGRATE is only intended to be used for an in-memory flag,
    and the hex value assigned to it collides with FS_DIRECTIO_FL (which
    is also stored in i_flags).  There's no reason for the
    EXT4_EXT_MIGRATE bit to be stored in i_flags, so we switch it to use
    i_state instead.
    
    Cc: "Aneesh Kumar K.V" &lt;aneesh.kumar@linux.vnet.ibm.com&gt;
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index 2a0f75d55fad..84e7f1d00a83 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -268,7 +268,6 @@ struct flex_groups {
 #define EXT4_TOPDIR_FL			0x00020000 /* Top of directory hierarchies*/
 #define EXT4_HUGE_FILE_FL               0x00040000 /* Set to each huge file */
 #define EXT4_EXTENTS_FL			0x00080000 /* Inode uses extents */
-#define EXT4_EXT_MIGRATE		0x00100000 /* Inode is migrating */
 #define EXT4_RESERVED_FL		0x80000000 /* reserved for ext4 lib */
 
 #define EXT4_FL_USER_VISIBLE		0x000BDFFF /* User visible flags */
@@ -306,6 +305,7 @@ static inline __u32 ext4_mask_flags(umode_t mode, __u32 flags)
 #define EXT4_STATE_XATTR		0x00000004 /* has in-inode xattrs */
 #define EXT4_STATE_NO_EXPAND		0x00000008 /* No space for expansion */
 #define EXT4_STATE_DA_ALLOC_CLOSE	0x00000010 /* Alloc DA blks on close */
+#define EXT4_STATE_EXT_MIGRATE		0x00000020 /* Inode is migrating */
 
 /* Used to pass group descriptor data when online resize is done */
 struct ext4_new_group_input {
diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 5a8979259c9a..a5b4ce40cc66 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -1255,8 +1255,7 @@ int ext4_get_blocks(handle_t *handle, struct inode *inode, sector_t block,
 			 * i_data's format changing.  Force the migrate
 			 * to fail by clearing migrate flags
 			 */
-			EXT4_I(inode)-&gt;i_flags = EXT4_I(inode)-&gt;i_flags &amp;
-							~EXT4_EXT_MIGRATE;
+			EXT4_I(inode)-&gt;i_state &amp;= ~EXT4_STATE_EXT_MIGRATE;
 		}
 	}
 
@@ -4596,8 +4595,7 @@ static int ext4_do_update_inode(handle_t *handle,
 	if (ext4_inode_blocks_set(handle, raw_inode, ei))
 		goto out_brelse;
 	raw_inode-&gt;i_dtime = cpu_to_le32(ei-&gt;i_dtime);
-	/* clear the migrate flag in the raw_inode */
-	raw_inode-&gt;i_flags = cpu_to_le32(ei-&gt;i_flags &amp; ~EXT4_EXT_MIGRATE);
+	raw_inode-&gt;i_flags = cpu_to_le32(ei-&gt;i_flags);
 	if (EXT4_SB(inode-&gt;i_sb)-&gt;s_es-&gt;s_creator_os !=
 	    cpu_to_le32(EXT4_OS_HURD))
 		raw_inode-&gt;i_file_acl_high =
diff --git a/fs/ext4/migrate.c b/fs/ext4/migrate.c
index 05361ad5b80a..bf519f239ae6 100644
--- a/fs/ext4/migrate.c
+++ b/fs/ext4/migrate.c
@@ -353,17 +353,16 @@ static int ext4_ext_swap_inode_data(handle_t *handle, struct inode *inode,
 
 	down_write(&amp;EXT4_I(inode)-&gt;i_data_sem);
 	/*
-	 * if EXT4_EXT_MIGRATE is cleared a block allocation
+	 * if EXT4_STATE_EXT_MIGRATE is cleared a block allocation
 	 * happened after we started the migrate. We need to
 	 * fail the migrate
 	 */
-	if (!(EXT4_I(inode)-&gt;i_flags &amp; EXT4_EXT_MIGRATE)) {
+	if (!(EXT4_I(inode)-&gt;i_state &amp; EXT4_STATE_EXT_MIGRATE)) {
 		retval = -EAGAIN;
 		up_write(&amp;EXT4_I(inode)-&gt;i_data_sem);
 		goto err_out;
 	} else
-		EXT4_I(inode)-&gt;i_flags = EXT4_I(inode)-&gt;i_flags &amp;
-							~EXT4_EXT_MIGRATE;
+		EXT4_I(inode)-&gt;i_state &amp;= ~EXT4_STATE_EXT_MIGRATE;
 	/*
 	 * We have the extent map build with the tmp inode.
 	 * Now copy the i_data across
@@ -517,14 +516,15 @@ int ext4_ext_migrate(struct inode *inode)
 	 * when we add extents we extent the journal
 	 */
 	/*
-	 * Even though we take i_mutex we can still cause block allocation
-	 * via mmap write to holes. If we have allocated new blocks we fail
-	 * migrate.  New block allocation will clear EXT4_EXT_MIGRATE flag.
-	 * The flag is updated with i_data_sem held to prevent racing with
-	 * block allocation.
+	 * Even though we take i_mutex we can still cause block
+	 * allocation via mmap write to holes. If we have allocated
+	 * new blocks we fail migrate.  New block allocation will
+	 * clear EXT4_STATE_EXT_MIGRATE flag.  The flag is updated
+	 * with i_data_sem held to prevent racing with block
+	 * allocation.
 	 */
 	down_read((&amp;EXT4_I(inode)-&gt;i_data_sem));
-	EXT4_I(inode)-&gt;i_flags = EXT4_I(inode)-&gt;i_flags | EXT4_EXT_MIGRATE;
+	EXT4_I(inode)-&gt;i_state |= EXT4_STATE_EXT_MIGRATE;
 	up_read((&amp;EXT4_I(inode)-&gt;i_data_sem));
 
 	handle = ext4_journal_start(inode, 1);</pre><hr><pre>commit 3661d28615ea580c1db02a972fd4d3898df1cb01
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Mon Sep 14 22:59:50 2009 -0400

    ext4: Fix include/trace/events/ext4.h to work with Systemtap
    
    Using relative pathnames in #include statements interacts badly with
    SystemTap, since the fs/ext4/*.h header files are not packaged up as
    part of a distribution kernel's header files.  Since systemtap doesn't
    use TP_fast_assign(), we can use a blind structure definition and then
    make sure the needed header files are defined before the ext4 source
    files #include the trace/events/ext4.h header file.
    
    https://bugzilla.redhat.com/show_bug.cgi?id=512478
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 04c693357336..af95dd8ba54b 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -45,6 +45,7 @@
 #include "ext4_jbd2.h"
 #include "xattr.h"
 #include "acl.h"
+#include "mballoc.h"
 
 #define CREATE_TRACE_POINTS
 #include &lt;trace/events/ext4.h&gt;
diff --git a/include/trace/events/ext4.h b/include/trace/events/ext4.h
index 68b53c7ef8a7..6fe6ce9ee071 100644
--- a/include/trace/events/ext4.h
+++ b/include/trace/events/ext4.h
@@ -5,10 +5,12 @@
 #define _TRACE_EXT4_H
 
 #include &lt;linux/writeback.h&gt;
-#include "../../../fs/ext4/ext4.h"
-#include "../../../fs/ext4/mballoc.h"
 #include &lt;linux/tracepoint.h&gt;
 
+struct ext4_allocation_context;
+struct ext4_allocation_request;
+struct ext4_prealloc_space;
+
 TRACE_EVENT(ext4_free_inode,
 	TP_PROTO(struct inode *inode),
 </pre><hr><pre>commit 7ad9bb651fc2036ea94bed94da76a4b08959a911
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Sep 11 16:51:28 2009 -0400

    ext4: Fix initalization of s_flex_groups
    
    The s_flex_groups array should have been initialized using atomic_add
    to sum up the free counts from the block groups that make up a
    flex_bg.  By using atomic_set, the value of the s_flex_groups array
    was set to the values of the last block group in the flex_bg.
    
    The impact of this bug is that the block and inode allocation
    algorithms might not pick the best flex_bg for new allocation.
    
    Thanks to Damien Guibouret for pointing out this problem!
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 9f6fa3f74629..04c693357336 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -1694,12 +1694,12 @@ static int ext4_fill_flex_info(struct super_block *sb)
 		gdp = ext4_get_group_desc(sb, i, NULL);
 
 		flex_group = ext4_flex_group(sbi, i);
-		atomic_set(&amp;sbi-&gt;s_flex_groups[flex_group].free_inodes,
-			   ext4_free_inodes_count(sb, gdp));
-		atomic_set(&amp;sbi-&gt;s_flex_groups[flex_group].free_blocks,
-			   ext4_free_blks_count(sb, gdp));
-		atomic_set(&amp;sbi-&gt;s_flex_groups[flex_group].used_dirs,
-			   ext4_used_dirs_count(sb, gdp));
+		atomic_add(ext4_free_inodes_count(sb, gdp),
+			   &amp;sbi-&gt;s_flex_groups[flex_group].free_inodes);
+		atomic_add(ext4_free_blks_count(sb, gdp),
+			   &amp;sbi-&gt;s_flex_groups[flex_group].free_blocks);
+		atomic_add(ext4_used_dirs_count(sb, gdp),
+			   &amp;sbi-&gt;s_flex_groups[flex_group].used_dirs);
 	}
 
 	return 1;</pre><hr><pre>commit 0e3d2a6313d03413d93327202a60256d1d726fdc
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Sep 11 09:30:12 2009 -0400

    ext4: Fix async commit mode to be safe by using a barrier
    
    Previously the journal_async_commit mount option was equivalent to
    using barrier=0 (and just as unsafe).  This patch fixes it so that we
    eliminate the barrier before the commit block (by not using ordered
    mode), and explicitly issuing an empty barrier bio after writing the
    commit block.  Because of the journal checksum, it is safe to do this;
    if the journal blocks are not all written before a power failure, the
    checksum in the commit block will prevent the last transaction from
    being replayed.
    
    Using the fs_mark benchmark, using journal_async_commit shows a 50%
    improvement:
    
    FSUse%        Count         Size    Files/sec     App Overhead
         8         1000        10240         30.5            28242
    
    vs.
    
    FSUse%        Count         Size    Files/sec     App Overhead
         8         1000        10240         45.8            28620
    
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;

diff --git a/fs/jbd2/commit.c b/fs/jbd2/commit.c
index 0df600e9162d..26d991ddc1e6 100644
--- a/fs/jbd2/commit.c
+++ b/fs/jbd2/commit.c
@@ -25,6 +25,7 @@
 #include &lt;linux/writeback.h&gt;
 #include &lt;linux/backing-dev.h&gt;
 #include &lt;linux/bio.h&gt;
+#include &lt;linux/blkdev.h&gt;
 #include &lt;trace/events/jbd2.h&gt;
 
 /*
@@ -133,8 +134,8 @@ static int journal_submit_commit_record(journal_t *journal,
 	bh-&gt;b_end_io = journal_end_buffer_io_sync;
 
 	if (journal-&gt;j_flags &amp; JBD2_BARRIER &amp;&amp;
-		!JBD2_HAS_INCOMPAT_FEATURE(journal,
-					 JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT)) {
+	    !JBD2_HAS_INCOMPAT_FEATURE(journal,
+				       JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT)) {
 		set_buffer_ordered(bh);
 		barrier_done = 1;
 	}
@@ -706,11 +707,13 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	/* Done it all: now write the commit record asynchronously. */
 
 	if (JBD2_HAS_INCOMPAT_FEATURE(journal,
-		JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT)) {
+				      JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT)) {
 		err = journal_submit_commit_record(journal, commit_transaction,
 						 &amp;cbh, crc32_sum);
 		if (err)
 			__jbd2_journal_abort_hard(journal);
+		if (journal-&gt;j_flags &amp; JBD2_BARRIER)
+			blkdev_issue_flush(journal-&gt;j_dev, NULL);
 	}
 
 	/*
@@ -833,7 +836,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	jbd_debug(3, "JBD: commit phase 5\n");
 
 	if (!JBD2_HAS_INCOMPAT_FEATURE(journal,
-		JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT)) {
+				       JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT)) {
 		err = journal_submit_commit_record(journal, commit_transaction,
 						&amp;cbh, crc32_sum);
 		if (err)</pre>
    <div class="pagination">
        <a href='1_88.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><span>[89]</span><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_90.html'>Next&gt;&gt;</a>
    <div>
</body>
