<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_128.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><span>[129]</span><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_130.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit f32ea1cd124c9a8b847e33123d156cb55699fa51
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Thu Jan 30 17:20:04 2020 -0500

    efi/x86: Mark setup_graphics static
    
    This function is only called from efi_main in the same source file.
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Link: https://lore.kernel.org/r/20200130222004.1932152-1-nivedita@alum.mit.edu
    Signed-off-by: Ard Biesheuvel &lt;ardb@kernel.org&gt;

diff --git a/arch/x86/boot/compressed/eboot.c b/arch/x86/boot/compressed/eboot.c
index c92fe0b75cec..32423e83ba8f 100644
--- a/arch/x86/boot/compressed/eboot.c
+++ b/arch/x86/boot/compressed/eboot.c
@@ -315,7 +315,7 @@ setup_uga(struct screen_info *si, efi_guid_t *uga_proto, unsigned long size)
 	return status;
 }
 
-void setup_graphics(struct boot_params *boot_params)
+static void setup_graphics(struct boot_params *boot_params)
 {
 	efi_guid_t graphics_proto = EFI_GRAPHICS_OUTPUT_PROTOCOL_GUID;
 	struct screen_info *si;</pre><hr><pre>commit 8a3abe30de9fffec8b44adeb78f93ecb0f09b0c5
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Sun Feb 2 12:13:53 2020 -0500

    x86/boot: Micro-optimize GDT loading instructions
    
    Rearrange the instructions a bit to use a 32-bit displacement once
    instead of 2/3 times. This saves 8 bytes of machine code.
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Link: https://lore.kernel.org/r/20200202171353.3736319-8-nivedita@alum.mit.edu
    Signed-off-by: Ard Biesheuvel &lt;ardb@kernel.org&gt;

diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index c36e6156b6a3..a4f5561c1c0e 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -69,8 +69,9 @@ SYM_FUNC_START(startup_32)
 	subl	$1b, %ebp
 
 	/* Load new GDT with the 64bit segments using 32bit descriptor */
-	addl	%ebp, gdt+2(%ebp)
-	lgdt	gdt(%ebp)
+	leal	gdt(%ebp), %eax
+	movl	%eax, 2(%eax)
+	lgdt	(%eax)
 
 	/* Load segment registers with our descriptors */
 	movl	$__BOOT_DS, %eax
@@ -355,9 +356,9 @@ SYM_CODE_START(startup_64)
 	 */
 
 	/* Make sure we have GDT with 32-bit code segment */
-	leaq	gdt(%rip), %rax
-	movq	%rax, gdt64+2(%rip)
-	lgdt	gdt64(%rip)
+	leaq	gdt64(%rip), %rax
+	addq	%rax, 2(%rax)
+	lgdt	(%rax)
 
 	/*
 	 * paging_prepare() sets up the trampoline and checks if we need to
@@ -625,12 +626,12 @@ SYM_FUNC_END(.Lno_longmode)
 	.data
 SYM_DATA_START_LOCAL(gdt64)
 	.word	gdt_end - gdt - 1
-	.quad   0
+	.quad   gdt - gdt64
 SYM_DATA_END(gdt64)
 	.balign	8
 SYM_DATA_START_LOCAL(gdt)
 	.word	gdt_end - gdt - 1
-	.long	gdt
+	.long	0
 	.word	0
 	.quad	0x00cf9a000000ffff	/* __KERNEL32_CS */
 	.quad	0x00af9a000000ffff	/* __KERNEL_CS */</pre><hr><pre>commit b75e2b076d00751579c73cfbbc8a7eac7d2a0468
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Sun Feb 2 12:13:52 2020 -0500

    x86/boot: GDT limit value should be size - 1
    
    The limit value for the GDTR should be such that adding it to the base
    address gives the address of the last byte of the GDT, i.e. it should be
    one less than the size, not the size.
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Link: https://lore.kernel.org/r/20200202171353.3736319-7-nivedita@alum.mit.edu
    Signed-off-by: Ard Biesheuvel &lt;ardb@kernel.org&gt;

diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index 69cc6c68741e..c36e6156b6a3 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -624,12 +624,12 @@ SYM_FUNC_END(.Lno_longmode)
 
 	.data
 SYM_DATA_START_LOCAL(gdt64)
-	.word	gdt_end - gdt
+	.word	gdt_end - gdt - 1
 	.quad   0
 SYM_DATA_END(gdt64)
 	.balign	8
 SYM_DATA_START_LOCAL(gdt)
-	.word	gdt_end - gdt
+	.word	gdt_end - gdt - 1
 	.long	gdt
 	.word	0
 	.quad	0x00cf9a000000ffff	/* __KERNEL32_CS */</pre><hr><pre>commit ef5a7b5eb13ed88ba9690ab27def3a085332cc8c
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Sun Feb 2 12:13:51 2020 -0500

    efi/x86: Remove GDT setup from efi_main
    
    The 64-bit kernel will already load a GDT in startup_64, which is the
    next function to execute after return from efi_main.
    
    Add GDT setup code to the 32-bit kernel's startup_32 as well. Doing it
    in the head code has the advantage that we can avoid potentially
    corrupting the GDT during copy/decompression. This also removes
    dependence on having a specific GDT layout setup by the bootloader.
    
    Both startup_32 and startup_64 now clear interrupts on entry, so we can
    remove that from efi_main as well.
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Link: https://lore.kernel.org/r/20200202171353.3736319-6-nivedita@alum.mit.edu
    Signed-off-by: Ard Biesheuvel &lt;ardb@kernel.org&gt;

diff --git a/arch/x86/boot/compressed/eboot.c b/arch/x86/boot/compressed/eboot.c
index 287393d725f0..c92fe0b75cec 100644
--- a/arch/x86/boot/compressed/eboot.c
+++ b/arch/x86/boot/compressed/eboot.c
@@ -712,10 +712,8 @@ struct boot_params *efi_main(efi_handle_t handle,
 			     efi_system_table_t *sys_table_arg,
 			     struct boot_params *boot_params)
 {
-	struct desc_ptr *gdt = NULL;
 	struct setup_header *hdr = &amp;boot_params-&gt;hdr;
 	efi_status_t status;
-	struct desc_struct *desc;
 	unsigned long cmdline_paddr;
 
 	sys_table = sys_table_arg;
@@ -753,20 +751,6 @@ struct boot_params *efi_main(efi_handle_t handle,
 
 	setup_quirks(boot_params);
 
-	status = efi_bs_call(allocate_pool, EFI_LOADER_DATA, sizeof(*gdt),
-			     (void **)&amp;gdt);
-	if (status != EFI_SUCCESS) {
-		efi_printk("Failed to allocate memory for 'gdt' structure\n");
-		goto fail;
-	}
-
-	gdt-&gt;size = 0x800;
-	status = efi_low_alloc(gdt-&gt;size, 8, (unsigned long *)&amp;gdt-&gt;address);
-	if (status != EFI_SUCCESS) {
-		efi_printk("Failed to allocate memory for 'gdt'\n");
-		goto fail;
-	}
-
 	/*
 	 * If the kernel isn't already loaded at the preferred load
 	 * address, relocate it.
@@ -793,93 +777,6 @@ struct boot_params *efi_main(efi_handle_t handle,
 		goto fail;
 	}
 
-	memset((char *)gdt-&gt;address, 0x0, gdt-&gt;size);
-	desc = (struct desc_struct *)gdt-&gt;address;
-
-	/* The first GDT is a dummy. */
-	desc++;
-
-	if (IS_ENABLED(CONFIG_X86_64)) {
-		/* __KERNEL32_CS */
-		desc-&gt;limit0	= 0xffff;
-		desc-&gt;base0	= 0x0000;
-		desc-&gt;base1	= 0x0000;
-		desc-&gt;type	= SEG_TYPE_CODE | SEG_TYPE_EXEC_READ;
-		desc-&gt;s		= DESC_TYPE_CODE_DATA;
-		desc-&gt;dpl	= 0;
-		desc-&gt;p		= 1;
-		desc-&gt;limit1	= 0xf;
-		desc-&gt;avl	= 0;
-		desc-&gt;l		= 0;
-		desc-&gt;d		= SEG_OP_SIZE_32BIT;
-		desc-&gt;g		= SEG_GRANULARITY_4KB;
-		desc-&gt;base2	= 0x00;
-
-		desc++;
-	} else {
-		/* Second entry is unused on 32-bit */
-		desc++;
-	}
-
-	/* __KERNEL_CS */
-	desc-&gt;limit0	= 0xffff;
-	desc-&gt;base0	= 0x0000;
-	desc-&gt;base1	= 0x0000;
-	desc-&gt;type	= SEG_TYPE_CODE | SEG_TYPE_EXEC_READ;
-	desc-&gt;s		= DESC_TYPE_CODE_DATA;
-	desc-&gt;dpl	= 0;
-	desc-&gt;p		= 1;
-	desc-&gt;limit1	= 0xf;
-	desc-&gt;avl	= 0;
-
-	if (IS_ENABLED(CONFIG_X86_64)) {
-		desc-&gt;l = 1;
-		desc-&gt;d = 0;
-	} else {
-		desc-&gt;l = 0;
-		desc-&gt;d = SEG_OP_SIZE_32BIT;
-	}
-	desc-&gt;g		= SEG_GRANULARITY_4KB;
-	desc-&gt;base2	= 0x00;
-	desc++;
-
-	/* __KERNEL_DS */
-	desc-&gt;limit0	= 0xffff;
-	desc-&gt;base0	= 0x0000;
-	desc-&gt;base1	= 0x0000;
-	desc-&gt;type	= SEG_TYPE_DATA | SEG_TYPE_READ_WRITE;
-	desc-&gt;s		= DESC_TYPE_CODE_DATA;
-	desc-&gt;dpl	= 0;
-	desc-&gt;p		= 1;
-	desc-&gt;limit1	= 0xf;
-	desc-&gt;avl	= 0;
-	desc-&gt;l		= 0;
-	desc-&gt;d		= SEG_OP_SIZE_32BIT;
-	desc-&gt;g		= SEG_GRANULARITY_4KB;
-	desc-&gt;base2	= 0x00;
-	desc++;
-
-	if (IS_ENABLED(CONFIG_X86_64)) {
-		/* Task segment value */
-		desc-&gt;limit0	= 0x0000;
-		desc-&gt;base0	= 0x0000;
-		desc-&gt;base1	= 0x0000;
-		desc-&gt;type	= SEG_TYPE_TSS;
-		desc-&gt;s		= 0;
-		desc-&gt;dpl	= 0;
-		desc-&gt;p		= 1;
-		desc-&gt;limit1	= 0x0;
-		desc-&gt;avl	= 0;
-		desc-&gt;l		= 0;
-		desc-&gt;d		= 0;
-		desc-&gt;g		= SEG_GRANULARITY_4KB;
-		desc-&gt;base2	= 0x00;
-		desc++;
-	}
-
-	asm volatile("cli");
-	asm volatile ("lgdt %0" : : "m" (*gdt));
-
 	return boot_params;
 fail:
 	efi_printk("efi_main() failed!\n");
diff --git a/arch/x86/boot/compressed/head_32.S b/arch/x86/boot/compressed/head_32.S
index cb2cb91fce45..356060c5332c 100644
--- a/arch/x86/boot/compressed/head_32.S
+++ b/arch/x86/boot/compressed/head_32.S
@@ -64,12 +64,6 @@
 SYM_FUNC_START(startup_32)
 	cld
 	cli
-	movl	$__BOOT_DS, %eax
-	movl	%eax, %ds
-	movl	%eax, %es
-	movl	%eax, %fs
-	movl	%eax, %gs
-	movl	%eax, %ss
 
 /*
  * Calculate the delta between where we were compiled to run
@@ -84,6 +78,19 @@ SYM_FUNC_START(startup_32)
 1:	popl	%ebp
 	subl	$1b, %ebp
 
+	/* Load new GDT */
+	leal	gdt(%ebp), %eax
+	movl	%eax, 2(%eax)
+	lgdt	(%eax)
+
+	/* Load segment registers with our descriptors */
+	movl	$__BOOT_DS, %eax
+	movl	%eax, %ds
+	movl	%eax, %es
+	movl	%eax, %fs
+	movl	%eax, %gs
+	movl	%eax, %ss
+
 /*
  * %ebp contains the address we are loaded at by the boot loader and %ebx
  * contains the address where we should move the kernel image temporarily
@@ -129,6 +136,16 @@ SYM_FUNC_START(startup_32)
 	cld
 	popl	%esi
 
+	/*
+	 * The GDT may get overwritten either during the copy we just did or
+	 * during extract_kernel below. To avoid any issues, repoint the GDTR
+	 * to the new copy of the GDT. EAX still contains the previously
+	 * calculated relocation offset of init_size - _end.
+	 */
+	leal	gdt(%ebx), %edx
+	addl	%eax, 2(%edx)
+	lgdt	(%edx)
+
 /*
  * Jump to the relocated address.
  */
@@ -201,6 +218,17 @@ SYM_FUNC_START_LOCAL_NOALIGN(.Lrelocated)
 	jmp	*%eax
 SYM_FUNC_END(.Lrelocated)
 
+	.data
+	.balign	8
+SYM_DATA_START_LOCAL(gdt)
+	.word	gdt_end - gdt - 1
+	.long	0
+	.word	0
+	.quad	0x0000000000000000	/* Reserved */
+	.quad	0x00cf9a000000ffff	/* __KERNEL_CS */
+	.quad	0x00cf92000000ffff	/* __KERNEL_DS */
+SYM_DATA_END_LABEL(gdt, SYM_L_LOCAL, gdt_end)
+
 /*
  * Stack and heap for uncompression
  */</pre><hr><pre>commit cae0e431a02cd63fecaf677ae166f184644125a7
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Sun Feb 2 12:13:50 2020 -0500

    x86/boot: Clear direction and interrupt flags in startup_64
    
    startup_32 already clears these flags on entry, do it in startup_64 as
    well for consistency.
    
    The direction flag in particular is not specified to be cleared in the
    boot protocol documentation, and we currently call into C code
    (paging_prepare) without explicitly clearing it.
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Link: https://lore.kernel.org/r/20200202171353.3736319-5-nivedita@alum.mit.edu
    Signed-off-by: Ard Biesheuvel &lt;ardb@kernel.org&gt;

diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index 27eb2a6786db..69cc6c68741e 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -264,6 +264,9 @@ SYM_CODE_START(startup_64)
 	 * and command line.
 	 */
 
+	cld
+	cli
+
 	/* Setup data segments. */
 	xorl	%eax, %eax
 	movl	%eax, %ds</pre><hr><pre>commit 32d009137a5646947d450da6fa641a1f4dc1e42c
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Sun Feb 2 12:13:49 2020 -0500

    x86/boot: Reload GDTR after copying to the end of the buffer
    
    The GDT may get overwritten during the copy or during extract_kernel,
    which will cause problems if any segment register is touched before the
    GDTR is reloaded by the decompressed kernel. For safety update the GDTR
    to point to the GDT within the copied kernel.
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Link: https://lore.kernel.org/r/20200202171353.3736319-4-nivedita@alum.mit.edu
    Signed-off-by: Ard Biesheuvel &lt;ardb@kernel.org&gt;

diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index c56b30bd9c7b..27eb2a6786db 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -439,6 +439,16 @@ trampoline_return:
 	cld
 	popq	%rsi
 
+	/*
+	 * The GDT may get overwritten either during the copy we just did or
+	 * during extract_kernel below. To avoid any issues, repoint the GDTR
+	 * to the new copy of the GDT.
+	 */
+	leaq	gdt64(%rbx), %rax
+	subq	%rbp, 2(%rax)
+	addq	%rbx, 2(%rax)
+	lgdt	(%rax)
+
 /*
  * Jump to the relocated address.
  */</pre><hr><pre>commit 90ff226281e1083988a42cfc51f89d91734cc55e
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Sun Feb 2 12:13:48 2020 -0500

    efi/x86: Don't depend on firmware GDT layout
    
    When booting in mixed mode, the firmware's GDT is still installed at
    handover entry in efi32_stub_entry. We save the GDTR for later use in
    __efi64_thunk but we are assuming that descriptor 2 (__KERNEL_CS) is a
    valid 32-bit code segment descriptor and that descriptor 3
    (__KERNEL_DS/__BOOT_DS) is a valid data segment descriptor.
    
    This happens to be true for OVMF (it actually uses descriptor 1 for data
    segments, but descriptor 3 is also setup as data), but we shouldn't
    depend on this being the case.
    
    Fix this by saving the code and data selectors in addition to the GDTR
    in efi32_stub_entry, and restoring them in __efi64_thunk before calling
    the firmware. The UEFI specification guarantees that selectors will be
    flat, so using the DS selector for all the segment registers should be
    enough.
    
    We also need to install our own GDT before initializing segment
    registers in startup_32, so move the GDT load up to the beginning of the
    function.
    
    [ardb: mention mixed mode in the commit log]
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Link: https://lore.kernel.org/r/20200202171353.3736319-3-nivedita@alum.mit.edu
    Signed-off-by: Ard Biesheuvel &lt;ardb@kernel.org&gt;

diff --git a/arch/x86/boot/compressed/efi_thunk_64.S b/arch/x86/boot/compressed/efi_thunk_64.S
index 8fb7f6799c52..2b2049259619 100644
--- a/arch/x86/boot/compressed/efi_thunk_64.S
+++ b/arch/x86/boot/compressed/efi_thunk_64.S
@@ -54,11 +54,16 @@ SYM_FUNC_START(__efi64_thunk)
 	 * Switch to gdt with 32-bit segments. This is the firmware GDT
 	 * that was installed when the kernel started executing. This
 	 * pointer was saved at the EFI stub entry point in head_64.S.
+	 *
+	 * Pass the saved DS selector to the 32-bit code, and use far return to
+	 * restore the saved CS selector.
 	 */
 	leaq	efi32_boot_gdt(%rip), %rax
 	lgdt	(%rax)
 
-	pushq	$__KERNEL_CS
+	movzwl	efi32_boot_ds(%rip), %edx
+	movzwq	efi32_boot_cs(%rip), %rax
+	pushq	%rax
 	leaq	efi_enter32(%rip), %rax
 	pushq	%rax
 	lretq
@@ -73,6 +78,10 @@ SYM_FUNC_START(__efi64_thunk)
 	movl	%ebx, %es
 	pop	%rbx
 	movl	%ebx, %ds
+	/* Clear out 32-bit selector from FS and GS */
+	xorl	%ebx, %ebx
+	movl	%ebx, %fs
+	movl	%ebx, %gs
 
 	/*
 	 * Convert 32-bit status code into 64-bit.
@@ -92,10 +101,12 @@ SYM_FUNC_END(__efi64_thunk)
  * The stack should represent the 32-bit calling convention.
  */
 SYM_FUNC_START_LOCAL(efi_enter32)
-	movl	$__KERNEL_DS, %eax
-	movl	%eax, %ds
-	movl	%eax, %es
-	movl	%eax, %ss
+	/* Load firmware selector into data and stack segment registers */
+	movl	%edx, %ds
+	movl	%edx, %es
+	movl	%edx, %fs
+	movl	%edx, %gs
+	movl	%edx, %ss
 
 	/* Reload pgtables */
 	movl	%cr3, %eax
@@ -157,6 +168,14 @@ SYM_DATA_START(efi32_boot_gdt)
 	.quad	0
 SYM_DATA_END(efi32_boot_gdt)
 
+SYM_DATA_START(efi32_boot_cs)
+	.word	0
+SYM_DATA_END(efi32_boot_cs)
+
+SYM_DATA_START(efi32_boot_ds)
+	.word	0
+SYM_DATA_END(efi32_boot_ds)
+
 SYM_DATA_START(efi_gdt64)
 	.word	efi_gdt64_end - efi_gdt64
 	.long	0			/* Filled out by user */
diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index bd44d89540d3..c56b30bd9c7b 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -54,10 +54,6 @@ SYM_FUNC_START(startup_32)
 	 */
 	cld
 	cli
-	movl	$(__BOOT_DS), %eax
-	movl	%eax, %ds
-	movl	%eax, %es
-	movl	%eax, %ss
 
 /*
  * Calculate the delta between where we were compiled to run
@@ -72,10 +68,20 @@ SYM_FUNC_START(startup_32)
 1:	popl	%ebp
 	subl	$1b, %ebp
 
+	/* Load new GDT with the 64bit segments using 32bit descriptor */
+	addl	%ebp, gdt+2(%ebp)
+	lgdt	gdt(%ebp)
+
+	/* Load segment registers with our descriptors */
+	movl	$__BOOT_DS, %eax
+	movl	%eax, %ds
+	movl	%eax, %es
+	movl	%eax, %fs
+	movl	%eax, %gs
+	movl	%eax, %ss
+
 /* setup a stack and make sure cpu supports long mode. */
-	movl	$boot_stack_end, %eax
-	addl	%ebp, %eax
-	movl	%eax, %esp
+	leal	boot_stack_end(%ebp), %esp
 
 	call	verify_cpu
 	testl	%eax, %eax
@@ -112,10 +118,6 @@ SYM_FUNC_START(startup_32)
  * Prepare for entering 64 bit mode
  */
 
-	/* Load new GDT with the 64bit segments using 32bit descriptor */
-	addl	%ebp, gdt+2(%ebp)
-	lgdt	gdt(%ebp)
-
 	/* Enable PAE mode */
 	movl	%cr4, %eax
 	orl	$X86_CR4_PAE, %eax
@@ -232,9 +234,13 @@ SYM_FUNC_START(efi32_stub_entry)
 
 	movl	%ecx, efi32_boot_args(%ebp)
 	movl	%edx, efi32_boot_args+4(%ebp)
-	sgdtl	efi32_boot_gdt(%ebp)
 	movb	$0, efi_is64(%ebp)
 
+	/* Save firmware GDTR and code/data selectors */
+	sgdtl	efi32_boot_gdt(%ebp)
+	movw	%cs, efi32_boot_cs(%ebp)
+	movw	%ds, efi32_boot_ds(%ebp)
+
 	/* Disable paging */
 	movl	%cr0, %eax
 	btrl	$X86_CR0_PG_BIT, %eax</pre><hr><pre>commit 67a6af7ad1d161dbc9c139e868d5549e632923f7
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Sun Feb 2 12:13:47 2020 -0500

    x86/boot: Remove KEEP_SEGMENTS support
    
    Commit a24e785111a3 ("i386: paravirt boot sequence") added this flag for
    use by paravirtualized environments such as Xen. However, Xen never made
    use of this flag [1], and it was only ever used by lguest [2].
    
    Commit ecda85e70277 ("x86/lguest: Remove lguest support") removed
    lguest, so KEEP_SEGMENTS has lost its last user.
    
    [1] https://lore.kernel.org/lkml/4D4B097C.5050405@goop.org
    [2] https://www.mail-archive.com/lguest@lists.ozlabs.org/msg00469.html
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Link: https://lore.kernel.org/r/20200202171353.3736319-2-nivedita@alum.mit.edu
    Signed-off-by: Ard Biesheuvel &lt;ardb@kernel.org&gt;

diff --git a/Documentation/x86/boot.rst b/Documentation/x86/boot.rst
index c9c201596c3e..fa7ddc0428c8 100644
--- a/Documentation/x86/boot.rst
+++ b/Documentation/x86/boot.rst
@@ -490,15 +490,11 @@ Protocol:	2.00+
 		kernel) to not write early messages that require
 		accessing the display hardware directly.
 
-  Bit 6 (write): KEEP_SEGMENTS
+  Bit 6 (obsolete): KEEP_SEGMENTS
 
 	Protocol: 2.07+
 
-	- If 0, reload the segment registers in the 32bit entry point.
-	- If 1, do not reload the segment registers in the 32bit entry point.
-
-		Assume that %cs %ds %ss %es are all set to flat segments with
-		a base of 0 (or the equivalent for their environment).
+        - This flag is obsolete.
 
   Bit 7 (write): CAN_USE_HEAP
 
diff --git a/arch/x86/boot/compressed/head_32.S b/arch/x86/boot/compressed/head_32.S
index 73f17d0544dd..cb2cb91fce45 100644
--- a/arch/x86/boot/compressed/head_32.S
+++ b/arch/x86/boot/compressed/head_32.S
@@ -63,13 +63,6 @@
 	__HEAD
 SYM_FUNC_START(startup_32)
 	cld
-	/*
-	 * Test KEEP_SEGMENTS flag to see if the bootloader is asking
-	 * us to not reload segments
-	 */
-	testb	$KEEP_SEGMENTS, BP_loadflags(%esi)
-	jnz	1f
-
 	cli
 	movl	$__BOOT_DS, %eax
 	movl	%eax, %ds
@@ -77,7 +70,6 @@ SYM_FUNC_START(startup_32)
 	movl	%eax, %fs
 	movl	%eax, %gs
 	movl	%eax, %ss
-1:
 
 /*
  * Calculate the delta between where we were compiled to run
diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index 1f1f6c8139b3..bd44d89540d3 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -53,19 +53,11 @@ SYM_FUNC_START(startup_32)
 	 * all need to be under the 4G limit.
 	 */
 	cld
-	/*
-	 * Test KEEP_SEGMENTS flag to see if the bootloader is asking
-	 * us to not reload segments
-	 */
-	testb $KEEP_SEGMENTS, BP_loadflags(%esi)
-	jnz 1f
-
 	cli
 	movl	$(__BOOT_DS), %eax
 	movl	%eax, %ds
 	movl	%eax, %es
 	movl	%eax, %ss
-1:
 
 /*
  * Calculate the delta between where we were compiled to run
diff --git a/arch/x86/kernel/head_32.S b/arch/x86/kernel/head_32.S
index 3923ab4630d7..f66a6b90f954 100644
--- a/arch/x86/kernel/head_32.S
+++ b/arch/x86/kernel/head_32.S
@@ -67,11 +67,6 @@ __HEAD
 SYM_CODE_START(startup_32)
 	movl pa(initial_stack),%ecx
 	
-	/* test KEEP_SEGMENTS flag to see if the bootloader is asking
-		us to not reload segments */
-	testb $KEEP_SEGMENTS, BP_loadflags(%esi)
-	jnz 2f
-
 /*
  * Set segments to known values.
  */
@@ -82,7 +77,6 @@ SYM_CODE_START(startup_32)
 	movl %eax,%fs
 	movl %eax,%gs
 	movl %eax,%ss
-2:
 	leal -__PAGE_OFFSET(%ecx),%esp
 
 /*</pre><hr><pre>commit 3ee372ccce4d4e7c610748d0583979d3ed3a0cf4
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Thu Jan 9 10:02:17 2020 -0500

    x86/boot/compressed/64: Remove .bss/.pgtable from bzImage
    
    Commit
    
      5b11f1cee579 ("x86, boot: straighten out ranges to copy/zero in
      compressed/head*.S")
    
    introduced a separate .pgtable section, splitting it out from the rest
    of .bss. This section was added without the writeable flag, marking it
    as read-only. This results in the linker putting the .rela.dyn section
    (containing bogus dynamic relocations from head_64.o) after the .bss and
    .pgtable sections.
    
    When objcopy is used to convert compressed/vmlinux into a binary for
    the bzImage:
    
    $ objcopy  -O binary -R .note -R .comment -S arch/x86/boot/compressed/vmlinux \
                    arch/x86/boot/vmlinux.bin
    
    the .bss and .pgtable sections get materialized as ~176KiB of zero
    bytes in the binary in order to place .rela.dyn at the correct location.
    
    Fix this by marking .pgtable as writeable. This moves the .rela.dyn
    section up in the ELF image layout so that .bss and .pgtable are the
    last allocated sections and so don't appear in bzImage.
    
     [ bp: Massage commit message. ]
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Signed-off-by: Borislav Petkov &lt;bp@suse.de&gt;
    Acked-by: Kees Cook &lt;keescook@chromium.org&gt;
    Link: https://lkml.kernel.org/r/20200109150218.16544-1-nivedita@alum.mit.edu

diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index 68f31c48d6c2..c8ee6eff13ef 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -645,7 +645,7 @@ SYM_DATA_END_LABEL(boot_stack, SYM_L_LOCAL, boot_stack_end)
 /*
  * Space for page tables (not in .bss so not zeroed)
  */
-	.section ".pgtable","a",@nobits
+	.section ".pgtable","aw",@nobits
 	.balign 4096
 SYM_DATA_LOCAL(pgtable,		.fill BOOT_PGT_SIZE, 1, 0)
 </pre><hr><pre>commit a86255fe5258714e1f7c1bdfe95f08e4d098d450
Author: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
Date:   Tue Feb 11 12:33:33 2020 -0500

    x86/boot/compressed/64: Use 32-bit (zero-extended) MOV for z_output_len
    
    z_output_len is the size of the decompressed payload (i.e. vmlinux +
    vmlinux.relocs) and is generated as an unsigned 32-bit quantity by
    mkpiggy.c.
    
    The current
    
      movq $z_output_len, %r9
    
    instruction generates a sign-extended move to %r9. Using
    
      movl $z_output_len, %r9d
    
    will instead zero-extend into %r9, which is appropriate for an unsigned
    32-bit quantity. This is also what is already done for z_input_len, the
    size of the compressed payload.
    
    [ bp:
    
      Also, z_output_len cannot be a 64-bit quantity because it participates
      in:
    
      init_size:              .long INIT_SIZE         # kernel initialization size
    
      through INIT_SIZE which is a 32-bit quantity determined by the .long
      directive (vs .quad for 64-bit). Furthermore, if it really must be a
      64-bit quantity, then the insn must be MOVABS which can accommodate a
      64-bit immediate and which the toolchain does not generate automatically.
    ]
    
    Signed-off-by: Arvind Sankar &lt;nivedita@alum.mit.edu&gt;
    Signed-off-by: Borislav Petkov &lt;bp@suse.de&gt;
    Link: https://lkml.kernel.org/r/20200211173333.1722739-1-nivedita@alum.mit.edu

diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index d1220de1de52..68f31c48d6c2 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -482,7 +482,7 @@ SYM_FUNC_START_LOCAL_NOALIGN(.Lrelocated)
 	leaq	input_data(%rip), %rdx  /* input_data */
 	movl	$z_input_len, %ecx	/* input_len */
 	movq	%rbp, %r8		/* output target address */
-	movq	$z_output_len, %r9	/* decompressed length, end of relocs */
+	movl	$z_output_len, %r9d	/* decompressed length, end of relocs */
 	call	extract_kernel		/* returns kernel location in %rax */
 	popq	%rsi
 </pre>
    <div class="pagination">
        <a href='1_128.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><a href='1_40.html'>40</a><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><span>[129]</span><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_130.html'>Next&gt;&gt;</a>
    <div>
</body>
