<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by University of South Carolina</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by University of South Carolina</h1>
    <div class="pagination">
        <a href='5_33.html'>&lt;&lt;Prev</a><a href='5.html'>1</a><a href='5_2.html'>2</a><a href='5_3.html'>3</a><a href='5_4.html'>4</a><a href='5_5.html'>5</a><a href='5_6.html'>6</a><a href='5_7.html'>7</a><a href='5_8.html'>8</a><a href='5_9.html'>9</a><a href='5_10.html'>10</a><a href='5_11.html'>11</a><a href='5_12.html'>12</a><a href='5_13.html'>13</a><a href='5_14.html'>14</a><a href='5_15.html'>15</a><a href='5_16.html'>16</a><a href='5_17.html'>17</a><a href='5_18.html'>18</a><a href='5_19.html'>19</a><a href='5_20.html'>20</a><a href='5_21.html'>21</a><a href='5_22.html'>22</a><a href='5_23.html'>23</a><a href='5_24.html'>24</a><a href='5_25.html'>25</a><a href='5_26.html'>26</a><a href='5_27.html'>27</a><a href='5_28.html'>28</a><a href='5_29.html'>29</a><a href='5_30.html'>30</a><a href='5_31.html'>31</a><a href='5_32.html'>32</a><a href='5_33.html'>33</a><span>[34]</span><a href='5_35.html'>35</a><a href='5_36.html'>36</a><a href='5_37.html'>37</a><a href='5_38.html'>38</a><a href='5_39.html'>39</a><a href='5_40.html'>40</a><a href='5_41.html'>41</a><a href='5_42.html'>42</a><a href='5_43.html'>43</a><a href='5_44.html'>44</a><a href='5_45.html'>45</a><a href='5_46.html'>46</a><a href='5_47.html'>47</a><a href='5_48.html'>48</a><a href='5_35.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit 41be14442213b6dbeea3cba2ed18a2923666278c
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Wed Feb 28 17:32:18 2007 -0600

    [SCSI] iscsi transport: use atomic for session_nr allocations
    
    qla4xxx and iscsi_tcp or iser could be creating
    sessions at the same time, so make session_nr id
    allocation atomic.
    
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: James Bottomley &lt;James.Bottomley@SteelEye.com&gt;

diff --git a/drivers/scsi/scsi_transport_iscsi.c b/drivers/scsi/scsi_transport_iscsi.c
index ce0d14af33c8..ff05c84479ca 100644
--- a/drivers/scsi/scsi_transport_iscsi.c
+++ b/drivers/scsi/scsi_transport_iscsi.c
@@ -49,7 +49,7 @@ struct iscsi_internal {
 	struct class_device_attribute *session_attrs[ISCSI_SESSION_ATTRS + 1];
 };
 
-static int iscsi_session_nr;	/* sysfs session id for next new session */
+static atomic_t iscsi_session_nr; /* sysfs session id for next new session */
 
 /*
  * list of registered transports and lock that must
@@ -300,7 +300,7 @@ int iscsi_add_session(struct iscsi_cls_session *session, unsigned int target_id)
 	int err;
 
 	ihost = shost-&gt;shost_data;
-	session-&gt;sid = iscsi_session_nr++;
+	session-&gt;sid = atomic_add_return(1, &amp;iscsi_session_nr);
 	session-&gt;target_id = target_id;
 
 	snprintf(session-&gt;dev.bus_id, BUS_ID_SIZE, "session%u",
@@ -1419,6 +1419,8 @@ static __init int iscsi_transport_init(void)
 	printk(KERN_INFO "Loading iSCSI transport class v%s.\n",
 		ISCSI_TRANSPORT_VERSION);
 
+	atomic_set(&amp;iscsi_session_nr, 0);
+
 	err = class_register(&amp;iscsi_transport_class);
 	if (err)
 		return err;</pre><hr><pre>commit bf32ed33e97ac7905fa5a2bf49a634c2eaf62457
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Wed Feb 28 17:32:17 2007 -0600

    [SCSI] iscsi: rename DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH
    
    This patch renames DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH to avoid
    confusion with the drivers default values (DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH
    is the iscsi RFC specific default).
    
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: James Bottomley &lt;James.Bottomley@SteelEye.com&gt;

diff --git a/drivers/infiniband/ulp/iser/iser_initiator.c b/drivers/infiniband/ulp/iser/iser_initiator.c
index 89e37283c836..3261bb327281 100644
--- a/drivers/infiniband/ulp/iser/iser_initiator.c
+++ b/drivers/infiniband/ulp/iser/iser_initiator.c
@@ -201,7 +201,7 @@ static int iser_post_receive_control(struct iscsi_conn *conn)
 	 * what's common for both schemes is that the connection is not started
 	 */
 	if (conn-&gt;c_stage != ISCSI_CONN_STARTED)
-		rx_data_size = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
+		rx_data_size = ISCSI_DEF_MAX_RECV_SEG_LEN;
 	else /* FIXME till user space sets conn-&gt;max_recv_dlength correctly */
 		rx_data_size = 128;
 
diff --git a/drivers/scsi/iscsi_tcp.c b/drivers/scsi/iscsi_tcp.c
index 8f55e1431433..6fd084583491 100644
--- a/drivers/scsi/iscsi_tcp.c
+++ b/drivers/scsi/iscsi_tcp.c
@@ -527,12 +527,12 @@ iscsi_tcp_hdr_recv(struct iscsi_conn *conn)
 		 * than 8K, but there are no targets that currently do this.
 		 * For now we fail until we find a vendor that needs it
 		 */
-		if (DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH &lt;
+		if (ISCSI_DEF_MAX_RECV_SEG_LEN &lt;
 		    tcp_conn-&gt;in.datalen) {
 			printk(KERN_ERR "iscsi_tcp: received buffer of len %u "
 			      "but conn buffer is only %u (opcode %0x)\n",
 			      tcp_conn-&gt;in.datalen,
-			      DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH, opcode);
+			      ISCSI_DEF_MAX_RECV_SEG_LEN, opcode);
 			rc = ISCSI_ERR_PROTO;
 			break;
 		}
@@ -1762,7 +1762,7 @@ iscsi_tcp_conn_create(struct iscsi_cls_session *cls_session, uint32_t conn_idx)
 	 * due to strange issues with iser these are not set
 	 * in iscsi_conn_setup
 	 */
-	conn-&gt;max_recv_dlength = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
+	conn-&gt;max_recv_dlength = ISCSI_DEF_MAX_RECV_SEG_LEN;
 
 	tcp_conn = kzalloc(sizeof(*tcp_conn), GFP_KERNEL);
 	if (!tcp_conn)
diff --git a/drivers/scsi/libiscsi.c b/drivers/scsi/libiscsi.c
index 0ad484f87b1d..04707d667c9d 100644
--- a/drivers/scsi/libiscsi.c
+++ b/drivers/scsi/libiscsi.c
@@ -1520,7 +1520,7 @@ iscsi_conn_setup(struct iscsi_cls_session *cls_session, uint32_t conn_idx)
 	}
 	spin_unlock_bh(&amp;session-&gt;lock);
 
-	data = kmalloc(DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH, GFP_KERNEL);
+	data = kmalloc(ISCSI_DEF_MAX_RECV_SEG_LEN, GFP_KERNEL);
 	if (!data)
 		goto login_mtask_data_alloc_fail;
 	conn-&gt;login_mtask-&gt;data = conn-&gt;data = data;
diff --git a/include/scsi/iscsi_proto.h b/include/scsi/iscsi_proto.h
index 4a44278ed768..8d1e4e8026fe 100644
--- a/include/scsi/iscsi_proto.h
+++ b/include/scsi/iscsi_proto.h
@@ -588,7 +588,17 @@ struct iscsi_reject {
 #define VALUE_MAXLEN		255
 #define TARGET_NAME_MAXLEN	VALUE_MAXLEN
 
-#define DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH	8192
+#define ISCSI_DEF_MAX_RECV_SEG_LEN		8192
+#define ISCSI_MIN_MAX_RECV_SEG_LEN		512
+#define ISCSI_MAX_MAX_RECV_SEG_LEN		16777215
+
+#define ISCSI_DEF_FIRST_BURST_LEN		65536
+#define ISCSI_MIN_FIRST_BURST_LEN		512
+#define ISCSI_MAX_FIRST_BURST_LEN		16777215
+
+#define ISCSI_DEF_MAX_BURST_LEN			262144
+#define ISCSI_MIN_MAX_BURST_LEN			512
+#define ISCSI_MAX_MAX_BURST_LEN			16777215
 
 /************************* RFC 3720 End *****************************/
 </pre><hr><pre>commit 05db888a46866fd4eae643792c162e1a5c1a8612
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Wed Feb 28 17:32:16 2007 -0600

    [SCSI] libiscsi: clear mtask
    
    Consolidate the mtask clearing code.
    
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: James Bottomley &lt;James.Bottomley@SteelEye.com&gt;

diff --git a/drivers/scsi/libiscsi.c b/drivers/scsi/libiscsi.c
index 6346a913c36e..0ad484f87b1d 100644
--- a/drivers/scsi/libiscsi.c
+++ b/drivers/scsi/libiscsi.c
@@ -577,7 +577,7 @@ void iscsi_conn_failure(struct iscsi_conn *conn, enum iscsi_err err)
 }
 EXPORT_SYMBOL_GPL(iscsi_conn_failure);
 
-static int iscsi_xmit_imm_task(struct iscsi_conn *conn)
+static int iscsi_xmit_mtask(struct iscsi_conn *conn)
 {
 	struct iscsi_hdr *hdr = conn-&gt;mtask-&gt;hdr;
 	int rc, was_logout = 0;
@@ -591,6 +591,9 @@ static int iscsi_xmit_imm_task(struct iscsi_conn *conn)
 	if (rc)
 		return rc;
 
+	/* done with this in-progress mtask */
+	conn-&gt;mtask = NULL;
+
 	if (was_logout) {
 		set_bit(ISCSI_SUSPEND_BIT, &amp;conn-&gt;suspend_tx);
 		return -ENODATA;
@@ -643,11 +646,9 @@ static int iscsi_data_xmit(struct iscsi_conn *conn)
 		conn-&gt;ctask = NULL;
 	}
 	if (conn-&gt;mtask) {
-		rc = iscsi_xmit_imm_task(conn);
+		rc = iscsi_xmit_mtask(conn);
 	        if (rc)
 		        goto again;
-		/* done with this in-progress mtask */
-		conn-&gt;mtask = NULL;
 	}
 
 	/* process immediate first */
@@ -658,12 +659,10 @@ static int iscsi_data_xmit(struct iscsi_conn *conn)
 			list_add_tail(&amp;conn-&gt;mtask-&gt;running,
 				      &amp;conn-&gt;mgmt_run_list);
 			spin_unlock_bh(&amp;conn-&gt;session-&gt;lock);
-			rc = iscsi_xmit_imm_task(conn);
+			rc = iscsi_xmit_mtask(conn);
 		        if (rc)
 			        goto again;
 	        }
-		/* done with this mtask */
-		conn-&gt;mtask = NULL;
 	}
 
 	/* process command queue */
@@ -701,12 +700,10 @@ static int iscsi_data_xmit(struct iscsi_conn *conn)
 			list_add_tail(&amp;conn-&gt;mtask-&gt;running,
 				      &amp;conn-&gt;mgmt_run_list);
 			spin_unlock_bh(&amp;conn-&gt;session-&gt;lock);
-		        rc = tt-&gt;xmit_mgmt_task(conn, conn-&gt;mtask);
-			if (rc)
+			rc = iscsi_xmit_mtask(conn);
+		        if (rc)
 			        goto again;
 	        }
-		/* done with this mtask */
-		conn-&gt;mtask = NULL;
 	}
 
 	return -ENODATA;</pre><hr><pre>commit 779ea1207b6a43943faa44f41be7311263315604
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Wed Feb 28 17:32:15 2007 -0600

    [SCSI] libiscsi: flush work before freeing connection
    
    It's possible that we call iscsi_xmitworker after iscsi_conn_release
    which causes a oops. This patch flushes the workqueue.
    
    Signed-off-by: FUJITA Tomonori &lt;fujita.tomonori@lab.ntt.co.jp&gt;
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: James Bottomley &lt;James.Bottomley@SteelEye.com&gt;

diff --git a/drivers/scsi/libiscsi.c b/drivers/scsi/libiscsi.c
index 7c75771c77ff..6346a913c36e 100644
--- a/drivers/scsi/libiscsi.c
+++ b/drivers/scsi/libiscsi.c
@@ -1597,6 +1597,9 @@ void iscsi_conn_teardown(struct iscsi_cls_conn *cls_conn)
 		wake_up(&amp;conn-&gt;ehwait);
 	}
 
+	/* flush queued up work because we free the connection below */
+	scsi_flush_work(session-&gt;host);
+
 	spin_lock_bh(&amp;session-&gt;lock);
 	kfree(conn-&gt;data);
 	kfree(conn-&gt;persistent_address);</pre><hr><pre>commit c0d4d573feed199b16094c072e7cb07afb01c598
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Mon Jan 29 21:18:38 2007 -0500

    [PATCH] Fix SG_IO timeout jiffy conversion
    
    Commit 85e04e371b5a321b5df2bc3f8e0099a64fb087d7 cleaned up the timeout
    conversion, but did it exactly the wrong way.  We get msecs from user
    space, and should convert them into jiffies. Not the other way around.
    
    Here is a fix with the overflow check sg.c has added in.  This fixes DVD
    burnign with Nero.
    
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    [ "you'll be wanting a comma there" - Andrew ]
    Cc: Andrew Morton &lt;akpm@osdl.org&gt;
    Signed-off-by: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;

diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
index 2528a0c0dec8..65c6a3cba6d6 100644
--- a/block/scsi_ioctl.c
+++ b/block/scsi_ioctl.c
@@ -223,7 +223,7 @@ static int verify_command(struct file *file, unsigned char *cmd)
 static int sg_io(struct file *file, request_queue_t *q,
 		struct gendisk *bd_disk, struct sg_io_hdr *hdr)
 {
-	unsigned long start_time;
+	unsigned long start_time, timeout;
 	int writing = 0, ret = 0;
 	struct request *rq;
 	char sense[SCSI_SENSE_BUFFERSIZE];
@@ -271,7 +271,8 @@ static int sg_io(struct file *file, request_queue_t *q,
 
 	rq-&gt;cmd_type = REQ_TYPE_BLOCK_PC;
 
-	rq-&gt;timeout = jiffies_to_msecs(hdr-&gt;timeout);
+	timeout = msecs_to_jiffies(hdr-&gt;timeout);
+	rq-&gt;timeout = (timeout &lt; INT_MAX) ? timeout : INT_MAX;
 	if (!rq-&gt;timeout)
 		rq-&gt;timeout = q-&gt;sg_timeout;
 	if (!rq-&gt;timeout)</pre><hr><pre>commit 9b80cb4be1f4181875e0cf274dc59f42964fdf1b
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Sun Dec 17 12:10:28 2006 -0600

    [SCSI] libiscsi: fix senselen calculation
    
    Yanling Qi, noted that when the sense data length of
    a check-condition is greater than 0x7f (127), senselen = (data[0] &lt;&lt; 8)
    | data[1] will become negative. It causes different kinds of panics from
    GPF, spin_lock deadlock to spin_lock recursion.
    
    We were also swapping this value on big endien machines.
    
    This patch fixes both issues by using be16_to_cpu().
    
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: James Bottomley &lt;James.Bottomley@SteelEye.com&gt;

diff --git a/drivers/scsi/libiscsi.c b/drivers/scsi/libiscsi.c
index e11b23c641e2..d37048c96eab 100644
--- a/drivers/scsi/libiscsi.c
+++ b/drivers/scsi/libiscsi.c
@@ -260,7 +260,7 @@ static int iscsi_scsi_cmd_rsp(struct iscsi_conn *conn, struct iscsi_hdr *hdr,
 	}
 
 	if (rhdr-&gt;cmd_status == SAM_STAT_CHECK_CONDITION) {
-		int senselen;
+		uint16_t senselen;
 
 		if (datalen &lt; 2) {
 invalid_datalen:
@@ -270,12 +270,12 @@ static int iscsi_scsi_cmd_rsp(struct iscsi_conn *conn, struct iscsi_hdr *hdr,
 			goto out;
 		}
 
-		senselen = (data[0] &lt;&lt; 8) | data[1];
+		senselen = be16_to_cpu(*(uint16_t *)data);
 		if (datalen &lt; senselen)
 			goto invalid_datalen;
 
 		memcpy(sc-&gt;sense_buffer, data + 2,
-		       min(senselen, SCSI_SENSE_BUFFERSIZE));
+		       min_t(uint16_t, senselen, SCSI_SENSE_BUFFERSIZE));
 		debug_scsi("copied %d bytes of sense\n",
 			   min(senselen, SCSI_SENSE_BUFFERSIZE));
 	}</pre><hr><pre>commit 0e75f9063f5c55fb0b0b546a7c356f8ec186825e
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Fri Dec 1 10:40:55 2006 +0100

    [PATCH] block: support larger block pc requests
    
    This patch modifies blk_rq_map/unmap_user() and the cdrom and scsi_ioctl.c
    users so that it supports requests larger than bio by chaining them together.
    
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: Jens Axboe &lt;jens.axboe@oracle.com&gt;

diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
index 9eaee6640535..0f82e12f7b67 100644
--- a/block/ll_rw_blk.c
+++ b/block/ll_rw_blk.c
@@ -2322,6 +2322,84 @@ void blk_insert_request(request_queue_t *q, struct request *rq,
 
 EXPORT_SYMBOL(blk_insert_request);
 
+static int __blk_rq_unmap_user(struct bio *bio)
+{
+	int ret = 0;
+
+	if (bio) {
+		if (bio_flagged(bio, BIO_USER_MAPPED))
+			bio_unmap_user(bio);
+		else
+			ret = bio_uncopy_user(bio);
+	}
+
+	return ret;
+}
+
+static int __blk_rq_map_user(request_queue_t *q, struct request *rq,
+			     void __user *ubuf, unsigned int len)
+{
+	unsigned long uaddr;
+	struct bio *bio, *orig_bio;
+	int reading, ret;
+
+	reading = rq_data_dir(rq) == READ;
+
+	/*
+	 * if alignment requirement is satisfied, map in user pages for
+	 * direct dma. else, set up kernel bounce buffers
+	 */
+	uaddr = (unsigned long) ubuf;
+	if (!(uaddr &amp; queue_dma_alignment(q)) &amp;&amp; !(len &amp; queue_dma_alignment(q)))
+		bio = bio_map_user(q, NULL, uaddr, len, reading);
+	else
+		bio = bio_copy_user(q, uaddr, len, reading);
+
+	if (IS_ERR(bio)) {
+		return PTR_ERR(bio);
+	}
+
+	orig_bio = bio;
+	blk_queue_bounce(q, &amp;bio);
+	/*
+	 * We link the bounce buffer in and could have to traverse it
+	 * later so we have to get a ref to prevent it from being freed
+	 */
+	bio_get(bio);
+
+	/*
+	 * for most (all? don't know of any) queues we could
+	 * skip grabbing the queue lock here. only drivers with
+	 * funky private -&gt;back_merge_fn() function could be
+	 * problematic.
+	 */
+	spin_lock_irq(q-&gt;queue_lock);
+	if (!rq-&gt;bio)
+		blk_rq_bio_prep(q, rq, bio);
+	else if (!q-&gt;back_merge_fn(q, rq, bio)) {
+		ret = -EINVAL;
+		spin_unlock_irq(q-&gt;queue_lock);
+		goto unmap_bio;
+	} else {
+		rq-&gt;biotail-&gt;bi_next = bio;
+		rq-&gt;biotail = bio;
+
+		rq-&gt;nr_sectors += bio_sectors(bio);
+		rq-&gt;hard_nr_sectors = rq-&gt;nr_sectors;
+		rq-&gt;data_len += bio-&gt;bi_size;
+	}
+	spin_unlock_irq(q-&gt;queue_lock);
+
+	return bio-&gt;bi_size;
+
+unmap_bio:
+	/* if it was boucned we must call the end io function */
+	bio_endio(bio, bio-&gt;bi_size, 0);
+	__blk_rq_unmap_user(orig_bio);
+	bio_put(bio);
+	return ret;
+}
+
 /**
  * blk_rq_map_user - map user data to a request, for REQ_BLOCK_PC usage
  * @q:		request queue where request should be inserted
@@ -2343,42 +2421,44 @@ EXPORT_SYMBOL(blk_insert_request);
  *    unmapping.
  */
 int blk_rq_map_user(request_queue_t *q, struct request *rq, void __user *ubuf,
-		    unsigned int len)
+		    unsigned long len)
 {
-	unsigned long uaddr;
-	struct bio *bio;
-	int reading;
+	unsigned long bytes_read = 0;
+	int ret;
 
 	if (len &gt; (q-&gt;max_hw_sectors &lt;&lt; 9))
 		return -EINVAL;
 	if (!len || !ubuf)
 		return -EINVAL;
 
-	reading = rq_data_dir(rq) == READ;
+	while (bytes_read != len) {
+		unsigned long map_len, end, start;
 
-	/*
-	 * if alignment requirement is satisfied, map in user pages for
-	 * direct dma. else, set up kernel bounce buffers
-	 */
-	uaddr = (unsigned long) ubuf;
-	if (!(uaddr &amp; queue_dma_alignment(q)) &amp;&amp; !(len &amp; queue_dma_alignment(q)))
-		bio = bio_map_user(q, NULL, uaddr, len, reading);
-	else
-		bio = bio_copy_user(q, uaddr, len, reading);
+		map_len = min_t(unsigned long, len - bytes_read, BIO_MAX_SIZE);
+		end = ((unsigned long)ubuf + map_len + PAGE_SIZE - 1)
+								&gt;&gt; PAGE_SHIFT;
+		start = (unsigned long)ubuf &gt;&gt; PAGE_SHIFT;
 
-	if (!IS_ERR(bio)) {
-		rq-&gt;bio = rq-&gt;biotail = bio;
-		blk_rq_bio_prep(q, rq, bio);
+		/*
+		 * A bad offset could cause us to require BIO_MAX_PAGES + 1
+		 * pages. If this happens we just lower the requested
+		 * mapping len by a page so that we can fit
+		 */
+		if (end - start &gt; BIO_MAX_PAGES)
+			map_len -= PAGE_SIZE;
 
-		rq-&gt;buffer = rq-&gt;data = NULL;
-		rq-&gt;data_len = len;
-		return 0;
+		ret = __blk_rq_map_user(q, rq, ubuf, map_len);
+		if (ret &lt; 0)
+			goto unmap_rq;
+		bytes_read += ret;
+		ubuf += ret;
 	}
 
-	/*
-	 * bio is the err-ptr
-	 */
-	return PTR_ERR(bio);
+	rq-&gt;buffer = rq-&gt;data = NULL;
+	return 0;
+unmap_rq:
+	blk_rq_unmap_user(rq);
+	return ret;
 }
 
 EXPORT_SYMBOL(blk_rq_map_user);
@@ -2404,7 +2484,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
  *    unmapping.
  */
 int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
-			struct sg_iovec *iov, int iov_count)
+			struct sg_iovec *iov, int iov_count, unsigned int len)
 {
 	struct bio *bio;
 
@@ -2418,10 +2498,15 @@ int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
 	if (IS_ERR(bio))
 		return PTR_ERR(bio);
 
-	rq-&gt;bio = rq-&gt;biotail = bio;
+	if (bio-&gt;bi_size != len) {
+		bio_endio(bio, bio-&gt;bi_size, 0);
+		bio_unmap_user(bio);
+		return -EINVAL;
+	}
+
+	bio_get(bio);
 	blk_rq_bio_prep(q, rq, bio);
 	rq-&gt;buffer = rq-&gt;data = NULL;
-	rq-&gt;data_len = bio-&gt;bi_size;
 	return 0;
 }
 
@@ -2429,23 +2514,26 @@ EXPORT_SYMBOL(blk_rq_map_user_iov);
 
 /**
  * blk_rq_unmap_user - unmap a request with user data
- * @bio:	bio to be unmapped
- * @ulen:	length of user buffer
+ * @rq:		rq to be unmapped
  *
  * Description:
- *    Unmap a bio previously mapped by blk_rq_map_user().
+ *    Unmap a rq previously mapped by blk_rq_map_user().
+ *    rq-&gt;bio must be set to the original head of the request.
  */
-int blk_rq_unmap_user(struct bio *bio, unsigned int ulen)
+int blk_rq_unmap_user(struct request *rq)
 {
-	int ret = 0;
+	struct bio *bio, *mapped_bio;
 
-	if (bio) {
-		if (bio_flagged(bio, BIO_USER_MAPPED))
-			bio_unmap_user(bio);
+	while ((bio = rq-&gt;bio)) {
+		if (bio_flagged(bio, BIO_BOUNCED))
+			mapped_bio = bio-&gt;bi_private;
 		else
-			ret = bio_uncopy_user(bio);
-	}
+			mapped_bio = bio;
 
+		__blk_rq_unmap_user(mapped_bio);
+		rq-&gt;bio = bio-&gt;bi_next;
+		bio_put(bio);
+	}
 	return 0;
 }
 
@@ -2476,11 +2564,8 @@ int blk_rq_map_kern(request_queue_t *q, struct request *rq, void *kbuf,
 	if (rq_data_dir(rq) == WRITE)
 		bio-&gt;bi_rw |= (1 &lt;&lt; BIO_RW);
 
-	rq-&gt;bio = rq-&gt;biotail = bio;
 	blk_rq_bio_prep(q, rq, bio);
-
 	rq-&gt;buffer = rq-&gt;data = NULL;
-	rq-&gt;data_len = len;
 	return 0;
 }
 
@@ -3495,6 +3580,7 @@ void blk_rq_bio_prep(request_queue_t *q, struct request *rq, struct bio *bio)
 	rq-&gt;hard_cur_sectors = rq-&gt;current_nr_sectors;
 	rq-&gt;hard_nr_sectors = rq-&gt;nr_sectors = bio_sectors(bio);
 	rq-&gt;buffer = bio_data(bio);
+	rq-&gt;data_len = bio-&gt;bi_size;
 
 	rq-&gt;bio = rq-&gt;biotail = bio;
 }
diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
index e55a75621437..5493c2fbbab1 100644
--- a/block/scsi_ioctl.c
+++ b/block/scsi_ioctl.c
@@ -226,7 +226,6 @@ static int sg_io(struct file *file, request_queue_t *q,
 	unsigned long start_time;
 	int writing = 0, ret = 0;
 	struct request *rq;
-	struct bio *bio;
 	char sense[SCSI_SENSE_BUFFERSIZE];
 	unsigned char cmd[BLK_MAX_CDB];
 
@@ -258,30 +257,6 @@ static int sg_io(struct file *file, request_queue_t *q,
 	if (!rq)
 		return -ENOMEM;
 
-	if (hdr-&gt;iovec_count) {
-		const int size = sizeof(struct sg_iovec) * hdr-&gt;iovec_count;
-		struct sg_iovec *iov;
-
-		iov = kmalloc(size, GFP_KERNEL);
-		if (!iov) {
-			ret = -ENOMEM;
-			goto out;
-		}
-
-		if (copy_from_user(iov, hdr-&gt;dxferp, size)) {
-			kfree(iov);
-			ret = -EFAULT;
-			goto out;
-		}
-
-		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count);
-		kfree(iov);
-	} else if (hdr-&gt;dxfer_len)
-		ret = blk_rq_map_user(q, rq, hdr-&gt;dxferp, hdr-&gt;dxfer_len);
-
-	if (ret)
-		goto out;
-
 	/*
 	 * fill in request structure
 	 */
@@ -294,7 +269,6 @@ static int sg_io(struct file *file, request_queue_t *q,
 	rq-&gt;sense_len = 0;
 
 	rq-&gt;cmd_type = REQ_TYPE_BLOCK_PC;
-	bio = rq-&gt;bio;
 
 	/*
 	 * bounce this after holding a reference to the original bio, it's
@@ -309,6 +283,31 @@ static int sg_io(struct file *file, request_queue_t *q,
 	if (!rq-&gt;timeout)
 		rq-&gt;timeout = BLK_DEFAULT_TIMEOUT;
 
+	if (hdr-&gt;iovec_count) {
+		const int size = sizeof(struct sg_iovec) * hdr-&gt;iovec_count;
+		struct sg_iovec *iov;
+
+		iov = kmalloc(size, GFP_KERNEL);
+		if (!iov) {
+			ret = -ENOMEM;
+			goto out;
+		}
+
+		if (copy_from_user(iov, hdr-&gt;dxferp, size)) {
+			kfree(iov);
+			ret = -EFAULT;
+			goto out;
+		}
+
+		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count,
+					  hdr-&gt;dxfer_len);
+		kfree(iov);
+	} else if (hdr-&gt;dxfer_len)
+		ret = blk_rq_map_user(q, rq, hdr-&gt;dxferp, hdr-&gt;dxfer_len);
+
+	if (ret)
+		goto out;
+
 	rq-&gt;retries = 0;
 
 	start_time = jiffies;
@@ -339,7 +338,7 @@ static int sg_io(struct file *file, request_queue_t *q,
 			hdr-&gt;sb_len_wr = len;
 	}
 
-	if (blk_rq_unmap_user(bio, hdr-&gt;dxfer_len))
+	if (blk_rq_unmap_user(rq))
 		ret = -EFAULT;
 
 	/* may not have succeeded, but output values written to control
diff --git a/drivers/cdrom/cdrom.c b/drivers/cdrom/cdrom.c
index 7ea0f48f8fa6..2df5cf4ec743 100644
--- a/drivers/cdrom/cdrom.c
+++ b/drivers/cdrom/cdrom.c
@@ -2133,16 +2133,14 @@ static int cdrom_read_cdda_bpc(struct cdrom_device_info *cdi, __u8 __user *ubuf,
 		rq-&gt;timeout = 60 * HZ;
 		bio = rq-&gt;bio;
 
-		if (rq-&gt;bio)
-			blk_queue_bounce(q, &amp;rq-&gt;bio);
-
 		if (blk_execute_rq(q, cdi-&gt;disk, rq, 0)) {
 			struct request_sense *s = rq-&gt;sense;
 			ret = -EIO;
 			cdi-&gt;last_sense = s-&gt;sense_key;
 		}
 
-		if (blk_rq_unmap_user(bio, len))
+		rq-&gt;bio = bio;
+		if (blk_rq_unmap_user(rq))
 			ret = -EFAULT;
 
 		if (ret)
diff --git a/fs/bio.c b/fs/bio.c
index d91cfbf7ebc4..aa4d09bd4e71 100644
--- a/fs/bio.c
+++ b/fs/bio.c
@@ -560,10 +560,8 @@ struct bio *bio_copy_user(request_queue_t *q, unsigned long uaddr,
 			break;
 		}
 
-		if (bio_add_pc_page(q, bio, page, bytes, 0) &lt; bytes) {
-			ret = -EINVAL;
+		if (bio_add_pc_page(q, bio, page, bytes, 0) &lt; bytes)
 			break;
-		}
 
 		len -= bytes;
 	}
@@ -750,7 +748,6 @@ struct bio *bio_map_user_iov(request_queue_t *q, struct block_device *bdev,
 			     int write_to_vm)
 {
 	struct bio *bio;
-	int len = 0, i;
 
 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
 
@@ -765,18 +762,7 @@ struct bio *bio_map_user_iov(request_queue_t *q, struct block_device *bdev,
 	 */
 	bio_get(bio);
 
-	for (i = 0; i &lt; iov_count; i++)
-		len += iov[i].iov_len;
-
-	if (bio-&gt;bi_size == len)
-		return bio;
-
-	/*
-	 * don't support partial mappings
-	 */
-	bio_endio(bio, bio-&gt;bi_size, 0);
-	bio_unmap_user(bio);
-	return ERR_PTR(-EINVAL);
+	return bio;
 }
 
 static void __bio_unmap_user(struct bio *bio)
diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
index 7bfcde2d5578..e1c7286165ff 100644
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@ -678,10 +678,11 @@ extern void __blk_stop_queue(request_queue_t *q);
 extern void blk_run_queue(request_queue_t *);
 extern void blk_start_queueing(request_queue_t *);
 extern void blk_queue_activity_fn(request_queue_t *, activity_fn *, void *);
-extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
-extern int blk_rq_unmap_user(struct bio *, unsigned int);
+extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned long);
+extern int blk_rq_unmap_user(struct request *);
 extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
-extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
+extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
+			       struct sg_iovec *, int, unsigned int);
 extern int blk_execute_rq(request_queue_t *, struct gendisk *,
 			  struct request *, int);
 extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,</pre><hr><pre>commit ad2d7225709b11da47e092634cbdf0591829ae9c
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Fri Dec 1 10:40:20 2006 +0100

    [PATCH] block: kill length alignment test in bio_map_user()
    
    The target mode support is mapping in bios using bio_map_user. The
    current targets do not need their len to be aligned with a queue limit
    so this check is causing some problems. Note: pointers passed into the
    kernel are properly aligned by usersapace tgt code so the uaddr check
    in bio_map_user is ok.
    
    The major user, blk_bio_map_user checks for the len before mapping
    so it is not affected by this patch.
    
    And the semi-newly added user blk_rq_map_user_iov has been failing
    out when the len is not aligned properly so maybe people have been
    good and not sending misaligned lens or that path is not used very
    often and this change will not be very dangerous. st and sg do not
    check the length and we have not seen any problem reports from those
    wider used paths so this patch should be fairly safe - for mm
    and wider testing at least.
    
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: FUJITA Tomonori &lt;fujita.tomonori@lab.ntt.co.jp&gt;
    Signed-off-by: James Bottomley &lt;James.Bottomley@SteelEye.com&gt;
    Signed-off-by: Jens Axboe &lt;jens.axboe@oracle.com&gt;

diff --git a/fs/bio.c b/fs/bio.c
index f95c8749499f..d91cfbf7ebc4 100644
--- a/fs/bio.c
+++ b/fs/bio.c
@@ -622,10 +622,9 @@ static struct bio *__bio_map_user_iov(request_queue_t *q,
 
 		nr_pages += end - start;
 		/*
-		 * transfer and buffer must be aligned to at least hardsector
-		 * size for now, in the future we can relax this restriction
+		 * buffer must be aligned to at least hardsector size for now
 		 */
-		if ((uaddr &amp; queue_dma_alignment(q)) || (len &amp; queue_dma_alignment(q)))
+		if (uaddr &amp; queue_dma_alignment(q))
 			return ERR_PTR(-EINVAL);
 	}
 </pre><hr><pre>commit 82a0d7b5829ebd033b7f808c026ab43509913692
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Wed Nov 8 15:58:34 2006 -0600

    [SCSI] iscsi class: update version
    
    Update version number
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: James Bottomley &lt;James.Bottomley@SteelEye.com&gt;

diff --git a/drivers/scsi/scsi_transport_iscsi.c b/drivers/scsi/scsi_transport_iscsi.c
index 2d3baa99ca25..9b25124a989e 100644
--- a/drivers/scsi/scsi_transport_iscsi.c
+++ b/drivers/scsi/scsi_transport_iscsi.c
@@ -33,7 +33,7 @@
 #define ISCSI_SESSION_ATTRS 11
 #define ISCSI_CONN_ATTRS 11
 #define ISCSI_HOST_ATTRS 0
-#define ISCSI_TRANSPORT_VERSION "2.0-685"
+#define ISCSI_TRANSPORT_VERSION "2.0-724"
 
 struct iscsi_internal {
 	int daemon_pid;</pre><hr><pre>commit db37c505e5dfc1a26d6c82f1ce0c3ae06641c3e0
Author: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
Date:   Wed Nov 8 15:58:33 2006 -0600

    [SCSI] iscsi_tcp: fix xmittask oops
    
    XMSTATE_SOL_HDR could be set when the xmit thread tests it, but there may
    not be anything on the r2tqueue yet. Move the XMSTATE_SOL_HDR set
    before the addition to the queue to make sure that when we pull something
    off it it is valid. This does not add locks around the xmstate test or make
    that a atmoic_t because this is a fast path and if it is set when we test it
    we can handle it there without the overhead. Later on we check the xmitqueue
    for all requests with the session lock so we will not miss it.
    
    Signed-off-by: Mike Christie &lt;michaelc@cs.wisc.edu&gt;
    Signed-off-by: James Bottomley &lt;James.Bottomley@SteelEye.com&gt;

diff --git a/drivers/scsi/iscsi_tcp.c b/drivers/scsi/iscsi_tcp.c
index c0b8b33e935c..d0b139cccbbc 100644
--- a/drivers/scsi/iscsi_tcp.c
+++ b/drivers/scsi/iscsi_tcp.c
@@ -415,8 +415,8 @@ iscsi_r2t_rsp(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
 	iscsi_solicit_data_init(conn, ctask, r2t);
 
 	tcp_ctask-&gt;exp_r2tsn = r2tsn + 1;
-	tcp_ctask-&gt;xmstate |= XMSTATE_SOL_HDR;
 	__kfifo_put(tcp_ctask-&gt;r2tqueue, (void*)&amp;r2t, sizeof(void*));
+	tcp_ctask-&gt;xmstate |= XMSTATE_SOL_HDR;
 	list_move_tail(&amp;ctask-&gt;running, &amp;conn-&gt;xmitqueue);
 
 	scsi_queue_work(session-&gt;host, &amp;conn-&gt;xmitwork);
@@ -1627,9 +1627,12 @@ static int iscsi_send_sol_pdu(struct iscsi_conn *conn,
 	if (tcp_ctask-&gt;xmstate &amp; XMSTATE_SOL_HDR) {
 		tcp_ctask-&gt;xmstate &amp;= ~XMSTATE_SOL_HDR;
 		tcp_ctask-&gt;xmstate |= XMSTATE_SOL_DATA;
-		if (!tcp_ctask-&gt;r2t)
+		if (!tcp_ctask-&gt;r2t) {
+			spin_lock_bh(&amp;session-&gt;lock);
 			__kfifo_get(tcp_ctask-&gt;r2tqueue, (void*)&amp;tcp_ctask-&gt;r2t,
 				    sizeof(void*));
+			spin_unlock_bh(&amp;session-&gt;lock);
+		}
 send_hdr:
 		r2t = tcp_ctask-&gt;r2t;
 		dtask = &amp;r2t-&gt;dtask;</pre>
    <div class="pagination">
        <a href='5_33.html'>&lt;&lt;Prev</a><a href='5.html'>1</a><a href='5_2.html'>2</a><a href='5_3.html'>3</a><a href='5_4.html'>4</a><a href='5_5.html'>5</a><a href='5_6.html'>6</a><a href='5_7.html'>7</a><a href='5_8.html'>8</a><a href='5_9.html'>9</a><a href='5_10.html'>10</a><a href='5_11.html'>11</a><a href='5_12.html'>12</a><a href='5_13.html'>13</a><a href='5_14.html'>14</a><a href='5_15.html'>15</a><a href='5_16.html'>16</a><a href='5_17.html'>17</a><a href='5_18.html'>18</a><a href='5_19.html'>19</a><a href='5_20.html'>20</a><a href='5_21.html'>21</a><a href='5_22.html'>22</a><a href='5_23.html'>23</a><a href='5_24.html'>24</a><a href='5_25.html'>25</a><a href='5_26.html'>26</a><a href='5_27.html'>27</a><a href='5_28.html'>28</a><a href='5_29.html'>29</a><a href='5_30.html'>30</a><a href='5_31.html'>31</a><a href='5_32.html'>32</a><a href='5_33.html'>33</a><span>[34]</span><a href='5_35.html'>35</a><a href='5_36.html'>36</a><a href='5_37.html'>37</a><a href='5_38.html'>38</a><a href='5_39.html'>39</a><a href='5_40.html'>40</a><a href='5_41.html'>41</a><a href='5_42.html'>42</a><a href='5_43.html'>43</a><a href='5_44.html'>44</a><a href='5_45.html'>45</a><a href='5_46.html'>46</a><a href='5_47.html'>47</a><a href='5_48.html'>48</a><a href='5_35.html'>Next&gt;&gt;</a>
    <div>
</body>
