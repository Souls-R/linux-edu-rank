<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by University of Michigan - Ann Arbor</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by University of Michigan - Ann Arbor</h1>
    <div class="pagination">
        <a href='4_52.html'>&lt;&lt;Prev</a><a href='4.html'>1</a><a href='4_2.html'>2</a><a href='4_3.html'>3</a><a href='4_4.html'>4</a><a href='4_5.html'>5</a><a href='4_6.html'>6</a><a href='4_7.html'>7</a><a href='4_8.html'>8</a><a href='4_9.html'>9</a><a href='4_10.html'>10</a><a href='4_11.html'>11</a><a href='4_12.html'>12</a><a href='4_13.html'>13</a><a href='4_14.html'>14</a><a href='4_15.html'>15</a><a href='4_16.html'>16</a><a href='4_17.html'>17</a><a href='4_18.html'>18</a><a href='4_19.html'>19</a><a href='4_20.html'>20</a><a href='4_21.html'>21</a><a href='4_22.html'>22</a><a href='4_23.html'>23</a><a href='4_24.html'>24</a><a href='4_25.html'>25</a><a href='4_26.html'>26</a><a href='4_27.html'>27</a><a href='4_28.html'>28</a><a href='4_29.html'>29</a><a href='4_30.html'>30</a><a href='4_31.html'>31</a><a href='4_32.html'>32</a><a href='4_33.html'>33</a><a href='4_34.html'>34</a><a href='4_35.html'>35</a><a href='4_36.html'>36</a><a href='4_37.html'>37</a><a href='4_38.html'>38</a><a href='4_39.html'>39</a><a href='4_40.html'>40</a><a href='4_41.html'>41</a><a href='4_42.html'>42</a><a href='4_43.html'>43</a><a href='4_44.html'>44</a><a href='4_45.html'>45</a><a href='4_46.html'>46</a><a href='4_47.html'>47</a><a href='4_48.html'>48</a><a href='4_49.html'>49</a><a href='4_50.html'>50</a><a href='4_51.html'>51</a><a href='4_52.html'>52</a><span>[53]</span><a href='4_54.html'>54</a><a href='4_55.html'>55</a><a href='4_56.html'>56</a><a href='4_57.html'>57</a><a href='4_54.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit 3a65588adc4401622b204caa897123e16a4a0318
Author: J. Bruce Fields &lt;bfields@fieldses.org&gt;
Date:   Wed Jan 18 17:43:19 2006 -0800

    [PATCH] nfsd4: rename lk_stateowner
    
    One of the things that's confusing about nfsd4_lock is that the lk_stateowner
    field could be set to either of two different lockowners: the open owner or
    the lock owner.  Rename to lk_replay_owner and add a comment to make it clear
    that it's used for whichever stateowner has its sequence id bumped for replay
    detection.
    
    Signed-off-by: J. Bruce Fields &lt;bfields@citi.umich.edu&gt;
    Signed-off-by: Neil Brown &lt;neilb@suse.de&gt;
    Signed-off-by: Andrew Morton &lt;akpm@osdl.org&gt;
    Signed-off-by: Linus Torvalds &lt;torvalds@osdl.org&gt;

diff --git a/fs/nfsd/nfs4state.c b/fs/nfsd/nfs4state.c
index 5bf7fd3947ce..578ea521c827 100644
--- a/fs/nfsd/nfs4state.c
+++ b/fs/nfsd/nfs4state.c
@@ -2725,11 +2725,11 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 				        lock-&gt;lk_new_open_seqid,
 		                        &amp;lock-&gt;lk_new_open_stateid,
 		                        CHECK_FH | OPEN_STATE,
-		                        &amp;lock-&gt;lk_stateowner, &amp;open_stp,
+		                        &amp;lock-&gt;lk_replay_owner, &amp;open_stp,
 					lock);
 		if (status)
 			goto out;
-		open_sop = lock-&gt;lk_stateowner;
+		open_sop = lock-&gt;lk_replay_owner;
 		/* create lockowner and lock stateid */
 		fp = open_stp-&gt;st_file;
 		strhashval = lock_ownerstr_hashval(fp-&gt;fi_inode, 
@@ -2752,12 +2752,12 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 				       lock-&gt;lk_old_lock_seqid, 
 				       &amp;lock-&gt;lk_old_lock_stateid, 
 				       CHECK_FH | LOCK_STATE, 
-				       &amp;lock-&gt;lk_stateowner, &amp;lock_stp, lock);
+				       &amp;lock-&gt;lk_replay_owner, &amp;lock_stp, lock);
 		if (status)
 			goto out;
-		lock_sop = lock-&gt;lk_stateowner;
+		lock_sop = lock-&gt;lk_replay_owner;
 	}
-	/* lock-&gt;lk_stateowner and lock_stp have been created or found */
+	/* lock-&gt;lk_replay_owner and lock_stp have been created or found */
 	filp = lock_stp-&gt;st_vfs_file;
 
 	status = nfserr_grace;
@@ -2830,9 +2830,9 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 out:
 	if (status &amp;&amp; lock-&gt;lk_is_new &amp;&amp; lock_sop)
 		release_stateowner(lock_sop);
-	if (lock-&gt;lk_stateowner) {
-		nfs4_get_stateowner(lock-&gt;lk_stateowner);
-		*replay_owner = lock-&gt;lk_stateowner;
+	if (lock-&gt;lk_replay_owner) {
+		nfs4_get_stateowner(lock-&gt;lk_replay_owner);
+		*replay_owner = lock-&gt;lk_replay_owner;
 	}
 	nfs4_unlock_state();
 	return status;
diff --git a/fs/nfsd/nfs4xdr.c b/fs/nfsd/nfs4xdr.c
index dcd673186944..6b743327686c 100644
--- a/fs/nfsd/nfs4xdr.c
+++ b/fs/nfsd/nfs4xdr.c
@@ -528,7 +528,7 @@ nfsd4_decode_lock(struct nfsd4_compoundargs *argp, struct nfsd4_lock *lock)
 {
 	DECODE_HEAD;
 
-	lock-&gt;lk_stateowner = NULL;
+	lock-&gt;lk_replay_owner = NULL;
 	/*
 	* type, reclaim(boolean), offset, length, new_lock_owner(boolean)
 	*/
@@ -1895,7 +1895,6 @@ nfsd4_encode_lock_denied(struct nfsd4_compoundres *resp, struct nfsd4_lock_denie
 static void
 nfsd4_encode_lock(struct nfsd4_compoundres *resp, int nfserr, struct nfsd4_lock *lock)
 {
-
 	ENCODE_SEQID_OP_HEAD;
 
 	if (!nfserr) {
@@ -1906,7 +1905,7 @@ nfsd4_encode_lock(struct nfsd4_compoundres *resp, int nfserr, struct nfsd4_lock
 	} else if (nfserr == nfserr_denied)
 		nfsd4_encode_lock_denied(resp, &amp;lock-&gt;lk_denied);
 
-	ENCODE_SEQID_OP_TAIL(lock-&gt;lk_stateowner);
+	ENCODE_SEQID_OP_TAIL(lock-&gt;lk_replay_owner);
 }
 
 static void
diff --git a/include/linux/nfsd/xdr4.h b/include/linux/nfsd/xdr4.h
index 8903688890ce..77adba7d2281 100644
--- a/include/linux/nfsd/xdr4.h
+++ b/include/linux/nfsd/xdr4.h
@@ -145,8 +145,9 @@ struct nfsd4_lock {
 		} ok;
 		struct nfsd4_lock_denied        denied;
 	} u;
-
-	struct nfs4_stateowner *lk_stateowner;
+	/* The lk_replay_owner is the open owner in the open_to_lock_owner
+	 * case and the lock owner otherwise: */
+	struct nfs4_stateowner *lk_replay_owner;
 };
 #define lk_new_open_seqid       v.new.open_seqid
 #define lk_new_open_stateid     v.new.open_stateid</pre><hr><pre>commit 8a280510852959c0d51b1d625e90c0491c238368
Author: J. Bruce Fields &lt;bfields@fieldses.org&gt;
Date:   Wed Jan 18 17:43:18 2006 -0800

    [PATCH] nfsd4: fix nfsd4_lock cleanup on failure
    
    release_state_owner also puts the lock owner on the close_lru.  There's no
    need for that, though; replays of the failed lock would be handled by the
    openowner not the lockowner.
    
    Also consolidate the cleanup a bit, fixing leaks that can happen if errors
    occur between the time a new lock owner is allocated and the lock is done.
    
    Remove a comment and dprintk that look a little redundant.
    
    Signed-off-by: J. Bruce Fields &lt;bfields@citi.umich.edu&gt;
    Signed-off-by: Neil Brown &lt;neilb@suse.de&gt;
    Signed-off-by: Andrew Morton &lt;akpm@osdl.org&gt;
    Signed-off-by: Linus Torvalds &lt;torvalds@osdl.org&gt;

diff --git a/fs/nfsd/nfs4state.c b/fs/nfsd/nfs4state.c
index 3d4a2ec97caa..5bf7fd3947ce 100644
--- a/fs/nfsd/nfs4state.c
+++ b/fs/nfsd/nfs4state.c
@@ -2744,10 +2744,8 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 		if (lock_sop == NULL)
 			goto out;
 		lock_stp = alloc_init_lock_stateid(lock_sop, fp, open_stp);
-		if (lock_stp == NULL) {
-			release_stateowner(lock_sop);
+		if (lock_stp == NULL)
 			goto out;
-		}
 	} else {
 		/* lock (lock owner + lock stateid) already exists */
 		status = nfs4_preprocess_seqid_op(current_fh,
@@ -2815,7 +2813,7 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 		status = nfserr_deadlock;
 	default:        
 		dprintk("NFSD: nfsd4_lock: posix_lock_file() failed! status %d\n",status);
-		goto out_destroy_new_stateid;
+		goto out;
 	}
 
 conflicting_lock:
@@ -2829,17 +2827,9 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 		goto out;
 	}
 	nfs4_set_lock_denied(conflock, &amp;lock-&gt;lk_denied);
-
-out_destroy_new_stateid:
-	if (lock-&gt;lk_is_new) {
-		dprintk("NFSD: nfsd4_lock: destroy new stateid!\n");
-		/*
-		 * An error encountered after instantiation of the new
-		 * stateid has forced us to destroy it.
-		 */
-		release_state_owner(lock_stp, LOCK_STATE);
-	}
 out:
+	if (status &amp;&amp; lock-&gt;lk_is_new &amp;&amp; lock_sop)
+		release_stateowner(lock_sop);
 	if (lock-&gt;lk_stateowner) {
 		nfs4_get_stateowner(lock-&gt;lk_stateowner);
 		*replay_owner = lock-&gt;lk_stateowner;</pre><hr><pre>commit a6f6ef2f1d7329111fcad7db48fb7adba5062d0a
Author: Andy Adamson &lt;andros@citi.umich.edu&gt;
Date:   Wed Jan 18 17:43:17 2006 -0800

    [PATCH] nfsd4: misc lock fixes
    
    Logic fixes for LOCK and UNLOCK.
    
    - Move the permission check on the current file handle outside of
      nfs4_lock_state()
    
    - remove the file manager fl_release_private calls; fl_ops is not set.
    
    Signed-off-by: Andy Adamson &lt;andros@citi.umich.edu&gt;
    Signed-off-by: J. Bruce Fields &lt;bfields@citi.umich.edu&gt;
    Signed-off-by: Neil Brown &lt;neilb@suse.de&gt;
    Signed-off-by: Andrew Morton &lt;akpm@osdl.org&gt;
    Signed-off-by: Linus Torvalds &lt;torvalds@osdl.org&gt;

diff --git a/fs/nfsd/nfs4state.c b/fs/nfsd/nfs4state.c
index 6bbefd06f10d..3d4a2ec97caa 100644
--- a/fs/nfsd/nfs4state.c
+++ b/fs/nfsd/nfs4state.c
@@ -2700,6 +2700,11 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 	if (check_lock_length(lock-&gt;lk_offset, lock-&gt;lk_length))
 		 return nfserr_inval;
 
+	if ((status = fh_verify(rqstp, current_fh, S_IFREG, MAY_LOCK))) {
+		dprintk("NFSD: nfsd4_lock: permission denied!\n");
+		return status;
+	}
+
 	nfs4_lock_state();
 
 	if (lock-&gt;lk_is_new) {
@@ -2757,11 +2762,6 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 	/* lock-&gt;lk_stateowner and lock_stp have been created or found */
 	filp = lock_stp-&gt;st_vfs_file;
 
-	if ((status = fh_verify(rqstp, current_fh, S_IFREG, MAY_LOCK))) {
-		dprintk("NFSD: nfsd4_lock: permission denied!\n");
-		goto out;
-	}
-
 	status = nfserr_grace;
 	if (nfs4_in_grace() &amp;&amp; !lock-&gt;lk_reclaim)
 		goto out;
@@ -2802,8 +2802,6 @@ nfsd4_lock(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 	*/
 
 	status = posix_lock_file(filp, &amp;file_lock);
-	if (file_lock.fl_ops &amp;&amp; file_lock.fl_ops-&gt;fl_release_private)
-		file_lock.fl_ops-&gt;fl_release_private(&amp;file_lock);
 	dprintk("NFSD: nfsd4_lock: posix_lock_file status %d\n",status);
 	switch (-status) {
 	case 0: /* success! */
@@ -2977,8 +2975,6 @@ nfsd4_locku(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_lock
 	*  Try to unlock the file in the VFS.
 	*/
 	status = posix_lock_file(filp, &amp;file_lock); 
-	if (file_lock.fl_ops &amp;&amp; file_lock.fl_ops-&gt;fl_release_private)
-		file_lock.fl_ops-&gt;fl_release_private(&amp;file_lock);
 	if (status) {
 		dprintk("NFSD: nfs4_locku: posix_lock_file failed!\n");
 		goto out_nfserr;</pre><hr><pre>commit 1918e341383ab787d6c5b17200f4ed901b10c777
Author: J. Bruce Fields &lt;bfields@fieldses.org&gt;
Date:   Wed Jan 18 17:43:16 2006 -0800

    [PATCH] svcrpc: save and restore the daddr field when request deferred
    
    The server code currently keeps track of the destination address on every
    request so that it can reply using the same address.  However we forget to do
    that in the case of a deferred request.  Remedy this oversight.  &gt;From folks
    at PolyServe.
    
    Signed-off-by: J. Bruce Fields &lt;bfields@citi.umich.edu&gt;
    Signed-off-by: Neil Brown &lt;neilb@suse.de&gt;
    Signed-off-by: Andrew Morton &lt;akpm@osdl.org&gt;
    Signed-off-by: Linus Torvalds &lt;torvalds@osdl.org&gt;

diff --git a/include/linux/sunrpc/svc.h b/include/linux/sunrpc/svc.h
index e4086ec8b952..50cab2a09f28 100644
--- a/include/linux/sunrpc/svc.h
+++ b/include/linux/sunrpc/svc.h
@@ -246,6 +246,7 @@ struct svc_deferred_req {
 	u32			prot;	/* protocol (UDP or TCP) */
 	struct sockaddr_in	addr;
 	struct svc_sock		*svsk;	/* where reply must go */
+	u32			daddr;	/* where reply must come from */
 	struct cache_deferred_req handle;
 	int			argslen;
 	u32			args[0];
diff --git a/net/sunrpc/svcsock.c b/net/sunrpc/svcsock.c
index e67613e4eb18..50580620e897 100644
--- a/net/sunrpc/svcsock.c
+++ b/net/sunrpc/svcsock.c
@@ -1527,6 +1527,7 @@ svc_defer(struct cache_req *req)
 		dr-&gt;handle.owner = rqstp-&gt;rq_server;
 		dr-&gt;prot = rqstp-&gt;rq_prot;
 		dr-&gt;addr = rqstp-&gt;rq_addr;
+		dr-&gt;daddr = rqstp-&gt;rq_daddr;
 		dr-&gt;argslen = rqstp-&gt;rq_arg.len &gt;&gt; 2;
 		memcpy(dr-&gt;args, rqstp-&gt;rq_arg.head[0].iov_base-skip, dr-&gt;argslen&lt;&lt;2);
 	}
@@ -1552,6 +1553,7 @@ static int svc_deferred_recv(struct svc_rqst *rqstp)
 	rqstp-&gt;rq_arg.len = dr-&gt;argslen&lt;&lt;2;
 	rqstp-&gt;rq_prot        = dr-&gt;prot;
 	rqstp-&gt;rq_addr        = dr-&gt;addr;
+	rqstp-&gt;rq_daddr       = dr-&gt;daddr;
 	return dr-&gt;argslen&lt;&lt;2;
 }
 </pre><hr><pre>commit ad8e4b75c8a7bed475d72ce09bf5267188621961
Author: Martin Murray &lt;murrayma@citi.umich.edu&gt;
Date:   Tue Jan 10 13:02:29 2006 -0800

    [AF_NETLINK]: Fix DoS in netlink_rcv_skb()
    
    From: Martin Murray &lt;murrayma@citi.umich.edu&gt;
    
    Sanity check nlmsg_len during netlink_rcv_skb.  An nlmsg_len == 0 can
    cause infinite loop in kernel, effectively DoSing machine.  Noted by
    Matin Murray.
    
    Signed-off-by: Chris Wright &lt;chrisw@sous-sol.org&gt;
    Signed-off-by: David S. Miller &lt;davem@davemloft.net&gt;

diff --git a/net/netlink/af_netlink.c b/net/netlink/af_netlink.c
index a67f1b44c9a3..bb50c8a9fcad 100644
--- a/net/netlink/af_netlink.c
+++ b/net/netlink/af_netlink.c
@@ -1422,7 +1422,7 @@ static int netlink_rcv_skb(struct sk_buff *skb, int (*cb)(struct sk_buff *,
 	while (skb-&gt;len &gt;= nlmsg_total_size(0)) {
 		nlh = (struct nlmsghdr *) skb-&gt;data;
 
-		if (skb-&gt;len &lt; nlh-&gt;nlmsg_len)
+		if (nlh-&gt;nlmsg_len &lt; NLMSG_HDRLEN || skb-&gt;len &lt; nlh-&gt;nlmsg_len)
 			return 0;
 
 		total_len = min(NLMSG_ALIGN(nlh-&gt;nlmsg_len), skb-&gt;len);</pre><hr><pre>commit 6cd7525a00f3b926e8bd2e402954ed3e09a8e924
Author: Chuck Lever &lt;cel@citi.umich.edu&gt;
Date:   Thu Sep 22 21:24:59 2005 -0400

    SUNRPC: fix bug in patch "portmapper doesn't need a reserved port"
    
     The in-kernel portmapper does in fact need a reserved port when registering
     new services, but not when performing bind queries.
    
     Ensure that we distinguish between the two cases.
    
     Signed-off-by: Chuck Lever &lt;cel@netapp.com&gt;
     Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/net/sunrpc/pmap_clnt.c b/net/sunrpc/pmap_clnt.c
index d8e3f220002b..a398575f94b8 100644
--- a/net/sunrpc/pmap_clnt.c
+++ b/net/sunrpc/pmap_clnt.c
@@ -26,7 +26,7 @@
 #define PMAP_GETPORT		3
 
 static struct rpc_procinfo	pmap_procedures[];
-static struct rpc_clnt *	pmap_create(char *, struct sockaddr_in *, int);
+static struct rpc_clnt *	pmap_create(char *, struct sockaddr_in *, int, int);
 static void			pmap_getport_done(struct rpc_task *);
 static struct rpc_program	pmap_program;
 static DEFINE_SPINLOCK(pmap_lock);
@@ -65,7 +65,7 @@ rpc_getport(struct rpc_task *task, struct rpc_clnt *clnt)
 	map-&gt;pm_binding = 1;
 	spin_unlock(&amp;pmap_lock);
 
-	pmap_clnt = pmap_create(clnt-&gt;cl_server, sap, map-&gt;pm_prot);
+	pmap_clnt = pmap_create(clnt-&gt;cl_server, sap, map-&gt;pm_prot, 0);
 	if (IS_ERR(pmap_clnt)) {
 		task-&gt;tk_status = PTR_ERR(pmap_clnt);
 		goto bailout;
@@ -112,7 +112,7 @@ rpc_getport_external(struct sockaddr_in *sin, __u32 prog, __u32 vers, int prot)
 			NIPQUAD(sin-&gt;sin_addr.s_addr), prog, vers, prot);
 
 	sprintf(hostname, "%u.%u.%u.%u", NIPQUAD(sin-&gt;sin_addr.s_addr));
-	pmap_clnt = pmap_create(hostname, sin, prot);
+	pmap_clnt = pmap_create(hostname, sin, prot, 0);
 	if (IS_ERR(pmap_clnt))
 		return PTR_ERR(pmap_clnt);
 
@@ -171,7 +171,7 @@ rpc_register(u32 prog, u32 vers, int prot, unsigned short port, int *okay)
 
 	sin.sin_family = AF_INET;
 	sin.sin_addr.s_addr = htonl(INADDR_LOOPBACK);
-	pmap_clnt = pmap_create("localhost", &amp;sin, IPPROTO_UDP);
+	pmap_clnt = pmap_create("localhost", &amp;sin, IPPROTO_UDP, 1);
 	if (IS_ERR(pmap_clnt)) {
 		error = PTR_ERR(pmap_clnt);
 		dprintk("RPC: couldn't create pmap client. Error = %d\n", error);
@@ -198,7 +198,7 @@ rpc_register(u32 prog, u32 vers, int prot, unsigned short port, int *okay)
 }
 
 static struct rpc_clnt *
-pmap_create(char *hostname, struct sockaddr_in *srvaddr, int proto)
+pmap_create(char *hostname, struct sockaddr_in *srvaddr, int proto, int privileged)
 {
 	struct rpc_xprt	*xprt;
 	struct rpc_clnt	*clnt;
@@ -208,7 +208,8 @@ pmap_create(char *hostname, struct sockaddr_in *srvaddr, int proto)
 	if (IS_ERR(xprt))
 		return (struct rpc_clnt *)xprt;
 	xprt-&gt;addr.sin_port = htons(RPC_PMAP_PORT);
-	xprt-&gt;resvport = 0;
+	if (!privileged)
+		xprt-&gt;resvport = 0;
 
 	/* printk("pmap: create clnt\n"); */
 	clnt = rpc_new_client(xprt, hostname,</pre><hr><pre>commit 262965f53defd312a294b45366ea17907b6a616b
Author: Chuck Lever &lt;cel@citi.umich.edu&gt;
Date:   Thu Aug 11 16:25:56 2005 -0400

    [PATCH] RPC: separate TCP and UDP socket write paths
    
     Split the RPC client's main socket write path into a TCP version and a UDP
     version to eliminate another dependency on the "xprt-&gt;stream" variable.
    
     Compiler optimization removes unneeded code from xs_sendpages, as this
     function is now called with some constant arguments.
    
     We can now cleanly perform transport protocol-specific return code testing
     and error recovery in each path.
    
     Test-plan:
     Millions of fsx operations.  Performance characterization such as
     "sio" or "iozone".  Examine oprofile results for any changes before and
     after this patch is applied.
    
     Version: Thu, 11 Aug 2005 16:08:46 -0400
    
     Signed-off-by: Chuck Lever &lt;cel@netapp.com&gt;
     Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/net/sunrpc/xprtsock.c b/net/sunrpc/xprtsock.c
index f91529787b9b..57988300640a 100644
--- a/net/sunrpc/xprtsock.c
+++ b/net/sunrpc/xprtsock.c
@@ -40,6 +40,12 @@
  */
 #define XS_MAX_RESVPORT		(800U)
 
+/*
+ * How many times to try sending a request on a socket before waiting
+ * for the socket buffer to clear.
+ */
+#define XS_SENDMSG_RETRY	(10U)
+
 #ifdef RPC_DEBUG
 # undef  RPC_DEBUG_DATA
 # define RPCDBG_FACILITY	RPCDBG_TRANS
@@ -114,13 +120,18 @@ static int xs_send_tail(struct socket *sock, struct xdr_buf *xdr, unsigned int b
  * @base: starting position in the buffer
  *
  */
-static int xs_sendpages(struct socket *sock, struct sockaddr *addr, int addrlen, struct xdr_buf *xdr, unsigned int base)
+static inline int xs_sendpages(struct socket *sock, struct sockaddr *addr, int addrlen, struct xdr_buf *xdr, unsigned int base)
 {
 	struct page **ppage = xdr-&gt;pages;
 	unsigned int len, pglen = xdr-&gt;page_len;
 	int err, ret = 0;
 	ssize_t (*sendpage)(struct socket *, struct page *, int, size_t, int);
 
+	if (unlikely(!sock))
+		return -ENOTCONN;
+
+	clear_bit(SOCK_ASYNC_NOSPACE, &amp;sock-&gt;flags);
+
 	len = xdr-&gt;head[0].iov_len;
 	if (base &lt; len || (addr != NULL &amp;&amp; base == 0)) {
 		err = xs_send_head(sock, addr, addrlen, xdr, base, len);
@@ -187,140 +198,162 @@ static int xs_sendpages(struct socket *sock, struct sockaddr *addr, int addrlen,
 }
 
 /**
- * xs_sendmsg - write an RPC request to a socket
- * @xprt: generic transport
- * @req: the RPC request to write
+ * xs_nospace - place task on wait queue if transmit was incomplete
+ * @task: task to put to sleep
  *
  */
-static int xs_sendmsg(struct rpc_xprt *xprt, struct rpc_rqst *req)
+static void xs_nospace(struct rpc_task *task)
 {
-	struct socket *sock = xprt-&gt;sock;
-	struct xdr_buf *xdr = &amp;req-&gt;rq_snd_buf;
-	struct sockaddr *addr = NULL;
-	int addrlen = 0;
-	unsigned int skip;
-	int result;
+	struct rpc_rqst *req = task-&gt;tk_rqstp;
+	struct rpc_xprt *xprt = req-&gt;rq_xprt;
 
-	if (!sock)
-		return -ENOTCONN;
+	dprintk("RPC: %4d xmit incomplete (%u left of %u)\n",
+			task-&gt;tk_pid, req-&gt;rq_slen - req-&gt;rq_bytes_sent,
+			req-&gt;rq_slen);
+
+	if (test_bit(SOCK_ASYNC_NOSPACE, &amp;xprt-&gt;sock-&gt;flags)) {
+		/* Protect against races with write_space */
+		spin_lock_bh(&amp;xprt-&gt;transport_lock);
+
+		/* Don't race with disconnect */
+		if (!xprt_connected(xprt))
+			task-&gt;tk_status = -ENOTCONN;
+		else if (test_bit(SOCK_NOSPACE, &amp;xprt-&gt;sock-&gt;flags))
+			xprt_wait_for_buffer_space(task);
+
+		spin_unlock_bh(&amp;xprt-&gt;transport_lock);
+	} else
+		/* Keep holding the socket if it is blocked */
+		rpc_delay(task, HZ&gt;&gt;4);
+}
+
+/**
+ * xs_udp_send_request - write an RPC request to a UDP socket
+ * @task: address of RPC task that manages the state of an RPC request
+ *
+ * Return values:
+ *        0:	The request has been sent
+ *   EAGAIN:	The socket was blocked, please call again later to
+ *		complete the request
+ * ENOTCONN:	Caller needs to invoke connect logic then call again
+ *    other:	Some other error occured, the request was not sent
+ */
+static int xs_udp_send_request(struct rpc_task *task)
+{
+	struct rpc_rqst *req = task-&gt;tk_rqstp;
+	struct rpc_xprt *xprt = req-&gt;rq_xprt;
+	struct xdr_buf *xdr = &amp;req-&gt;rq_snd_buf;
+	int status;
 
 	xs_pktdump("packet data:",
 				req-&gt;rq_svec-&gt;iov_base,
 				req-&gt;rq_svec-&gt;iov_len);
 
-	/* For UDP, we need to provide an address */
-	if (!xprt-&gt;stream) {
-		addr = (struct sockaddr *) &amp;xprt-&gt;addr;
-		addrlen = sizeof(xprt-&gt;addr);
-	}
-	/* Don't repeat bytes */
-	skip = req-&gt;rq_bytes_sent;
+	req-&gt;rq_xtime = jiffies;
+	status = xs_sendpages(xprt-&gt;sock, (struct sockaddr *) &amp;xprt-&gt;addr,
+				sizeof(xprt-&gt;addr), xdr, req-&gt;rq_bytes_sent);
 
-	clear_bit(SOCK_ASYNC_NOSPACE, &amp;sock-&gt;flags);
-	result = xs_sendpages(sock, addr, addrlen, xdr, skip);
+	dprintk("RPC:      xs_udp_send_request(%u) = %d\n",
+			xdr-&gt;len - req-&gt;rq_bytes_sent, status);
 
-	dprintk("RPC:      xs_sendmsg(%d) = %d\n", xdr-&gt;len - skip, result);
+	if (likely(status &gt;= (int) req-&gt;rq_slen))
+		return 0;
 
-	if (result &gt;= 0)
-		return result;
+	/* Still some bytes left; set up for a retry later. */
+	if (status &gt; 0)
+		status = -EAGAIN;
 
-	switch (result) {
+	switch (status) {
+	case -ENETUNREACH:
+	case -EPIPE:
 	case -ECONNREFUSED:
 		/* When the server has died, an ICMP port unreachable message
 		 * prompts ECONNREFUSED. */
-	case -EAGAIN:
 		break;
-	case -ECONNRESET:
-	case -ENOTCONN:
-	case -EPIPE:
-		/* connection broken */
-		if (xprt-&gt;stream)
-			result = -ENOTCONN;
+	case -EAGAIN:
+		xs_nospace(task);
 		break;
 	default:
+		dprintk("RPC:      sendmsg returned unrecognized error %d\n",
+			-status);
 		break;
 	}
-	return result;
+
+	return status;
 }
 
 /**
- * xs_send_request - write an RPC request to a socket
+ * xs_tcp_send_request - write an RPC request to a TCP socket
  * @task: address of RPC task that manages the state of an RPC request
  *
  * Return values:
- *      0:  The request has been sent
- * EAGAIN:  The socket was blocked, please call again later to
- *          complete the request
- *  other:  Some other error occured, the request was not sent
+ *        0:	The request has been sent
+ *   EAGAIN:	The socket was blocked, please call again later to
+ *		complete the request
+ * ENOTCONN:	Caller needs to invoke connect logic then call again
+ *    other:	Some other error occured, the request was not sent
  *
  * XXX: In the case of soft timeouts, should we eventually give up
- *      if the socket is not able to make progress?
+ *	if sendmsg is not able to make progress?
  */
-static int xs_send_request(struct rpc_task *task)
+static int xs_tcp_send_request(struct rpc_task *task)
 {
 	struct rpc_rqst *req = task-&gt;tk_rqstp;
 	struct rpc_xprt *xprt = req-&gt;rq_xprt;
+	struct xdr_buf *xdr = &amp;req-&gt;rq_snd_buf;
+	u32 *marker = req-&gt;rq_svec[0].iov_base;
 	int status, retry = 0;
 
-	/* set up everything as needed. */
 	/* Write the record marker */
-	if (xprt-&gt;stream) {
-		u32 *marker = req-&gt;rq_svec[0].iov_base;
+	*marker = htonl(0x80000000|(req-&gt;rq_slen-sizeof(*marker)));
 
-		*marker = htonl(0x80000000|(req-&gt;rq_slen-sizeof(*marker)));
-	}
+	xs_pktdump("packet data:",
+				req-&gt;rq_svec-&gt;iov_base,
+				req-&gt;rq_svec-&gt;iov_len);
 
 	/* Continue transmitting the packet/record. We must be careful
 	 * to cope with writespace callbacks arriving _after_ we have
-	 * called sendmsg().
-	 */
+	 * called sendmsg(). */
 	while (1) {
 		req-&gt;rq_xtime = jiffies;
-		status = xs_sendmsg(xprt, req);
+		status = xs_sendpages(xprt-&gt;sock, NULL, 0, xdr,
+						req-&gt;rq_bytes_sent);
 
-		if (status &lt; 0)
-			break;
+		dprintk("RPC:      xs_tcp_send_request(%u) = %d\n",
+				xdr-&gt;len - req-&gt;rq_bytes_sent, status);
 
-		if (xprt-&gt;stream) {
-			req-&gt;rq_bytes_sent += status;
-
-			/* If we've sent the entire packet, immediately
-			 * reset the count of bytes sent. */
-			if (req-&gt;rq_bytes_sent &gt;= req-&gt;rq_slen) {
-				req-&gt;rq_bytes_sent = 0;
-				return 0;
-			}
-		} else {
-			if (status &gt;= req-&gt;rq_slen)
-				return 0;
-			status = -EAGAIN;
+		if (unlikely(status &lt; 0))
 			break;
-		}
 
-		dprintk("RPC: %4d xmit incomplete (%d left of %d)\n",
-				task-&gt;tk_pid, req-&gt;rq_slen - req-&gt;rq_bytes_sent,
-				req-&gt;rq_slen);
+		/* If we've sent the entire packet, immediately
+		 * reset the count of bytes sent. */
+		req-&gt;rq_bytes_sent += status;
+		if (likely(req-&gt;rq_bytes_sent &gt;= req-&gt;rq_slen)) {
+			req-&gt;rq_bytes_sent = 0;
+			return 0;
+		}
 
 		status = -EAGAIN;
-		if (retry++ &gt; 50)
+		if (retry++ &gt; XS_SENDMSG_RETRY)
 			break;
 	}
 
-	if (status == -EAGAIN) {
-		if (test_bit(SOCK_ASYNC_NOSPACE, &amp;xprt-&gt;sock-&gt;flags)) {
-			/* Protect against races with write_space */
-			spin_lock_bh(&amp;xprt-&gt;transport_lock);
-			/* Don't race with disconnect */
-			if (!xprt_connected(xprt))
-				task-&gt;tk_status = -ENOTCONN;
-			else if (test_bit(SOCK_NOSPACE, &amp;xprt-&gt;sock-&gt;flags))
-				xprt_wait_for_buffer_space(task);
-			spin_unlock_bh(&amp;xprt-&gt;transport_lock);
-			return status;
-		}
-		/* Keep holding the socket if it is blocked */
-		rpc_delay(task, HZ&gt;&gt;4);
+	switch (status) {
+	case -EAGAIN:
+		xs_nospace(task);
+		break;
+	case -ECONNREFUSED:
+	case -ECONNRESET:
+	case -ENOTCONN:
+	case -EPIPE:
+		status = -ENOTCONN;
+		break;
+	default:
+		dprintk("RPC:      sendmsg returned unrecognized error %d\n",
+			-status);
+		break;
 	}
+
 	return status;
 }
 
@@ -992,10 +1025,18 @@ static void xs_connect(struct rpc_task *task)
 	}
 }
 
-static struct rpc_xprt_ops xs_ops = {
+static struct rpc_xprt_ops xs_udp_ops = {
+	.set_buffer_size	= xs_set_buffer_size,
+	.connect		= xs_connect,
+	.send_request		= xs_udp_send_request,
+	.close			= xs_close,
+	.destroy		= xs_destroy,
+};
+
+static struct rpc_xprt_ops xs_tcp_ops = {
 	.set_buffer_size	= xs_set_buffer_size,
 	.connect		= xs_connect,
-	.send_request		= xs_send_request,
+	.send_request		= xs_tcp_send_request,
 	.close			= xs_close,
 	.destroy		= xs_destroy,
 };
@@ -1033,7 +1074,7 @@ int xs_setup_udp(struct rpc_xprt *xprt, struct rpc_timeout *to)
 
 	INIT_WORK(&amp;xprt-&gt;connect_worker, xs_udp_connect_worker, xprt);
 
-	xprt-&gt;ops = &amp;xs_ops;
+	xprt-&gt;ops = &amp;xs_udp_ops;
 
 	if (to)
 		xprt-&gt;timeout = *to;
@@ -1072,7 +1113,7 @@ int xs_setup_tcp(struct rpc_xprt *xprt, struct rpc_timeout *to)
 
 	INIT_WORK(&amp;xprt-&gt;connect_worker, xs_tcp_connect_worker, xprt);
 
-	xprt-&gt;ops = &amp;xs_ops;
+	xprt-&gt;ops = &amp;xs_tcp_ops;
 
 	if (to)
 		xprt-&gt;timeout = *to;</pre><hr><pre>commit b0d93ad511ce2f37823a07c7a3258117a431f5fb
Author: Chuck Lever &lt;cel@citi.umich.edu&gt;
Date:   Thu Aug 11 16:25:53 2005 -0400

    [PATCH] RPC: separate TCP and UDP transport connection logic
    
     Create separate connection worker functions for managing UDP and TCP
     transport sockets.  This eliminates several dependencies on "xprt-&gt;stream".
    
     Test-plan:
     Destructive testing (unplugging the network temporarily).  Connectathon with
     v2, v3, and v4.
    
     Version: Thu, 11 Aug 2005 16:08:18 -0400
    
     Signed-off-by: Chuck Lever &lt;cel@netapp.com&gt;
     Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/net/sunrpc/xprtsock.c b/net/sunrpc/xprtsock.c
index 70a772d7a796..f91529787b9b 100644
--- a/net/sunrpc/xprtsock.c
+++ b/net/sunrpc/xprtsock.c
@@ -836,102 +836,118 @@ static int xs_bindresvport(struct rpc_xprt *xprt, struct socket *sock)
 	return err;
 }
 
-static struct socket *xs_create(struct rpc_xprt *xprt, int proto, int resvport)
+/**
+ * xs_udp_connect_worker - set up a UDP socket
+ * @args: RPC transport to connect
+ *
+ * Invoked by a work queue tasklet.
+ */
+static void xs_udp_connect_worker(void *args)
 {
-	struct socket *sock;
-	int type, err;
-
-	dprintk("RPC:      xs_create(%s %d)\n",
-			   (proto == IPPROTO_UDP)? "udp" : "tcp", proto);
+	struct rpc_xprt *xprt = (struct rpc_xprt *) args;
+	struct socket *sock = xprt-&gt;sock;
+	int err, status = -EIO;
 
-	type = (proto == IPPROTO_UDP)? SOCK_DGRAM : SOCK_STREAM;
+	if (xprt-&gt;shutdown || xprt-&gt;addr.sin_port == 0)
+		goto out;
 
-	if ((err = sock_create_kern(PF_INET, type, proto, &amp;sock)) &lt; 0) {
-		dprintk("RPC:      can't create socket (%d).\n", -err);
-		return NULL;
-	}
+	dprintk("RPC:      xs_udp_connect_worker for xprt %p\n", xprt);
 
-	/* If the caller has the capability, bind to a reserved port */
-	if (resvport &amp;&amp; xs_bindresvport(xprt, sock) &lt; 0)
-		goto failed;
+	/* Start by resetting any existing state */
+	xs_close(xprt);
 
-	return sock;
+	if ((err = sock_create_kern(PF_INET, SOCK_DGRAM, IPPROTO_UDP, &amp;sock)) &lt; 0) {
+		dprintk("RPC:      can't create UDP transport socket (%d).\n", -err);
+		goto out;
+	}
 
-failed:
-	sock_release(sock);
-	return NULL;
-}
+	if (xprt-&gt;resvport &amp;&amp; xs_bindresvport(xprt, sock) &lt; 0) {
+		sock_release(sock);
+		goto out;
+	}
 
-static void xs_bind(struct rpc_xprt *xprt, struct socket *sock)
-{
-	struct sock *sk = sock-&gt;sk;
+	if (!xprt-&gt;inet) {
+		struct sock *sk = sock-&gt;sk;
 
-	if (xprt-&gt;inet)
-		return;
+		write_lock_bh(&amp;sk-&gt;sk_callback_lock);
 
-	write_lock_bh(&amp;sk-&gt;sk_callback_lock);
-	sk-&gt;sk_user_data = xprt;
-	xprt-&gt;old_data_ready = sk-&gt;sk_data_ready;
-	xprt-&gt;old_state_change = sk-&gt;sk_state_change;
-	xprt-&gt;old_write_space = sk-&gt;sk_write_space;
-	if (xprt-&gt;prot == IPPROTO_UDP) {
+		sk-&gt;sk_user_data = xprt;
+		xprt-&gt;old_data_ready = sk-&gt;sk_data_ready;
+		xprt-&gt;old_state_change = sk-&gt;sk_state_change;
+		xprt-&gt;old_write_space = sk-&gt;sk_write_space;
 		sk-&gt;sk_data_ready = xs_udp_data_ready;
 		sk-&gt;sk_write_space = xs_udp_write_space;
 		sk-&gt;sk_no_check = UDP_CSUM_NORCV;
+
 		xprt_set_connected(xprt);
-	} else {
-		tcp_sk(sk)-&gt;nonagle = 1;	/* disable Nagle's algorithm */
-		sk-&gt;sk_data_ready = xs_tcp_data_ready;
-		sk-&gt;sk_state_change = xs_tcp_state_change;
-		sk-&gt;sk_write_space = xs_tcp_write_space;
-		xprt_clear_connected(xprt);
-	}
 
-	/* Reset to new socket */
-	xprt-&gt;sock = sock;
-	xprt-&gt;inet = sk;
-	write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
+		/* Reset to new socket */
+		xprt-&gt;sock = sock;
+		xprt-&gt;inet = sk;
 
-	return;
+		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
+	}
+	xs_set_buffer_size(xprt);
+	status = 0;
+out:
+	xprt_wake_pending_tasks(xprt, status);
+	xprt_clear_connecting(xprt);
 }
 
 /**
- * xs_connect_worker - try to connect a socket to a remote endpoint
+ * xs_tcp_connect_worker - connect a TCP socket to a remote endpoint
  * @args: RPC transport to connect
  *
  * Invoked by a work queue tasklet.
  */
-static void xs_connect_worker(void *args)
+static void xs_tcp_connect_worker(void *args)
 {
 	struct rpc_xprt *xprt = (struct rpc_xprt *)args;
 	struct socket *sock = xprt-&gt;sock;
-	int status = -EIO;
+	int err, status = -EIO;
 
 	if (xprt-&gt;shutdown || xprt-&gt;addr.sin_port == 0)
 		goto out;
 
-	dprintk("RPC:      xs_connect_worker xprt %p\n", xprt);
+	dprintk("RPC:      xs_tcp_connect_worker for xprt %p\n", xprt);
 
-	/*
-	 * Start by resetting any existing state
-	 */
+	/* Start by resetting any existing socket state */
 	xs_close(xprt);
-	sock = xs_create(xprt, xprt-&gt;prot, xprt-&gt;resvport);
-	if (sock == NULL) {
-		/* couldn't create socket or bind to reserved port;
-		 * this is likely a permanent error, so cause an abort */
+
+	if ((err = sock_create_kern(PF_INET, SOCK_STREAM, IPPROTO_TCP, &amp;sock)) &lt; 0) {
+		dprintk("RPC:      can't create TCP transport socket (%d).\n", -err);
 		goto out;
 	}
-	xs_bind(xprt, sock);
-	xs_set_buffer_size(xprt);
 
-	status = 0;
-	if (!xprt-&gt;stream)
+	if (xprt-&gt;resvport &amp;&amp; xs_bindresvport(xprt, sock) &lt; 0) {
+		sock_release(sock);
 		goto out;
+	}
 
-	/*
-	 * Tell the socket layer to start connecting...
-	 */
+	if (!xprt-&gt;inet) {
+		struct sock *sk = sock-&gt;sk;
+
+		write_lock_bh(&amp;sk-&gt;sk_callback_lock);
+
+		sk-&gt;sk_user_data = xprt;
+		xprt-&gt;old_data_ready = sk-&gt;sk_data_ready;
+		xprt-&gt;old_state_change = sk-&gt;sk_state_change;
+		xprt-&gt;old_write_space = sk-&gt;sk_write_space;
+		sk-&gt;sk_data_ready = xs_tcp_data_ready;
+		sk-&gt;sk_state_change = xs_tcp_state_change;
+		sk-&gt;sk_write_space = xs_tcp_write_space;
+		tcp_sk(sk)-&gt;nonagle = 1;
+
+		xprt_clear_connected(xprt);
+
+		/* Reset to new socket */
+		xprt-&gt;sock = sock;
+		xprt-&gt;inet = sk;
+
+		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
+	}
+
+	/* Tell the socket layer to start connecting... */
 	status = sock-&gt;ops-&gt;connect(sock, (struct sockaddr *) &amp;xprt-&gt;addr,
 			sizeof(xprt-&gt;addr), O_NONBLOCK);
 	dprintk("RPC: %p  connect status %d connected %d sock state %d\n",
@@ -959,18 +975,20 @@ static void xs_connect(struct rpc_task *task)
 {
 	struct rpc_xprt *xprt = task-&gt;tk_xprt;
 
-	if (!xprt_test_and_set_connecting(xprt)) {
-		if (xprt-&gt;sock != NULL) {
-			dprintk("RPC:      xs_connect delayed xprt %p\n", xprt);
-			schedule_delayed_work(&amp;xprt-&gt;connect_worker,
+	if (xprt_test_and_set_connecting(xprt))
+		return;
+
+	if (xprt-&gt;sock != NULL) {
+		dprintk("RPC:      xs_connect delayed xprt %p\n", xprt);
+		schedule_delayed_work(&amp;xprt-&gt;connect_worker,
 					RPC_REESTABLISH_TIMEOUT);
-		} else {
-			dprintk("RPC:      xs_connect scheduled xprt %p\n", xprt);
-			schedule_work(&amp;xprt-&gt;connect_worker);
-			/* flush_scheduled_work can sleep... */
-			if (!RPC_IS_ASYNC(task))
-				flush_scheduled_work();
-		}
+	} else {
+		dprintk("RPC:      xs_connect scheduled xprt %p\n", xprt);
+		schedule_work(&amp;xprt-&gt;connect_worker);
+
+		/* flush_scheduled_work can sleep... */
+		if (!RPC_IS_ASYNC(task))
+			flush_scheduled_work();
 	}
 }
 
@@ -1013,7 +1031,7 @@ int xs_setup_udp(struct rpc_xprt *xprt, struct rpc_timeout *to)
 	/* XXX: header size can vary due to auth type, IPv6, etc. */
 	xprt-&gt;max_payload = (1U &lt;&lt; 16) - (MAX_HEADER &lt;&lt; 3);
 
-	INIT_WORK(&amp;xprt-&gt;connect_worker, xs_connect_worker, xprt);
+	INIT_WORK(&amp;xprt-&gt;connect_worker, xs_udp_connect_worker, xprt);
 
 	xprt-&gt;ops = &amp;xs_ops;
 
@@ -1052,7 +1070,7 @@ int xs_setup_tcp(struct rpc_xprt *xprt, struct rpc_timeout *to)
 	xprt-&gt;resvport = capable(CAP_NET_BIND_SERVICE) ? 1 : 0;
 	xprt-&gt;max_payload = (1U &lt;&lt; 31) - 1;
 
-	INIT_WORK(&amp;xprt-&gt;connect_worker, xs_connect_worker, xprt);
+	INIT_WORK(&amp;xprt-&gt;connect_worker, xs_tcp_connect_worker, xprt);
 
 	xprt-&gt;ops = &amp;xs_ops;
 </pre><hr><pre>commit c7b2cae8a634015b72941ba2fc6c4bc9b8d3a129
Author: Chuck Lever &lt;cel@citi.umich.edu&gt;
Date:   Thu Aug 11 16:25:50 2005 -0400

    [PATCH] RPC: separate TCP and UDP write space callbacks
    
     Split the socket write space callback function into a TCP version and UDP
     version, eliminating one dependence on the "xprt-&gt;stream" variable.
    
     Keep the common pieces of this path in xprt.c so other transports can use
     it too.
    
     Test-plan:
     Write-intensive workload on a single mount point.
    
     Version: Thu, 11 Aug 2005 16:07:51 -0400
    
     Signed-off-by: Chuck Lever &lt;cel@netapp.com&gt;
     Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/include/linux/sunrpc/xprt.h b/include/linux/sunrpc/xprt.h
index bfbc492ae36d..e73174c7e450 100644
--- a/include/linux/sunrpc/xprt.h
+++ b/include/linux/sunrpc/xprt.h
@@ -240,6 +240,8 @@ int			xprt_destroy(struct rpc_xprt *xprt);
  * Transport switch helper functions
  */
 void			xprt_wake_pending_tasks(struct rpc_xprt *xprt, int status);
+void			xprt_wait_for_buffer_space(struct rpc_task *task);
+void			xprt_write_space(struct rpc_xprt *xprt);
 struct rpc_rqst *	xprt_lookup_rqst(struct rpc_xprt *xprt, u32 xid);
 void			xprt_complete_rqst(struct rpc_xprt *xprt, struct rpc_rqst *req, int copied);
 void			xprt_disconnect(struct rpc_xprt *xprt);
diff --git a/net/sunrpc/xprt.c b/net/sunrpc/xprt.c
index 247fa1ec870c..31ef7dc7eed6 100644
--- a/net/sunrpc/xprt.c
+++ b/net/sunrpc/xprt.c
@@ -241,6 +241,40 @@ void xprt_wake_pending_tasks(struct rpc_xprt *xprt, int status)
 		rpc_wake_up(&amp;xprt-&gt;pending);
 }
 
+/**
+ * xprt_wait_for_buffer_space - wait for transport output buffer to clear
+ * @task: task to be put to sleep
+ *
+ */
+void xprt_wait_for_buffer_space(struct rpc_task *task)
+{
+	struct rpc_rqst *req = task-&gt;tk_rqstp;
+	struct rpc_xprt *xprt = req-&gt;rq_xprt;
+
+	task-&gt;tk_timeout = req-&gt;rq_timeout;
+	rpc_sleep_on(&amp;xprt-&gt;pending, task, NULL, NULL);
+}
+
+/**
+ * xprt_write_space - wake the task waiting for transport output buffer space
+ * @xprt: transport with waiting tasks
+ *
+ * Can be called in a soft IRQ context, so xprt_write_space never sleeps.
+ */
+void xprt_write_space(struct rpc_xprt *xprt)
+{
+	if (unlikely(xprt-&gt;shutdown))
+		return;
+
+	spin_lock_bh(&amp;xprt-&gt;transport_lock);
+	if (xprt-&gt;snd_task) {
+		dprintk("RPC:      write space: waking waiting task on xprt %p\n",
+				xprt);
+		rpc_wake_up_task(xprt-&gt;snd_task);
+	}
+	spin_unlock_bh(&amp;xprt-&gt;transport_lock);
+}
+
 static void xprt_reset_majortimeo(struct rpc_rqst *req)
 {
 	struct rpc_timeout *to = &amp;req-&gt;rq_xprt-&gt;timeout;
diff --git a/net/sunrpc/xprtsock.c b/net/sunrpc/xprtsock.c
index 7f0b9f7f167b..70a772d7a796 100644
--- a/net/sunrpc/xprtsock.c
+++ b/net/sunrpc/xprtsock.c
@@ -308,15 +308,13 @@ static int xs_send_request(struct rpc_task *task)
 
 	if (status == -EAGAIN) {
 		if (test_bit(SOCK_ASYNC_NOSPACE, &amp;xprt-&gt;sock-&gt;flags)) {
-			/* Protect against races with xs_write_space */
+			/* Protect against races with write_space */
 			spin_lock_bh(&amp;xprt-&gt;transport_lock);
 			/* Don't race with disconnect */
 			if (!xprt_connected(xprt))
 				task-&gt;tk_status = -ENOTCONN;
-			else if (test_bit(SOCK_NOSPACE, &amp;xprt-&gt;sock-&gt;flags)) {
-				task-&gt;tk_timeout = req-&gt;rq_timeout;
-				rpc_sleep_on(&amp;xprt-&gt;pending, task, NULL, NULL);
-			}
+			else if (test_bit(SOCK_NOSPACE, &amp;xprt-&gt;sock-&gt;flags))
+				xprt_wait_for_buffer_space(task);
 			spin_unlock_bh(&amp;xprt-&gt;transport_lock);
 			return status;
 		}
@@ -721,45 +719,68 @@ static void xs_tcp_state_change(struct sock *sk)
 }
 
 /**
- * xs_write_space - callback invoked when socket buffer space becomes
- *                         available
+ * xs_udp_write_space - callback invoked when socket buffer space
+ *                             becomes available
  * @sk: socket whose state has changed
  *
  * Called when more output buffer space is available for this socket.
  * We try not to wake our writers until they can make "significant"
- * progress, otherwise we'll waste resources thrashing sock_sendmsg
+ * progress, otherwise we'll waste resources thrashing kernel_sendmsg
  * with a bunch of small requests.
  */
-static void xs_write_space(struct sock *sk)
+static void xs_udp_write_space(struct sock *sk)
 {
-	struct rpc_xprt *xprt;
-	struct socket *sock;
-
 	read_lock(&amp;sk-&gt;sk_callback_lock);
-	if (!(xprt = xprt_from_sock(sk)) || !(sock = sk-&gt;sk_socket))
-		goto out;
-	if (xprt-&gt;shutdown)
-		goto out;
 
-	/* Wait until we have enough socket memory */
-	if (xprt-&gt;stream) {
-		/* from net/core/stream.c:sk_stream_write_space */
-		if (sk_stream_wspace(sk) &lt; sk_stream_min_wspace(sk))
+	/* from net/core/sock.c:sock_def_write_space */
+	if (sock_writeable(sk)) {
+		struct socket *sock;
+		struct rpc_xprt *xprt;
+
+		if (unlikely(!(sock = sk-&gt;sk_socket)))
 			goto out;
-	} else {
-		/* from net/core/sock.c:sock_def_write_space */
-		if (!sock_writeable(sk))
+		if (unlikely(!(xprt = xprt_from_sock(sk))))
+			goto out;
+		if (unlikely(!test_and_clear_bit(SOCK_NOSPACE, &amp;sock-&gt;flags)))
 			goto out;
+
+		xprt_write_space(xprt);
 	}
 
-	if (!test_and_clear_bit(SOCK_NOSPACE, &amp;sock-&gt;flags))
-		goto out;
+ out:
+	read_unlock(&amp;sk-&gt;sk_callback_lock);
+}
 
-	spin_lock_bh(&amp;xprt-&gt;transport_lock);
-	if (xprt-&gt;snd_task)
-		rpc_wake_up_task(xprt-&gt;snd_task);
-	spin_unlock_bh(&amp;xprt-&gt;transport_lock);
-out:
+/**
+ * xs_tcp_write_space - callback invoked when socket buffer space
+ *                             becomes available
+ * @sk: socket whose state has changed
+ *
+ * Called when more output buffer space is available for this socket.
+ * We try not to wake our writers until they can make "significant"
+ * progress, otherwise we'll waste resources thrashing kernel_sendmsg
+ * with a bunch of small requests.
+ */
+static void xs_tcp_write_space(struct sock *sk)
+{
+	read_lock(&amp;sk-&gt;sk_callback_lock);
+
+	/* from net/core/stream.c:sk_stream_write_space */
+	if (sk_stream_wspace(sk) &gt;= sk_stream_min_wspace(sk)) {
+		struct socket *sock;
+		struct rpc_xprt *xprt;
+
+		if (unlikely(!(sock = sk-&gt;sk_socket)))
+			goto out;
+		if (unlikely(!(xprt = xprt_from_sock(sk))))
+			goto out;
+		if (unlikely(!test_and_clear_bit(SOCK_NOSPACE, &amp;sock-&gt;flags)))
+			goto out;
+
+		xprt_write_space(xprt);
+	}
+
+ out:
 	read_unlock(&amp;sk-&gt;sk_callback_lock);
 }
 
@@ -855,15 +876,16 @@ static void xs_bind(struct rpc_xprt *xprt, struct socket *sock)
 	xprt-&gt;old_write_space = sk-&gt;sk_write_space;
 	if (xprt-&gt;prot == IPPROTO_UDP) {
 		sk-&gt;sk_data_ready = xs_udp_data_ready;
+		sk-&gt;sk_write_space = xs_udp_write_space;
 		sk-&gt;sk_no_check = UDP_CSUM_NORCV;
 		xprt_set_connected(xprt);
 	} else {
 		tcp_sk(sk)-&gt;nonagle = 1;	/* disable Nagle's algorithm */
 		sk-&gt;sk_data_ready = xs_tcp_data_ready;
 		sk-&gt;sk_state_change = xs_tcp_state_change;
+		sk-&gt;sk_write_space = xs_tcp_write_space;
 		xprt_clear_connected(xprt);
 	}
-	sk-&gt;sk_write_space = xs_write_space;
 
 	/* Reset to new socket */
 	xprt-&gt;sock = sock;</pre><hr><pre>commit 55aa4f58aa43dc9a51fb80010630d94b96053a2e
Author: Chuck Lever &lt;cel@citi.umich.edu&gt;
Date:   Thu Aug 11 16:25:47 2005 -0400

    [PATCH] RPC: client-side transport switch cleanup
    
     Clean-up: change some comments to reflect the realities of the new RPC
     transport switch mechanism.  Get rid of unused xprt_receive() prototype.
    
     Also, organize function prototypes in xprt.h by usage and scope.
    
     Test-plan:
     Compile kernel with CONFIG_NFS enabled.
    
     Version: Thu, 11 Aug 2005 16:07:21 -0400
    
     Signed-off-by: Chuck Lever &lt;cel@netapp.com&gt;
     Signed-off-by: Trond Myklebust &lt;Trond.Myklebust@netapp.com&gt;

diff --git a/include/linux/sunrpc/xprt.h b/include/linux/sunrpc/xprt.h
index d5223993fca9..bfbc492ae36d 100644
--- a/include/linux/sunrpc/xprt.h
+++ b/include/linux/sunrpc/xprt.h
@@ -1,5 +1,5 @@
 /*
- *  linux/include/linux/sunrpc/clnt_xprt.h
+ *  linux/include/linux/sunrpc/xprt.h
  *
  *  Declarations for the RPC transport interface.
  *
@@ -150,8 +150,8 @@ struct rpc_xprt {
 	unsigned long		cong;		/* current congestion */
 	unsigned long		cwnd;		/* congestion window */
 
-	unsigned int		rcvsize,	/* socket receive buffer size */
-				sndsize;	/* socket send buffer size */
+	unsigned int		rcvsize,	/* transport rcv buffer size */
+				sndsize;	/* transport send buffer size */
 
 	size_t			max_payload;	/* largest RPC payload size,
 						   in bytes */
@@ -184,12 +184,12 @@ struct rpc_xprt {
 	unsigned long		tcp_copied,	/* copied to request */
 				tcp_flags;
 	/*
-	 * Connection of sockets
+	 * Connection of transports
 	 */
-	struct work_struct	sock_connect;
+	struct work_struct	connect_worker;
 	unsigned short		port;
 	/*
-	 * Disconnection of idle sockets
+	 * Disconnection of idle transports
 	 */
 	struct work_struct	task_cleanup;
 	struct timer_list	timer;
@@ -219,27 +219,36 @@ struct rpc_xprt {
 
 #ifdef __KERNEL__
 
-struct rpc_xprt *	xprt_create_proto(int proto, struct sockaddr_in *addr,
-					struct rpc_timeout *toparms);
-void			xprt_disconnect(struct rpc_xprt *);
-int			xprt_destroy(struct rpc_xprt *);
-void			xprt_set_timeout(struct rpc_timeout *, unsigned int,
-					unsigned long);
-struct rpc_rqst *	xprt_lookup_rqst(struct rpc_xprt *, u32);
-void			xprt_complete_rqst(struct rpc_xprt *,
-					struct rpc_rqst *, int);
-void			xprt_reserve(struct rpc_task *);
-int			xprt_prepare_transmit(struct rpc_task *);
-void			xprt_transmit(struct rpc_task *);
-void			xprt_receive(struct rpc_task *);
-void			xprt_wake_pending_tasks(struct rpc_xprt *, int);
+/*
+ * Transport operations used by ULPs
+ */
+struct rpc_xprt *	xprt_create_proto(int proto, struct sockaddr_in *addr, struct rpc_timeout *to);
+void			xprt_set_timeout(struct rpc_timeout *to, unsigned int retr, unsigned long incr);
+
+/*
+ * Generic internal transport functions
+ */
+void			xprt_connect(struct rpc_task *task);
+void			xprt_reserve(struct rpc_task *task);
+int			xprt_prepare_transmit(struct rpc_task *task);
+void			xprt_transmit(struct rpc_task *task);
 int			xprt_adjust_timeout(struct rpc_rqst *req);
-void			xprt_release(struct rpc_task *);
-void			xprt_connect(struct rpc_task *);
-int			xs_setup_udp(struct rpc_xprt *,
-					struct rpc_timeout *);
-int			xs_setup_tcp(struct rpc_xprt *,
-					struct rpc_timeout *);
+void			xprt_release(struct rpc_task *task);
+int			xprt_destroy(struct rpc_xprt *xprt);
+
+/*
+ * Transport switch helper functions
+ */
+void			xprt_wake_pending_tasks(struct rpc_xprt *xprt, int status);
+struct rpc_rqst *	xprt_lookup_rqst(struct rpc_xprt *xprt, u32 xid);
+void			xprt_complete_rqst(struct rpc_xprt *xprt, struct rpc_rqst *req, int copied);
+void			xprt_disconnect(struct rpc_xprt *xprt);
+
+/*
+ * Socket transport setup operations
+ */
+int			xs_setup_udp(struct rpc_xprt *xprt, struct rpc_timeout *to);
+int			xs_setup_tcp(struct rpc_xprt *xprt, struct rpc_timeout *to);
 
 /*
  * Reserved bit positions in xprt-&gt;state
diff --git a/net/sunrpc/clnt.c b/net/sunrpc/clnt.c
index 0d1b010a4a01..4677959d2834 100644
--- a/net/sunrpc/clnt.c
+++ b/net/sunrpc/clnt.c
@@ -1,5 +1,5 @@
 /*
- *  linux/net/sunrpc/rpcclnt.c
+ *  linux/net/sunrpc/clnt.c
  *
  *  This file contains the high-level RPC interface.
  *  It is modeled as a finite state machine to support both synchronous
diff --git a/net/sunrpc/xprt.c b/net/sunrpc/xprt.c
index 2f9cd468b953..247fa1ec870c 100644
--- a/net/sunrpc/xprt.c
+++ b/net/sunrpc/xprt.c
@@ -10,12 +10,12 @@
  *	one is available. Otherwise, it sleeps on the backlog queue
  *	(xprt_reserve).
  *  -	Next, the caller puts together the RPC message, stuffs it into
- *	the request struct, and calls xprt_call().
- *  -	xprt_call transmits the message and installs the caller on the
- *	socket's wait list. At the same time, it installs a timer that
+ *	the request struct, and calls xprt_transmit().
+ *  -	xprt_transmit sends the message and installs the caller on the
+ *	transport's wait list. At the same time, it installs a timer that
  *	is run after the packet's timeout has expired.
  *  -	When a packet arrives, the data_ready handler walks the list of
- *	pending requests for that socket. If a matching XID is found, the
+ *	pending requests for that transport. If a matching XID is found, the
  *	caller is woken up, and the timer removed.
  *  -	When no reply arrives within the timeout interval, the timer is
  *	fired by the kernel and runs xprt_timer(). It either adjusts the
@@ -32,6 +32,8 @@
  *  tasks that rely on callbacks.
  *
  *  Copyright (C) 1995-1997, Olaf Kirch &lt;okir@monad.swb.de&gt;
+ *
+ *  Transport switch API copyright (C) 2005, Chuck Lever &lt;cel@netapp.com&gt;
  */
 
 #include &lt;linux/module.h&gt;
@@ -52,8 +54,6 @@
 # define RPCDBG_FACILITY	RPCDBG_XPRT
 #endif
 
-#define XPRT_MAX_BACKOFF	(8)
-
 /*
  * Local functions
  */
@@ -65,9 +65,9 @@ static int      __xprt_get_cong(struct rpc_xprt *, struct rpc_task *);
 static int	xprt_clear_backlog(struct rpc_xprt *xprt);
 
 /*
- * Serialize write access to sockets, in order to prevent different
+ * Serialize write access to transports, in order to prevent different
  * requests from interfering with each other.
- * Also prevents TCP socket connects from colliding with writes.
+ * Also prevents transport connects from colliding with writes.
  */
 static int
 __xprt_lock_write(struct rpc_xprt *xprt, struct rpc_task *task)
@@ -91,7 +91,7 @@ __xprt_lock_write(struct rpc_xprt *xprt, struct rpc_task *task)
 	clear_bit(XPRT_LOCKED, &amp;xprt-&gt;state);
 	smp_mb__after_clear_bit();
 out_sleep:
-	dprintk("RPC: %4d failed to lock socket %p\n", task-&gt;tk_pid, xprt);
+	dprintk("RPC: %4d failed to lock transport %p\n", task-&gt;tk_pid, xprt);
 	task-&gt;tk_timeout = 0;
 	task-&gt;tk_status = -EAGAIN;
 	if (req &amp;&amp; req-&gt;rq_ntrans)
@@ -144,7 +144,7 @@ __xprt_lock_write_next(struct rpc_xprt *xprt)
 }
 
 /*
- * Releases the socket for use by other requests.
+ * Releases the transport for use by other requests.
  */
 static void
 __xprt_release_write(struct rpc_xprt *xprt, struct rpc_task *task)
@@ -294,8 +294,7 @@ int xprt_adjust_timeout(struct rpc_rqst *req)
 	return status;
 }
 
-static void
-xprt_socket_autoclose(void *args)
+static void xprt_autoclose(void *args)
 {
 	struct rpc_xprt *xprt = (struct rpc_xprt *)args;
 
@@ -329,7 +328,6 @@ xprt_init_autodisconnect(unsigned long data)
 	if (test_and_set_bit(XPRT_LOCKED, &amp;xprt-&gt;state))
 		goto out_abort;
 	spin_unlock(&amp;xprt-&gt;transport_lock);
-	/* Let keventd close the socket */
 	if (xprt_connecting(xprt))
 		xprt_release_write(xprt, NULL);
 	else
@@ -770,7 +768,7 @@ static struct rpc_xprt *xprt_setup(int proto, struct sockaddr_in *ap, struct rpc
 
 	INIT_LIST_HEAD(&amp;xprt-&gt;free);
 	INIT_LIST_HEAD(&amp;xprt-&gt;recv);
-	INIT_WORK(&amp;xprt-&gt;task_cleanup, xprt_socket_autoclose, xprt);
+	INIT_WORK(&amp;xprt-&gt;task_cleanup, xprt_autoclose, xprt);
 	init_timer(&amp;xprt-&gt;timer);
 	xprt-&gt;timer.function = xprt_init_autodisconnect;
 	xprt-&gt;timer.data = (unsigned long) xprt;
diff --git a/net/sunrpc/xprtsock.c b/net/sunrpc/xprtsock.c
index 182da2edf61c..7f0b9f7f167b 100644
--- a/net/sunrpc/xprtsock.c
+++ b/net/sunrpc/xprtsock.c
@@ -11,6 +11,8 @@
  * Rewrite of larges part of the code in order to stabilize TCP stuff.
  * Fix behaviour when socket buffer is full.
  *  (C) 1999 Trond Myklebust &lt;trond.myklebust@fys.uio.no&gt;
+ *
+ * IP socket transport implementation, (C) 2005 Chuck Lever &lt;cel@netapp.com&gt;
  */
 
 #include &lt;linux/types.h&gt;
@@ -363,7 +365,7 @@ static void xs_destroy(struct rpc_xprt *xprt)
 {
 	dprintk("RPC:      xs_destroy xprt %p\n", xprt);
 
-	cancel_delayed_work(&amp;xprt-&gt;sock_connect);
+	cancel_delayed_work(&amp;xprt-&gt;connect_worker);
 	flush_scheduled_work();
 
 	xprt_disconnect(xprt);
@@ -938,11 +940,11 @@ static void xs_connect(struct rpc_task *task)
 	if (!xprt_test_and_set_connecting(xprt)) {
 		if (xprt-&gt;sock != NULL) {
 			dprintk("RPC:      xs_connect delayed xprt %p\n", xprt);
-			schedule_delayed_work(&amp;xprt-&gt;sock_connect,
+			schedule_delayed_work(&amp;xprt-&gt;connect_worker,
 					RPC_REESTABLISH_TIMEOUT);
 		} else {
 			dprintk("RPC:      xs_connect scheduled xprt %p\n", xprt);
-			schedule_work(&amp;xprt-&gt;sock_connect);
+			schedule_work(&amp;xprt-&gt;connect_worker);
 			/* flush_scheduled_work can sleep... */
 			if (!RPC_IS_ASYNC(task))
 				flush_scheduled_work();
@@ -989,7 +991,7 @@ int xs_setup_udp(struct rpc_xprt *xprt, struct rpc_timeout *to)
 	/* XXX: header size can vary due to auth type, IPv6, etc. */
 	xprt-&gt;max_payload = (1U &lt;&lt; 16) - (MAX_HEADER &lt;&lt; 3);
 
-	INIT_WORK(&amp;xprt-&gt;sock_connect, xs_connect_worker, xprt);
+	INIT_WORK(&amp;xprt-&gt;connect_worker, xs_connect_worker, xprt);
 
 	xprt-&gt;ops = &amp;xs_ops;
 
@@ -1028,7 +1030,7 @@ int xs_setup_tcp(struct rpc_xprt *xprt, struct rpc_timeout *to)
 	xprt-&gt;resvport = capable(CAP_NET_BIND_SERVICE) ? 1 : 0;
 	xprt-&gt;max_payload = (1U &lt;&lt; 31) - 1;
 
-	INIT_WORK(&amp;xprt-&gt;sock_connect, xs_connect_worker, xprt);
+	INIT_WORK(&amp;xprt-&gt;connect_worker, xs_connect_worker, xprt);
 
 	xprt-&gt;ops = &amp;xs_ops;
 </pre>
    <div class="pagination">
        <a href='4_52.html'>&lt;&lt;Prev</a><a href='4.html'>1</a><a href='4_2.html'>2</a><a href='4_3.html'>3</a><a href='4_4.html'>4</a><a href='4_5.html'>5</a><a href='4_6.html'>6</a><a href='4_7.html'>7</a><a href='4_8.html'>8</a><a href='4_9.html'>9</a><a href='4_10.html'>10</a><a href='4_11.html'>11</a><a href='4_12.html'>12</a><a href='4_13.html'>13</a><a href='4_14.html'>14</a><a href='4_15.html'>15</a><a href='4_16.html'>16</a><a href='4_17.html'>17</a><a href='4_18.html'>18</a><a href='4_19.html'>19</a><a href='4_20.html'>20</a><a href='4_21.html'>21</a><a href='4_22.html'>22</a><a href='4_23.html'>23</a><a href='4_24.html'>24</a><a href='4_25.html'>25</a><a href='4_26.html'>26</a><a href='4_27.html'>27</a><a href='4_28.html'>28</a><a href='4_29.html'>29</a><a href='4_30.html'>30</a><a href='4_31.html'>31</a><a href='4_32.html'>32</a><a href='4_33.html'>33</a><a href='4_34.html'>34</a><a href='4_35.html'>35</a><a href='4_36.html'>36</a><a href='4_37.html'>37</a><a href='4_38.html'>38</a><a href='4_39.html'>39</a><a href='4_40.html'>40</a><a href='4_41.html'>41</a><a href='4_42.html'>42</a><a href='4_43.html'>43</a><a href='4_44.html'>44</a><a href='4_45.html'>45</a><a href='4_46.html'>46</a><a href='4_47.html'>47</a><a href='4_48.html'>48</a><a href='4_49.html'>49</a><a href='4_50.html'>50</a><a href='4_51.html'>51</a><a href='4_52.html'>52</a><span>[53]</span><a href='4_54.html'>54</a><a href='4_55.html'>55</a><a href='4_56.html'>56</a><a href='4_57.html'>57</a><a href='4_54.html'>Next&gt;&gt;</a>
    <div>
</body>
