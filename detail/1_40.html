<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Massachusetts Institute of Technology</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Massachusetts Institute of Technology</h1>
    <div class="pagination">
        <a href='1_39.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><span>[40]</span><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_41.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit cff850312cc7c0e0b9fe8b573687812dea232031
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Jun 10 23:18:16 2014 -0400

    random: only update the last_pulled time if we actually transferred entropy
    
    In xfer_secondary_pull(), check to make sure we need to pull from the
    secondary pool before checking and potentially updating the
    last_pulled time.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: George Spelvin &lt;linux@horizon.com&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index bc0de22f31f4..364a8001a2bd 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -920,6 +920,11 @@ static ssize_t extract_entropy(struct entropy_store *r, void *buf,
 static void _xfer_secondary_pool(struct entropy_store *r, size_t nbytes);
 static void xfer_secondary_pool(struct entropy_store *r, size_t nbytes)
 {
+	if (!r-&gt;pull ||
+	    r-&gt;entropy_count &gt;= (nbytes &lt;&lt; (ENTROPY_SHIFT + 3)) ||
+	    r-&gt;entropy_count &gt; r-&gt;poolinfo-&gt;poolfracbits)
+		return;
+
 	if (r-&gt;limit == 0 &amp;&amp; random_min_urandom_seed) {
 		unsigned long now = jiffies;
 
@@ -928,10 +933,8 @@ static void xfer_secondary_pool(struct entropy_store *r, size_t nbytes)
 			return;
 		r-&gt;last_pulled = now;
 	}
-	if (r-&gt;pull &amp;&amp;
-	    r-&gt;entropy_count &lt; (nbytes &lt;&lt; (ENTROPY_SHIFT + 3)) &amp;&amp;
-	    r-&gt;entropy_count &lt; r-&gt;poolinfo-&gt;poolfracbits)
-		_xfer_secondary_pool(r, nbytes);
+
+	_xfer_secondary_pool(r, nbytes);
 }
 
 static void _xfer_secondary_pool(struct entropy_store *r, size_t nbytes)</pre><hr><pre>commit 85608f8e16c28f818f6bb9918958d231afa8bec2
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Jun 10 23:09:20 2014 -0400

    random: remove unneeded hash of a portion of the entropy pool
    
    We previously extracted a portion of the entropy pool in
    mix_pool_bytes() and hashed it in to avoid racing CPU's from returning
    duplicate random values.  Now that we are using a spinlock to prevent
    this from happening, this is no longer necessary.  So remove it, to
    simplify the code a bit.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: George Spelvin &lt;linux@horizon.com&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index 922a2e4089f9..bc0de22f31f4 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -481,9 +481,9 @@ static __u32 const twist_table[8] = {
  * the entropy is concentrated in the low-order bits.
  */
 static void _mix_pool_bytes(struct entropy_store *r, const void *in,
-			    int nbytes, __u8 out[64])
+			    int nbytes)
 {
-	unsigned long i, j, tap1, tap2, tap3, tap4, tap5;
+	unsigned long i, tap1, tap2, tap3, tap4, tap5;
 	int input_rotate;
 	int wordmask = r-&gt;poolinfo-&gt;poolwords - 1;
 	const char *bytes = in;
@@ -525,27 +525,23 @@ static void _mix_pool_bytes(struct entropy_store *r, const void *in,
 
 	r-&gt;input_rotate = input_rotate;
 	r-&gt;add_ptr = i;
-
-	if (out)
-		for (j = 0; j &lt; 16; j++)
-			((__u32 *)out)[j] = r-&gt;pool[(i - j) &amp; wordmask];
 }
 
 static void __mix_pool_bytes(struct entropy_store *r, const void *in,
-			     int nbytes, __u8 out[64])
+			     int nbytes)
 {
 	trace_mix_pool_bytes_nolock(r-&gt;name, nbytes, _RET_IP_);
-	_mix_pool_bytes(r, in, nbytes, out);
+	_mix_pool_bytes(r, in, nbytes);
 }
 
 static void mix_pool_bytes(struct entropy_store *r, const void *in,
-			   int nbytes, __u8 out[64])
+			   int nbytes)
 {
 	unsigned long flags;
 
 	trace_mix_pool_bytes(r-&gt;name, nbytes, _RET_IP_);
 	spin_lock_irqsave(&amp;r-&gt;lock, flags);
-	_mix_pool_bytes(r, in, nbytes, out);
+	_mix_pool_bytes(r, in, nbytes);
 	spin_unlock_irqrestore(&amp;r-&gt;lock, flags);
 }
 
@@ -737,13 +733,13 @@ void add_device_randomness(const void *buf, unsigned int size)
 
 	trace_add_device_randomness(size, _RET_IP_);
 	spin_lock_irqsave(&amp;input_pool.lock, flags);
-	_mix_pool_bytes(&amp;input_pool, buf, size, NULL);
-	_mix_pool_bytes(&amp;input_pool, &amp;time, sizeof(time), NULL);
+	_mix_pool_bytes(&amp;input_pool, buf, size);
+	_mix_pool_bytes(&amp;input_pool, &amp;time, sizeof(time));
 	spin_unlock_irqrestore(&amp;input_pool.lock, flags);
 
 	spin_lock_irqsave(&amp;nonblocking_pool.lock, flags);
-	_mix_pool_bytes(&amp;nonblocking_pool, buf, size, NULL);
-	_mix_pool_bytes(&amp;nonblocking_pool, &amp;time, sizeof(time), NULL);
+	_mix_pool_bytes(&amp;nonblocking_pool, buf, size);
+	_mix_pool_bytes(&amp;nonblocking_pool, &amp;time, sizeof(time));
 	spin_unlock_irqrestore(&amp;nonblocking_pool.lock, flags);
 }
 EXPORT_SYMBOL(add_device_randomness);
@@ -776,7 +772,7 @@ static void add_timer_randomness(struct timer_rand_state *state, unsigned num)
 	sample.cycles = random_get_entropy();
 	sample.num = num;
 	r = nonblocking_pool.initialized ? &amp;input_pool : &amp;nonblocking_pool;
-	mix_pool_bytes(r, &amp;sample, sizeof(sample), NULL);
+	mix_pool_bytes(r, &amp;sample, sizeof(sample));
 
 	/*
 	 * Calculate number of bits of randomness we probably added.
@@ -864,7 +860,7 @@ void add_interrupt_randomness(int irq, int irq_flags)
 		return;
 	}
 	fast_pool-&gt;last = now;
-	__mix_pool_bytes(r, &amp;fast_pool-&gt;pool, sizeof(fast_pool-&gt;pool), NULL);
+	__mix_pool_bytes(r, &amp;fast_pool-&gt;pool, sizeof(fast_pool-&gt;pool));
 
 	/*
 	 * If we have architectural seed generator, produce a seed and
@@ -872,7 +868,7 @@ void add_interrupt_randomness(int irq, int irq_flags)
 	 * 50% entropic.
 	 */
 	if (arch_get_random_seed_long(&amp;seed)) {
-		__mix_pool_bytes(r, &amp;seed, sizeof(seed), NULL);
+		__mix_pool_bytes(r, &amp;seed, sizeof(seed));
 		credit += sizeof(seed) * 4;
 	}
 	spin_unlock(&amp;r-&gt;lock);
@@ -955,7 +951,7 @@ static void _xfer_secondary_pool(struct entropy_store *r, size_t nbytes)
 				  ENTROPY_BITS(r), ENTROPY_BITS(r-&gt;pull));
 	bytes = extract_entropy(r-&gt;pull, tmp, bytes,
 				random_read_wakeup_bits / 8, rsvd_bytes);
-	mix_pool_bytes(r, tmp, bytes, NULL);
+	mix_pool_bytes(r, tmp, bytes);
 	credit_entropy_bits(r, bytes*8);
 }
 
@@ -1031,7 +1027,6 @@ static void extract_buf(struct entropy_store *r, __u8 *out)
 		unsigned long l[LONGS(20)];
 	} hash;
 	__u32 workspace[SHA_WORKSPACE_WORDS];
-	__u8 extract[64];
 	unsigned long flags;
 
 	/*
@@ -1060,15 +1055,9 @@ static void extract_buf(struct entropy_store *r, __u8 *out)
 	 * brute-forcing the feedback as hard as brute-forcing the
 	 * hash.
 	 */
-	__mix_pool_bytes(r, hash.w, sizeof(hash.w), extract);
+	__mix_pool_bytes(r, hash.w, sizeof(hash.w));
 	spin_unlock_irqrestore(&amp;r-&gt;lock, flags);
 
-	/*
-	 * To avoid duplicates, we atomically extract a portion of the
-	 * pool while mixing, and hash one final time.
-	 */
-	sha_transform(hash.w, extract, workspace);
-	memset(extract, 0, sizeof(extract));
 	memset(workspace, 0, sizeof(workspace));
 
 	/*
@@ -1255,14 +1244,14 @@ static void init_std_data(struct entropy_store *r)
 	unsigned long rv;
 
 	r-&gt;last_pulled = jiffies;
-	mix_pool_bytes(r, &amp;now, sizeof(now), NULL);
+	mix_pool_bytes(r, &amp;now, sizeof(now));
 	for (i = r-&gt;poolinfo-&gt;poolbytes; i &gt; 0; i -= sizeof(rv)) {
 		if (!arch_get_random_seed_long(&amp;rv) &amp;&amp;
 		    !arch_get_random_long(&amp;rv))
 			rv = random_get_entropy();
-		mix_pool_bytes(r, &amp;rv, sizeof(rv), NULL);
+		mix_pool_bytes(r, &amp;rv, sizeof(rv));
 	}
-	mix_pool_bytes(r, utsname(), sizeof(*(utsname())), NULL);
+	mix_pool_bytes(r, utsname(), sizeof(*(utsname())));
 }
 
 /*
@@ -1325,7 +1314,7 @@ static int arch_random_refill(void)
 	if (n) {
 		unsigned int rand_bytes = n * sizeof(unsigned long);
 
-		mix_pool_bytes(&amp;input_pool, buf, rand_bytes, NULL);
+		mix_pool_bytes(&amp;input_pool, buf, rand_bytes);
 		credit_entropy_bits(&amp;input_pool, rand_bytes*4);
 	}
 
@@ -1415,7 +1404,7 @@ write_pool(struct entropy_store *r, const char __user *buffer, size_t count)
 		count -= bytes;
 		p += bytes;
 
-		mix_pool_bytes(r, buf, bytes, NULL);
+		mix_pool_bytes(r, buf, bytes);
 		cond_resched();
 	}
 </pre><hr><pre>commit 91fcb532efe366d79b93a3c8c368b9dca6176a55
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Tue Jun 10 22:46:37 2014 -0400

    random: always update the entropy pool under the spinlock
    
    Instead of using lockless techniques introduced in commit
    902c098a3663, use spin_trylock to try to grab entropy pool's lock.  If
    we can't get the lock, then just try again on the next interrupt.
    
    Based on discussions with George Spelvin.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: George Spelvin &lt;linux@horizon.com&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index 0a7ac0a7b252..922a2e4089f9 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -495,9 +495,8 @@ static void _mix_pool_bytes(struct entropy_store *r, const void *in,
 	tap4 = r-&gt;poolinfo-&gt;tap4;
 	tap5 = r-&gt;poolinfo-&gt;tap5;
 
-	smp_rmb();
-	input_rotate = ACCESS_ONCE(r-&gt;input_rotate);
-	i = ACCESS_ONCE(r-&gt;add_ptr);
+	input_rotate = r-&gt;input_rotate;
+	i = r-&gt;add_ptr;
 
 	/* mix one byte at a time to simplify size handling and churn faster */
 	while (nbytes--) {
@@ -524,9 +523,8 @@ static void _mix_pool_bytes(struct entropy_store *r, const void *in,
 		input_rotate = (input_rotate + (i ? 7 : 14)) &amp; 31;
 	}
 
-	ACCESS_ONCE(r-&gt;input_rotate) = input_rotate;
-	ACCESS_ONCE(r-&gt;add_ptr) = i;
-	smp_wmb();
+	r-&gt;input_rotate = input_rotate;
+	r-&gt;add_ptr = i;
 
 	if (out)
 		for (j = 0; j &lt; 16; j++)
@@ -845,7 +843,7 @@ void add_interrupt_randomness(int irq, int irq_flags)
 	__u32			input[4], c_high, j_high;
 	__u64			ip;
 	unsigned long		seed;
-	int			credit;
+	int			credit = 0;
 
 	c_high = (sizeof(cycles) &gt; 4) ? cycles &gt;&gt; 32 : 0;
 	j_high = (sizeof(now) &gt; 4) ? now &gt;&gt; 32 : 0;
@@ -860,36 +858,40 @@ void add_interrupt_randomness(int irq, int irq_flags)
 	if ((fast_pool-&gt;count &amp; 63) &amp;&amp; !time_after(now, fast_pool-&gt;last + HZ))
 		return;
 
-	fast_pool-&gt;last = now;
-
 	r = nonblocking_pool.initialized ? &amp;input_pool : &amp;nonblocking_pool;
+	if (!spin_trylock(&amp;r-&gt;lock)) {
+		fast_pool-&gt;count--;
+		return;
+	}
+	fast_pool-&gt;last = now;
 	__mix_pool_bytes(r, &amp;fast_pool-&gt;pool, sizeof(fast_pool-&gt;pool), NULL);
 
+	/*
+	 * If we have architectural seed generator, produce a seed and
+	 * add it to the pool.  For the sake of paranoia count it as
+	 * 50% entropic.
+	 */
+	if (arch_get_random_seed_long(&amp;seed)) {
+		__mix_pool_bytes(r, &amp;seed, sizeof(seed), NULL);
+		credit += sizeof(seed) * 4;
+	}
+	spin_unlock(&amp;r-&gt;lock);
+
 	/*
 	 * If we don't have a valid cycle counter, and we see
 	 * back-to-back timer interrupts, then skip giving credit for
 	 * any entropy, otherwise credit 1 bit.
 	 */
-	credit = 1;
+	credit++;
 	if (cycles == 0) {
 		if (irq_flags &amp; __IRQF_TIMER) {
 			if (fast_pool-&gt;last_timer_intr)
-				credit = 0;
+				credit--;
 			fast_pool-&gt;last_timer_intr = 1;
 		} else
 			fast_pool-&gt;last_timer_intr = 0;
 	}
 
-	/*
-	 * If we have architectural seed generator, produce a seed and
-	 * add it to the pool.  For the sake of paranoia count it as
-	 * 50% entropic.
-	 */
-	if (arch_get_random_seed_long(&amp;seed)) {
-		__mix_pool_bytes(r, &amp;seed, sizeof(seed), NULL);
-		credit += sizeof(seed) * 4;
-	}
-
 	credit_entropy_bits(r, credit);
 }
 </pre><hr><pre>commit 3f1f9b851311a76226140b55b1ea22111234a7c2
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sat Jul 12 15:32:24 2014 -0400

    ext4: fix a potential deadlock in __ext4_es_shrink()
    
    This fixes the following lockdep complaint:
    
    [ INFO: possible circular locking dependency detected ]
    3.16.0-rc2-mm1+ #7 Tainted: G           O
    -------------------------------------------------------
    kworker/u24:0/4356 is trying to acquire lock:
     (&amp;(&amp;sbi-&gt;s_es_lru_lock)-&gt;rlock){+.+.-.}, at: [&lt;ffffffff81285fff&gt;] __ext4_es_shrink+0x4f/0x2e0
    
    but task is already holding lock:
     (&amp;ei-&gt;i_es_lock){++++-.}, at: [&lt;ffffffff81286961&gt;] ext4_es_insert_extent+0x71/0x180
    
    which lock already depends on the new lock.
    
     Possible unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&amp;ei-&gt;i_es_lock);
                                   lock(&amp;(&amp;sbi-&gt;s_es_lru_lock)-&gt;rlock);
                                   lock(&amp;ei-&gt;i_es_lock);
      lock(&amp;(&amp;sbi-&gt;s_es_lru_lock)-&gt;rlock);
    
     *** DEADLOCK ***
    
    6 locks held by kworker/u24:0/4356:
     #0:  ("writeback"){.+.+.+}, at: [&lt;ffffffff81071d00&gt;] process_one_work+0x180/0x560
     #1:  ((&amp;(&amp;wb-&gt;dwork)-&gt;work)){+.+.+.}, at: [&lt;ffffffff81071d00&gt;] process_one_work+0x180/0x560
     #2:  (&amp;type-&gt;s_umount_key#22){++++++}, at: [&lt;ffffffff811a9c74&gt;] grab_super_passive+0x44/0x90
     #3:  (jbd2_handle){+.+...}, at: [&lt;ffffffff812979f9&gt;] start_this_handle+0x189/0x5f0
     #4:  (&amp;ei-&gt;i_data_sem){++++..}, at: [&lt;ffffffff81247062&gt;] ext4_map_blocks+0x132/0x550
     #5:  (&amp;ei-&gt;i_es_lock){++++-.}, at: [&lt;ffffffff81286961&gt;] ext4_es_insert_extent+0x71/0x180
    
    stack backtrace:
    CPU: 0 PID: 4356 Comm: kworker/u24:0 Tainted: G           O   3.16.0-rc2-mm1+ #7
    Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
    Workqueue: writeback bdi_writeback_workfn (flush-253:0)
     ffffffff8213dce0 ffff880014b07538 ffffffff815df0bb 0000000000000007
     ffffffff8213e040 ffff880014b07588 ffffffff815db3dd ffff880014b07568
     ffff880014b07610 ffff88003b868930 ffff88003b868908 ffff88003b868930
    Call Trace:
     [&lt;ffffffff815df0bb&gt;] dump_stack+0x4e/0x68
     [&lt;ffffffff815db3dd&gt;] print_circular_bug+0x1fb/0x20c
     [&lt;ffffffff810a7a3e&gt;] __lock_acquire+0x163e/0x1d00
     [&lt;ffffffff815e89dc&gt;] ? retint_restore_args+0xe/0xe
     [&lt;ffffffff815ddc7b&gt;] ? __slab_alloc+0x4a8/0x4ce
     [&lt;ffffffff81285fff&gt;] ? __ext4_es_shrink+0x4f/0x2e0
     [&lt;ffffffff810a8707&gt;] lock_acquire+0x87/0x120
     [&lt;ffffffff81285fff&gt;] ? __ext4_es_shrink+0x4f/0x2e0
     [&lt;ffffffff8128592d&gt;] ? ext4_es_free_extent+0x5d/0x70
     [&lt;ffffffff815e6f09&gt;] _raw_spin_lock+0x39/0x50
     [&lt;ffffffff81285fff&gt;] ? __ext4_es_shrink+0x4f/0x2e0
     [&lt;ffffffff8119760b&gt;] ? kmem_cache_alloc+0x18b/0x1a0
     [&lt;ffffffff81285fff&gt;] __ext4_es_shrink+0x4f/0x2e0
     [&lt;ffffffff812869b8&gt;] ext4_es_insert_extent+0xc8/0x180
     [&lt;ffffffff812470f4&gt;] ext4_map_blocks+0x1c4/0x550
     [&lt;ffffffff8124c4c4&gt;] ext4_writepages+0x6d4/0xd00
            ...
    
    Reported-by: Minchan Kim &lt;minchan@kernel.org&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Reported-by: Minchan Kim &lt;minchan@kernel.org&gt;
    Cc: stable@vger.kernel.org
    Cc: Zheng Liu &lt;gnehzuil.liu@gmail.com&gt;

diff --git a/fs/ext4/extents_status.c b/fs/ext4/extents_status.c
index 3f5c188953a4..0b7e28e7eaa4 100644
--- a/fs/ext4/extents_status.c
+++ b/fs/ext4/extents_status.c
@@ -966,10 +966,10 @@ static int __ext4_es_shrink(struct ext4_sb_info *sbi, int nr_to_scan,
 			continue;
 		}
 
-		if (ei-&gt;i_es_lru_nr == 0 || ei == locked_ei)
+		if (ei-&gt;i_es_lru_nr == 0 || ei == locked_ei ||
+		    !write_trylock(&amp;ei-&gt;i_es_lock))
 			continue;
 
-		write_lock(&amp;ei-&gt;i_es_lock);
 		shrunk = __es_try_to_reclaim_extents(ei, nr_to_scan);
 		if (ei-&gt;i_es_lru_nr == 0)
 			list_del_init(&amp;ei-&gt;i_es_lru);</pre><hr><pre>commit f9ae9cf5d72b3926ca48ea60e15bdbb840f42372
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri Jul 11 13:55:40 2014 -0400

    ext4: revert commit which was causing fs corruption after journal replays
    
    Commit 007649375f6af2 ("ext4: initialize multi-block allocator before
    checking block descriptors") causes the block group descriptor's count
    of the number of free blocks to become inconsistent with the number of
    free blocks in the allocation bitmap.  This is a harmless form of fs
    corruption, but it causes the kernel to potentially remount the file
    system read-only, or to panic, depending on the file systems's error
    behavior.
    
    Thanks to Eric Whitney for his tireless work to reproduce and to find
    the guilty commit.
    
    Fixes: 007649375f6af2 ("ext4: initialize multi-block allocator before checking block descriptors"
    
    Cc: stable@vger.kernel.org  # 3.15
    Reported-by: David Jander &lt;david@protonic.nl&gt;
    Reported-by: Matteo Croce &lt;technoboy85@gmail.com&gt;
    Tested-by: Eric Whitney &lt;enwlinux@gmail.com&gt;
    Suggested-by: Eric Whitney &lt;enwlinux@gmail.com&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;

diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 6297c07c937f..6df7bc611dbd 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -3879,38 +3879,19 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 			goto failed_mount2;
 		}
 	}
-
-	/*
-	 * set up enough so that it can read an inode,
-	 * and create new inode for buddy allocator
-	 */
-	sbi-&gt;s_gdb_count = db_count;
-	if (!test_opt(sb, NOLOAD) &amp;&amp;
-	    EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL))
-		sb-&gt;s_op = &amp;ext4_sops;
-	else
-		sb-&gt;s_op = &amp;ext4_nojournal_sops;
-
-	ext4_ext_init(sb);
-	err = ext4_mb_init(sb);
-	if (err) {
-		ext4_msg(sb, KERN_ERR, "failed to initialize mballoc (%d)",
-			 err);
-		goto failed_mount2;
-	}
-
 	if (!ext4_check_descriptors(sb, &amp;first_not_zeroed)) {
 		ext4_msg(sb, KERN_ERR, "group descriptors corrupted!");
-		goto failed_mount2a;
+		goto failed_mount2;
 	}
 	if (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_FLEX_BG))
 		if (!ext4_fill_flex_info(sb)) {
 			ext4_msg(sb, KERN_ERR,
 			       "unable to initialize "
 			       "flex_bg meta info!");
-			goto failed_mount2a;
+			goto failed_mount2;
 		}
 
+	sbi-&gt;s_gdb_count = db_count;
 	get_random_bytes(&amp;sbi-&gt;s_next_generation, sizeof(u32));
 	spin_lock_init(&amp;sbi-&gt;s_next_gen_lock);
 
@@ -3945,6 +3926,14 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	sbi-&gt;s_stripe = ext4_get_stripe_size(sbi);
 	sbi-&gt;s_extent_max_zeroout_kb = 32;
 
+	/*
+	 * set up enough so that it can read an inode
+	 */
+	if (!test_opt(sb, NOLOAD) &amp;&amp;
+	    EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL))
+		sb-&gt;s_op = &amp;ext4_sops;
+	else
+		sb-&gt;s_op = &amp;ext4_nojournal_sops;
 	sb-&gt;s_export_op = &amp;ext4_export_ops;
 	sb-&gt;s_xattr = ext4_xattr_handlers;
 #ifdef CONFIG_QUOTA
@@ -4134,13 +4123,21 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	if (err) {
 		ext4_msg(sb, KERN_ERR, "failed to reserve %llu clusters for "
 			 "reserved pool", ext4_calculate_resv_clusters(sb));
-		goto failed_mount5;
+		goto failed_mount4a;
 	}
 
 	err = ext4_setup_system_zone(sb);
 	if (err) {
 		ext4_msg(sb, KERN_ERR, "failed to initialize system "
 			 "zone (%d)", err);
+		goto failed_mount4a;
+	}
+
+	ext4_ext_init(sb);
+	err = ext4_mb_init(sb);
+	if (err) {
+		ext4_msg(sb, KERN_ERR, "failed to initialize mballoc (%d)",
+			 err);
 		goto failed_mount5;
 	}
 
@@ -4217,8 +4214,11 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 failed_mount7:
 	ext4_unregister_li_request(sb);
 failed_mount6:
-	ext4_release_system_zone(sb);
+	ext4_mb_release(sb);
 failed_mount5:
+	ext4_ext_release(sb);
+	ext4_release_system_zone(sb);
+failed_mount4a:
 	dput(sb-&gt;s_root);
 	sb-&gt;s_root = NULL;
 failed_mount4:
@@ -4242,14 +4242,11 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	percpu_counter_destroy(&amp;sbi-&gt;s_extent_cache_cnt);
 	if (sbi-&gt;s_mmp_tsk)
 		kthread_stop(sbi-&gt;s_mmp_tsk);
-failed_mount2a:
-	ext4_mb_release(sb);
 failed_mount2:
 	for (i = 0; i &lt; db_count; i++)
 		brelse(sbi-&gt;s_group_desc[i]);
 	ext4_kvfree(sbi-&gt;s_group_desc);
 failed_mount:
-	ext4_ext_release(sb);
 	if (sbi-&gt;s_chksum_driver)
 		crypto_free_shash(sbi-&gt;s_chksum_driver);
 	if (sbi-&gt;s_proc) {</pre><hr><pre>commit 94d4c066a4ff170a2671b1a9b153febbf36796f6
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sat Jul 5 19:15:50 2014 -0400

    ext4: clarify ext4_error message in ext4_mb_generate_buddy_error()
    
    We are spending a lot of time explaining to users what this error
    means.  Let's try to improve the message to avoid this problem.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c
index 7f72f50a8fa7..2dcb936be90e 100644
--- a/fs/ext4/mballoc.c
+++ b/fs/ext4/mballoc.c
@@ -752,8 +752,8 @@ void ext4_mb_generate_buddy(struct super_block *sb,
 
 	if (free != grp-&gt;bb_free) {
 		ext4_grp_locked_error(sb, group, 0, 0,
-				      "%u clusters in bitmap, %u in gd; "
-				      "block bitmap corrupt.",
+				      "block bitmap and bg descriptor "
+				      "inconsistent: %u vs %u free clusters",
 				      free, grp-&gt;bb_free);
 		/*
 		 * If we intend to continue, we consider group descriptor</pre><hr><pre>commit ae0f78de2c43b6fadd007c231a352b13b5be8ed2
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sat Jul 5 18:40:52 2014 -0400

    ext4: clarify error count warning messages
    
    Make it clear that values printed are times, and that it is error
    since last fsck. Also add note about fsck version required.
    
    Signed-off-by: Pavel Machek &lt;pavel@ucw.cz&gt;
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Reviewed-by: Andreas Dilger &lt;adilger@dilger.ca&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index b9b9aabfb4d2..342394772b6c 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -2809,10 +2809,11 @@ static void print_daily_error_info(unsigned long arg)
 	es = sbi-&gt;s_es;
 
 	if (es-&gt;s_error_count)
-		ext4_msg(sb, KERN_NOTICE, "error count: %u",
+		/* fsck newer than v1.41.13 is needed to clean this condition. */
+		ext4_msg(sb, KERN_NOTICE, "error count since last fsck: %u",
 			 le32_to_cpu(es-&gt;s_error_count));
 	if (es-&gt;s_first_error_time) {
-		printk(KERN_NOTICE "EXT4-fs (%s): initial error at %u: %.*s:%d",
+		printk(KERN_NOTICE "EXT4-fs (%s): initial error at time %u: %.*s:%d",
 		       sb-&gt;s_id, le32_to_cpu(es-&gt;s_first_error_time),
 		       (int) sizeof(es-&gt;s_first_error_func),
 		       es-&gt;s_first_error_func,
@@ -2826,7 +2827,7 @@ static void print_daily_error_info(unsigned long arg)
 		printk("\n");
 	}
 	if (es-&gt;s_last_error_time) {
-		printk(KERN_NOTICE "EXT4-fs (%s): last error at %u: %.*s:%d",
+		printk(KERN_NOTICE "EXT4-fs (%s): last error at time %u: %.*s:%d",
 		       sb-&gt;s_id, le32_to_cpu(es-&gt;s_last_error_time),
 		       (int) sizeof(es-&gt;s_last_error_func),
 		       es-&gt;s_last_error_func,</pre><hr><pre>commit 61c219f5814277ecb71d64cb30297028d6665979
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sat Jul 5 16:28:35 2014 -0400

    ext4: fix unjournalled bg descriptor while initializing inode bitmap
    
    The first time that we allocate from an uninitialized inode allocation
    bitmap, if the block allocation bitmap is also uninitalized, we need
    to get write access to the block group descriptor before we start
    modifying the block group descriptor flags and updating the free block
    count, etc.  Otherwise, there is the potential of a bad journal
    checksum (if journal checksums are enabled), and of the file system
    becoming inconsistent if we crash at exactly the wrong time.
    
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: stable@vger.kernel.org

diff --git a/fs/ext4/ialloc.c b/fs/ext4/ialloc.c
index a87455df38bc..0840bf321cdb 100644
--- a/fs/ext4/ialloc.c
+++ b/fs/ext4/ialloc.c
@@ -874,6 +874,13 @@ struct inode *__ext4_new_inode(handle_t *handle, struct inode *dir,
 		goto out;
 	}
 
+	BUFFER_TRACE(group_desc_bh, "get_write_access");
+	err = ext4_journal_get_write_access(handle, group_desc_bh);
+	if (err) {
+		ext4_std_error(sb, err);
+		goto out;
+	}
+
 	/* We may have to initialize the block bitmap if it isn't already */
 	if (ext4_has_group_desc_csum(sb) &amp;&amp;
 	    gdp-&gt;bg_flags &amp; cpu_to_le16(EXT4_BG_BLOCK_UNINIT)) {
@@ -910,13 +917,6 @@ struct inode *__ext4_new_inode(handle_t *handle, struct inode *dir,
 		}
 	}
 
-	BUFFER_TRACE(group_desc_bh, "get_write_access");
-	err = ext4_journal_get_write_access(handle, group_desc_bh);
-	if (err) {
-		ext4_std_error(sb, err);
-		goto out;
-	}
-
 	/* Update the relevant bg descriptor fields */
 	if (ext4_has_group_desc_csum(sb)) {
 		int free;</pre><hr><pre>commit e33ba5fa7afce1a9f159704121d4e4d110df8185
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Sun Jun 15 21:04:32 2014 -0400

    random: fix nasty entropy accounting bug
    
    Commit 0fb7a01af5b0 "random: simplify accounting code", introduced in
    v3.15, has a very nasty accounting problem when the entropy pool has
    has fewer bytes of entropy than the number of requested reserved
    bytes.  In that case, "have_bytes - reserved" goes negative, and since
    size_t is unsigned, the expression:
    
           ibytes = min_t(size_t, ibytes, have_bytes - reserved);
    
    ... does not do the right thing.  This is rather bad, because it
    defeats the catastrophic reseeding feature in the
    xfer_secondary_pool() path.
    
    It also can cause the "BUG: spinlock trylock failure on UP" for some
    kernel configurations when prandom_reseed() calls get_random_bytes()
    in the early init, since when the entropy count gets corrupted,
    credit_entropy_bits() erroneously believes that the nonblocking pool
    has been fully initialized (when in fact it is not), and so it calls
    prandom_reseed(true) recursively leading to the spinlock BUG.
    
    The logic is *not* the same it was originally, but in the cases where
    it matters, the behavior is the same, and the resulting code is
    hopefully easier to read and understand.
    
    Fixes: 0fb7a01af5b0 "random: simplify accounting code"
    Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu&gt;
    Cc: Greg Price &lt;price@mit.edu&gt;
    Cc: stable@vger.kernel.org  #v3.15

diff --git a/drivers/char/random.c b/drivers/char/random.c
index 102c50d38902..2b6e4cd8de8e 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -979,7 +979,6 @@ static void push_to_pool(struct work_struct *work)
 static size_t account(struct entropy_store *r, size_t nbytes, int min,
 		      int reserved)
 {
-	int have_bytes;
 	int entropy_count, orig;
 	size_t ibytes;
 
@@ -988,17 +987,19 @@ static size_t account(struct entropy_store *r, size_t nbytes, int min,
 	/* Can we pull enough? */
 retry:
 	entropy_count = orig = ACCESS_ONCE(r-&gt;entropy_count);
-	have_bytes = entropy_count &gt;&gt; (ENTROPY_SHIFT + 3);
 	ibytes = nbytes;
 	/* If limited, never pull more than available */
-	if (r-&gt;limit)
-		ibytes = min_t(size_t, ibytes, have_bytes - reserved);
+	if (r-&gt;limit) {
+		int have_bytes = entropy_count &gt;&gt; (ENTROPY_SHIFT + 3);
+
+		if ((have_bytes -= reserved) &lt; 0)
+			have_bytes = 0;
+		ibytes = min_t(size_t, ibytes, have_bytes);
+	}
 	if (ibytes &lt; min)
 		ibytes = 0;
-	if (have_bytes &gt;= ibytes + reserved)
-		entropy_count -= ibytes &lt;&lt; (ENTROPY_SHIFT + 3);
-	else
-		entropy_count = reserved &lt;&lt; (ENTROPY_SHIFT + 3);
+	if ((entropy_count -= ibytes &lt;&lt; (ENTROPY_SHIFT + 3)) &lt; 0)
+		entropy_count = 0;
 
 	if (cmpxchg(&amp;r-&gt;entropy_count, orig, entropy_count) != orig)
 		goto retry;</pre><hr><pre>commit f9c6d4987b23e0a514464bae6771933a48e4cd01
Author: Theodore Ts'o &lt;tytso@mit.edu&gt;
Date:   Fri May 16 21:40:41 2014 -0400

    random: fix BUG_ON caused by accounting simplification
    
    Commit ee1de406ba6eb1 ("random: simplify accounting logic") simplified
    things too much, in that it allows the following to trigger an
    overflow that results in a BUG_ON crash:
    
    dd if=/dev/urandom of=/dev/zero bs=67108707 count=1
    
    Thanks to Peter Zihlstra for discovering the crash, and Hannes
    Frederic for analyizing the root cause.
    
    Signed-off-by: "Theodore Ts'o" &lt;tytso@mit.edu&gt;
    Reported-by: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Reported-by: Hannes Frederic Sowa &lt;hannes@stressinduktion.org&gt;
    Cc: Greg Price &lt;price@mit.edu&gt;

diff --git a/drivers/char/random.c b/drivers/char/random.c
index 6b75713d953a..102c50d38902 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -995,8 +995,11 @@ static size_t account(struct entropy_store *r, size_t nbytes, int min,
 		ibytes = min_t(size_t, ibytes, have_bytes - reserved);
 	if (ibytes &lt; min)
 		ibytes = 0;
-	entropy_count = max_t(int, 0,
-			      entropy_count - (ibytes &lt;&lt; (ENTROPY_SHIFT + 3)));
+	if (have_bytes &gt;= ibytes + reserved)
+		entropy_count -= ibytes &lt;&lt; (ENTROPY_SHIFT + 3);
+	else
+		entropy_count = reserved &lt;&lt; (ENTROPY_SHIFT + 3);
+
 	if (cmpxchg(&amp;r-&gt;entropy_count, orig, entropy_count) != orig)
 		goto retry;
 </pre>
    <div class="pagination">
        <a href='1_39.html'>&lt;&lt;Prev</a><a href='1.html'>1</a><a href='1_2.html'>2</a><a href='1_3.html'>3</a><a href='1_4.html'>4</a><a href='1_5.html'>5</a><a href='1_6.html'>6</a><a href='1_7.html'>7</a><a href='1_8.html'>8</a><a href='1_9.html'>9</a><a href='1_10.html'>10</a><a href='1_11.html'>11</a><a href='1_12.html'>12</a><a href='1_13.html'>13</a><a href='1_14.html'>14</a><a href='1_15.html'>15</a><a href='1_16.html'>16</a><a href='1_17.html'>17</a><a href='1_18.html'>18</a><a href='1_19.html'>19</a><a href='1_20.html'>20</a><a href='1_21.html'>21</a><a href='1_22.html'>22</a><a href='1_23.html'>23</a><a href='1_24.html'>24</a><a href='1_25.html'>25</a><a href='1_26.html'>26</a><a href='1_27.html'>27</a><a href='1_28.html'>28</a><a href='1_29.html'>29</a><a href='1_30.html'>30</a><a href='1_31.html'>31</a><a href='1_32.html'>32</a><a href='1_33.html'>33</a><a href='1_34.html'>34</a><a href='1_35.html'>35</a><a href='1_36.html'>36</a><a href='1_37.html'>37</a><a href='1_38.html'>38</a><a href='1_39.html'>39</a><span>[40]</span><a href='1_41.html'>41</a><a href='1_42.html'>42</a><a href='1_43.html'>43</a><a href='1_44.html'>44</a><a href='1_45.html'>45</a><a href='1_46.html'>46</a><a href='1_47.html'>47</a><a href='1_48.html'>48</a><a href='1_49.html'>49</a><a href='1_50.html'>50</a><a href='1_51.html'>51</a><a href='1_52.html'>52</a><a href='1_53.html'>53</a><a href='1_54.html'>54</a><a href='1_55.html'>55</a><a href='1_56.html'>56</a><a href='1_57.html'>57</a><a href='1_58.html'>58</a><a href='1_59.html'>59</a><a href='1_60.html'>60</a><a href='1_61.html'>61</a><a href='1_62.html'>62</a><a href='1_63.html'>63</a><a href='1_64.html'>64</a><a href='1_65.html'>65</a><a href='1_66.html'>66</a><a href='1_67.html'>67</a><a href='1_68.html'>68</a><a href='1_69.html'>69</a><a href='1_70.html'>70</a><a href='1_71.html'>71</a><a href='1_72.html'>72</a><a href='1_73.html'>73</a><a href='1_74.html'>74</a><a href='1_75.html'>75</a><a href='1_76.html'>76</a><a href='1_77.html'>77</a><a href='1_78.html'>78</a><a href='1_79.html'>79</a><a href='1_80.html'>80</a><a href='1_81.html'>81</a><a href='1_82.html'>82</a><a href='1_83.html'>83</a><a href='1_84.html'>84</a><a href='1_85.html'>85</a><a href='1_86.html'>86</a><a href='1_87.html'>87</a><a href='1_88.html'>88</a><a href='1_89.html'>89</a><a href='1_90.html'>90</a><a href='1_91.html'>91</a><a href='1_92.html'>92</a><a href='1_93.html'>93</a><a href='1_94.html'>94</a><a href='1_95.html'>95</a><a href='1_96.html'>96</a><a href='1_97.html'>97</a><a href='1_98.html'>98</a><a href='1_99.html'>99</a><a href='1_100.html'>100</a><a href='1_101.html'>101</a><a href='1_102.html'>102</a><a href='1_103.html'>103</a><a href='1_104.html'>104</a><a href='1_105.html'>105</a><a href='1_106.html'>106</a><a href='1_107.html'>107</a><a href='1_108.html'>108</a><a href='1_109.html'>109</a><a href='1_110.html'>110</a><a href='1_111.html'>111</a><a href='1_112.html'>112</a><a href='1_113.html'>113</a><a href='1_114.html'>114</a><a href='1_115.html'>115</a><a href='1_116.html'>116</a><a href='1_117.html'>117</a><a href='1_118.html'>118</a><a href='1_119.html'>119</a><a href='1_120.html'>120</a><a href='1_121.html'>121</a><a href='1_122.html'>122</a><a href='1_123.html'>123</a><a href='1_124.html'>124</a><a href='1_125.html'>125</a><a href='1_126.html'>126</a><a href='1_127.html'>127</a><a href='1_128.html'>128</a><a href='1_129.html'>129</a><a href='1_130.html'>130</a><a href='1_131.html'>131</a><a href='1_132.html'>132</a><a href='1_133.html'>133</a><a href='1_134.html'>134</a><a href='1_135.html'>135</a><a href='1_136.html'>136</a><a href='1_137.html'>137</a><a href='1_138.html'>138</a><a href='1_139.html'>139</a><a href='1_140.html'>140</a><a href='1_141.html'>141</a><a href='1_142.html'>142</a><a href='1_143.html'>143</a><a href='1_144.html'>144</a><a href='1_145.html'>145</a><a href='1_146.html'>146</a><a href='1_147.html'>147</a><a href='1_148.html'>148</a><a href='1_149.html'>149</a><a href='1_150.html'>150</a><a href='1_151.html'>151</a><a href='1_152.html'>152</a><a href='1_153.html'>153</a><a href='1_154.html'>154</a><a href='1_41.html'>Next&gt;&gt;</a>
    <div>
</body>
